{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2625c700cd0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6614,  0.2669,  0.0617,  0.6213, -0.4519]],\n",
      "       grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "word_to_ix = {\"hello\": 0, \"world\": 1}\n",
    "embeds = nn.Embedding(2, 5)  # 2 words in vocab, 5 dimensional embeddings\n",
    "lookup_tensor = torch.tensor([word_to_ix[\"hello\"]], dtype=torch.long)\n",
    "hello_embed = embeds(lookup_tensor)\n",
    "print(hello_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['forty', 'When'], 'winters'), (['winters', 'forty'], 'shall'), (['shall', 'winters'], 'besiege')]\n"
     ]
    }
   ],
   "source": [
    "CONTEXT_SIZE = 2\n",
    "EMBEDDING_DIM = 10\n",
    "# We will use Shakespeare Sonnet 2\n",
    "test_sentence = \"\"\"When forty winters shall besiege thy brow,\n",
    "And dig deep trenches in thy beauty's field,\n",
    "Thy youth's proud livery so gazed on now,\n",
    "Will be a totter'd weed of small worth held:\n",
    "Then being asked, where all thy beauty lies,\n",
    "Where all the treasure of thy lusty days;\n",
    "To say, within thine own deep sunken eyes,\n",
    "Were an all-eating shame, and thriftless praise.\n",
    "How much more praise deserv'd thy beauty's use,\n",
    "If thou couldst answer 'This fair child of mine\n",
    "Shall sum my count, and make my old excuse,'\n",
    "Proving his beauty by succession thine!\n",
    "This were to be new made when thou art old,\n",
    "And see thy blood warm when thou feel'st it cold.\"\"\".split()\n",
    "# we should tokenize the input, but we will ignore that for now\n",
    "# build a list of tuples.\n",
    "# Each tuple is ([ word_i-CONTEXT_SIZE, ..., word_i-1 ], target word)\n",
    "ngrams = [\n",
    "    (\n",
    "        [test_sentence[i - j - 1] for j in range(CONTEXT_SIZE)],\n",
    "        test_sentence[i]\n",
    "    )\n",
    "    for i in range(CONTEXT_SIZE, len(test_sentence))\n",
    "]\n",
    "# Print the first 3, just so you can see what they look like.\n",
    "print(ngrams[:3])\n",
    "\n",
    "vocab = set(test_sentence)\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4198, -4.0783, -4.7874, -4.8897, -4.0923, -5.0492, -4.5195, -4.4847,\n",
      "         -4.8235, -4.4609, -4.7630, -4.5476, -4.6811, -4.7654, -5.0643, -4.7324,\n",
      "         -4.5814, -4.1848, -4.8280, -4.4023, -4.7455, -4.3362, -4.7263, -4.8628,\n",
      "         -4.3984, -4.7615, -4.4350, -4.2321, -4.2178, -4.4724, -4.3562, -4.5951,\n",
      "         -4.7008, -4.7020, -4.5191, -4.5236, -4.6918, -4.7598, -4.7326, -4.7027,\n",
      "         -4.6900, -4.5302, -4.5079, -4.3595, -4.4304, -4.2689, -4.4659, -4.7245,\n",
      "         -4.7363, -5.0334, -4.5351, -4.5905, -4.6966, -4.5326, -4.3569, -4.7695,\n",
      "         -4.4256, -4.5159, -4.3019, -4.6803, -4.8774, -4.4400, -4.6056, -4.4515,\n",
      "         -4.5509, -4.9959, -4.6232, -4.2461, -4.5705, -4.4081, -4.6676, -4.6423,\n",
      "         -4.9145, -5.0592, -4.9387, -4.8583, -4.5148, -4.5656, -4.6878, -4.7331,\n",
      "         -4.3151, -4.4570, -4.6073, -4.6535, -4.9076, -4.2625, -4.7891, -4.5447,\n",
      "         -4.8102, -4.4328, -4.6118, -4.5038, -4.7547, -4.4954, -4.4328, -4.6684,\n",
      "         -4.5858]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : winters\n",
      "target index is: [3] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2681, -4.6663, -4.4051, -4.6379, -4.2065, -4.5846, -4.5529, -4.2479,\n",
      "         -4.7425, -4.9144, -4.9811, -4.7888, -4.5692, -4.2781, -4.5601, -4.3676,\n",
      "         -4.1064, -4.6556, -4.6395, -4.8622, -4.8462, -4.6365, -4.7776, -4.5788,\n",
      "         -4.4176, -4.8902, -4.4586, -4.4679, -4.3548, -4.5637, -4.2762, -5.0422,\n",
      "         -4.9036, -4.5998, -4.9134, -4.8835, -4.5681, -4.7065, -5.0312, -4.6631,\n",
      "         -4.9262, -4.3802, -4.8528, -4.3581, -5.1382, -4.3509, -5.1059, -5.1592,\n",
      "         -4.9145, -4.2731, -4.6264, -4.3916, -4.8357, -4.1096, -4.9534, -4.1528,\n",
      "         -4.2435, -4.1843, -4.8453, -4.4063, -4.2764, -4.6408, -4.4401, -4.1017,\n",
      "         -4.5513, -3.9562, -5.3843, -4.4774, -4.8463, -4.6565, -4.5535, -4.2256,\n",
      "         -4.9473, -4.8809, -4.5800, -5.1501, -4.9096, -4.1376, -4.7601, -4.8118,\n",
      "         -4.3741, -4.5645, -4.7021, -5.0813, -4.7328, -4.4082, -4.6799, -4.6339,\n",
      "         -5.0865, -4.3854, -4.4249, -4.7015, -4.6699, -4.6627, -4.3982, -4.7559,\n",
      "         -4.3574]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : shall\n",
      "target index is: [10] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5705, -4.3241, -5.0809, -4.8661, -4.2142, -4.7629, -4.4292, -4.6704,\n",
      "         -4.7629, -4.4446, -4.7049, -4.3828, -4.8176, -4.6914, -5.0557, -4.5246,\n",
      "         -4.7241, -4.5963, -4.6669, -4.5098, -4.4996, -3.9725, -4.6998, -4.4898,\n",
      "         -4.2310, -4.7803, -4.5838, -4.5952, -4.4300, -4.6179, -4.8523, -4.6672,\n",
      "         -4.6324, -4.7808, -4.6822, -4.4565, -4.9286, -4.5176, -5.0157, -4.3936,\n",
      "         -4.9220, -4.6980, -4.6857, -4.7190, -4.3983, -4.4504, -4.6437, -4.6388,\n",
      "         -4.4022, -5.0859, -4.4749, -4.7349, -4.6170, -4.3026, -4.5056, -4.5112,\n",
      "         -4.6489, -4.5630, -4.2357, -4.5614, -4.7941, -4.4516, -4.2395, -4.0961,\n",
      "         -4.4596, -4.7806, -4.6495, -4.5463, -4.6435, -4.1857, -4.3723, -4.6837,\n",
      "         -4.5438, -4.6875, -4.9215, -4.8193, -4.0786, -4.7440, -4.8855, -4.6891,\n",
      "         -4.4401, -4.4889, -4.9160, -4.5997, -4.6061, -4.4560, -4.8538, -4.9382,\n",
      "         -4.7735, -4.3010, -4.6886, -4.9037, -4.5914, -4.2119, -4.6015, -4.7975,\n",
      "         -4.3794]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : besiege\n",
      "target index is: [75] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3781, -4.5098, -4.3948, -4.7754, -4.0672, -4.7766, -4.6107, -4.2641,\n",
      "         -4.6821, -4.6976, -4.9429, -4.7079, -4.6530, -4.5460, -5.0387, -4.6749,\n",
      "         -4.5870, -4.4372, -4.8341, -4.5959, -4.5664, -4.8620, -4.6296, -4.5733,\n",
      "         -4.3891, -4.7438, -4.6735, -4.5806, -4.2475, -4.3556, -4.4816, -4.6108,\n",
      "         -4.7599, -4.6690, -4.8600, -4.7738, -4.6170, -4.6678, -4.6783, -4.4719,\n",
      "         -4.4839, -4.6784, -4.7560, -4.1418, -4.5176, -4.4716, -4.3517, -4.3881,\n",
      "         -4.5582, -4.5907, -4.5924, -4.3270, -4.8088, -4.3631, -4.7351, -4.5436,\n",
      "         -4.5195, -4.5149, -4.4611, -4.6765, -5.0573, -4.4684, -4.5683, -3.7750,\n",
      "         -4.6810, -4.4425, -4.8296, -4.6362, -4.5665, -4.7369, -4.5566, -4.5210,\n",
      "         -4.7888, -4.9446, -4.7698, -4.7340, -4.7501, -4.2553, -4.8892, -4.8660,\n",
      "         -4.6899, -4.5092, -4.6143, -4.9484, -4.7016, -4.2635, -4.3418, -4.7868,\n",
      "         -5.3112, -4.1603, -4.7121, -4.6746, -4.5294, -4.5774, -4.3319, -4.5746,\n",
      "         -4.8109]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3009, -4.5378, -4.7213, -4.9110, -4.0253, -4.6650, -4.8238, -4.3476,\n",
      "         -5.2649, -4.3142, -4.8685, -4.1206, -4.8656, -4.6860, -4.6756, -4.9638,\n",
      "         -4.9107, -4.5899, -4.4696, -4.5155, -4.4679, -4.4699, -4.8407, -4.5258,\n",
      "         -4.8864, -4.8537, -4.1144, -4.5709, -4.5948, -4.5617, -4.6877, -4.8865,\n",
      "         -4.8661, -4.5312, -4.5339, -5.1614, -4.5608, -4.9822, -4.8453, -4.6732,\n",
      "         -4.8329, -4.9488, -4.8507, -4.5614, -4.6517, -4.3062, -4.8313, -4.7862,\n",
      "         -4.7571, -4.7017, -4.3682, -5.0695, -4.4060, -4.3793, -5.0111, -4.2246,\n",
      "         -4.7854, -4.4938, -4.4841, -4.2305, -4.3122, -4.5020, -4.6416, -3.8502,\n",
      "         -4.2965, -4.6805, -5.0805, -4.5590, -4.6874, -4.7137, -4.2888, -4.7205,\n",
      "         -5.1892, -4.7616, -4.4242, -4.9230, -4.3715, -4.2316, -4.5304, -4.5287,\n",
      "         -4.7346, -4.2642, -4.9734, -4.9553, -4.6493, -4.4324, -4.4133, -4.5040,\n",
      "         -4.8358, -4.5586, -4.0891, -4.3875, -4.6112, -4.4356, -4.1438, -4.6683,\n",
      "         -4.5609]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : brow,\n",
      "target index is: [13] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4374, -4.3001, -4.6713, -4.6229, -4.2775, -4.8555, -4.8166, -4.4167,\n",
      "         -4.6887, -4.7496, -4.8761, -4.5420, -4.8092, -4.3919, -4.7588, -4.8849,\n",
      "         -4.6481, -4.7140, -4.5031, -4.4854, -4.7923, -4.9236, -4.8064, -4.3185,\n",
      "         -4.6034, -4.8080, -4.7073, -4.2542, -4.0985, -4.3550, -4.2366, -4.7439,\n",
      "         -4.9152, -4.5346, -4.9091, -5.0225, -4.5231, -4.8926, -4.3514, -4.3400,\n",
      "         -4.7331, -4.5927, -4.4618, -4.1277, -4.6384, -4.1367, -4.7099, -4.8190,\n",
      "         -4.6189, -4.8238, -4.8706, -4.4685, -4.9158, -4.0987, -4.5906, -4.3914,\n",
      "         -4.3844, -4.1187, -4.7185, -4.6336, -4.8677, -4.4171, -4.5264, -4.1100,\n",
      "         -4.7524, -4.5623, -5.0838, -4.5336, -4.6104, -4.4301, -4.3703, -4.4940,\n",
      "         -4.8234, -4.9363, -4.8111, -5.0209, -5.1037, -3.9059, -4.9693, -5.0148,\n",
      "         -5.0081, -4.5367, -4.7374, -5.1043, -4.9894, -4.4058, -4.3722, -4.5380,\n",
      "         -4.9149, -3.9670, -4.8961, -4.5754, -4.6861, -4.5562, -4.2833, -4.8267,\n",
      "         -4.2864]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : And\n",
      "target index is: [6] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4363, -4.3410, -4.6117, -4.7676, -4.1927, -4.8223, -4.7341, -4.4513,\n",
      "         -4.8400, -4.5731, -4.4580, -4.3351, -4.9182, -5.0279, -4.3794, -4.8389,\n",
      "         -4.8575, -4.9794, -4.4653, -4.4795, -4.3989, -4.3411, -4.7523, -4.6290,\n",
      "         -4.6421, -4.6922, -4.3101, -4.4051, -4.3548, -4.9207, -4.5615, -5.2206,\n",
      "         -4.7411, -4.6026, -4.4436, -4.8131, -4.6803, -4.8933, -4.7953, -4.6078,\n",
      "         -4.7944, -4.9490, -4.9225, -4.7309, -4.7192, -4.4740, -4.5106, -4.6023,\n",
      "         -4.4577, -4.9942, -4.5166, -4.6508, -4.4659, -4.6968, -5.1590, -4.5710,\n",
      "         -4.5351, -4.4936, -4.4768, -4.5679, -4.6115, -4.6403, -4.8632, -4.1533,\n",
      "         -4.9383, -4.6468, -4.9697, -4.5598, -4.6076, -4.6824, -4.0758, -4.7742,\n",
      "         -5.0825, -4.6287, -4.2312, -4.8048, -4.7758, -4.3237, -4.8158, -4.2113,\n",
      "         -4.6083, -4.0135, -4.9448, -4.6973, -4.3672, -4.4612, -4.5102, -4.5093,\n",
      "         -4.7841, -4.3003, -4.6131, -4.5193, -4.2715, -4.0804, -4.1253, -4.4173,\n",
      "         -4.5056]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : dig\n",
      "target index is: [42] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4094, -4.6082, -4.7161, -4.9262, -4.2110, -4.8252, -4.7069, -4.5079,\n",
      "         -4.5318, -4.6578, -4.8710, -4.9765, -4.7615, -4.8178, -4.5423, -4.7143,\n",
      "         -4.6623, -4.7522, -4.6916, -4.4235, -4.8709, -4.4956, -5.1194, -4.6827,\n",
      "         -4.5027, -4.9396, -4.4765, -4.4673, -4.1295, -4.7590, -4.5036, -4.8156,\n",
      "         -4.8824, -4.7797, -4.2405, -4.5030, -4.3856, -4.6934, -4.8129, -4.6772,\n",
      "         -4.7934, -4.4369, -4.7462, -4.6096, -4.7031, -4.2102, -4.8726, -4.5010,\n",
      "         -4.6492, -4.8528, -4.3498, -4.7257, -4.6631, -4.4991, -4.7051, -4.5890,\n",
      "         -4.1926, -4.3036, -4.6107, -4.4202, -4.5642, -4.6884, -4.6561, -4.5870,\n",
      "         -4.6597, -4.3801, -5.0090, -4.5459, -4.6265, -4.8014, -4.2138, -4.1373,\n",
      "         -5.0112, -4.9102, -4.7316, -4.7645, -4.7217, -4.1559, -4.8361, -4.4826,\n",
      "         -4.4192, -4.4848, -4.5038, -5.0002, -4.4827, -4.3675, -4.2868, -4.4346,\n",
      "         -4.6985, -4.1697, -4.5174, -4.4045, -4.7686, -4.4352, -4.5651, -4.4125,\n",
      "         -4.2552]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : deep\n",
      "target index is: [76] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5765, -4.8889, -4.6775, -4.6084, -4.2257, -4.8170, -4.4014, -4.1759,\n",
      "         -4.7181, -5.0164, -4.8106, -4.4271, -4.5608, -4.8684, -4.8412, -4.2848,\n",
      "         -4.2426, -4.8153, -4.4667, -4.9523, -4.4906, -4.2148, -4.6627, -4.7150,\n",
      "         -4.1601, -4.9089, -4.4645, -4.7403, -4.6288, -4.4755, -4.7119, -4.6589,\n",
      "         -4.9189, -4.8799, -4.3944, -4.6160, -4.9583, -4.4965, -5.0162, -4.7197,\n",
      "         -4.8155, -4.6511, -4.8798, -4.5483, -4.4180, -4.3303, -4.5540, -4.6298,\n",
      "         -4.4729, -4.3150, -4.5163, -4.1507, -4.7582, -4.4085, -4.6510, -4.4401,\n",
      "         -4.5112, -4.5675, -4.5042, -4.6233, -5.0413, -4.6793, -4.5217, -3.9216,\n",
      "         -4.7058, -4.4502, -4.8676, -4.3973, -4.6884, -4.5632, -4.3623, -4.6603,\n",
      "         -4.6139, -4.5157, -4.6203, -4.9429, -4.5104, -4.5669, -4.9642, -4.7246,\n",
      "         -4.1639, -4.7465, -4.6926, -4.6250, -4.3473, -4.5745, -4.6728, -5.0504,\n",
      "         -4.9426, -4.3755, -4.5367, -4.7329, -4.6842, -4.3950, -4.4407, -4.4576,\n",
      "         -4.5688]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : trenches\n",
      "target index is: [54] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5067, -4.5099, -4.9185, -5.4023, -4.0664, -4.6402, -4.4538, -4.3714,\n",
      "         -4.8290, -4.3953, -4.8840, -4.3803, -4.7998, -4.8380, -4.9623, -4.7241,\n",
      "         -4.4565, -4.6352, -4.6716, -4.6809, -4.5656, -4.2481, -4.9513, -4.5568,\n",
      "         -4.4651, -4.8800, -4.1555, -4.5644, -4.5977, -4.7108, -4.4803, -5.0312,\n",
      "         -4.9268, -4.8818, -4.4998, -4.5718, -4.3559, -4.7667, -5.0192, -4.6707,\n",
      "         -4.8564, -4.8033, -4.5938, -4.5144, -4.4468, -4.4156, -4.5364, -4.7366,\n",
      "         -4.3982, -5.1803, -4.1403, -4.7487, -4.6754, -4.3669, -4.4721, -4.6714,\n",
      "         -4.9019, -4.6576, -4.2953, -4.4696, -4.6868, -4.4253, -4.4925, -4.0694,\n",
      "         -4.5087, -4.6648, -4.7463, -4.4619, -4.4454, -4.3519, -4.6328, -4.6721,\n",
      "         -5.1964, -4.6715, -4.8287, -5.0872, -4.2999, -4.1682, -4.4539, -4.5506,\n",
      "         -4.5650, -4.5186, -4.6293, -4.5097, -4.6876, -4.4346, -4.5073, -4.6719,\n",
      "         -4.6826, -4.6088, -4.1145, -4.5423, -4.7266, -4.2508, -4.5582, -4.7610,\n",
      "         -4.5037]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : in\n",
      "target index is: [95] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7601, -4.4444, -4.5668, -4.5149, -4.1361, -4.6727, -4.7312, -4.2066,\n",
      "         -4.7531, -4.5787, -4.6551, -4.2542, -4.4487, -4.7145, -4.8340, -4.6460,\n",
      "         -4.5964, -4.7384, -4.1980, -4.4867, -4.5241, -4.5481, -4.6278, -4.6381,\n",
      "         -4.2576, -4.9676, -4.4405, -4.8095, -4.3475, -4.4783, -4.7248, -4.6933,\n",
      "         -4.9232, -4.6546, -4.6262, -5.0628, -4.4703, -4.6412, -4.3334, -4.7236,\n",
      "         -4.5012, -4.5709, -4.9434, -4.6818, -4.5159, -4.3813, -4.4789, -4.9065,\n",
      "         -4.8271, -4.5066, -4.6227, -4.1832, -4.6657, -4.2576, -4.7355, -4.4105,\n",
      "         -4.5225, -4.3064, -4.3350, -4.7223, -4.8031, -4.6541, -4.5069, -4.0518,\n",
      "         -4.7777, -4.4365, -4.7158, -4.5895, -4.7966, -4.8290, -4.4195, -4.4787,\n",
      "         -5.0067, -4.7967, -4.8474, -4.8341, -4.6679, -4.3307, -4.7905, -5.0277,\n",
      "         -4.8214, -4.2206, -4.6807, -4.6728, -4.7187, -4.4064, -4.6440, -4.6726,\n",
      "         -4.8548, -4.2858, -4.9126, -4.7197, -4.6392, -4.3068, -4.4799, -4.5977,\n",
      "         -4.5136]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2977, -4.5159, -5.1383, -4.8385, -4.2608, -4.7130, -4.8216, -4.3601,\n",
      "         -5.2574, -4.2401, -4.9058, -4.1955, -4.4824, -4.3850, -4.9818, -5.0713,\n",
      "         -4.6293, -4.6083, -4.6031, -4.3951, -4.5058, -4.5140, -4.6448, -4.5908,\n",
      "         -4.5776, -5.0637, -4.2569, -4.5147, -4.6046, -4.7622, -4.7695, -4.4843,\n",
      "         -4.9648, -4.7683, -4.8269, -5.3754, -4.6743, -4.5589, -4.6419, -4.3438,\n",
      "         -4.5388, -4.6480, -4.3673, -4.4033, -4.2069, -4.1437, -4.6928, -4.6805,\n",
      "         -4.9477, -4.8098, -4.6222, -4.6973, -4.4391, -4.3362, -4.4882, -4.5314,\n",
      "         -4.6000, -4.3689, -4.4227, -4.6632, -4.6800, -4.4506, -4.3328, -4.1778,\n",
      "         -4.0065, -4.8226, -4.8497, -4.4957, -4.6314, -4.2185, -4.3252, -4.6236,\n",
      "         -4.7576, -4.7552, -4.7925, -4.7300, -4.2722, -4.1688, -4.5633, -4.6985,\n",
      "         -4.8612, -4.7522, -4.8379, -5.0167, -5.0905, -4.4531, -4.6818, -4.4903,\n",
      "         -5.1529, -4.6007, -4.4424, -4.7556, -4.9160, -4.3749, -4.2439, -4.8440,\n",
      "         -4.4443]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty's\n",
      "target index is: [80] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2951, -4.4797, -4.7762, -4.5156, -4.1892, -4.9172, -4.6095, -4.3225,\n",
      "         -4.3677, -5.1033, -4.9769, -4.2963, -4.7086, -4.7137, -4.6041, -4.7396,\n",
      "         -4.8653, -5.1407, -4.5538, -4.3900, -4.9348, -4.7290, -4.6478, -4.4767,\n",
      "         -4.2030, -4.6445, -4.6502, -4.4031, -3.8386, -4.5545, -4.8043, -4.6078,\n",
      "         -4.7229, -4.5373, -4.6146, -5.1350, -4.8554, -4.6187, -4.6639, -4.4917,\n",
      "         -4.6677, -4.2174, -4.9903, -4.0384, -4.5128, -4.0795, -4.4130, -4.4842,\n",
      "         -4.5577, -4.8935, -4.7827, -4.4761, -4.7587, -4.3022, -4.6038, -4.3935,\n",
      "         -4.2929, -4.3560, -4.7202, -5.0507, -4.8217, -4.1772, -4.4465, -4.0697,\n",
      "         -5.0332, -4.7911, -5.0939, -4.6564, -4.8300, -4.6408, -4.2662, -4.6916,\n",
      "         -4.5189, -4.8570, -4.8000, -4.8923, -5.2090, -4.2972, -4.7868, -4.4642,\n",
      "         -4.7886, -4.3179, -5.2215, -4.8458, -4.8572, -4.1080, -4.6041, -5.0107,\n",
      "         -5.0145, -4.5812, -5.2465, -4.4838, -4.6112, -4.4715, -4.2721, -4.2785,\n",
      "         -4.5013]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : field,\n",
      "target index is: [77] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.0705, -4.1452, -4.7628, -5.6403, -4.0412, -5.0742, -4.5581, -4.4009,\n",
      "         -4.8866, -4.7760, -4.6856, -5.1236, -5.0877, -4.9002, -4.6497, -4.7984,\n",
      "         -4.8811, -4.7050, -4.7866, -4.6183, -4.7652, -4.2896, -5.1585, -4.6497,\n",
      "         -4.6584, -4.8617, -4.3047, -4.0207, -4.2365, -4.9002, -4.2784, -4.7883,\n",
      "         -4.7891, -4.6538, -4.4907, -4.9525, -4.7200, -5.0246, -4.9749, -4.7944,\n",
      "         -4.5601, -5.1450, -4.8966, -4.6156, -4.6119, -4.0109, -5.0736, -4.4135,\n",
      "         -4.5825, -5.0262, -3.8196, -5.2183, -4.4357, -4.7881, -4.7684, -4.5051,\n",
      "         -4.5158, -4.3982, -4.4705, -4.2459, -4.7525, -4.5548, -4.3962, -3.7201,\n",
      "         -4.4664, -4.5464, -5.0096, -4.6481, -4.4625, -4.4743, -4.5957, -4.3998,\n",
      "         -5.3928, -4.9709, -4.7733, -4.8946, -4.4449, -4.1199, -4.5896, -4.4853,\n",
      "         -4.5666, -4.3692, -5.2444, -5.2341, -4.5395, -4.4876, -4.2411, -4.8265,\n",
      "         -4.6415, -4.1984, -4.1731, -4.3090, -4.9416, -4.1756, -4.4511, -4.9009,\n",
      "         -4.4558]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Thy\n",
      "target index is: [73] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3090, -4.5890, -4.7196, -4.6528, -4.2242, -4.9394, -4.6543, -4.1493,\n",
      "         -4.7365, -4.9188, -4.6691, -4.2397, -4.3726, -4.7396, -4.6355, -4.3586,\n",
      "         -4.6768, -4.8433, -4.1315, -4.6892, -4.5219, -4.2309, -4.8169, -4.7930,\n",
      "         -4.1746, -4.8522, -4.5777, -4.7125, -3.9987, -4.4660, -4.7734, -4.7138,\n",
      "         -4.8793, -4.5604, -4.6993, -5.1100, -4.9073, -4.5515, -4.8077, -4.9552,\n",
      "         -4.7504, -4.4024, -4.9742, -4.6501, -4.4887, -4.4173, -4.6215, -5.0928,\n",
      "         -4.6988, -4.5119, -4.6167, -4.3001, -4.7802, -4.4862, -4.8061, -4.4739,\n",
      "         -4.2158, -4.1936, -4.5591, -4.4313, -4.8186, -4.4197, -4.4969, -3.8837,\n",
      "         -4.8263, -4.6259, -4.7912, -4.8744, -4.8736, -4.6709, -4.3232, -4.3814,\n",
      "         -4.8870, -4.6901, -4.7744, -4.9155, -4.6082, -4.3653, -4.8687, -4.7430,\n",
      "         -4.5058, -4.3004, -5.1116, -4.6806, -4.3452, -4.7464, -4.7052, -4.6485,\n",
      "         -4.6834, -4.6722, -4.7327, -4.6443, -4.7197, -4.1412, -4.4692, -4.5809,\n",
      "         -4.4655]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : youth's\n",
      "target index is: [89] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2417, -4.7353, -4.7435, -4.8471, -4.1090, -4.7209, -4.9085, -4.5405,\n",
      "         -4.8280, -5.0129, -4.8982, -4.4278, -4.7501, -4.4057, -5.0526, -4.8193,\n",
      "         -4.6775, -4.6682, -4.6472, -4.6456, -4.3628, -4.4689, -4.5933, -4.5303,\n",
      "         -4.3274, -4.7415, -4.6908, -4.7725, -4.4856, -4.3828, -5.0087, -4.3669,\n",
      "         -4.9541, -4.6111, -4.6662, -5.1857, -4.7647, -4.7560, -4.8206, -4.2995,\n",
      "         -4.6385, -4.6483, -4.9099, -4.3376, -4.3145, -4.4948, -4.4790, -4.3974,\n",
      "         -4.5435, -4.4680, -4.4078, -4.8314, -4.5045, -4.2048, -4.4007, -4.4061,\n",
      "         -4.4671, -4.5410, -4.5888, -4.4687, -4.7263, -4.4102, -4.4613, -3.6229,\n",
      "         -4.2758, -4.3285, -4.8805, -4.6106, -4.7723, -4.5637, -4.3397, -4.6258,\n",
      "         -4.9209, -4.8349, -4.8613, -4.6367, -4.4548, -4.3094, -4.9184, -4.2768,\n",
      "         -4.7615, -4.7425, -4.9749, -5.2060, -4.5569, -4.3015, -4.4846, -5.0184,\n",
      "         -5.2677, -4.1810, -4.4704, -4.7293, -4.6532, -4.4671, -4.4151, -4.7097,\n",
      "         -4.8626]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : proud\n",
      "target index is: [50] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5762, -4.3365, -4.9546, -5.0845, -4.3620, -4.6331, -4.4223, -4.5054,\n",
      "         -5.3483, -4.4896, -4.8762, -4.4360, -4.8981, -4.6016, -4.6000, -5.1267,\n",
      "         -4.9239, -4.6835, -4.5080, -4.0753, -4.3816, -4.3720, -4.9636, -4.4894,\n",
      "         -4.9173, -4.9110, -4.4448, -4.3612, -4.7825, -4.8599, -4.7582, -4.6038,\n",
      "         -4.8675, -4.7950, -4.3423, -5.1308, -4.6221, -5.0312, -4.6571, -4.1731,\n",
      "         -4.3632, -4.6189, -4.6723, -4.4257, -4.6110, -4.2009, -4.8314, -4.2911,\n",
      "         -4.4527, -5.4097, -4.2800, -5.1029, -4.3140, -4.4683, -4.4880, -4.5296,\n",
      "         -4.8171, -4.4786, -4.3923, -4.7701, -4.6501, -4.3048, -4.6174, -4.3021,\n",
      "         -4.3298, -4.8743, -4.9325, -4.2186, -4.6305, -4.2693, -4.4422, -4.8180,\n",
      "         -4.9373, -4.9990, -4.5801, -4.8210, -4.5891, -4.2613, -4.3371, -4.1232,\n",
      "         -4.9129, -4.8012, -5.1609, -4.8431, -5.0110, -4.3522, -4.5242, -4.5404,\n",
      "         -4.7185, -4.2627, -4.4119, -4.1397, -4.8728, -4.5020, -4.2210, -4.6367,\n",
      "         -4.2494]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : livery\n",
      "target index is: [28] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6699, -4.4193, -5.0074, -4.7333, -4.0765, -5.1340, -4.4614, -4.3384,\n",
      "         -4.5755, -4.4653, -4.8903, -4.5825, -4.7508, -4.8659, -4.3023, -4.5797,\n",
      "         -4.7887, -5.0245, -4.7549, -4.4441, -4.8050, -4.0742, -5.1074, -4.7717,\n",
      "         -4.2303, -4.9000, -4.1528, -4.4260, -4.1090, -4.8307, -4.9332, -5.1295,\n",
      "         -4.9076, -4.7471, -4.6532, -4.7891, -4.5830, -4.7099, -5.0507, -4.5008,\n",
      "         -4.9438, -4.5263, -4.7928, -4.7326, -4.8154, -4.2651, -4.6367, -4.8872,\n",
      "         -4.3912, -5.0486, -4.3593, -4.6417, -4.5403, -4.2661, -4.6665, -4.3575,\n",
      "         -4.3015, -4.2173, -4.6950, -4.9063, -4.5204, -4.4675, -4.2092, -4.4497,\n",
      "         -4.5932, -4.5758, -4.7463, -4.7181, -4.6930, -4.3892, -4.2203, -4.4017,\n",
      "         -4.8199, -4.9317, -4.6453, -4.9155, -4.6430, -4.1591, -4.7373, -4.5484,\n",
      "         -4.5919, -4.6084, -4.9264, -4.6846, -4.5000, -4.3960, -4.4520, -4.8229,\n",
      "         -4.4473, -4.5163, -4.9733, -4.5539, -4.7418, -4.2859, -4.4837, -4.4998,\n",
      "         -3.9776]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : so\n",
      "target index is: [69] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4168, -4.2855, -4.9240, -4.8076, -4.2364, -5.0384, -4.6604, -4.3968,\n",
      "         -4.5637, -4.6596, -4.7824, -4.8074, -4.4598, -5.0109, -4.8546, -4.6129,\n",
      "         -4.7089, -4.4282, -4.5501, -4.5727, -4.4110, -4.2616, -5.1015, -4.7996,\n",
      "         -4.3552, -4.9276, -4.3578, -4.4884, -4.1956, -4.6763, -4.8352, -4.7785,\n",
      "         -4.9772, -4.9591, -4.6071, -4.7738, -4.8640, -4.4375, -4.8381, -4.6899,\n",
      "         -4.6434, -4.6533, -4.6231, -4.5686, -4.3892, -4.2685, -4.5011, -4.5599,\n",
      "         -4.4858, -4.8964, -4.5774, -4.4544, -4.8484, -4.3554, -4.4758, -4.6878,\n",
      "         -4.2115, -4.3804, -4.2952, -4.6516, -4.8882, -4.5325, -4.1982, -4.1451,\n",
      "         -4.4364, -4.8596, -4.4929, -4.4507, -4.3098, -4.4510, -4.2802, -4.4593,\n",
      "         -4.8026, -4.8764, -4.9994, -4.8656, -4.2837, -4.4805, -5.1348, -4.8219,\n",
      "         -4.3920, -4.6186, -4.8520, -4.7441, -4.7160, -4.4012, -4.5617, -4.6437,\n",
      "         -4.7535, -4.2550, -4.7653, -4.8393, -4.7444, -4.1486, -4.6868, -4.6429,\n",
      "         -4.3042]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : gazed\n",
      "target index is: [17] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4646, -4.3282, -4.6928, -4.7811, -4.3030, -4.6396, -4.5610, -4.3433,\n",
      "         -4.5774, -4.7425, -4.6918, -4.5661, -4.5781, -4.6972, -4.7708, -4.6239,\n",
      "         -4.4324, -4.6712, -4.6525, -4.5107, -4.6807, -4.6150, -4.7559, -4.6087,\n",
      "         -4.4078, -4.8686, -4.4282, -4.5727, -4.3253, -4.6120, -4.3958, -4.8337,\n",
      "         -4.8877, -4.7278, -4.5821, -4.6675, -4.5847, -4.6137, -4.7027, -4.5920,\n",
      "         -4.6962, -4.5828, -4.4316, -4.4170, -4.6012, -4.2657, -4.6859, -4.5645,\n",
      "         -4.4458, -4.5938, -4.5438, -4.2827, -4.8744, -4.4859, -4.6596, -4.3752,\n",
      "         -4.5713, -4.3367, -4.5305, -4.7066, -4.7397, -4.6086, -4.6640, -4.3107,\n",
      "         -4.6372, -4.6117, -4.8204, -4.4568, -4.5741, -4.5198, -4.4612, -4.4360,\n",
      "         -4.5053, -4.8371, -4.7137, -4.8334, -4.6658, -4.1790, -4.9304, -4.8723,\n",
      "         -4.6210, -4.6157, -4.6952, -4.8307, -4.5053, -4.4987, -4.3115, -4.6867,\n",
      "         -4.6872, -4.2959, -4.7002, -4.5427, -4.7985, -4.4868, -4.5654, -4.5379,\n",
      "         -4.4992]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : on\n",
      "target index is: [87] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4807, -4.6573, -4.6060, -4.6139, -4.2329, -4.6116, -4.4041, -4.2658,\n",
      "         -4.6741, -4.7051, -4.6364, -4.7798, -4.7506, -4.5810, -4.6703, -4.4685,\n",
      "         -4.3049, -4.6334, -4.6688, -4.7523, -4.8138, -4.6533, -4.7473, -4.5127,\n",
      "         -4.4524, -4.7528, -4.6108, -4.4996, -4.6037, -4.4078, -4.4552, -4.6820,\n",
      "         -4.7585, -4.7038, -4.7362, -4.6394, -4.7173, -4.6629, -4.9500, -4.5804,\n",
      "         -4.7005, -4.5359, -4.8215, -4.2944, -4.7059, -4.3763, -4.6125, -4.5762,\n",
      "         -4.4503, -4.3526, -4.7466, -4.4149, -5.1044, -4.2582, -4.6409, -4.2924,\n",
      "         -4.2441, -4.3527, -4.6299, -4.4823, -4.7280, -4.7390, -4.4515, -4.0314,\n",
      "         -4.8094, -4.2852, -4.8129, -4.5094, -4.5887, -4.5457, -4.4899, -4.6164,\n",
      "         -4.6987, -4.4471, -4.5736, -4.8078, -4.6959, -4.5373, -5.0176, -4.7895,\n",
      "         -4.4208, -4.4574, -4.7641, -4.7025, -4.6369, -4.4833, -4.6089, -4.7535,\n",
      "         -4.9288, -4.2388, -4.5224, -4.3506, -4.7672, -4.6549, -4.5036, -4.6656,\n",
      "         -4.7783]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : now,\n",
      "target index is: [63] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4656, -4.6008, -4.8475, -4.9204, -3.8279, -4.5205, -4.5359, -4.5248,\n",
      "         -4.6708, -4.6400, -4.5824, -4.3864, -5.0851, -4.8416, -4.7712, -4.5264,\n",
      "         -4.5477, -4.7952, -4.5990, -4.4217, -4.5711, -4.0846, -4.9583, -4.9077,\n",
      "         -4.6679, -4.9660, -4.6873, -4.3162, -4.3373, -4.7620, -4.4147, -5.0035,\n",
      "         -4.7208, -4.6295, -4.2465, -4.9096, -4.5466, -4.8787, -5.0978, -4.7273,\n",
      "         -4.6735, -4.4916, -4.7581, -4.4748, -4.6088, -4.3775, -4.3863, -4.8890,\n",
      "         -4.5381, -5.1268, -4.7620, -4.5772, -4.5026, -4.4612, -4.5527, -4.4464,\n",
      "         -4.2139, -4.4924, -4.4176, -4.5331, -4.5017, -4.5939, -4.8059, -4.2979,\n",
      "         -4.4500, -4.4259, -4.6979, -4.5251, -4.6885, -4.4296, -4.4323, -4.5682,\n",
      "         -5.0469, -4.9413, -4.6283, -4.8509, -5.0368, -4.4273, -4.7845, -4.4466,\n",
      "         -4.6256, -4.0719, -4.9049, -4.8223, -4.3239, -4.3254, -4.5633, -4.5369,\n",
      "         -4.8550, -4.4124, -4.6762, -4.1987, -4.7089, -4.3409, -4.5759, -4.5717,\n",
      "         -4.6050]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Will\n",
      "target index is: [36] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4072, -4.7720, -4.8063, -4.8721, -4.1052, -4.6465, -4.6639, -4.2742,\n",
      "         -4.5479, -4.7342, -4.6254, -4.6468, -4.6115, -4.8521, -4.9209, -4.3120,\n",
      "         -4.4703, -4.5891, -4.3610, -4.5656, -4.8291, -4.1442, -4.9846, -5.0479,\n",
      "         -4.1531, -5.0201, -4.4173, -4.4268, -4.1962, -4.4473, -4.4580, -4.8956,\n",
      "         -5.0388, -4.8623, -4.3588, -4.6835, -4.6293, -4.6589, -5.0780, -4.7749,\n",
      "         -4.9786, -4.5717, -4.4380, -4.6174, -4.6966, -4.3509, -4.6921, -4.6858,\n",
      "         -4.5691, -4.8926, -4.3929, -4.5850, -4.9080, -4.5784, -4.6421, -4.4480,\n",
      "         -4.1007, -4.3282, -4.2971, -4.5214, -4.9781, -4.7348, -4.4758, -4.4446,\n",
      "         -4.5258, -4.4360, -4.6947, -4.5525, -4.7355, -4.6911, -4.2751, -4.2852,\n",
      "         -4.8224, -4.9345, -4.7304, -4.7716, -4.4481, -4.2977, -4.7631, -4.7968,\n",
      "         -4.4810, -4.6380, -4.6338, -4.7166, -4.4332, -4.4996, -4.5391, -4.7922,\n",
      "         -4.6573, -4.3245, -4.6764, -4.5188, -4.8049, -4.4844, -4.8174, -4.3831,\n",
      "         -4.2981]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : be\n",
      "target index is: [24] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3558, -4.6545, -4.7596, -4.7628, -4.1517, -4.9904, -4.6137, -4.3272,\n",
      "         -4.7612, -4.7991, -4.6356, -4.2794, -4.6697, -5.0085, -5.0985, -4.3660,\n",
      "         -4.3850, -4.7671, -4.6918, -4.9880, -4.3640, -3.9520, -4.5266, -4.6633,\n",
      "         -4.1198, -5.0951, -4.3249, -4.8207, -4.3819, -4.5864, -4.3632, -5.2299,\n",
      "         -4.8443, -4.7766, -4.5982, -4.5425, -4.6896, -4.5242, -4.9979, -4.8496,\n",
      "         -5.0304, -4.7160, -4.6361, -4.6741, -4.3979, -4.4950, -4.5752, -4.7552,\n",
      "         -4.5980, -4.6058, -4.7206, -4.0731, -5.0998, -4.4261, -4.6898, -4.6500,\n",
      "         -4.5108, -4.5122, -4.3302, -4.6953, -4.9102, -4.5359, -4.5758, -4.0253,\n",
      "         -4.6843, -4.4983, -4.8547, -4.4108, -4.3087, -4.3986, -4.1834, -4.6356,\n",
      "         -4.9474, -4.7576, -5.0857, -5.1976, -4.5023, -4.2641, -4.9644, -4.9030,\n",
      "         -4.1937, -4.5551, -4.6541, -4.4685, -4.3392, -4.4714, -4.3880, -4.8740,\n",
      "         -5.0088, -4.5323, -4.2183, -4.7545, -4.5514, -4.4027, -4.5247, -4.6019,\n",
      "         -4.5388]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : a\n",
      "target index is: [46] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4039, -4.5118, -4.6626, -5.3686, -4.1333, -4.6994, -4.2740, -4.0479,\n",
      "         -4.7824, -4.5522, -4.8535, -4.9034, -4.4077, -4.7566, -4.6862, -4.2990,\n",
      "         -4.1992, -4.6200, -4.6681, -4.6030, -5.1029, -4.3317, -4.9254, -4.9584,\n",
      "         -4.3249, -5.2864, -4.1817, -4.4171, -4.2775, -4.6535, -4.4726, -4.7450,\n",
      "         -4.8848, -5.0143, -4.4471, -4.6511, -4.5260, -4.3871, -4.9015, -4.5712,\n",
      "         -4.8364, -4.6007, -4.9670, -4.2983, -4.9452, -4.1733, -4.8598, -4.7476,\n",
      "         -4.7243, -4.7699, -4.1325, -4.6235, -4.5622, -4.4892, -4.6399, -4.5924,\n",
      "         -4.3130, -4.5554, -4.3826, -4.7387, -4.8520, -4.7161, -4.4647, -4.3160,\n",
      "         -4.6491, -4.3809, -5.0429, -4.3572, -4.7787, -4.8252, -4.7125, -4.4564,\n",
      "         -4.8958, -4.8750, -4.6639, -4.8797, -4.4583, -4.2624, -4.4607, -4.6966,\n",
      "         -4.4162, -4.6018, -4.7295, -4.7209, -4.8726, -4.3575, -4.5921, -4.7175,\n",
      "         -4.7378, -4.3311, -4.5995, -4.3698, -5.0711, -4.3180, -4.7627, -4.3170,\n",
      "         -4.2883]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : totter'd\n",
      "target index is: [20] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7510, -4.6395, -4.9522, -4.8778, -4.3859, -4.7961, -4.6867, -4.0536,\n",
      "         -4.8831, -4.6009, -4.8415, -4.2557, -4.3202, -4.6862, -4.9807, -4.6114,\n",
      "         -4.6871, -4.4413, -4.3080, -4.7159, -4.6006, -4.3622, -4.7434, -4.7878,\n",
      "         -4.1179, -5.1676, -4.4873, -4.7621, -4.1508, -4.3663, -4.4911, -4.7772,\n",
      "         -4.8181, -4.8633, -4.8752, -5.1869, -4.6370, -4.5080, -4.7810, -4.5567,\n",
      "         -4.7391, -4.7372, -4.6730, -4.6138, -4.6311, -4.4087, -4.8484, -4.8074,\n",
      "         -4.8079, -4.7148, -4.3707, -4.4908, -4.8431, -4.5259, -4.5505, -4.4193,\n",
      "         -4.3906, -4.2796, -4.2586, -4.4193, -4.7663, -4.4695, -4.5315, -3.8950,\n",
      "         -4.5450, -4.6391, -4.4445, -4.6630, -4.6323, -4.0352, -4.3912, -4.2539,\n",
      "         -5.0564, -4.8499, -5.0102, -5.0324, -4.2965, -4.3088, -4.5132, -4.9254,\n",
      "         -4.7137, -4.5642, -4.9625, -4.6016, -4.8457, -4.5582, -4.6220, -4.6796,\n",
      "         -4.8171, -4.4541, -4.5480, -4.6885, -4.8257, -4.0983, -4.6544, -4.7031,\n",
      "         -4.2870]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : weed\n",
      "target index is: [29] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6269, -4.7117, -4.5432, -4.6730, -4.1415, -4.7535, -4.5750, -4.3313,\n",
      "         -4.6802, -4.8080, -4.6484, -4.6507, -4.6757, -4.7900, -5.0487, -4.8071,\n",
      "         -4.4165, -4.4282, -4.4471, -4.5595, -4.5580, -4.6588, -4.7400, -4.4684,\n",
      "         -4.2238, -4.8336, -4.5492, -4.7180, -4.5429, -4.4784, -4.2882, -4.5948,\n",
      "         -4.5571, -4.7211, -4.6354, -4.7233, -4.3840, -4.5679, -4.3844, -4.6082,\n",
      "         -4.6241, -4.6722, -4.7924, -4.6002, -4.5303, -4.2562, -4.2466, -4.5319,\n",
      "         -4.6691, -4.4777, -4.7284, -4.3173, -4.8834, -4.3733, -4.4538, -4.5167,\n",
      "         -4.4417, -4.3452, -4.3054, -4.6614, -5.0164, -4.5121, -4.5216, -4.2000,\n",
      "         -4.8435, -4.6682, -4.6568, -4.6012, -4.5172, -4.4698, -4.5456, -4.6195,\n",
      "         -4.8271, -4.9245, -4.8367, -4.7882, -4.6246, -4.2368, -5.0071, -4.8866,\n",
      "         -4.7174, -4.5242, -4.6347, -4.5658, -4.7172, -4.5253, -4.4281, -4.7829,\n",
      "         -4.9843, -4.1584, -4.7122, -4.4782, -4.6755, -4.4779, -4.5319, -4.7766,\n",
      "         -4.5848]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : of\n",
      "target index is: [57] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5470, -4.4052, -4.3572, -4.6179, -3.9202, -4.7309, -5.0281, -4.4663,\n",
      "         -4.7178, -4.6103, -4.6324, -4.2369, -4.8671, -4.8420, -4.6339, -4.5479,\n",
      "         -4.5651, -4.9335, -4.4484, -4.7938, -4.4108, -4.1482, -4.5984, -4.4642,\n",
      "         -4.3965, -4.7341, -4.4563, -4.7140, -4.3724, -4.6112, -4.4580, -5.2680,\n",
      "         -4.7196, -4.2724, -4.6557, -4.9978, -4.5847, -4.8777, -4.6214, -4.8913,\n",
      "         -4.7106, -4.7781, -4.8386, -4.6668, -4.5009, -4.4187, -4.4694, -4.9371,\n",
      "         -4.8104, -4.4416, -4.6337, -4.4711, -4.8683, -4.2960, -4.9784, -4.4896,\n",
      "         -4.6316, -4.4488, -4.4860, -4.4322, -4.7398, -4.8178, -4.7069, -3.7752,\n",
      "         -4.7634, -4.6209, -5.0243, -4.6260, -4.6125, -4.7470, -4.3047, -4.5064,\n",
      "         -4.9817, -4.7019, -4.6340, -4.7682, -4.7620, -4.4293, -4.9079, -4.9077,\n",
      "         -4.6763, -4.0636, -4.8283, -4.7551, -4.4335, -4.5755, -4.4090, -4.5663,\n",
      "         -4.9171, -4.1810, -4.6279, -4.7326, -4.5627, -4.4379, -4.0578, -4.7979,\n",
      "         -4.4269]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : small\n",
      "target index is: [38] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3523, -4.2925, -4.6769, -4.8326, -4.2808, -4.7382, -4.6033, -4.5166,\n",
      "         -4.6765, -4.9141, -4.8799, -4.6597, -4.7798, -4.4914, -4.3047, -4.7439,\n",
      "         -4.8030, -5.0066, -4.5974, -4.2660, -4.8059, -4.5525, -4.7324, -4.4251,\n",
      "         -4.7256, -5.0863, -4.7221, -4.4097, -4.1093, -4.5768, -4.4678, -4.9933,\n",
      "         -4.7747, -4.6355, -4.4299, -4.8554, -4.7682, -4.8446, -4.8961, -4.3794,\n",
      "         -4.6147, -4.5696, -4.9115, -4.1304, -4.9004, -4.1401, -4.9773, -4.4065,\n",
      "         -4.4401, -4.8494, -4.9123, -4.6830, -4.7930, -4.4191, -4.6138, -4.6391,\n",
      "         -4.2442, -4.2892, -4.6253, -4.6436, -4.5939, -4.7103, -4.7999, -4.2635,\n",
      "         -4.9504, -4.4761, -5.1578, -4.2158, -4.6864, -4.7663, -4.2000, -4.6319,\n",
      "         -4.7849, -4.6895, -4.8279, -4.6865, -5.1681, -4.3443, -4.7691, -4.1958,\n",
      "         -4.6967, -4.4218, -4.8169, -5.0035, -4.6235, -4.1094, -4.3123, -4.4186,\n",
      "         -5.0227, -4.1927, -4.5826, -4.2580, -4.6635, -4.5865, -4.2410, -4.3700,\n",
      "         -4.3198]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : worth\n",
      "target index is: [83] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7239, -4.6333, -4.7388, -5.0301, -4.2275, -4.8351, -4.3622, -4.4849,\n",
      "         -4.6958, -4.6942, -5.0861, -4.7959, -4.9087, -4.8373, -4.4538, -4.5341,\n",
      "         -4.5164, -4.8390, -4.5832, -4.4672, -4.7899, -3.9064, -5.2797, -4.6794,\n",
      "         -4.1809, -5.1052, -4.2255, -4.0464, -4.5755, -4.5626, -4.9973, -4.9221,\n",
      "         -5.0686, -4.8763, -4.5314, -4.3025, -4.8133, -4.9132, -5.1893, -4.6465,\n",
      "         -4.9438, -5.1885, -4.8246, -4.6353, -4.7971, -4.4771, -4.7851, -5.0001,\n",
      "         -4.2574, -4.9326, -3.9117, -4.7556, -4.2205, -3.8569, -4.9894, -4.0581,\n",
      "         -4.8083, -4.4162, -4.5160, -4.5146, -4.7966, -4.8399, -4.5216, -4.1334,\n",
      "         -4.8453, -4.2014, -5.0662, -4.5114, -4.8257, -4.6160, -4.1781, -4.6873,\n",
      "         -4.8841, -4.3311, -4.4492, -5.0593, -4.5009, -4.4029, -5.0101, -4.7204,\n",
      "         -4.2718, -4.3239, -4.8121, -4.4785, -4.2708, -4.3510, -5.0555, -5.2376,\n",
      "         -4.5065, -4.2240, -4.6006, -4.7163, -4.5140, -4.3114, -4.3722, -4.8250,\n",
      "         -4.3218]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : held:\n",
      "target index is: [19] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4307, -4.3751, -5.0650, -5.0776, -3.9946, -4.9041, -4.3850, -4.5424,\n",
      "         -4.6427, -4.1448, -5.0375, -4.6035, -4.8679, -4.7579, -4.4205, -4.6653,\n",
      "         -4.6001, -4.6922, -4.9709, -4.5082, -4.3805, -4.3697, -5.1121, -4.7148,\n",
      "         -4.8277, -5.2051, -4.4316, -4.4128, -4.6078, -4.6569, -4.7505, -4.6334,\n",
      "         -4.7634, -5.1752, -4.5918, -4.6142, -4.4952, -4.6605, -4.9544, -4.2391,\n",
      "         -4.5781, -4.6057, -4.4754, -4.2444, -4.2874, -4.5605, -4.6682, -4.5471,\n",
      "         -4.1870, -5.3515, -4.3463, -4.9668, -4.7476, -4.3261, -4.7311, -4.5837,\n",
      "         -4.5786, -4.6599, -4.5230, -4.5739, -4.6547, -4.4024, -4.4177, -4.4427,\n",
      "         -4.4458, -4.7454, -4.7075, -4.2811, -4.5660, -4.3473, -4.5502, -4.9218,\n",
      "         -4.8470, -4.5935, -4.8664, -5.3432, -4.2162, -4.7563, -4.7407, -4.7367,\n",
      "         -4.6652, -4.2174, -4.7908, -4.5398, -5.3152, -3.9338, -5.0760, -4.5373,\n",
      "         -4.7116, -3.9936, -4.5887, -4.8256, -4.8003, -4.1239, -4.6149, -4.3110,\n",
      "         -4.2581]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Then\n",
      "target index is: [65] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4038, -4.4866, -4.8931, -4.7514, -3.9448, -4.8755, -4.6844, -4.7240,\n",
      "         -4.8036, -4.6280, -4.7171, -4.6069, -4.7679, -4.6832, -4.7714, -4.6070,\n",
      "         -4.5277, -4.6861, -5.1204, -4.7486, -4.5843, -4.2298, -5.0057, -4.3201,\n",
      "         -4.4244, -4.7304, -4.7823, -4.2693, -4.3094, -4.3857, -4.6591, -4.5529,\n",
      "         -4.8811, -4.8580, -4.5329, -4.2896, -4.6719, -5.0228, -5.0010, -4.4240,\n",
      "         -4.8903, -4.4140, -4.5138, -4.3574, -4.3356, -4.3412, -4.5153, -4.7227,\n",
      "         -4.3236, -4.9969, -4.6764, -4.5183, -4.9919, -4.0010, -4.5709, -4.3843,\n",
      "         -4.2621, -4.4746, -4.7127, -4.3222, -4.7639, -4.6137, -4.4710, -4.3813,\n",
      "         -4.6689, -4.5916, -4.7542, -4.2684, -4.5937, -4.4488, -4.3865, -4.6804,\n",
      "         -4.8145, -4.7801, -4.9263, -4.9961, -4.4815, -4.5081, -5.1767, -5.0045,\n",
      "         -4.4963, -4.2009, -4.4147, -4.5118, -4.7928, -4.0745, -4.8160, -5.0132,\n",
      "         -4.8463, -4.0873, -4.7390, -4.9147, -4.5459, -4.4029, -4.4923, -4.8768,\n",
      "         -4.7045]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : being\n",
      "target index is: [32] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4106, -4.2522, -4.6116, -5.0715, -4.1618, -4.3927, -4.5256, -4.0993,\n",
      "         -4.9783, -4.4400, -4.8271, -4.3398, -4.6614, -4.4386, -5.0170, -4.3974,\n",
      "         -4.4372, -4.4647, -4.6725, -4.0539, -4.8348, -4.7497, -4.5629, -4.6173,\n",
      "         -4.9101, -4.5766, -4.6239, -4.5259, -4.4075, -4.7651, -4.2776, -4.8270,\n",
      "         -4.8961, -4.5448, -4.5206, -4.7900, -4.4989, -4.9781, -4.9252, -4.8123,\n",
      "         -4.6882, -4.7245, -4.5274, -4.1752, -4.4734, -4.1211, -4.7140, -4.7204,\n",
      "         -4.7672, -4.6661, -4.6927, -4.3613, -4.5447, -4.5129, -4.9807, -4.6673,\n",
      "         -4.5597, -4.6509, -4.4959, -4.5586, -4.8974, -4.8475, -4.7640, -4.2037,\n",
      "         -4.5489, -4.5176, -5.0111, -4.4725, -4.6715, -4.8527, -4.5499, -4.6311,\n",
      "         -4.6916, -5.1142, -4.3720, -4.5355, -4.6710, -4.3927, -4.6988, -4.6756,\n",
      "         -4.6913, -4.4163, -4.4575, -4.9119, -4.8041, -4.4612, -4.3546, -4.1999,\n",
      "         -5.0979, -4.3553, -4.6914, -4.3995, -5.0004, -4.4861, -4.4302, -4.3962,\n",
      "         -4.6562]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : asked,\n",
      "target index is: [23] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2157, -4.6133, -4.5142, -4.6309, -4.1418, -4.8220, -4.7216, -4.3782,\n",
      "         -4.6517, -4.5881, -4.6665, -4.3465, -4.6647, -4.7237, -4.6609, -4.7731,\n",
      "         -4.7212, -5.0532, -4.4346, -4.8034, -4.5243, -4.4704, -4.7518, -4.5861,\n",
      "         -4.4163, -4.8433, -4.5392, -4.4961, -4.3022, -4.5503, -4.5951, -4.8094,\n",
      "         -4.6582, -4.5486, -4.7077, -5.0404, -4.5673, -4.4371, -4.5330, -4.6536,\n",
      "         -4.7415, -4.3908, -4.6609, -4.4767, -4.4057, -4.1895, -4.6426, -4.8615,\n",
      "         -4.7899, -4.5067, -4.5824, -4.3938, -4.9012, -4.4162, -4.8032, -4.3691,\n",
      "         -4.5761, -4.3134, -4.3624, -4.6410, -4.7083, -4.5115, -4.6173, -3.9342,\n",
      "         -4.7774, -4.6067, -4.9429, -4.6552, -4.8616, -4.6387, -4.4954, -4.5675,\n",
      "         -4.9151, -4.5151, -4.6396, -4.9492, -4.7722, -4.2870, -4.7576, -4.9459,\n",
      "         -4.6178, -4.1767, -4.9099, -4.6207, -4.4065, -4.5315, -4.6222, -4.5383,\n",
      "         -5.0111, -4.4508, -4.5456, -4.5001, -4.6621, -4.6087, -4.2554, -4.6893,\n",
      "         -4.4194]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : where\n",
      "target index is: [51] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3862, -4.2719, -4.6773, -4.9593, -4.2377, -4.9322, -4.7773, -4.6288,\n",
      "         -4.8748, -4.6403, -4.9548, -4.5821, -4.8337, -4.6526, -4.6317, -4.9418,\n",
      "         -4.6660, -4.5884, -4.9123, -4.5272, -4.6446, -4.5470, -4.9050, -4.5073,\n",
      "         -4.5941, -4.7474, -4.3533, -4.3832, -4.2983, -4.6302, -4.3306, -4.9192,\n",
      "         -4.7337, -4.6339, -4.5119, -4.9700, -4.4590, -4.6719, -4.7856, -4.5465,\n",
      "         -4.6089, -4.6960, -4.6383, -4.5544, -4.5804, -4.1128, -4.7821, -4.5518,\n",
      "         -4.7410, -4.7869, -4.2357, -4.8938, -4.7599, -4.4875, -4.4713, -4.6936,\n",
      "         -4.5298, -4.4360, -4.5678, -4.5441, -4.5460, -4.4581, -4.5052, -4.3312,\n",
      "         -4.4745, -4.7969, -5.0468, -4.2845, -4.3949, -4.3283, -4.6698, -4.4601,\n",
      "         -5.0674, -5.0174, -4.8331, -4.9425, -4.6473, -4.1965, -4.5474, -4.5055,\n",
      "         -4.4538, -4.3784, -4.7519, -4.9033, -4.8364, -4.2618, -4.3259, -4.4711,\n",
      "         -4.7717, -4.3832, -4.2391, -4.6903, -4.6965, -4.3451, -4.2497, -4.5858,\n",
      "         -4.2081]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : all\n",
      "target index is: [52] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4791, -4.2670, -4.6867, -4.7878, -4.4020, -4.8236, -4.4855, -4.4496,\n",
      "         -4.5381, -4.8673, -5.0145, -4.7193, -4.4964, -4.6022, -4.5971, -4.6306,\n",
      "         -4.6321, -4.7297, -4.5908, -4.2297, -4.8229, -4.7481, -4.7783, -4.4914,\n",
      "         -4.3913, -4.8600, -4.4718, -4.4906, -4.1916, -4.8093, -4.4825, -4.7685,\n",
      "         -4.8626, -4.8057, -4.4827, -4.5339, -4.5981, -4.4860, -4.6485, -4.6010,\n",
      "         -4.7140, -4.5937, -4.7395, -4.4745, -4.8148, -4.1614, -4.8099, -4.6342,\n",
      "         -4.5659, -4.8119, -4.4205, -4.4409, -4.6247, -4.2865, -4.7048, -4.5516,\n",
      "         -4.3687, -4.4057, -4.5746, -4.7473, -4.7711, -4.7099, -4.5529, -4.5326,\n",
      "         -4.7973, -4.5238, -5.0899, -4.3571, -4.6388, -4.6634, -4.4264, -4.4628,\n",
      "         -4.5494, -4.9086, -4.6225, -4.6461, -4.6261, -4.2208, -4.6856, -4.6645,\n",
      "         -4.5433, -4.5838, -4.6632, -4.8504, -4.6387, -4.3479, -4.4755, -4.5848,\n",
      "         -4.7093, -4.2958, -4.7078, -4.6359, -4.6511, -4.5037, -4.3229, -4.4395,\n",
      "         -4.1941]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4732, -4.3493, -4.9443, -4.7891, -4.2651, -4.7868, -4.8947, -4.3818,\n",
      "         -5.0867, -4.2644, -5.0048, -4.3573, -4.5199, -4.6953, -4.6488, -4.7861,\n",
      "         -4.5363, -4.4515, -4.4375, -4.4967, -4.6379, -4.3255, -4.6047, -4.7800,\n",
      "         -4.4584, -5.0786, -4.3297, -4.5165, -4.4771, -4.5080, -4.7354, -4.6636,\n",
      "         -4.8279, -4.6107, -4.8868, -5.0670, -4.6636, -4.6353, -4.8961, -4.6549,\n",
      "         -4.6275, -4.7462, -4.6715, -4.5803, -4.5158, -4.1035, -4.8015, -4.6984,\n",
      "         -4.8607, -4.6736, -4.7514, -4.7671, -4.5953, -4.2507, -4.4550, -4.7678,\n",
      "         -4.3141, -4.4093, -4.4477, -4.5597, -4.7066, -4.5867, -4.2857, -4.2492,\n",
      "         -4.2086, -4.7466, -4.7127, -4.2118, -4.6123, -4.3676, -4.4104, -4.5495,\n",
      "         -4.7966, -4.6261, -4.7699, -4.7496, -4.2200, -4.4291, -4.5106, -4.7030,\n",
      "         -4.5724, -4.5447, -4.7935, -5.0312, -4.8738, -4.4616, -4.7452, -4.6089,\n",
      "         -4.8966, -4.4634, -4.5195, -4.7701, -4.8182, -4.3053, -4.0441, -4.8287,\n",
      "         -4.3502]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty\n",
      "target index is: [0] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4303, -4.6513, -4.8365, -4.9171, -4.2137, -4.6771, -4.4684, -4.2212,\n",
      "         -5.1015, -4.4851, -4.8182, -4.4009, -4.3252, -4.6294, -4.8150, -5.0721,\n",
      "         -4.6588, -4.5634, -4.6687, -4.4720, -4.7706, -4.7202, -4.9494, -4.6268,\n",
      "         -4.5006, -5.1825, -4.3172, -4.4208, -4.2227, -4.7041, -4.5318, -4.3194,\n",
      "         -4.7002, -4.8773, -4.6661, -5.1383, -4.3075, -4.5507, -4.3708, -4.3948,\n",
      "         -4.5347, -4.3600, -4.6135, -4.2647, -4.5369, -4.0355, -4.8708, -4.5802,\n",
      "         -4.8893, -4.8045, -4.4899, -4.6835, -4.8438, -4.4940, -4.5412, -4.5551,\n",
      "         -4.4608, -4.4507, -4.4837, -4.5350, -4.7004, -4.4182, -4.3906, -4.3532,\n",
      "         -4.2977, -5.0099, -4.8481, -4.3967, -4.7908, -4.0315, -4.5530, -4.4294,\n",
      "         -5.0835, -4.9335, -4.7668, -4.7456, -4.6005, -3.8985, -4.5230, -4.7968,\n",
      "         -4.7640, -4.7606, -4.8334, -4.9238, -5.1291, -4.3173, -4.5398, -4.3696,\n",
      "         -5.3179, -4.8286, -4.7807, -4.5388, -4.8948, -4.3370, -4.5003, -4.7918,\n",
      "         -4.2370]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : lies,\n",
      "target index is: [59] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2846, -4.6362, -4.6670, -4.6605, -4.1796, -4.8711, -4.4922, -4.2540,\n",
      "         -4.6535, -5.1562, -4.7820, -4.4235, -4.5368, -4.7794, -4.7852, -4.6491,\n",
      "         -4.4498, -4.9527, -4.8678, -4.9100, -4.4334, -4.5134, -4.7397, -4.4913,\n",
      "         -4.1585, -4.8666, -4.4971, -4.4184, -4.3271, -4.5910, -4.6074, -4.6923,\n",
      "         -4.5379, -5.0854, -4.4819, -4.6388, -4.8856, -4.3127, -4.6731, -4.3630,\n",
      "         -5.0337, -4.2285, -4.7416, -4.4054, -4.4928, -4.1537, -4.4936, -4.5937,\n",
      "         -4.5634, -4.5439, -4.5945, -4.1663, -5.0443, -4.3479, -4.7254, -4.3031,\n",
      "         -4.5723, -4.5140, -4.7379, -4.7818, -4.6701, -4.2689, -4.5071, -4.3300,\n",
      "         -4.6925, -4.6524, -4.7014, -4.3691, -4.6750, -4.4319, -4.4105, -4.6227,\n",
      "         -4.4752, -4.9490, -4.8850, -4.9232, -4.6468, -4.1473, -4.9146, -5.0713,\n",
      "         -4.4057, -4.7071, -4.6794, -4.7963, -4.4172, -4.4694, -4.4551, -5.0399,\n",
      "         -4.9850, -4.5083, -4.7527, -4.6929, -4.4267, -4.6067, -4.6918, -4.5656,\n",
      "         -4.4306]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Where\n",
      "target index is: [18] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5687, -4.4079, -4.3668, -4.5883, -4.2082, -4.9761, -4.7892, -4.4828,\n",
      "         -4.6721, -4.7616, -4.6933, -4.4799, -4.7130, -4.7909, -4.5690, -4.5517,\n",
      "         -4.8578, -4.5995, -4.5534, -4.6186, -4.3679, -4.2953, -4.7954, -4.6307,\n",
      "         -4.4107, -4.7851, -4.6726, -4.4555, -4.3376, -4.5465, -4.7019, -4.6531,\n",
      "         -4.8510, -4.5494, -4.6608, -4.8961, -4.5651, -4.8872, -4.5105, -4.5051,\n",
      "         -4.6652, -4.6543, -4.8651, -4.5272, -4.6655, -4.3897, -4.5613, -4.6697,\n",
      "         -4.4733, -4.8318, -4.5125, -4.8176, -4.6322, -4.6106, -4.7218, -4.7435,\n",
      "         -4.2593, -4.4624, -4.4073, -4.4857, -4.8280, -4.8164, -4.4912, -4.1678,\n",
      "         -4.8964, -4.4286, -4.9212, -4.3557, -4.5789, -4.6866, -4.2906, -4.4254,\n",
      "         -4.8444, -4.9526, -4.8146, -4.7843, -4.3246, -4.2949, -4.9482, -4.5465,\n",
      "         -4.4870, -4.2757, -4.6251, -4.7484, -4.6161, -4.4531, -4.3928, -4.6813,\n",
      "         -4.7800, -4.2315, -4.5711, -4.7011, -4.5709, -4.4112, -4.2599, -4.5053,\n",
      "         -4.5321]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : all\n",
      "target index is: [52] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3024, -4.2349, -4.6213, -4.9095, -4.3033, -4.5961, -4.5866, -4.4422,\n",
      "         -4.7879, -4.9537, -4.8603, -4.4992, -4.7603, -4.6831, -4.4970, -4.7153,\n",
      "         -4.7362, -5.0228, -4.3888, -4.2056, -4.7675, -4.3884, -4.7575, -4.4901,\n",
      "         -4.6108, -4.7273, -4.3903, -4.4741, -4.2232, -4.9619, -4.4577, -4.9345,\n",
      "         -4.8344, -4.6186, -4.2998, -4.6971, -4.5666, -4.7931, -4.7946, -4.6996,\n",
      "         -4.6384, -4.6159, -4.8730, -4.5644, -4.9207, -4.2151, -4.9945, -4.6326,\n",
      "         -4.6122, -4.8621, -4.4167, -4.6327, -4.4397, -4.4819, -4.9915, -4.6072,\n",
      "         -4.6020, -4.4867, -4.5977, -4.7788, -4.5449, -4.6229, -4.6699, -4.3559,\n",
      "         -4.9545, -4.4312, -5.1401, -4.5721, -4.7566, -4.6941, -4.3196, -4.5006,\n",
      "         -4.5845, -4.8662, -4.3724, -4.6096, -4.7561, -4.1781, -4.6086, -4.4024,\n",
      "         -4.5273, -4.4420, -4.8468, -4.9132, -4.4275, -4.4642, -4.3465, -4.5435,\n",
      "         -4.7265, -4.2447, -4.5501, -4.4047, -4.7298, -4.5133, -4.1233, -4.4067,\n",
      "         -4.3328]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : the\n",
      "target index is: [82] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1854, -4.3961, -4.5502, -4.8784, -4.1734, -4.6927, -4.6829, -4.3346,\n",
      "         -4.6239, -4.6936, -4.8818, -4.7426, -4.6415, -4.8074, -4.7057, -4.6440,\n",
      "         -4.4256, -4.5103, -4.4293, -4.6631, -4.8796, -4.4814, -4.8645, -4.6008,\n",
      "         -4.2315, -4.4975, -4.5413, -4.4721, -4.4221, -4.4835, -4.5571, -4.7355,\n",
      "         -4.5638, -4.6226, -4.8683, -4.7713, -4.8325, -4.5470, -4.8678, -4.7928,\n",
      "         -4.6865, -4.5459, -4.7674, -4.3444, -4.6037, -4.1617, -4.6063, -4.5217,\n",
      "         -4.5624, -4.4600, -4.5005, -4.5909, -4.9678, -4.4100, -4.5155, -4.6597,\n",
      "         -4.4197, -4.5411, -4.4049, -4.5546, -5.1407, -4.7549, -4.3728, -4.0204,\n",
      "         -4.8613, -4.7243, -4.7324, -4.4782, -4.6697, -4.7108, -4.6971, -4.5832,\n",
      "         -4.4986, -4.5835, -4.5081, -4.5354, -4.4312, -4.4822, -4.7835, -4.7905,\n",
      "         -4.2784, -4.3352, -4.8668, -4.7766, -4.5732, -4.5801, -4.7579, -4.7897,\n",
      "         -4.9138, -4.3515, -4.6315, -4.5239, -4.6647, -4.5363, -4.3353, -4.5971,\n",
      "         -4.5861]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : treasure\n",
      "target index is: [31] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4006, -4.3469, -4.7316, -4.9647, -4.1118, -4.7587, -4.6899, -4.5601,\n",
      "         -4.7644, -4.5567, -4.6206, -4.2675, -4.8386, -4.8346, -4.7977, -4.8066,\n",
      "         -4.4465, -4.7392, -4.6756, -4.5440, -4.5216, -4.4481, -4.9435, -4.6143,\n",
      "         -4.7709, -4.9716, -4.2817, -4.4346, -4.2905, -4.8896, -4.2479, -4.9993,\n",
      "         -4.6572, -4.5452, -4.4971, -5.0316, -4.4051, -4.6895, -4.7360, -4.7656,\n",
      "         -4.5741, -4.7395, -4.5452, -4.3334, -4.5715, -4.2422, -4.6515, -4.6785,\n",
      "         -4.7419, -4.8908, -4.2815, -4.7687, -4.7835, -4.8123, -4.6676, -4.3846,\n",
      "         -4.5525, -4.3352, -4.4782, -4.6194, -4.5075, -4.3663, -4.7853, -4.1725,\n",
      "         -4.4652, -4.6309, -5.1097, -4.6576, -4.2587, -4.3153, -4.7203, -4.6793,\n",
      "         -4.8822, -4.8953, -4.7501, -5.0174, -4.7452, -4.2595, -4.7011, -4.5572,\n",
      "         -4.6750, -4.1707, -4.8172, -4.9871, -4.6666, -4.4489, -4.3052, -4.2772,\n",
      "         -4.7438, -4.5130, -4.3433, -4.4396, -4.8578, -4.4725, -4.4884, -4.4633,\n",
      "         -4.2712]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : of\n",
      "target index is: [57] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5001, -4.1540, -4.3037, -4.5642, -4.1498, -4.8580, -4.9729, -4.4261,\n",
      "         -4.8170, -4.7644, -5.0792, -4.5438, -4.5827, -4.5831, -4.7941, -4.7465,\n",
      "         -4.6635, -4.5704, -4.5501, -4.5546, -4.5854, -4.3372, -4.7414, -4.3726,\n",
      "         -4.0875, -4.6785, -4.4798, -4.5590, -4.2586, -4.4705, -4.6702, -5.0584,\n",
      "         -5.0355, -4.5275, -4.8667, -4.8848, -4.7852, -4.7323, -4.5677, -4.7134,\n",
      "         -4.8348, -4.4676, -4.6449, -4.4716, -4.5693, -4.3052, -4.7558, -4.9283,\n",
      "         -4.6026, -4.5190, -4.4271, -4.4102, -4.9286, -4.2104, -4.6517, -4.6442,\n",
      "         -4.4363, -4.4382, -4.4511, -4.6950, -4.9006, -4.7206, -4.3649, -4.0981,\n",
      "         -4.7032, -4.6797, -4.9964, -4.5121, -4.7702, -4.6942, -4.5488, -4.4179,\n",
      "         -4.6887, -4.8669, -4.6574, -4.7873, -4.6193, -4.1578, -4.9100, -4.9371,\n",
      "         -4.3056, -4.3469, -4.7612, -4.8111, -4.5997, -4.4878, -4.6014, -4.6896,\n",
      "         -4.7670, -4.2056, -4.7011, -4.8019, -4.6029, -4.3493, -4.2860, -4.6279,\n",
      "         -4.2949]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2165, -4.2769, -4.9023, -5.0235, -4.1698, -4.7499, -4.7758, -4.2463,\n",
      "         -5.2525, -4.3699, -5.1465, -4.1335, -4.5877, -4.3760, -4.7072, -4.9213,\n",
      "         -4.5548, -4.5802, -4.7266, -4.1895, -4.7845, -4.7468, -4.5735, -4.4927,\n",
      "         -4.7361, -4.8564, -4.3627, -4.3275, -4.4176, -4.6657, -4.7079, -4.7430,\n",
      "         -4.9907, -4.7413, -4.8001, -5.2043, -4.5665, -4.5806, -4.9085, -4.4365,\n",
      "         -4.8449, -4.6366, -4.5101, -4.3681, -4.6508, -3.9858, -4.8249, -4.6795,\n",
      "         -4.8316, -4.7323, -4.6097, -4.7379, -4.4681, -4.2826, -4.7804, -4.7991,\n",
      "         -4.4653, -4.5097, -4.6702, -4.6984, -4.6130, -4.6637, -4.2815, -4.4483,\n",
      "         -4.3063, -4.7790, -5.1554, -4.2942, -4.5968, -4.5831, -4.2458, -4.6329,\n",
      "         -4.6781, -5.0706, -4.5316, -4.6882, -4.3242, -4.1818, -4.4773, -4.5907,\n",
      "         -4.6147, -4.5687, -4.6751, -5.0193, -5.1414, -4.2546, -4.6073, -4.2956,\n",
      "         -5.0761, -4.5117, -4.4585, -4.7681, -4.8664, -4.4625, -4.1922, -4.4516,\n",
      "         -4.3273]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : lusty\n",
      "target index is: [30] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2230, -4.5896, -4.4493, -4.9503, -4.1981, -4.6908, -4.6052, -4.1693,\n",
      "         -4.6859, -4.9661, -4.9242, -4.4953, -4.4445, -4.6386, -4.8994, -4.8201,\n",
      "         -4.4165, -4.7302, -4.4282, -4.7917, -4.7147, -5.0399, -4.7669, -4.6693,\n",
      "         -4.4205, -4.7097, -4.4975, -4.4752, -4.1772, -4.5269, -4.1998, -4.6915,\n",
      "         -4.5795, -4.8528, -4.7377, -4.8746, -4.3835, -4.4484, -4.4763, -4.5082,\n",
      "         -4.8193, -4.2680, -4.7847, -4.2866, -4.6715, -4.1331, -4.5039, -4.5770,\n",
      "         -4.7711, -4.5672, -4.6250, -4.3090, -5.0788, -4.4902, -4.8510, -4.7013,\n",
      "         -4.3624, -4.3958, -4.4937, -4.6761, -4.8265, -4.3545, -4.5941, -4.1560,\n",
      "         -4.6923, -4.7604, -4.8590, -4.7988, -4.8242, -4.4038, -4.6271, -4.3692,\n",
      "         -5.0248, -4.9692, -4.7065, -4.6723, -4.9386, -3.8217, -4.7006, -5.0311,\n",
      "         -4.5347, -4.5553, -4.6431, -4.9246, -4.8219, -4.4772, -4.3870, -4.4230,\n",
      "         -5.2354, -4.3813, -4.8313, -4.4981, -4.5635, -4.5715, -4.3834, -4.7605,\n",
      "         -4.3861]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : days;\n",
      "target index is: [48] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5555, -4.7765, -4.3893, -4.4389, -3.7788, -4.7571, -4.5814, -4.4244,\n",
      "         -4.5047, -4.9446, -4.4790, -4.6043, -5.1115, -5.0044, -4.6526, -4.5741,\n",
      "         -4.9433, -5.0627, -4.6030, -4.7662, -4.6180, -4.0445, -4.7736, -4.5132,\n",
      "         -4.4271, -4.8289, -4.5801, -4.4946, -4.5761, -4.5220, -4.5901, -4.6485,\n",
      "         -4.7064, -4.6936, -4.4160, -4.9479, -4.7454, -4.8536, -4.5844, -4.5576,\n",
      "         -4.8022, -4.6496, -5.0829, -4.4488, -4.8792, -4.6894, -4.3595, -4.4284,\n",
      "         -4.2717, -4.3333, -4.4678, -4.6667, -4.8035, -4.4658, -4.6995, -3.8891,\n",
      "         -4.5565, -4.2003, -4.4939, -4.5399, -4.6581, -4.8542, -4.9522, -3.9514,\n",
      "         -5.0280, -4.3661, -4.9357, -4.4987, -4.7372, -5.0402, -4.1894, -4.4733,\n",
      "         -4.8613, -5.0051, -4.4578, -4.9959, -4.7982, -4.5692, -4.8162, -4.6318,\n",
      "         -4.7791, -4.0177, -5.0254, -4.6496, -4.4290, -4.6720, -4.5305, -5.0012,\n",
      "         -4.8501, -4.2477, -4.6997, -4.3701, -4.5016, -4.5298, -4.3896, -4.4516,\n",
      "         -4.5663]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : To\n",
      "target index is: [26] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2718, -4.6261, -4.9979, -4.9489, -4.0337, -4.7854, -4.4969, -4.6783,\n",
      "         -4.5862, -4.6254, -4.9433, -4.4542, -4.8683, -4.5066, -4.8512, -4.6449,\n",
      "         -4.1851, -4.7104, -4.8704, -4.6884, -4.3247, -4.1774, -4.9985, -4.6841,\n",
      "         -4.5409, -4.8454, -4.3660, -4.4344, -4.3751, -4.8306, -4.6190, -4.9199,\n",
      "         -4.9512, -4.9515, -4.5235, -4.5509, -4.5867, -4.5500, -5.1308, -4.6562,\n",
      "         -4.7044, -4.6944, -4.3783, -4.7110, -4.1735, -4.4054, -4.5676, -4.8245,\n",
      "         -4.4346, -5.0143, -4.2455, -4.5651, -4.6603, -4.2297, -4.8156, -4.7151,\n",
      "         -4.6592, -4.6111, -4.5080, -4.5799, -4.6329, -4.4324, -4.5523, -4.2541,\n",
      "         -4.3605, -4.8345, -4.9637, -4.4833, -4.5822, -4.2787, -4.3803, -4.4946,\n",
      "         -4.9210, -4.5340, -4.8596, -5.0135, -4.5997, -4.3370, -4.9077, -4.6693,\n",
      "         -4.1631, -4.3337, -4.5553, -4.7034, -4.4285, -4.3954, -4.6408, -4.7208,\n",
      "         -4.8509, -4.5726, -4.4940, -4.9873, -4.5158, -4.2111, -4.3888, -4.7519,\n",
      "         -4.3824]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : say,\n",
      "target index is: [96] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.8108, -4.3296, -4.6509, -4.9259, -3.9657, -4.7256, -4.6337, -4.2702,\n",
      "         -4.7637, -4.4877, -4.7576, -4.6045, -4.6808, -4.7931, -4.5835, -4.8415,\n",
      "         -4.8259, -4.3607, -4.7220, -4.2304, -4.6966, -4.5810, -4.7968, -4.7227,\n",
      "         -4.4882, -4.8518, -4.4306, -4.5045, -4.2595, -4.5190, -4.6191, -4.6124,\n",
      "         -4.8574, -4.7359, -4.5230, -4.8468, -4.4914, -4.8431, -4.5436, -4.4634,\n",
      "         -4.5829, -4.6869, -4.6747, -4.4130, -4.6842, -4.4470, -4.3910, -4.4916,\n",
      "         -4.5238, -4.6847, -4.3493, -4.8151, -4.6866, -4.5450, -4.7336, -4.3937,\n",
      "         -4.6401, -4.4348, -4.4872, -4.6667, -4.6899, -4.6662, -4.5593, -4.1834,\n",
      "         -4.5639, -4.4655, -4.5426, -4.5995, -4.5719, -4.8381, -4.6318, -4.4430,\n",
      "         -4.8169, -5.1762, -4.6666, -4.7446, -4.4191, -4.5014, -4.7204, -4.8591,\n",
      "         -4.8165, -4.3747, -4.7048, -4.6666, -4.9386, -4.2107, -4.3976, -4.7190,\n",
      "         -4.6410, -4.1272, -4.7473, -4.5390, -4.6357, -4.2694, -4.6881, -4.4074,\n",
      "         -4.4578]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : within\n",
      "target index is: [34] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2508, -4.3254, -4.7359, -4.8965, -4.4795, -4.8589, -4.5577, -4.0767,\n",
      "         -5.1371, -4.5608, -4.9845, -4.3847, -4.2909, -4.6306, -5.1596, -5.0225,\n",
      "         -4.5381, -4.5828, -4.7323, -4.5796, -4.5315, -4.7067, -4.7979, -4.9270,\n",
      "         -4.5005, -4.9419, -4.1802, -4.3723, -4.1024, -4.5177, -4.5586, -4.6548,\n",
      "         -4.9381, -4.8199, -4.8118, -4.9818, -4.7495, -4.3402, -4.5530, -4.5389,\n",
      "         -4.6893, -4.6439, -4.4014, -4.3147, -4.3387, -3.9998, -4.6999, -4.7627,\n",
      "         -4.6467, -4.7625, -4.6402, -4.1920, -4.6822, -4.5768, -4.5301, -4.6252,\n",
      "         -4.6438, -4.2538, -4.3940, -4.9866, -4.8491, -4.5900, -4.5099, -4.3681,\n",
      "         -4.3560, -4.9355, -4.9769, -4.5173, -4.5379, -4.1532, -4.4123, -4.5572,\n",
      "         -4.7495, -4.7757, -4.7009, -4.8815, -4.5245, -4.0237, -4.6031, -5.0840,\n",
      "         -4.4176, -4.7193, -4.6119, -4.9356, -4.9013, -4.6706, -4.6772, -4.3818,\n",
      "         -5.1265, -4.5902, -4.5492, -4.4180, -4.8074, -4.5306, -4.4262, -4.5322,\n",
      "         -4.3849]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thine\n",
      "target index is: [56] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1462, -4.9075, -4.1356, -4.5757, -4.0935, -4.7062, -4.8865, -4.3128,\n",
      "         -4.7053, -4.8673, -4.8013, -4.8128, -4.7444, -4.7478, -4.7587, -4.6713,\n",
      "         -4.6190, -4.7376, -4.4898, -4.9730, -4.8265, -4.5863, -4.8570, -4.4540,\n",
      "         -4.3499, -4.7465, -4.6817, -4.4986, -4.2789, -4.3621, -4.3450, -4.5582,\n",
      "         -4.6422, -4.4917, -4.6790, -4.8757, -4.3708, -4.8396, -4.6740, -4.6864,\n",
      "         -4.9878, -4.2909, -4.9568, -4.2145, -4.8622, -4.2776, -4.6005, -4.4635,\n",
      "         -4.8041, -4.3168, -4.5553, -4.7140, -5.2186, -4.5536, -4.8989, -4.5816,\n",
      "         -4.1530, -4.3837, -4.4069, -4.2979, -4.7238, -4.6005, -4.5984, -4.0286,\n",
      "         -4.7627, -4.4412, -5.0936, -4.7376, -4.9460, -4.9721, -4.4606, -4.3841,\n",
      "         -5.2541, -5.0389, -4.5608, -4.7851, -4.7232, -4.0864, -4.7929, -4.8260,\n",
      "         -4.5131, -4.0721, -4.6612, -4.8300, -4.6459, -4.6231, -4.3831, -4.5288,\n",
      "         -5.2571, -4.3066, -4.4346, -4.3738, -4.5638, -4.7940, -4.2311, -4.7019,\n",
      "         -4.4399]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : own\n",
      "target index is: [92] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4189, -4.4164, -4.4621, -4.9264, -3.7346, -4.4313, -4.7390, -4.6037,\n",
      "         -4.9139, -5.0437, -4.8555, -4.6208, -5.1447, -4.8489, -4.7828, -4.6919,\n",
      "         -4.5749, -5.1259, -4.4784, -4.3585, -4.4548, -4.0431, -4.8134, -4.5995,\n",
      "         -4.7815, -4.7521, -4.5441, -4.5971, -4.5982, -5.0259, -4.1889, -4.8368,\n",
      "         -4.6448, -4.3573, -4.1977, -4.8705, -4.6460, -5.1288, -4.8738, -4.8261,\n",
      "         -4.4718, -4.7430, -5.0927, -4.2529, -4.9609, -4.3824, -4.5955, -4.4944,\n",
      "         -4.7293, -4.6840, -4.6223, -4.7824, -4.6954, -4.5706, -4.9351, -4.1884,\n",
      "         -4.7946, -4.4812, -4.4761, -4.5542, -4.4665, -4.7437, -5.0209, -3.7792,\n",
      "         -4.7487, -4.4664, -5.1742, -4.5518, -4.6283, -4.9471, -4.4732, -4.4654,\n",
      "         -4.6220, -5.1463, -4.3905, -4.6252, -4.9820, -4.5957, -4.7620, -4.4047,\n",
      "         -4.7683, -4.1909, -4.9501, -4.8905, -4.2182, -4.5650, -4.1507, -4.5891,\n",
      "         -4.8336, -4.3743, -4.4195, -4.3409, -4.7471, -4.6333, -3.9185, -4.6633,\n",
      "         -4.3016]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : deep\n",
      "target index is: [76] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3301, -4.6479, -4.6627, -4.7909, -4.2321, -4.5363, -4.3873, -4.2426,\n",
      "         -4.6900, -4.9171, -5.0704, -4.3762, -4.5116, -4.4793, -4.6828, -4.4111,\n",
      "         -4.0884, -4.7276, -4.6419, -4.6593, -4.5799, -4.5831, -4.7249, -4.6432,\n",
      "         -4.4753, -4.6384, -4.5664, -4.5100, -4.4458, -4.6037, -4.6453, -4.8861,\n",
      "         -4.9031, -4.8581, -4.6920, -4.8111, -4.7934, -4.4473, -5.1243, -4.7259,\n",
      "         -4.7075, -4.4975, -4.8941, -4.3974, -4.5413, -4.3553, -4.6258, -4.7829,\n",
      "         -4.5276, -4.4517, -4.6079, -4.3082, -4.7951, -4.3052, -4.9363, -4.6438,\n",
      "         -4.4045, -4.6465, -4.7406, -4.5983, -4.7894, -4.6413, -4.4246, -3.9692,\n",
      "         -4.6006, -4.4675, -4.9028, -4.4264, -4.5662, -4.6096, -4.4129, -4.6140,\n",
      "         -4.5459, -4.4185, -4.4724, -4.6118, -4.7129, -4.5860, -4.7685, -4.7081,\n",
      "         -4.0829, -4.5165, -4.6893, -4.7540, -4.4681, -4.4354, -4.7866, -4.7189,\n",
      "         -4.9929, -4.4748, -4.5501, -4.8617, -4.6687, -4.6433, -4.2210, -4.5721,\n",
      "         -4.6258]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : sunken\n",
      "target index is: [91] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4650, -4.5339, -4.6868, -4.8430, -4.1719, -4.8652, -4.6168, -4.7328,\n",
      "         -4.7265, -4.4289, -4.9282, -4.4730, -4.8305, -4.7107, -4.6650, -4.8303,\n",
      "         -4.8984, -4.7843, -4.7300, -4.3610, -4.4737, -4.1869, -5.0142, -4.5152,\n",
      "         -4.5693, -4.9082, -4.3830, -4.6419, -4.3360, -4.6463, -4.8854, -4.6369,\n",
      "         -4.6619, -4.7566, -4.7429, -5.0155, -4.7123, -4.6904, -4.7819, -4.2344,\n",
      "         -4.7941, -4.7353, -4.8683, -4.3678, -4.5093, -4.5710, -4.6889, -4.5541,\n",
      "         -4.3055, -4.9386, -3.9597, -5.2216, -4.4223, -4.4442, -4.7559, -4.2537,\n",
      "         -4.7838, -4.4907, -4.4801, -4.4807, -4.5308, -4.4638, -4.6214, -3.9357,\n",
      "         -4.5149, -4.6495, -4.9904, -4.5514, -4.6221, -4.5237, -4.4069, -4.5679,\n",
      "         -4.8311, -4.8179, -4.5457, -5.0438, -4.2280, -4.5717, -4.6647, -4.5254,\n",
      "         -4.6707, -4.1653, -4.9206, -4.5752, -4.7863, -4.3013, -4.7684, -4.8198,\n",
      "         -4.7600, -4.2829, -4.4344, -4.7008, -4.5312, -4.3330, -4.5062, -4.2812,\n",
      "         -4.3700]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : eyes,\n",
      "target index is: [58] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3170, -4.4708, -5.0969, -5.3246, -3.8381, -4.6391, -4.3875, -4.4919,\n",
      "         -4.7276, -4.5997, -5.1265, -4.6355, -4.8375, -4.5920, -4.6128, -4.6837,\n",
      "         -4.5557, -4.7238, -4.9958, -4.5467, -4.7483, -4.3201, -5.1329, -4.6079,\n",
      "         -4.5632, -4.8452, -4.4188, -4.3310, -4.3316, -4.7003, -4.7647, -4.5488,\n",
      "         -4.6649, -5.0473, -4.5875, -4.7205, -4.5120, -4.5799, -5.0841, -4.2814,\n",
      "         -4.5719, -4.3584, -4.7674, -4.3893, -4.6155, -4.2756, -4.8320, -4.4546,\n",
      "         -4.4789, -5.0613, -4.3005, -4.9535, -4.5299, -4.2440, -4.4575, -4.6712,\n",
      "         -4.5414, -4.7984, -4.6269, -4.4284, -4.5676, -4.3475, -4.1036, -4.4249,\n",
      "         -4.2612, -4.7201, -4.7295, -4.5311, -4.6243, -4.2772, -4.4916, -4.5700,\n",
      "         -4.8975, -4.8385, -4.7716, -4.8138, -4.4819, -4.4824, -4.7456, -4.7262,\n",
      "         -4.4490, -4.4921, -4.9209, -4.9063, -4.9069, -4.0390, -4.6180, -4.6330,\n",
      "         -4.6814, -4.4332, -4.8221, -4.6383, -4.8468, -4.1866, -4.6800, -4.6141,\n",
      "         -4.2381]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Were\n",
      "target index is: [37] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2603, -4.4835, -4.7053, -4.6582, -4.2065, -4.7066, -4.4558, -4.2930,\n",
      "         -4.7992, -4.9123, -4.5907, -4.4420, -4.5475, -4.8172, -4.9958, -4.6751,\n",
      "         -4.6969, -4.5653, -4.6859, -4.6889, -4.3343, -4.4460, -4.9353, -5.0165,\n",
      "         -4.3159, -4.9315, -4.5668, -4.4077, -4.1708, -4.4295, -4.6070, -4.6404,\n",
      "         -4.5735, -4.8581, -4.3529, -4.8290, -4.8596, -4.3763, -4.7525, -4.3683,\n",
      "         -4.7137, -4.5236, -4.6791, -4.6544, -4.5700, -4.1870, -4.2611, -4.7892,\n",
      "         -4.4907, -4.8664, -4.7156, -4.3060, -4.8219, -4.4895, -4.4699, -4.4536,\n",
      "         -4.3843, -4.4458, -4.4329, -4.8951, -4.6423, -4.1268, -4.5649, -4.3108,\n",
      "         -4.5021, -4.6912, -4.6107, -4.3538, -4.7156, -4.1553, -4.5182, -4.5499,\n",
      "         -4.6960, -5.1055, -4.9959, -4.9366, -4.6467, -4.2643, -4.8449, -4.8940,\n",
      "         -4.5784, -4.6786, -4.7494, -4.7958, -4.6235, -4.3363, -4.4445, -4.8165,\n",
      "         -4.8914, -4.4069, -4.8036, -4.4849, -4.6228, -4.5217, -4.8302, -4.6778,\n",
      "         -4.6019]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : an\n",
      "target index is: [74] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5250, -4.6847, -4.6712, -4.5007, -4.0916, -4.9880, -4.6804, -4.5295,\n",
      "         -4.7059, -4.4756, -4.9657, -4.7119, -4.8458, -4.9311, -4.7712, -4.8484,\n",
      "         -4.8043, -4.5801, -4.6668, -4.7526, -4.3788, -4.0581, -4.8966, -4.8621,\n",
      "         -4.4402, -5.2001, -4.3547, -4.1970, -4.6195, -4.3561, -4.8310, -4.5415,\n",
      "         -4.8667, -4.9036, -4.3861, -4.7094, -4.7470, -4.5755, -4.7630, -4.4607,\n",
      "         -4.9028, -4.7559, -4.5872, -4.5133, -4.4369, -4.4099, -4.5425, -4.5543,\n",
      "         -4.3350, -4.9974, -4.4165, -4.4440, -4.6794, -4.3688, -4.4381, -4.3409,\n",
      "         -4.4474, -4.3626, -4.2149, -4.8071, -4.6251, -4.5802, -4.5810, -4.3077,\n",
      "         -4.6047, -4.3829, -4.8442, -4.2800, -4.7253, -4.5625, -4.3553, -4.6194,\n",
      "         -4.8371, -4.8447, -5.0230, -5.1150, -4.3590, -4.2372, -4.6713, -4.8699,\n",
      "         -4.3894, -4.5635, -4.4483, -4.7988, -4.5084, -4.2943, -4.6549, -5.0289,\n",
      "         -4.8030, -4.5542, -4.4004, -4.4332, -4.5676, -4.5260, -4.6147, -4.4890,\n",
      "         -4.3540]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : all-eating\n",
      "target index is: [60] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4893, -4.5519, -4.8581, -4.7445, -3.9441, -4.7259, -4.7506, -4.4035,\n",
      "         -4.8226, -4.4095, -5.0381, -4.6606, -4.8957, -4.6141, -4.7062, -4.7029,\n",
      "         -4.4548, -4.4411, -4.8142, -4.5311, -4.7492, -4.5901, -4.9855, -4.8910,\n",
      "         -4.7220, -4.9163, -4.6887, -4.2423, -4.2401, -4.3974, -4.5359, -4.5427,\n",
      "         -4.8691, -4.9000, -4.3633, -4.7514, -4.2978, -4.9435, -4.8098, -4.5972,\n",
      "         -4.7688, -4.5342, -4.4676, -4.5386, -4.3966, -4.4257, -4.5224, -4.6284,\n",
      "         -4.6711, -4.8599, -4.4964, -4.8049, -4.8708, -4.2099, -4.6428, -4.7584,\n",
      "         -4.2999, -4.4421, -4.6391, -4.4721, -4.6773, -4.6383, -4.4572, -4.4414,\n",
      "         -4.4329, -4.4198, -4.6002, -4.2717, -4.7691, -4.5796, -4.3792, -4.2226,\n",
      "         -5.0667, -4.9307, -4.7513, -4.8062, -4.3943, -4.3211, -4.6723, -5.0175,\n",
      "         -4.4294, -4.3051, -4.3087, -4.9364, -4.9662, -4.0473, -4.7209, -4.5497,\n",
      "         -4.8783, -4.1978, -4.5314, -4.6524, -4.7511, -4.4715, -4.5994, -4.5552,\n",
      "         -4.5492]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : shame,\n",
      "target index is: [41] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6951, -4.7219, -4.8630, -4.4958, -4.1661, -4.6017, -4.6981, -4.4256,\n",
      "         -4.5903, -4.6298, -4.5937, -4.4872, -4.8600, -4.7403, -4.7787, -4.4927,\n",
      "         -4.4386, -4.9008, -4.5629, -4.5321, -4.5594, -4.2319, -4.7997, -4.5976,\n",
      "         -4.5568, -4.9620, -4.3828, -4.5171, -4.4870, -4.5909, -4.4083, -4.9978,\n",
      "         -5.1291, -4.7737, -4.5517, -4.7152, -4.5157, -5.0292, -4.8304, -4.7096,\n",
      "         -4.8110, -4.3740, -4.5111, -4.5789, -4.5967, -4.4758, -4.6337, -4.6547,\n",
      "         -4.4123, -4.6555, -4.8510, -4.2204, -4.8572, -4.3149, -4.8930, -4.1392,\n",
      "         -4.4522, -4.3275, -4.4176, -4.4730, -4.6412, -5.0137, -4.6850, -4.1948,\n",
      "         -4.7671, -4.2388, -5.0326, -4.4887, -4.6216, -4.6708, -3.9600, -4.4178,\n",
      "         -4.7587, -4.6141, -4.5980, -4.8622, -4.9348, -4.3069, -5.0782, -4.8615,\n",
      "         -4.6707, -4.4499, -4.4551, -4.5855, -4.3049, -4.5431, -4.3830, -4.7544,\n",
      "         -4.7606, -4.1668, -4.7333, -4.4024, -4.7416, -4.6445, -4.4682, -4.7317,\n",
      "         -4.4532]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : and\n",
      "target index is: [44] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7188, -4.5009, -4.5489, -4.6158, -4.1866, -4.7399, -4.5402, -4.3826,\n",
      "         -4.7099, -4.7948, -4.4653, -4.4602, -4.8404, -4.8723, -4.5429, -4.4980,\n",
      "         -4.6192, -4.8984, -4.6255, -4.6002, -4.3507, -4.2931, -4.5508, -4.4687,\n",
      "         -4.5196, -4.7072, -4.3876, -4.4383, -4.6221, -4.5323, -4.6416, -4.8315,\n",
      "         -4.8183, -4.7157, -4.4012, -4.4887, -4.7833, -4.9107, -4.6244, -4.5278,\n",
      "         -4.7763, -4.6766, -4.8694, -4.5855, -4.5867, -4.6035, -4.3810, -4.5930,\n",
      "         -4.2714, -4.5420, -4.6090, -4.5587, -4.6430, -4.3606, -4.9106, -4.4681,\n",
      "         -4.7214, -4.6616, -4.6247, -4.6485, -4.8159, -4.7686, -4.7679, -4.1613,\n",
      "         -4.9130, -4.4386, -4.8655, -4.3721, -4.6320, -4.8301, -4.2855, -4.7601,\n",
      "         -4.6168, -4.6503, -4.3899, -4.7433, -4.6278, -4.4612, -4.9093, -4.4205,\n",
      "         -4.4744, -4.3373, -4.6816, -4.6673, -4.5909, -4.3610, -4.6002, -4.7948,\n",
      "         -4.8729, -4.1287, -4.8334, -4.7549, -4.3146, -4.3293, -4.4241, -4.4166,\n",
      "         -4.5623]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thriftless\n",
      "target index is: [43] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4130, -4.4405, -4.5464, -4.7422, -4.0822, -4.5586, -4.6820, -4.4651,\n",
      "         -4.7266, -4.5076, -4.9270, -4.4050, -4.8016, -4.6520, -4.6332, -4.8973,\n",
      "         -4.8722, -4.5459, -4.8687, -4.1830, -4.6787, -4.7925, -4.6749, -4.6186,\n",
      "         -4.8556, -4.7489, -4.5541, -4.4367, -4.1755, -4.7050, -4.6819, -4.5132,\n",
      "         -4.7345, -4.5357, -4.6299, -5.0269, -4.6361, -4.9081, -4.5268, -4.4610,\n",
      "         -4.5397, -4.5893, -4.7541, -4.1865, -4.4607, -4.2806, -4.4568, -4.1463,\n",
      "         -4.5482, -4.6930, -4.8461, -4.9210, -4.6628, -4.6214, -4.8997, -4.7303,\n",
      "         -4.3972, -4.4932, -4.5340, -4.6880, -4.5725, -4.7474, -4.5579, -4.3578,\n",
      "         -4.6472, -4.8213, -4.9226, -4.3857, -4.4899, -4.7037, -4.1875, -4.6382,\n",
      "         -4.7774, -5.1088, -4.5721, -4.5685, -4.5077, -4.4887, -4.6464, -4.3521,\n",
      "         -4.7642, -4.3137, -4.5215, -4.8086, -5.0278, -4.2944, -4.4744, -4.5060,\n",
      "         -5.2545, -4.4241, -4.7534, -4.4345, -4.5430, -4.5414, -4.2153, -4.2669,\n",
      "         -4.5840]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : praise.\n",
      "target index is: [94] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-3.9444, -5.0397, -4.7187, -5.1074, -3.7744, -4.7195, -4.8534, -4.3859,\n",
      "         -4.6853, -4.9950, -4.6724, -4.3145, -4.6629, -4.5935, -4.7827, -4.5464,\n",
      "         -4.8632, -5.0530, -4.6950, -4.5255, -4.7845, -4.0285, -5.1771, -4.9548,\n",
      "         -4.4715, -4.8422, -4.4847, -4.0774, -3.8891, -4.8547, -4.5818, -4.7946,\n",
      "         -4.8382, -4.7513, -4.4250, -5.2863, -4.7139, -4.6517, -4.9874, -4.9072,\n",
      "         -4.6498, -4.3137, -4.9508, -4.5395, -4.7053, -4.3878, -4.8275, -4.6363,\n",
      "         -4.7310, -4.8278, -4.3067, -4.8076, -4.4652, -4.6027, -4.8374, -4.5193,\n",
      "         -3.9138, -4.4521, -4.5066, -4.7205, -4.3965, -4.4804, -4.3191, -4.2521,\n",
      "         -4.5709, -4.6178, -5.0868, -4.9546, -4.8787, -4.8557, -4.1678, -4.2327,\n",
      "         -4.8975, -5.1342, -4.5613, -4.5239, -4.8351, -4.0586, -4.6504, -4.4547,\n",
      "         -4.6156, -4.1951, -5.2154, -5.0537, -4.0984, -4.6355, -4.2698, -4.7544,\n",
      "         -5.1942, -4.9556, -5.0727, -4.2484, -4.7598, -4.3586, -4.5209, -4.4092,\n",
      "         -4.4543]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : How\n",
      "target index is: [12] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2129, -4.6587, -4.5206, -5.0603, -3.9961, -4.9835, -4.6777, -4.3799,\n",
      "         -5.1380, -4.9315, -5.0267, -5.0948, -4.7658, -4.5222, -5.3202, -5.0605,\n",
      "         -4.8395, -4.4265, -4.7879, -4.6976, -4.6372, -4.8420, -4.8900, -5.0185,\n",
      "         -4.4663, -5.1404, -4.5669, -4.1738, -4.2489, -4.6018, -4.3102, -3.9793,\n",
      "         -4.6210, -4.6895, -4.4367, -5.1701, -4.5267, -4.5065, -4.5050, -4.5081,\n",
      "         -4.3590, -4.8696, -4.7879, -4.1530, -4.6046, -3.9704, -4.4867, -4.1276,\n",
      "         -5.0599, -4.5332, -4.4135, -4.7711, -4.7056, -4.7242, -4.5126, -4.7805,\n",
      "         -4.4141, -4.5125, -4.2585, -4.6857, -4.6779, -4.3272, -4.2495, -4.1675,\n",
      "         -4.5293, -4.8762, -4.7012, -4.3225, -4.4683, -4.4057, -4.5428, -4.2760,\n",
      "         -5.2984, -5.3729, -4.9488, -4.7649, -4.5793, -4.0848, -4.6862, -4.5588,\n",
      "         -4.6895, -4.9451, -4.6767, -5.1651, -4.9818, -4.1051, -4.1186, -4.8170,\n",
      "         -5.5672, -4.3959, -4.4651, -4.1143, -4.8481, -4.8275, -4.3976, -4.7720,\n",
      "         -4.5228]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : much\n",
      "target index is: [68] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4896, -5.0039, -4.6461, -4.4309, -3.6082, -4.4906, -4.7860, -4.2636,\n",
      "         -4.9855, -4.5179, -4.5103, -4.4702, -4.8874, -4.8435, -4.9619, -4.7830,\n",
      "         -4.7811, -4.8424, -4.0873, -4.8752, -4.7430, -4.1022, -5.0859, -4.8149,\n",
      "         -4.5598, -5.0850, -4.5384, -4.3442, -4.5712, -4.6041, -4.2188, -4.9723,\n",
      "         -4.6715, -4.4706, -4.4389, -5.3177, -4.4824, -5.0457, -4.7174, -4.9889,\n",
      "         -4.8598, -4.5862, -4.9675, -4.6126, -4.8688, -4.3831, -4.6305, -5.1041,\n",
      "         -4.9783, -4.6000, -4.8870, -4.4388, -5.0651, -4.0937, -4.5741, -3.9661,\n",
      "         -4.2031, -4.0389, -4.2133, -4.1869, -4.5447, -4.8392, -4.5612, -3.8037,\n",
      "         -4.6009, -4.3521, -4.6836, -4.4633, -5.1192, -4.7386, -4.4234, -4.2458,\n",
      "         -5.4970, -5.0792, -4.5659, -5.0446, -4.9648, -4.1458, -4.7332, -5.1637,\n",
      "         -4.9320, -4.0952, -4.9581, -4.8548, -4.3111, -4.5924, -4.5578, -4.8371,\n",
      "         -5.2979, -4.4878, -4.8831, -4.0899, -4.6949, -4.5991, -4.2895, -5.1559,\n",
      "         -4.3455]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : more\n",
      "target index is: [4] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3467, -4.8188, -4.7071, -4.3801, -4.1571, -4.6204, -4.8955, -4.4320,\n",
      "         -4.8671, -4.4804, -4.8793, -4.3188, -4.7479, -4.4044, -4.8309, -4.7648,\n",
      "         -4.5831, -4.7732, -4.6796, -4.6571, -4.4234, -4.4444, -4.7081, -4.6195,\n",
      "         -4.5824, -4.8070, -4.5909, -4.4445, -4.3720, -4.5613, -4.7682, -4.6834,\n",
      "         -4.8839, -4.5393, -4.8952, -4.9962, -4.8986, -4.6734, -4.7682, -4.6482,\n",
      "         -4.6065, -4.5428, -4.6101, -4.4999, -4.0870, -4.3543, -4.5231, -4.6976,\n",
      "         -4.7011, -4.5500, -4.9357, -4.3108, -4.7747, -4.3255, -4.8110, -4.3750,\n",
      "         -4.4703, -4.2423, -4.4703, -4.6640, -4.6075, -4.6366, -4.5843, -3.8673,\n",
      "         -4.4865, -4.6034, -4.8345, -4.5847, -4.6450, -4.5855, -4.0043, -4.5384,\n",
      "         -4.6994, -4.4739, -4.4923, -4.8267, -4.7018, -4.4974, -4.8070, -4.8122,\n",
      "         -4.5601, -4.2503, -4.6597, -4.7832, -4.5213, -4.5768, -4.7666, -4.7206,\n",
      "         -5.2175, -4.4953, -4.7232, -4.6909, -4.6445, -4.5399, -4.1047, -4.9139,\n",
      "         -4.5194]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : praise\n",
      "target index is: [45] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4806, -4.4762, -4.7406, -5.2017, -4.0254, -4.5859, -4.5077, -4.2482,\n",
      "         -5.2281, -4.5801, -4.8375, -4.3352, -4.8169, -4.5831, -5.0731, -4.8100,\n",
      "         -4.6405, -4.4803, -4.7690, -4.1975, -4.7206, -4.6840, -5.0092, -4.7647,\n",
      "         -4.9565, -4.9152, -4.5001, -4.2230, -4.3269, -4.6208, -4.3021, -4.4168,\n",
      "         -4.8387, -4.8187, -4.4774, -5.1772, -4.3449, -5.0488, -4.5043, -4.5818,\n",
      "         -4.4862, -4.5888, -4.7357, -4.1377, -4.6555, -4.0782, -4.7242, -4.3848,\n",
      "         -4.8226, -5.1194, -4.2375, -5.0789, -4.4622, -4.7296, -4.5466, -4.6427,\n",
      "         -4.3620, -4.5503, -4.4272, -4.5530, -4.5473, -4.3320, -4.6097, -4.3431,\n",
      "         -4.3009, -4.6244, -5.2288, -4.5417, -4.5910, -4.3260, -4.6894, -4.5998,\n",
      "         -5.2170, -5.3285, -4.6771, -4.9029, -4.5913, -4.0823, -4.4669, -4.4368,\n",
      "         -4.9107, -4.6339, -4.7353, -5.0312, -4.9837, -4.2429, -4.1707, -4.2786,\n",
      "         -5.1221, -4.6526, -4.6001, -4.0050, -5.0600, -4.5080, -4.6532, -4.3864,\n",
      "         -4.3519]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : deserv'd\n",
      "target index is: [66] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4342, -4.6949, -4.5871, -4.3432, -4.0746, -4.7259, -4.6833, -4.3533,\n",
      "         -4.8439, -4.8267, -4.4705, -4.7433, -4.7938, -4.7449, -4.8882, -4.8055,\n",
      "         -4.8061, -4.8459, -4.5008, -4.8918, -4.4288, -4.4688, -4.8418, -4.6304,\n",
      "         -4.3030, -5.0925, -4.6812, -4.5067, -4.3075, -4.6590, -4.2092, -4.7003,\n",
      "         -4.8113, -4.7310, -4.5553, -5.2187, -4.5097, -4.6545, -4.5515, -4.6092,\n",
      "         -4.7973, -4.5834, -4.8266, -4.5086, -4.8414, -4.2462, -4.7495, -4.5538,\n",
      "         -4.7977, -4.4547, -4.8191, -4.3187, -5.1637, -4.4147, -4.5664, -4.4560,\n",
      "         -4.0544, -4.2165, -4.2332, -4.4538, -4.6490, -4.4611, -4.6010, -4.1901,\n",
      "         -4.6288, -4.4214, -4.6491, -4.2709, -4.5676, -4.3408, -4.5186, -4.4373,\n",
      "         -5.2496, -4.9434, -4.8736, -4.9505, -4.9924, -3.9816, -4.9648, -4.9064,\n",
      "         -4.6369, -4.4588, -4.8793, -4.8724, -4.6515, -4.2927, -4.1721, -4.6421,\n",
      "         -5.2013, -4.3037, -4.4660, -4.4784, -4.7688, -4.6824, -4.2404, -4.8130,\n",
      "         -4.3594]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3664, -4.2262, -4.9110, -4.6735, -4.2434, -4.7751, -4.8911, -4.2093,\n",
      "         -5.0411, -4.7775, -5.3379, -4.4849, -4.4175, -4.7098, -4.5983, -4.7278,\n",
      "         -4.4852, -4.5444, -4.3481, -4.4593, -4.6332, -4.2220, -4.7790, -4.7189,\n",
      "         -4.3864, -5.0082, -4.2949, -4.4660, -4.5412, -4.6372, -4.7874, -4.8012,\n",
      "         -5.2049, -4.6515, -4.6219, -5.0425, -4.6876, -4.7804, -5.0248, -4.8719,\n",
      "         -4.8392, -4.6960, -4.7999, -4.5717, -4.7577, -4.0046, -4.8282, -4.8937,\n",
      "         -4.8220, -4.5066, -4.8313, -4.3273, -4.5651, -4.1691, -4.4815, -4.7531,\n",
      "         -4.3073, -4.2062, -4.5507, -4.6021, -4.7550, -4.7083, -4.1224, -4.3472,\n",
      "         -4.4293, -4.6930, -4.8762, -4.2036, -4.8346, -4.7777, -4.3006, -4.4657,\n",
      "         -4.7776, -4.8538, -4.6909, -4.6466, -4.3509, -4.2905, -4.5851, -4.7423,\n",
      "         -4.2064, -4.6468, -4.7899, -5.0723, -4.6359, -4.4464, -4.7525, -4.8858,\n",
      "         -4.7759, -4.4070, -4.6201, -4.7436, -4.9468, -4.2686, -3.8303, -4.9213,\n",
      "         -4.1259]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty's\n",
      "target index is: [80] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2961, -4.4862, -4.7820, -4.5206, -4.1858, -4.9223, -4.6162, -4.3300,\n",
      "         -4.3732, -5.1080, -4.9815, -4.3036, -4.6931, -4.7191, -4.6097, -4.7467,\n",
      "         -4.8726, -5.1395, -4.5444, -4.3881, -4.9317, -4.7376, -4.6523, -4.4742,\n",
      "         -4.2047, -4.6490, -4.6453, -4.4108, -3.8361, -4.5537, -4.8007, -4.6001,\n",
      "         -4.7181, -4.5435, -4.6169, -5.1402, -4.8512, -4.6140, -4.6600, -4.4966,\n",
      "         -4.6742, -4.2172, -4.9945, -4.0371, -4.5129, -4.0759, -4.4149, -4.4908,\n",
      "         -4.5446, -4.8991, -4.7757, -4.4673, -4.7537, -4.3097, -4.6092, -4.4001,\n",
      "         -4.2904, -4.3458, -4.7185, -5.0425, -4.8201, -4.1840, -4.4527, -4.0692,\n",
      "         -5.0398, -4.7894, -5.0870, -4.6644, -4.8226, -4.6329, -4.2734, -4.6982,\n",
      "         -4.5240, -4.8517, -4.7956, -4.8969, -5.2016, -4.2643, -4.7564, -4.4700,\n",
      "         -4.7879, -4.3260, -5.2129, -4.8290, -4.8637, -4.1168, -4.6090, -5.0075,\n",
      "         -5.0173, -4.5759, -5.2510, -4.4786, -4.6010, -4.4771, -4.2671, -4.2847,\n",
      "         -4.5041]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : use,\n",
      "target index is: [11] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2128, -4.6102, -4.9705, -5.2667, -3.7303, -5.0844, -4.6889, -4.6049,\n",
      "         -4.7178, -4.5669, -4.9067, -4.7608, -5.3295, -4.8942, -4.6423, -4.8226,\n",
      "         -5.0094, -4.4800, -4.6946, -4.4140, -4.8161, -4.0774, -5.2733, -4.6424,\n",
      "         -4.3872, -4.8809, -4.2516, -4.1571, -4.0755, -5.0161, -4.7371, -4.6062,\n",
      "         -4.7880, -4.6062, -4.9534, -5.1840, -5.1035, -4.7857, -5.1168, -4.6763,\n",
      "         -4.6671, -5.3087, -4.9767, -4.6018, -4.7233, -4.4167, -4.7732, -4.3349,\n",
      "         -4.3871, -4.8756, -3.9727, -5.4843, -4.3381, -4.4985, -4.8446, -4.3339,\n",
      "         -4.4794, -4.3999, -4.3503, -4.1990, -4.6704, -4.5912, -4.3238, -3.5864,\n",
      "         -4.5617, -4.8542, -4.9209, -4.8427, -4.3733, -4.4935, -4.1977, -4.5399,\n",
      "         -5.1146, -4.7389, -4.6592, -4.8500, -4.1539, -4.6126, -4.7752, -4.4675,\n",
      "         -4.6490, -4.0263, -5.4920, -5.0588, -4.5971, -4.6342, -4.6161, -4.9639,\n",
      "         -4.7793, -4.3335, -4.3358, -4.4137, -4.6260, -4.0632, -4.2807, -4.6249,\n",
      "         -4.6070]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : If\n",
      "target index is: [61] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7474, -4.2996, -4.9273, -4.9505, -4.4354, -4.7646, -4.8294, -4.2684,\n",
      "         -4.6206, -4.7711, -4.8273, -4.1582, -4.7368, -4.4836, -4.8485, -4.8368,\n",
      "         -4.3781, -4.6302, -4.9034, -4.4732, -4.4946, -4.8923, -4.9573, -4.5842,\n",
      "         -4.5817, -4.8535, -4.4877, -4.2615, -4.3266, -4.4893, -4.4049, -4.7624,\n",
      "         -5.2215, -4.6865, -4.9603, -5.3557, -4.3986, -4.9316, -4.4694, -4.4700,\n",
      "         -4.3019, -4.8325, -4.2516, -4.4494, -4.2624, -4.3486, -4.5160, -4.7756,\n",
      "         -4.5645, -4.8440, -4.3288, -4.3702, -4.6318, -4.3521, -4.5214, -4.5061,\n",
      "         -4.5949, -4.4147, -4.8429, -4.6212, -4.5987, -4.2973, -4.4505, -3.7058,\n",
      "         -4.3966, -4.4134, -4.7693, -4.6331, -4.3246, -3.9803, -4.4932, -4.5207,\n",
      "         -4.8760, -4.8916, -5.0759, -5.0217, -4.8294, -4.0440, -4.8924, -4.8007,\n",
      "         -5.0593, -4.5467, -4.9034, -5.1417, -5.0050, -4.3286, -4.4058, -4.5638,\n",
      "         -5.0639, -4.1485, -4.7087, -4.8605, -4.9373, -4.2625, -4.6197, -4.8045,\n",
      "         -4.6290]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thou\n",
      "target index is: [22] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5652, -4.4335, -4.9628, -4.6226, -4.3909, -4.8738, -4.5000, -4.3724,\n",
      "         -4.4287, -4.7306, -4.5958, -4.4714, -4.7650, -4.8938, -4.6100, -4.5791,\n",
      "         -4.7349, -5.0993, -4.5237, -4.3947, -4.5556, -4.4470, -4.8797, -4.3271,\n",
      "         -4.2629, -4.5633, -4.4730, -4.6659, -4.5116, -4.7100, -4.8815, -4.9395,\n",
      "         -4.6989, -4.7210, -4.3447, -4.5233, -4.5375, -4.6696, -4.7045, -4.4937,\n",
      "         -5.0381, -4.1535, -4.8442, -4.7377, -4.4888, -4.3644, -4.3508, -4.6026,\n",
      "         -4.1471, -5.1575, -4.8529, -4.2600, -4.7464, -4.3454, -4.6886, -4.4251,\n",
      "         -4.5298, -4.4769, -4.4979, -4.7094, -4.7411, -4.4878, -4.2820, -4.4067,\n",
      "         -4.9389, -4.6441, -4.5573, -4.4602, -4.5881, -4.4638, -4.1590, -4.9015,\n",
      "         -4.5212, -4.7435, -4.6705, -4.8997, -4.5547, -4.3976, -4.8364, -4.4312,\n",
      "         -4.6352, -4.5739, -4.8632, -4.4690, -4.5258, -4.6199, -4.6918, -4.7028,\n",
      "         -4.7741, -4.2957, -5.0442, -4.3942, -4.5615, -4.5229, -4.6460, -4.5184,\n",
      "         -4.4597]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : couldst\n",
      "target index is: [47] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4922, -4.3384, -4.4766, -4.7812, -4.2030, -4.8100, -4.7879, -4.3653,\n",
      "         -4.6325, -4.7768, -4.6192, -4.4994, -4.6247, -4.8717, -4.6960, -4.2988,\n",
      "         -4.5636, -4.5472, -4.4406, -4.5849, -4.5218, -4.3016, -4.7341, -4.7709,\n",
      "         -4.2967, -4.5904, -4.4475, -4.6142, -4.2792, -4.6821, -4.5419, -4.8139,\n",
      "         -4.8129, -4.4779, -4.6460, -4.8190, -4.5845, -4.7937, -4.7699, -4.8352,\n",
      "         -4.5972, -4.7258, -4.7883, -4.6739, -4.6390, -4.5491, -4.6629, -4.7666,\n",
      "         -4.5770, -4.6019, -4.4923, -4.6264, -4.6510, -4.5330, -4.7475, -4.6445,\n",
      "         -4.4292, -4.5110, -4.4276, -4.4771, -4.7834, -4.6373, -4.4205, -4.1338,\n",
      "         -4.7515, -4.4603, -4.7969, -4.6945, -4.4961, -4.5974, -4.3736, -4.3712,\n",
      "         -4.7705, -4.8488, -4.7108, -4.7192, -4.3937, -4.3646, -4.8900, -4.6526,\n",
      "         -4.4900, -4.4027, -4.7939, -4.8047, -4.5016, -4.6167, -4.3780, -4.6662,\n",
      "         -4.6279, -4.3281, -4.5489, -4.7435, -4.6545, -4.2718, -4.4182, -4.5952,\n",
      "         -4.5756]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : answer\n",
      "target index is: [53] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4129, -4.7256, -4.7296, -4.7780, -4.2089, -4.5536, -4.7152, -4.2952,\n",
      "         -4.8057, -4.8201, -4.7356, -4.4044, -4.5379, -4.7245, -4.8315, -4.6597,\n",
      "         -4.2533, -4.6402, -4.3757, -4.6699, -4.5743, -4.3795, -4.6479, -4.5119,\n",
      "         -4.3029, -5.0270, -4.3258, -4.8169, -4.5501, -4.5179, -4.5497, -4.7327,\n",
      "         -4.7898, -4.7073, -4.3818, -4.8707, -4.5599, -4.3485, -4.7990, -4.7987,\n",
      "         -4.7763, -4.6172, -4.8008, -4.6383, -4.3870, -4.3173, -4.5522, -4.7123,\n",
      "         -4.7616, -4.3446, -4.7904, -4.4437, -4.8358, -4.3696, -4.5924, -4.5186,\n",
      "         -4.6083, -4.4573, -4.4145, -4.4563, -4.6043, -4.5749, -4.4557, -3.9719,\n",
      "         -4.5467, -4.5987, -4.8072, -4.6078, -4.6395, -4.5558, -4.4110, -4.5673,\n",
      "         -4.8027, -4.6666, -4.8384, -4.7686, -4.4153, -4.2869, -4.6916, -4.9230,\n",
      "         -4.4176, -4.6105, -4.6931, -4.8306, -4.6327, -4.7121, -4.4853, -4.5627,\n",
      "         -5.0972, -4.3363, -4.4478, -4.6727, -4.7630, -4.5037, -4.4884, -4.8144,\n",
      "         -4.3198]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : 'This\n",
      "target index is: [9] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4296, -4.6930, -4.8706, -4.6971, -3.7150, -4.6339, -4.4411, -4.3443,\n",
      "         -4.8952, -4.8393, -4.9157, -4.5898, -4.8713, -4.7608, -4.7821, -4.8151,\n",
      "         -4.4297, -4.8581, -4.7195, -4.5321, -4.4761, -4.4087, -4.9007, -4.3942,\n",
      "         -4.5565, -4.9665, -4.4537, -4.4502, -4.5511, -4.7485, -4.5238, -4.6749,\n",
      "         -4.6136, -4.9038, -4.3054, -4.6495, -4.5567, -4.7687, -4.8365, -4.3694,\n",
      "         -4.8100, -4.2238, -4.7205, -4.3828, -4.7354, -4.1413, -4.5073, -4.5569,\n",
      "         -4.6061, -4.8318, -4.9163, -4.4850, -5.0079, -3.9896, -4.4183, -4.2380,\n",
      "         -4.5904, -4.4087, -4.6450, -4.5692, -4.5012, -4.4248, -4.6314, -4.4426,\n",
      "         -4.4628, -4.6764, -4.4651, -4.2140, -4.6721, -4.7524, -4.3792, -4.5530,\n",
      "         -4.7885, -5.0633, -4.9003, -5.0168, -4.7854, -4.3977, -4.8284, -4.7902,\n",
      "         -4.7504, -4.4630, -4.7043, -4.8166, -4.6246, -4.2240, -4.3932, -4.8349,\n",
      "         -4.9328, -4.3663, -4.7148, -4.4644, -4.6078, -4.6578, -4.5101, -4.6963,\n",
      "         -4.3115]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : fair\n",
      "target index is: [21] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4116, -4.4327, -4.8705, -4.6020, -4.0995, -4.6418, -4.8367, -4.2882,\n",
      "         -4.6851, -4.4034, -4.8263, -4.4676, -4.6323, -4.6763, -4.7578, -4.5922,\n",
      "         -4.6195, -4.4868, -4.5856, -4.3775, -4.5650, -4.2476, -4.9444, -4.9071,\n",
      "         -4.4904, -4.7685, -4.4400, -4.3790, -4.2803, -4.6340, -4.6125, -4.6984,\n",
      "         -4.9892, -4.7725, -4.4859, -4.6655, -4.7933, -4.7892, -5.1436, -4.8390,\n",
      "         -4.7529, -4.5591, -4.4636, -4.6812, -4.4285, -4.2495, -4.5893, -4.8109,\n",
      "         -4.5412, -4.8612, -4.6949, -4.2949, -4.7110, -4.3774, -4.6990, -4.6849,\n",
      "         -4.2623, -4.3979, -4.4954, -4.5770, -4.6764, -4.5607, -4.5810, -4.4340,\n",
      "         -4.4478, -4.7237, -4.6902, -4.5326, -4.7963, -4.6427, -4.3366, -4.5782,\n",
      "         -4.6216, -4.8830, -4.5903, -4.6593, -4.5298, -4.4917, -4.7585, -4.7504,\n",
      "         -4.4126, -4.3165, -4.5264, -4.7018, -4.5793, -4.2694, -4.7886, -4.7381,\n",
      "         -4.7299, -4.3771, -4.8616, -4.7992, -4.7516, -4.1814, -4.3697, -4.6586,\n",
      "         -4.3960]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : child\n",
      "target index is: [5] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3818, -4.4196, -5.0122, -4.6476, -4.1058, -4.7709, -4.6435, -4.6825,\n",
      "         -4.6997, -4.4776, -4.9982, -4.5519, -4.8931, -4.7611, -4.7596, -4.8673,\n",
      "         -4.5543, -4.6864, -4.7986, -4.4606, -4.5487, -4.3805, -4.9568, -4.6261,\n",
      "         -4.7482, -5.2231, -4.5536, -4.4665, -4.1493, -4.7090, -4.4814, -4.7810,\n",
      "         -4.7052, -4.6790, -4.5481, -4.8018, -4.4695, -4.6720, -4.7028, -4.5083,\n",
      "         -4.6459, -4.4613, -4.4987, -4.3800, -4.5951, -4.2388, -4.7122, -4.5762,\n",
      "         -4.6003, -4.8974, -4.7399, -4.6046, -5.0515, -4.3491, -4.3866, -4.2307,\n",
      "         -4.3313, -4.3032, -4.5593, -4.7652, -4.5277, -4.3962, -4.7673, -4.4046,\n",
      "         -4.4402, -4.5815, -4.7879, -4.2997, -4.4633, -4.3995, -4.3981, -4.5157,\n",
      "         -4.8049, -4.9854, -5.0158, -5.2068, -4.8709, -4.2631, -4.7621, -4.7779,\n",
      "         -4.6342, -4.3701, -4.6575, -5.0117, -4.7114, -4.1599, -4.3799, -4.2999,\n",
      "         -4.8642, -4.4168, -4.4596, -4.3580, -4.6458, -4.5250, -4.6135, -4.5549,\n",
      "         -4.1674]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : of\n",
      "target index is: [57] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6243, -4.0474, -4.5551, -4.7200, -4.0833, -4.8369, -4.8590, -4.5177,\n",
      "         -4.7542, -4.8526, -5.0949, -4.4880, -4.5728, -4.5562, -4.6729, -4.5767,\n",
      "         -4.7495, -4.5641, -4.6579, -4.4251, -4.4940, -4.1757, -4.8447, -4.4433,\n",
      "         -4.2735, -4.5956, -4.4645, -4.4613, -4.2220, -4.7342, -4.7078, -4.9762,\n",
      "         -5.0889, -4.5264, -4.7118, -4.7189, -4.8437, -4.8725, -4.8652, -4.7505,\n",
      "         -4.6988, -4.4157, -4.5985, -4.5555, -4.5611, -4.2809, -4.8394, -4.9107,\n",
      "         -4.4957, -4.7498, -4.4861, -4.4542, -4.6535, -4.2953, -4.7752, -4.7208,\n",
      "         -4.3770, -4.4726, -4.4814, -4.5532, -4.8671, -4.8236, -4.3914, -4.2261,\n",
      "         -4.6180, -4.7096, -5.0396, -4.4429, -4.7647, -4.7080, -4.5112, -4.4885,\n",
      "         -4.6351, -4.9480, -4.5937, -4.7286, -4.5682, -4.3807, -4.9103, -4.8108,\n",
      "         -4.2027, -4.3687, -4.6327, -4.6550, -4.4502, -4.3697, -4.6321, -4.8200,\n",
      "         -4.5086, -4.2712, -4.8905, -4.8467, -4.6232, -4.1921, -4.1668, -4.7658,\n",
      "         -4.3301]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : mine\n",
      "target index is: [86] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1170, -4.3398, -4.6132, -5.0029, -4.1025, -4.6299, -4.8325, -4.4765,\n",
      "         -4.6951, -4.7837, -5.0384, -4.3220, -4.9469, -4.5578, -4.5873, -4.7589,\n",
      "         -4.6682, -4.8527, -4.5575, -4.1888, -4.9315, -4.7000, -4.6158, -4.1329,\n",
      "         -4.5283, -4.4704, -4.6668, -4.4505, -4.1966, -4.5971, -4.6055, -5.0028,\n",
      "         -4.7646, -4.4635, -4.6300, -4.6716, -4.6457, -4.7567, -4.8146, -4.7050,\n",
      "         -4.8586, -4.4460, -4.8049, -4.5123, -4.8102, -4.1578, -4.8431, -4.6127,\n",
      "         -4.5583, -4.5948, -4.6599, -4.8612, -4.6474, -4.3323, -4.7941, -4.6576,\n",
      "         -4.3093, -4.4710, -4.6765, -4.5593, -4.5777, -4.6372, -4.3947, -4.3279,\n",
      "         -4.7363, -4.6091, -5.1826, -4.7939, -4.6332, -4.7719, -4.2678, -4.5171,\n",
      "         -4.5850, -4.9516, -4.5810, -4.5904, -4.6594, -4.2326, -4.7780, -4.4721,\n",
      "         -4.6865, -4.3376, -4.7377, -4.8313, -4.6517, -4.4741, -4.4179, -4.4097,\n",
      "         -4.8906, -4.2404, -4.5780, -4.6026, -4.5374, -4.5171, -4.3231, -4.5814,\n",
      "         -4.3764]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Shall\n",
      "target index is: [81] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2788, -4.3550, -4.5859, -5.0829, -4.0229, -4.7152, -4.7058, -4.5330,\n",
      "         -4.7348, -4.9501, -4.7672, -4.2887, -4.6829, -4.7882, -4.7255, -4.5967,\n",
      "         -4.3145, -4.7027, -4.4920, -4.6235, -4.5821, -4.5024, -4.7508, -4.4180,\n",
      "         -4.4090, -4.5383, -4.3496, -4.4680, -4.4103, -4.8467, -4.1579, -5.0077,\n",
      "         -4.5521, -4.6022, -4.5572, -4.9739, -4.4569, -4.6503, -4.8773, -4.9570,\n",
      "         -4.6421, -4.7513, -4.7765, -4.6014, -4.6466, -4.1607, -4.5051, -4.6947,\n",
      "         -4.7712, -4.6460, -4.5640, -4.5862, -4.7271, -4.4295, -4.5613, -4.9680,\n",
      "         -4.5820, -4.6694, -4.5156, -4.5068, -4.6644, -4.5629, -4.6214, -4.0993,\n",
      "         -4.7681, -4.7235, -4.8275, -4.5312, -4.5223, -4.3647, -4.7792, -4.5971,\n",
      "         -4.8424, -4.8624, -4.7110, -4.5442, -4.6871, -4.1671, -4.6778, -4.5218,\n",
      "         -4.5472, -4.3658, -4.7938, -5.0795, -4.5425, -4.5673, -4.1703, -4.5658,\n",
      "         -4.9238, -4.3768, -4.5549, -4.7574, -4.7909, -4.3726, -4.1192, -4.6991,\n",
      "         -4.4503]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : sum\n",
      "target index is: [70] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3179, -4.3814, -4.6792, -4.8204, -4.1594, -4.8708, -4.5924, -4.3693,\n",
      "         -4.6412, -4.7744, -4.7023, -4.3302, -4.5633, -4.9589, -4.8253, -4.6713,\n",
      "         -4.5156, -5.1643, -4.7379, -4.6450, -4.6053, -4.3070, -4.7549, -4.5799,\n",
      "         -4.3021, -4.9656, -4.2998, -4.5122, -4.4478, -4.6169, -4.5684, -4.8796,\n",
      "         -4.8689, -4.8999, -4.3087, -4.4619, -4.7059, -4.4486, -4.6869, -4.5845,\n",
      "         -5.0410, -4.3777, -4.6005, -4.5124, -4.4306, -4.2038, -4.4313, -4.6315,\n",
      "         -4.3384, -4.7777, -4.5935, -4.1268, -4.9862, -4.4077, -4.7074, -4.5418,\n",
      "         -4.6271, -4.4845, -4.5718, -4.9396, -4.8232, -4.5684, -4.6569, -4.2805,\n",
      "         -4.9437, -4.5861, -4.8400, -4.3863, -4.5801, -4.6124, -4.3129, -4.7614,\n",
      "         -4.5446, -4.8213, -4.6637, -4.8010, -4.5919, -4.1671, -4.8462, -4.8498,\n",
      "         -4.3588, -4.6456, -4.5609, -4.6518, -4.2601, -4.6220, -4.4919, -4.6916,\n",
      "         -5.0130, -4.4196, -4.7350, -4.5433, -4.5511, -4.6661, -4.4689, -4.4209,\n",
      "         -4.3962]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : my\n",
      "target index is: [90] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4260, -4.3669, -4.6017, -5.1533, -4.1896, -5.1469, -4.4968, -4.4522,\n",
      "         -4.7366, -4.6044, -5.1420, -4.5686, -4.7698, -4.8039, -4.3522, -4.6144,\n",
      "         -4.6166, -4.6869, -4.9263, -4.3920, -4.8505, -4.2534, -4.8647, -4.5857,\n",
      "         -4.4120, -5.0143, -4.2065, -4.4549, -4.1188, -4.5910, -4.6815, -4.8533,\n",
      "         -4.7764, -4.8673, -4.7416, -4.5653, -4.6675, -4.4346, -4.8619, -4.5094,\n",
      "         -4.9206, -4.7663, -4.8893, -4.3610, -4.8691, -4.2819, -4.8107, -4.6317,\n",
      "         -4.5157, -5.1648, -4.0827, -5.0848, -4.4789, -4.5382, -4.7042, -4.5151,\n",
      "         -4.5144, -4.4856, -4.3249, -5.0232, -4.6208, -4.4141, -4.4743, -4.2224,\n",
      "         -4.6366, -4.3953, -5.0984, -4.5757, -4.3948, -4.5821, -4.5695, -4.5594,\n",
      "         -4.7454, -4.7834, -4.7187, -5.0230, -4.4197, -4.3095, -4.5715, -4.6503,\n",
      "         -4.4601, -4.4743, -4.8468, -4.4508, -4.6746, -4.1963, -4.5139, -4.8352,\n",
      "         -4.4855, -4.5793, -4.4332, -4.5459, -4.7027, -4.2947, -4.6134, -4.3088,\n",
      "         -4.1544]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : count,\n",
      "target index is: [55] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6072, -4.2206, -4.7425, -4.9411, -4.4516, -4.9385, -4.7088, -4.4155,\n",
      "         -4.6099, -4.8702, -4.9976, -4.6389, -4.6954, -4.7465, -4.7322, -4.6600,\n",
      "         -4.5528, -4.6113, -4.8556, -4.6666, -4.6257, -4.6697, -5.0347, -4.3623,\n",
      "         -4.4324, -4.7049, -4.4748, -4.2090, -4.2861, -4.6226, -4.2127, -4.8665,\n",
      "         -5.0401, -4.7584, -4.8356, -4.6425, -4.5462, -4.8206, -4.7143, -4.4810,\n",
      "         -4.6244, -4.6371, -4.3657, -4.5457, -4.5840, -4.1987, -4.9858, -4.6603,\n",
      "         -4.6423, -4.9643, -4.2641, -4.6345, -4.8168, -4.3131, -4.6168, -4.4428,\n",
      "         -4.1940, -4.2908, -4.6498, -4.4619, -4.5928, -4.5479, -4.2900, -4.1287,\n",
      "         -4.6138, -4.5157, -4.9834, -4.4007, -4.2174, -4.1868, -4.4337, -4.4887,\n",
      "         -4.7863, -4.8613, -4.9940, -5.1151, -4.3893, -4.2106, -4.9377, -4.9444,\n",
      "         -4.7116, -4.7242, -4.8530, -4.8673, -4.7570, -4.3309, -4.1903, -4.5491,\n",
      "         -4.7769, -4.3059, -4.3947, -4.9209, -4.7789, -4.2961, -4.5224, -4.7164,\n",
      "         -4.3794]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : and\n",
      "target index is: [44] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6917, -4.4594, -4.6964, -4.6723, -4.1647, -4.8999, -4.4564, -4.2601,\n",
      "         -4.7500, -4.9922, -4.6503, -4.4986, -4.6279, -4.8779, -4.7965, -4.3978,\n",
      "         -4.3157, -4.8306, -4.5570, -4.7145, -4.4853, -4.2762, -4.5349, -4.5310,\n",
      "         -4.1921, -4.8306, -4.4592, -4.5214, -4.7368, -4.4300, -4.6071, -4.8566,\n",
      "         -4.8336, -4.8058, -4.3502, -4.2714, -4.9053, -4.7925, -4.8369, -4.6539,\n",
      "         -4.9570, -4.6097, -4.8853, -4.5931, -4.4718, -4.5077, -4.3302, -4.8253,\n",
      "         -4.2393, -4.5771, -4.6553, -4.3035, -4.8422, -4.1680, -4.5875, -4.5811,\n",
      "         -4.5046, -4.6186, -4.6762, -4.7582, -4.9814, -4.7011, -4.3540, -4.1202,\n",
      "         -4.9425, -4.4721, -4.6999, -4.1385, -4.6526, -4.8242, -4.5275, -4.8310,\n",
      "         -4.3759, -4.6545, -4.7701, -4.8673, -4.3291, -4.4717, -4.9391, -4.4768,\n",
      "         -4.3458, -4.5167, -4.7815, -4.8145, -4.6400, -4.5266, -4.7029, -4.7823,\n",
      "         -4.9631, -4.1180, -4.9103, -4.9473, -4.3282, -4.3969, -4.4641, -4.4488,\n",
      "         -4.5500]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : make\n",
      "target index is: [14] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4898, -4.2502, -4.7302, -5.1101, -4.3107, -4.6323, -4.6146, -4.3780,\n",
      "         -4.6781, -4.6668, -4.7961, -4.5399, -4.8516, -4.6758, -4.4007, -4.5896,\n",
      "         -4.6099, -4.7307, -4.7243, -4.2074, -4.8779, -4.6564, -4.9916, -4.4054,\n",
      "         -4.7431, -4.6725, -4.4076, -4.3328, -4.3107, -4.6473, -4.5738, -4.7907,\n",
      "         -4.8888, -4.7269, -4.4431, -4.4428, -4.5289, -4.9949, -4.7858, -4.5838,\n",
      "         -4.6921, -4.6265, -4.6520, -4.4410, -4.8096, -4.3108, -5.0433, -4.5224,\n",
      "         -4.3953, -4.9980, -4.2095, -4.8543, -4.2814, -4.5410, -4.9763, -4.2700,\n",
      "         -4.4958, -4.4028, -4.8257, -4.4544, -4.5739, -4.6647, -4.3695, -4.4026,\n",
      "         -4.6185, -4.4700, -5.2566, -4.8527, -4.4291, -4.5670, -4.1932, -4.6273,\n",
      "         -4.5622, -4.9245, -4.4649, -4.7855, -4.5514, -4.2516, -4.8673, -4.7132,\n",
      "         -4.6900, -4.6256, -4.7173, -4.7639, -4.5882, -4.4938, -4.4566, -4.5511,\n",
      "         -4.5052, -4.1387, -4.6444, -4.3851, -4.7791, -4.4529, -4.6150, -4.5264,\n",
      "         -4.3566]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : my\n",
      "target index is: [90] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3845, -4.2292, -4.8745, -5.0536, -4.1707, -5.0116, -4.3711, -4.3853,\n",
      "         -4.8349, -4.6820, -4.6704, -4.3939, -4.6353, -4.9964, -4.7761, -4.4658,\n",
      "         -4.3637, -4.8177, -4.7554, -4.6366, -4.8173, -4.1173, -4.8093, -4.9008,\n",
      "         -4.2607, -5.0376, -4.1506, -4.5496, -4.1467, -4.7058, -4.3617, -4.8877,\n",
      "         -4.5876, -4.6812, -4.7254, -4.6555, -4.8467, -4.3579, -5.0319, -4.8446,\n",
      "         -4.6917, -4.8748, -4.6510, -4.5451, -4.5375, -4.2636, -4.6008, -4.8769,\n",
      "         -4.6184, -4.7745, -4.4990, -4.5873, -4.6995, -4.6127, -4.5130, -4.7380,\n",
      "         -4.7516, -4.5572, -4.4965, -4.8695, -4.7992, -4.1882, -4.4989, -3.9805,\n",
      "         -4.7261, -4.8801, -4.8297, -4.5010, -4.4711, -4.0708, -4.6994, -4.6966,\n",
      "         -4.6319, -4.6038, -4.7849, -4.9634, -4.4739, -4.4525, -4.4964, -4.5791,\n",
      "         -4.5223, -4.4541, -5.0119, -4.7434, -4.6806, -4.6459, -4.6529, -4.5628,\n",
      "         -4.6258, -4.2754, -4.5336, -4.7539, -4.7951, -4.1972, -4.3134, -4.4654,\n",
      "         -4.2936]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : old\n",
      "target index is: [84] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.0898, -4.3127, -4.4064, -5.0355, -4.2165, -5.2517, -4.4349, -4.4166,\n",
      "         -4.5149, -4.9239, -4.9757, -4.7955, -4.2935, -4.7930, -4.9243, -4.4217,\n",
      "         -4.5061, -4.6214, -4.8821, -4.7577, -4.7424, -4.2450, -5.1307, -4.7192,\n",
      "         -4.0749, -4.8598, -4.3180, -4.5092, -3.9011, -4.7199, -4.5923, -4.6879,\n",
      "         -4.6449, -4.9509, -4.8523, -4.5942, -4.7640, -4.3483, -4.7175, -4.5311,\n",
      "         -4.8424, -4.4789, -4.7731, -4.2504, -4.5415, -4.3705, -4.8375, -4.5611,\n",
      "         -4.6233, -4.9087, -4.0605, -4.7103, -4.9540, -4.6632, -4.7243, -4.5849,\n",
      "         -4.2400, -4.5918, -4.4041, -4.8388, -4.9511, -4.4020, -4.3737, -4.2520,\n",
      "         -4.7829, -4.7435, -4.8988, -4.5731, -4.5073, -4.3988, -4.5485, -4.3849,\n",
      "         -4.7571, -4.9030, -4.7542, -4.9727, -4.3468, -4.3472, -4.8981, -4.8988,\n",
      "         -4.1414, -4.5486, -4.8120, -4.7319, -4.5081, -4.5142, -4.6027, -4.7662,\n",
      "         -4.8561, -4.5475, -4.5961, -4.6057, -4.6152, -4.4310, -4.8113, -4.3672,\n",
      "         -4.4018]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : excuse,'\n",
      "target index is: [64] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5046, -4.4299, -4.5227, -4.7915, -4.1446, -4.9060, -4.6526, -4.3518,\n",
      "         -4.7657, -4.7997, -4.7510, -4.6526, -4.4933, -4.5220, -4.8331, -4.6076,\n",
      "         -4.7365, -4.2877, -4.6350, -4.6037, -4.4181, -4.6604, -4.5733, -4.7582,\n",
      "         -4.2799, -4.8107, -4.5940, -4.5503, -4.3502, -4.2552, -4.6414, -4.6764,\n",
      "         -4.8888, -4.7090, -4.6834, -5.2096, -4.7781, -4.6602, -4.6060, -4.5240,\n",
      "         -4.3794, -4.7921, -4.7976, -4.6203, -4.5901, -4.5728, -4.5486, -4.4325,\n",
      "         -4.4979, -4.4595, -4.3479, -4.5055, -4.5252, -4.4819, -4.5745, -4.4282,\n",
      "         -4.6016, -4.4755, -4.3835, -4.6035, -4.9498, -4.5467, -4.5207, -3.7288,\n",
      "         -4.6827, -4.4163, -4.6774, -4.3390, -4.5470, -4.6106, -4.5898, -4.5424,\n",
      "         -4.9463, -4.8831, -4.8488, -4.6424, -4.6321, -4.4874, -4.6848, -4.5621,\n",
      "         -4.7777, -4.6781, -4.9354, -4.9297, -4.6635, -4.2085, -4.4038, -4.9493,\n",
      "         -4.9082, -4.1562, -4.5009, -4.6971, -4.5920, -4.4746, -4.6492, -4.5477,\n",
      "         -4.8384]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Proving\n",
      "target index is: [25] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5243, -4.6032, -4.9691, -4.7041, -4.4670, -4.6807, -4.6916, -4.4433,\n",
      "         -4.6007, -4.5623, -4.9808, -4.3965, -4.4515, -4.5566, -4.5380, -4.8600,\n",
      "         -4.5687, -4.8599, -4.3771, -4.6386, -4.4819, -4.4511, -4.8651, -4.4657,\n",
      "         -4.4440, -4.7016, -4.1978, -4.5594, -4.4648, -4.4901, -5.0814, -4.8192,\n",
      "         -4.8309, -4.7785, -4.9575, -5.0141, -4.4413, -4.7276, -4.6149, -4.3560,\n",
      "         -4.7666, -4.5760, -4.6280, -4.6804, -4.3758, -4.3746, -4.7125, -4.8204,\n",
      "         -4.4541, -5.0546, -4.3205, -4.5172, -4.5378, -4.1139, -4.5480, -4.2510,\n",
      "         -4.6785, -4.3769, -4.5795, -4.3764, -4.4729, -4.3847, -4.3646, -3.9982,\n",
      "         -4.4109, -4.6032, -4.7119, -4.6752, -4.9262, -4.1787, -3.9953, -4.5047,\n",
      "         -5.0828, -4.3995, -4.7914, -4.9863, -4.3660, -4.4326, -4.6183, -4.6283,\n",
      "         -4.7751, -4.6081, -4.9127, -4.8881, -4.8671, -4.6035, -5.0984, -4.9682,\n",
      "         -4.8171, -4.4025, -4.6450, -4.6825, -4.7317, -4.2127, -4.5848, -4.8505,\n",
      "         -4.3591]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : his\n",
      "target index is: [49] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7699, -4.3111, -4.9258, -5.1168, -4.2456, -4.5874, -4.2673, -4.3483,\n",
      "         -4.9727, -4.4346, -4.7045, -4.2974, -4.7253, -4.7052, -4.9027, -4.5565,\n",
      "         -4.4821, -4.4648, -4.6674, -4.3570, -4.4804, -4.3778, -4.6419, -4.6564,\n",
      "         -4.6510, -4.7802, -4.4032, -4.5375, -4.7885, -4.5579, -4.7028, -4.5735,\n",
      "         -4.7778, -4.7419, -4.5069, -4.7015, -4.5114, -4.8482, -4.7170, -4.3341,\n",
      "         -4.4147, -4.5052, -4.4738, -4.3003, -4.4950, -4.6429, -4.4458, -4.4003,\n",
      "         -4.3474, -5.1988, -4.4418, -4.7386, -4.3932, -4.3195, -4.5915, -4.5403,\n",
      "         -4.8938, -4.7520, -4.2439, -4.7041, -4.9167, -4.5068, -4.5100, -4.3179,\n",
      "         -4.4462, -4.6967, -4.5776, -4.3450, -4.6690, -4.2919, -4.7527, -4.8463,\n",
      "         -4.7381, -4.8519, -4.6842, -4.9594, -4.4266, -4.4985, -4.4915, -4.4886,\n",
      "         -4.8347, -4.6502, -4.8397, -4.5685, -5.0046, -4.3743, -4.6998, -4.5816,\n",
      "         -4.8397, -4.2417, -4.6597, -4.2770, -4.9195, -4.5211, -4.6841, -4.6362,\n",
      "         -4.5050]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty\n",
      "target index is: [0] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6177, -4.4598, -4.8588, -4.6935, -4.4053, -4.7309, -4.7492, -4.0791,\n",
      "         -4.7963, -4.4681, -4.6300, -4.3059, -4.4187, -4.7818, -4.7542, -4.7077,\n",
      "         -4.6733, -4.5084, -4.3085, -4.4446, -4.5967, -4.4305, -4.7935, -4.9111,\n",
      "         -4.3304, -5.2784, -4.2745, -4.7386, -4.0031, -4.4878, -4.6255, -4.5987,\n",
      "         -4.9740, -4.6626, -4.5353, -5.0226, -4.4562, -4.5953, -4.6485, -4.8239,\n",
      "         -4.7191, -4.6269, -4.7260, -4.6945, -4.5994, -4.4141, -4.7713, -5.0062,\n",
      "         -4.8543, -4.8094, -4.6425, -4.4604, -4.8617, -4.5701, -4.6538, -4.5680,\n",
      "         -4.2513, -4.1744, -4.4106, -4.4102, -4.6592, -4.5510, -4.5391, -4.3495,\n",
      "         -4.4198, -4.6907, -4.6281, -4.7038, -4.6569, -4.3432, -4.4422, -4.4428,\n",
      "         -5.1458, -4.6200, -4.9248, -4.9109, -4.4300, -4.2110, -4.5097, -4.9148,\n",
      "         -4.5095, -4.3965, -4.6755, -4.7925, -4.7888, -4.5014, -4.6790, -4.2574,\n",
      "         -4.7691, -4.5888, -4.6061, -4.5514, -4.8629, -4.2852, -4.6047, -4.6187,\n",
      "         -4.2039]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : by\n",
      "target index is: [62] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.0404, -4.6557, -4.7074, -4.6664, -3.8852, -4.7217, -4.4930, -4.1898,\n",
      "         -4.8786, -4.9166, -4.7298, -4.5138, -4.4381, -4.6853, -4.7700, -4.7800,\n",
      "         -4.4023, -4.6795, -4.5803, -4.7790, -4.7320, -4.4303, -4.9847, -4.7037,\n",
      "         -4.1733, -4.7848, -4.4911, -4.3752, -4.4829, -4.7245, -4.5557, -4.4569,\n",
      "         -4.5567, -4.9064, -4.5717, -5.1188, -4.7837, -4.2439, -4.6940, -4.3882,\n",
      "         -4.6732, -4.4519, -4.8051, -4.3124, -4.4970, -3.8872, -4.4868, -4.7444,\n",
      "         -4.8967, -4.5133, -4.7413, -4.3801, -4.8861, -4.2334, -4.3997, -4.4504,\n",
      "         -4.3002, -4.4486, -4.6579, -4.8036, -4.8313, -4.2251, -4.3368, -4.3289,\n",
      "         -4.5581, -4.8114, -4.5825, -4.2014, -5.0000, -4.6331, -4.6914, -4.7015,\n",
      "         -4.5241, -5.0143, -4.7539, -4.8008, -4.6729, -4.3305, -4.8076, -5.0229,\n",
      "         -4.4126, -4.4811, -5.0017, -5.0124, -4.6664, -4.3126, -4.7433, -5.0888,\n",
      "         -5.1370, -4.5980, -4.8976, -4.7064, -4.5127, -4.4728, -4.5994, -4.7794,\n",
      "         -4.4852]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : succession\n",
      "target index is: [7] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6683, -4.3862, -4.6769, -4.6785, -4.1885, -4.6720, -4.7494, -4.4109,\n",
      "         -4.7034, -4.5434, -4.7137, -4.2487, -4.7861, -4.5121, -4.9566, -4.6696,\n",
      "         -4.6233, -4.4917, -4.8352, -4.5057, -4.3301, -4.5602, -4.8890, -4.8679,\n",
      "         -4.5576, -4.7257, -4.4752, -4.2487, -4.1752, -4.4521, -4.4590, -4.7528,\n",
      "         -4.9503, -4.5143, -4.8881, -5.2073, -4.5479, -4.9396, -4.5432, -4.5108,\n",
      "         -4.3559, -4.6893, -4.4300, -4.6968, -4.3264, -4.5290, -4.3229, -4.8035,\n",
      "         -4.4170, -4.8681, -4.5314, -4.5186, -4.5877, -4.3887, -4.6578, -4.4975,\n",
      "         -4.5790, -4.4005, -4.5902, -4.7251, -4.4989, -4.4353, -4.4094, -3.8552,\n",
      "         -4.3785, -4.5243, -4.6213, -4.5218, -4.4289, -4.1111, -4.3644, -4.3900,\n",
      "         -4.9830, -4.8423, -4.8084, -4.9252, -4.7875, -4.3283, -4.7630, -4.8930,\n",
      "         -4.9993, -4.5064, -4.6994, -4.8862, -4.7304, -4.4140, -4.4401, -4.5800,\n",
      "         -4.9914, -4.4548, -4.7633, -4.6311, -4.7929, -4.6952, -4.5716, -4.9992,\n",
      "         -4.6997]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thine!\n",
      "target index is: [40] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6633, -4.3854, -4.6915, -4.4479, -4.2241, -4.7510, -4.6236, -4.2711,\n",
      "         -4.7056, -4.6199, -4.6316, -4.4144, -4.7307, -4.7815, -4.4779, -4.7980,\n",
      "         -4.8841, -5.0263, -4.6104, -4.6108, -4.5354, -4.5395, -4.7049, -4.5268,\n",
      "         -4.5180, -4.6001, -4.2291, -4.3704, -4.4030, -4.6504, -4.8777, -4.8459,\n",
      "         -4.9072, -4.5192, -4.5088, -4.8602, -4.7667, -4.7588, -4.5852, -4.4234,\n",
      "         -4.7107, -4.6166, -4.6636, -4.5851, -4.6381, -4.4654, -4.5477, -4.5473,\n",
      "         -4.3065, -4.7427, -4.3772, -4.4571, -4.5230, -4.4852, -4.9627, -4.1433,\n",
      "         -4.7474, -4.3205, -4.6999, -4.7545, -4.5251, -4.5458, -4.6034, -4.1527,\n",
      "         -4.8516, -4.5321, -4.7218, -4.5851, -4.7750, -4.6582, -4.1482, -4.7489,\n",
      "         -4.8020, -4.5745, -4.3143, -4.9198, -4.7259, -4.4287, -4.6506, -4.4502,\n",
      "         -4.7407, -4.3369, -4.9456, -4.8389, -4.7175, -4.4483, -4.8638, -4.7908,\n",
      "         -4.7160, -4.3833, -4.8185, -4.3201, -4.5676, -4.2702, -4.5373, -4.2537,\n",
      "         -4.6472]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : This\n",
      "target index is: [1] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4888, -4.3325, -4.7537, -4.7606, -4.1870, -4.5648, -4.7933, -4.4385,\n",
      "         -4.5407, -4.5441, -4.7953, -4.6794, -4.8635, -4.6971, -4.4229, -4.7243,\n",
      "         -4.5933, -4.6241, -4.8167, -4.3991, -4.6809, -4.6086, -5.1248, -4.4896,\n",
      "         -4.6077, -4.6443, -4.5029, -4.3886, -4.2717, -4.7044, -4.5655, -4.7764,\n",
      "         -4.7919, -4.6579, -4.6104, -4.8679, -4.4533, -4.8751, -4.6844, -4.6135,\n",
      "         -4.6128, -4.4055, -4.6549, -4.6208, -4.6359, -4.2255, -4.7227, -4.5648,\n",
      "         -4.3046, -4.7641, -4.4605, -4.7001, -4.6863, -4.5367, -4.7721, -4.4258,\n",
      "         -4.2871, -4.2632, -4.7130, -4.3138, -4.5976, -4.7554, -4.3576, -4.2673,\n",
      "         -4.5540, -4.7656, -4.9366, -4.7367, -4.4680, -4.3645, -4.1477, -4.2937,\n",
      "         -4.9524, -4.9422, -4.6307, -4.8079, -4.5036, -4.3555, -4.8516, -4.6769,\n",
      "         -4.5840, -4.4398, -4.5925, -4.8237, -4.7366, -4.5662, -4.5273, -4.4810,\n",
      "         -4.7463, -4.2720, -4.6176, -4.5345, -4.8995, -4.4594, -4.4774, -4.7503,\n",
      "         -4.4836]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : were\n",
      "target index is: [93] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2764, -4.4750, -4.7670, -4.8864, -3.8242, -4.5684, -4.4220, -4.2812,\n",
      "         -4.6537, -4.8759, -4.6188, -4.4822, -4.6835, -4.9319, -4.7651, -4.5096,\n",
      "         -4.4751, -4.9755, -4.5781, -4.4286, -4.8660, -4.1436, -4.7772, -4.9596,\n",
      "         -4.3786, -4.6841, -4.4170, -4.3453, -4.2480, -4.8528, -4.3900, -4.9203,\n",
      "         -4.6498, -4.5721, -4.2896, -4.8295, -4.9418, -4.5575, -5.1243, -4.7730,\n",
      "         -4.6639, -4.6728, -4.7975, -4.5780, -4.8083, -4.2194, -4.2492, -4.7173,\n",
      "         -4.4659, -4.7339, -4.8206, -4.3251, -4.7694, -4.6010, -4.6006, -4.4269,\n",
      "         -4.3640, -4.4425, -4.3995, -4.7423, -4.6193, -4.5089, -4.8307, -4.0318,\n",
      "         -4.7318, -4.6731, -4.7536, -4.5642, -4.7795, -4.5228, -4.5760, -4.5695,\n",
      "         -4.4104, -4.8309, -4.6802, -4.5218, -4.8109, -4.7112, -4.7326, -4.4442,\n",
      "         -4.7170, -4.5024, -5.0632, -4.8071, -4.2455, -4.6263, -4.4367, -4.7580,\n",
      "         -4.7480, -4.4446, -4.7810, -4.5507, -4.7988, -4.4412, -4.4829, -4.4904,\n",
      "         -4.5157]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : to\n",
      "target index is: [72] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5884, -4.5181, -4.7240, -4.4736, -4.4715, -4.7761, -5.0022, -4.2450,\n",
      "         -4.7274, -4.6925, -4.6378, -4.6138, -4.5894, -4.7324, -4.7818, -4.5486,\n",
      "         -4.7422, -4.2547, -4.6076, -4.5716, -4.3635, -4.4685, -5.1173, -4.8255,\n",
      "         -4.4714, -4.9912, -4.5047, -4.2536, -4.1647, -4.7418, -4.6226, -4.2661,\n",
      "         -5.0939, -4.7396, -4.5732, -5.1615, -4.5210, -4.7107, -4.6161, -4.7328,\n",
      "         -4.4923, -4.5220, -4.5831, -4.5522, -4.5331, -4.3029, -4.6979, -4.7124,\n",
      "         -4.7609, -4.6829, -4.3791, -4.5742, -4.7099, -4.7958, -4.8288, -4.6622,\n",
      "         -3.9697, -4.1971, -4.4816, -4.3511, -4.5418, -4.4963, -4.3034, -4.1065,\n",
      "         -4.4476, -4.5233, -4.8930, -4.9258, -4.4985, -4.4186, -4.1428, -4.1370,\n",
      "         -5.1810, -5.0336, -4.8871, -4.9139, -4.3245, -4.2337, -4.8476, -4.6826,\n",
      "         -4.5442, -4.5545, -4.5438, -4.9723, -4.7621, -4.5622, -4.5214, -4.5012,\n",
      "         -5.0668, -4.5127, -4.6535, -4.6467, -5.1201, -4.2773, -4.5158, -4.8524,\n",
      "         -4.5798]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : be\n",
      "target index is: [24] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2041, -4.8176, -4.7913, -5.0621, -4.0068, -4.8018, -4.6741, -4.2114,\n",
      "         -4.8885, -5.1154, -4.9548, -4.2979, -4.6630, -4.9103, -5.0056, -4.5473,\n",
      "         -3.9523, -5.0197, -4.6112, -5.0431, -4.3673, -4.2100, -4.6916, -4.4718,\n",
      "         -4.2878, -5.0036, -4.0450, -4.7514, -4.5588, -4.7365, -4.1829, -5.3388,\n",
      "         -4.8478, -5.0620, -4.3101, -4.6906, -4.8103, -4.4355, -5.0740, -4.9692,\n",
      "         -5.0586, -4.3926, -4.6633, -4.4676, -4.2907, -4.0814, -4.5170, -4.6770,\n",
      "         -4.5951, -4.4537, -4.4576, -4.1004, -5.2814, -4.3529, -4.7461, -4.6543,\n",
      "         -4.8307, -4.5118, -4.5308, -4.8959, -4.9600, -4.5579, -4.6693, -3.8809,\n",
      "         -4.6406, -4.7122, -4.9696, -4.4379, -4.4042, -4.5120, -4.3362, -4.6979,\n",
      "         -4.6872, -4.8388, -4.6854, -4.8691, -4.7950, -4.0214, -4.8868, -5.0502,\n",
      "         -4.1701, -4.7956, -4.7127, -4.6626, -4.3366, -4.8740, -4.3067, -4.9261,\n",
      "         -4.9936, -4.4475, -4.4044, -4.6757, -4.7667, -4.5634, -4.2956, -4.6598,\n",
      "         -4.3134]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : new\n",
      "target index is: [27] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5655, -4.4811, -4.3490, -4.7100, -4.1593, -4.7226, -4.6697, -4.3800,\n",
      "         -4.6114, -4.6443, -4.8661, -4.5233, -4.6264, -4.7746, -4.5960, -4.6257,\n",
      "         -4.5652, -4.5532, -4.4623, -4.6155, -4.7884, -4.5908, -4.5977, -4.4793,\n",
      "         -4.3836, -4.6659, -4.4867, -4.6367, -4.4386, -4.3979, -4.5220, -4.6451,\n",
      "         -4.8418, -4.6774, -4.5734, -4.6943, -4.6224, -4.6747, -4.5837, -4.6983,\n",
      "         -4.6487, -4.5295, -4.9899, -4.6310, -4.7201, -4.5835, -4.6540, -4.5453,\n",
      "         -4.5357, -4.3554, -4.3210, -4.5331, -4.7099, -4.3247, -4.7246, -4.4770,\n",
      "         -4.5042, -4.6189, -4.5330, -4.6383, -4.7266, -4.6308, -4.5413, -4.0732,\n",
      "         -4.9812, -4.4478, -4.8705, -4.4258, -4.7059, -4.9810, -4.5572, -4.5581,\n",
      "         -4.7171, -4.7694, -4.6397, -4.6895, -4.5046, -4.4281, -4.6884, -4.8178,\n",
      "         -4.4673, -4.3418, -4.6112, -4.7722, -4.6745, -4.3173, -4.5678, -4.7530,\n",
      "         -4.7735, -4.1785, -4.6324, -4.8104, -4.4058, -4.5305, -4.3726, -4.4155,\n",
      "         -4.6645]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : made\n",
      "target index is: [16] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3839, -4.6179, -4.7631, -4.8409, -4.2288, -4.6634, -4.4536, -4.5172,\n",
      "         -4.6757, -4.4061, -4.8866, -4.4534, -4.6677, -4.5822, -4.6905, -4.8012,\n",
      "         -4.4352, -4.6990, -4.5994, -4.5995, -4.3416, -4.3835, -4.7957, -4.5516,\n",
      "         -4.6477, -5.1412, -4.1285, -4.6893, -4.6332, -4.7382, -4.5413, -4.8670,\n",
      "         -4.5530, -4.9029, -4.5040, -4.9587, -4.5302, -4.3718, -4.6328, -4.3994,\n",
      "         -4.6257, -4.5283, -4.5523, -4.4018, -4.4811, -4.4414, -4.6946, -4.5213,\n",
      "         -4.5802, -4.8666, -4.3717, -4.7888, -4.8494, -4.4588, -4.6025, -4.4188,\n",
      "         -4.7805, -4.5933, -4.4099, -4.6108, -4.5611, -4.5072, -4.5792, -4.2013,\n",
      "         -4.3233, -4.8820, -4.8248, -4.3500, -4.6047, -4.3795, -4.5570, -4.6367,\n",
      "         -4.8091, -4.7090, -4.7613, -4.8798, -4.5253, -4.3575, -4.4081, -4.5952,\n",
      "         -4.4918, -4.5751, -4.7407, -4.7563, -4.7810, -4.4349, -4.7206, -4.5093,\n",
      "         -4.9451, -4.6299, -4.3608, -4.5917, -4.6664, -4.5139, -4.5151, -4.4818,\n",
      "         -4.3320]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : when\n",
      "target index is: [85] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4850, -4.5462, -4.8634, -4.7654, -4.2356, -4.6449, -4.3218, -4.3816,\n",
      "         -4.8523, -4.5291, -4.9606, -4.4544, -4.7092, -4.6079, -4.4801, -4.5368,\n",
      "         -4.2402, -4.6538, -4.7293, -4.4912, -4.4823, -4.3602, -4.9419, -4.7357,\n",
      "         -4.6306, -5.0730, -4.5003, -4.2418, -4.7822, -4.7544, -4.6992, -4.5708,\n",
      "         -4.7457, -5.0019, -4.4589, -4.7664, -4.3674, -4.5893, -4.8459, -4.3673,\n",
      "         -4.5765, -4.7005, -4.6522, -4.3615, -4.6192, -4.1273, -4.7392, -4.8734,\n",
      "         -4.7145, -4.9623, -4.5615, -4.6442, -4.5329, -3.7775, -4.3829, -4.5830,\n",
      "         -4.5661, -4.6024, -4.5740, -4.6081, -4.6071, -4.4784, -4.3968, -4.5618,\n",
      "         -4.4396, -4.4762, -4.9053, -4.1572, -4.7480, -4.5135, -4.5826, -4.8444,\n",
      "         -4.8432, -4.7927, -4.8818, -5.0072, -4.5221, -4.3937, -4.5972, -4.8555,\n",
      "         -4.5246, -4.4201, -4.6389, -4.7464, -4.9096, -4.1090, -4.9541, -4.9148,\n",
      "         -4.8084, -4.3586, -4.4715, -4.6660, -4.7317, -4.4583, -4.4555, -4.7219,\n",
      "         -4.2613]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thou\n",
      "target index is: [22] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6567, -4.5624, -4.9539, -4.6698, -4.1876, -4.7769, -4.5177, -4.6885,\n",
      "         -4.6324, -4.5207, -4.6894, -4.2486, -4.8064, -4.6838, -4.7351, -4.3219,\n",
      "         -4.7103, -4.6502, -4.8055, -4.5128, -4.7650, -4.1736, -4.8986, -4.5855,\n",
      "         -4.2516, -4.6916, -4.7517, -4.3459, -4.2866, -4.3574, -4.6886, -4.5681,\n",
      "         -4.7893, -4.8013, -4.5839, -4.5451, -4.6297, -4.8352, -4.9465, -4.3283,\n",
      "         -4.8991, -4.2052, -4.6404, -4.5415, -4.4247, -4.4754, -4.5629, -4.8239,\n",
      "         -4.3672, -5.1543, -4.7060, -4.6701, -4.6528, -4.2149, -4.5990, -4.4063,\n",
      "         -4.2275, -4.5086, -4.6280, -4.4020, -4.6671, -4.5480, -4.3174, -4.5402,\n",
      "         -4.7409, -4.4946, -4.5921, -4.4291, -4.7597, -4.2621, -4.2712, -4.6018,\n",
      "         -4.8864, -4.9018, -4.7980, -4.9527, -4.5315, -4.6166, -4.8167, -4.6628,\n",
      "         -4.6276, -4.3815, -4.5395, -4.3773, -4.7031, -4.1910, -4.7150, -4.8560,\n",
      "         -4.8069, -4.4155, -4.8189, -4.6526, -4.5741, -4.5841, -4.6120, -4.6313,\n",
      "         -4.6754]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : art\n",
      "target index is: [15] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3733, -4.4512, -4.7427, -4.9153, -4.2288, -4.7832, -4.5845, -4.3643,\n",
      "         -4.6871, -4.8118, -4.6833, -4.4211, -4.4685, -4.7841, -4.7570, -4.2513,\n",
      "         -4.4903, -4.4955, -4.2560, -4.5881, -4.6103, -4.2162, -4.8840, -4.8714,\n",
      "         -4.2491, -4.7241, -4.4154, -4.5317, -4.1637, -4.5892, -4.5241, -4.8376,\n",
      "         -4.8630, -4.5796, -4.5702, -4.9254, -4.6381, -4.6217, -4.9407, -4.9192,\n",
      "         -4.8254, -4.8422, -4.7708, -4.7821, -4.6421, -4.4582, -4.6528, -4.9559,\n",
      "         -4.5894, -4.6656, -4.4406, -4.7576, -4.5255, -4.5268, -4.7638, -4.6675,\n",
      "         -4.3481, -4.4476, -4.4751, -4.4112, -4.6824, -4.4282, -4.3906, -4.1018,\n",
      "         -4.6325, -4.4541, -4.8335, -4.8031, -4.6236, -4.4583, -4.5053, -4.4823,\n",
      "         -4.9144, -4.7699, -4.6136, -4.8121, -4.4161, -4.3889, -4.7891, -4.6602,\n",
      "         -4.4615, -4.4408, -4.9465, -4.8432, -4.4461, -4.6764, -4.5474, -4.6392,\n",
      "         -4.5363, -4.3794, -4.5448, -4.7047, -4.5830, -4.1600, -4.6613, -4.5250,\n",
      "         -4.4793]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : old,\n",
      "target index is: [8] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4805, -4.5306, -4.9832, -4.6999, -4.2990, -4.7118, -4.6329, -4.3344,\n",
      "         -4.7054, -4.6057, -4.7660, -4.3631, -4.5697, -4.9561, -5.0480, -4.9434,\n",
      "         -4.6709, -4.7764, -4.5838, -4.6511, -4.3204, -4.2919, -4.8388, -4.5774,\n",
      "         -4.3921, -5.1308, -4.2823, -4.7220, -4.6413, -4.6065, -4.6828, -4.7577,\n",
      "         -4.6923, -4.8399, -4.4727, -4.8496, -4.7267, -4.3849, -4.5965, -4.3547,\n",
      "         -4.6352, -4.5531, -4.6260, -4.5499, -4.2809, -4.2838, -4.4772, -4.3945,\n",
      "         -4.4750, -4.9209, -4.7730, -4.2461, -4.9166, -4.3449, -4.3388, -4.3813,\n",
      "         -4.5919, -4.2965, -4.2663, -4.7643, -4.7626, -4.3918, -4.4548, -4.1583,\n",
      "         -4.5098, -4.7549, -4.6890, -4.3934, -4.3822, -4.1675, -4.3729, -4.6956,\n",
      "         -4.6417, -4.8625, -4.9547, -4.9756, -4.4598, -4.3206, -4.8598, -4.8343,\n",
      "         -4.6760, -4.7220, -4.8584, -4.7186, -4.5894, -4.5910, -4.5854, -4.8438,\n",
      "         -5.0298, -4.3145, -4.7886, -4.6761, -4.6665, -4.2654, -4.6410, -4.7041,\n",
      "         -4.2685]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : And\n",
      "target index is: [6] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4841, -4.3476, -4.5067, -4.5659, -4.3245, -5.0188, -4.5727, -4.4612,\n",
      "         -4.6352, -4.7965, -4.8427, -4.3940, -4.5413, -4.6297, -4.6692, -4.7109,\n",
      "         -4.6577, -4.6285, -4.9774, -4.5664, -4.4772, -4.5092, -4.6450, -4.5759,\n",
      "         -4.1956, -4.7075, -4.6048, -4.4273, -4.2637, -4.5195, -4.7148, -4.7723,\n",
      "         -4.6684, -4.6945, -4.6117, -4.5393, -4.7663, -4.5904, -4.5583, -4.4038,\n",
      "         -4.8550, -4.3721, -4.7044, -4.4131, -4.4986, -4.3683, -4.4409, -4.6237,\n",
      "         -4.5330, -4.7793, -4.5340, -4.4555, -4.9432, -4.3101, -4.5942, -4.5343,\n",
      "         -4.4274, -4.6023, -4.5646, -4.8027, -4.7055, -4.4721, -4.5139, -4.3720,\n",
      "         -4.7222, -4.6575, -4.7470, -4.2825, -4.7047, -4.6110, -4.5914, -4.6575,\n",
      "         -4.5253, -4.9491, -4.8005, -4.8001, -4.5806, -4.3090, -4.8505, -4.7723,\n",
      "         -4.3037, -4.4439, -4.5903, -4.7250, -4.5365, -4.3260, -4.6123, -4.7649,\n",
      "         -4.8599, -4.4947, -4.8226, -4.7642, -4.2902, -4.5144, -4.5328, -4.5208,\n",
      "         -4.5099]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : see\n",
      "target index is: [67] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4507, -4.5291, -4.7751, -4.9851, -4.4167, -4.7240, -4.5834, -4.4203,\n",
      "         -4.7901, -4.6045, -5.0559, -4.8469, -4.6626, -4.7337, -4.6777, -4.7144,\n",
      "         -4.5254, -4.5505, -4.7038, -4.4038, -4.7854, -4.7151, -5.0390, -4.7318,\n",
      "         -4.6789, -4.9087, -4.5471, -4.3166, -4.3597, -4.7516, -4.5245, -4.7074,\n",
      "         -5.0321, -4.8871, -4.2784, -4.5756, -4.2290, -4.5686, -4.7189, -4.7294,\n",
      "         -4.7516, -4.6217, -4.5685, -4.5947, -4.5412, -4.0642, -4.7811, -4.7046,\n",
      "         -4.7940, -4.8524, -4.2377, -4.5704, -4.6482, -4.3406, -4.7218, -4.7654,\n",
      "         -4.4008, -4.3513, -4.6248, -4.4536, -4.7641, -4.5895, -4.4388, -4.5684,\n",
      "         -4.5521, -4.4638, -5.1150, -4.4168, -4.5529, -4.6864, -4.2337, -4.1060,\n",
      "         -5.0133, -4.9828, -4.7627, -4.8635, -4.4067, -4.0695, -4.6308, -4.7513,\n",
      "         -4.3247, -4.7175, -4.3592, -4.9542, -4.7352, -4.3564, -4.4688, -4.5141,\n",
      "         -4.7309, -4.2722, -4.3099, -4.5296, -4.9479, -4.3764, -4.4216, -4.5677,\n",
      "         -4.1422]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6820, -4.4020, -4.9723, -4.5750, -4.2055, -4.6663, -4.6866, -4.2416,\n",
      "         -5.1340, -4.3944, -4.7479, -4.1739, -4.3042, -4.6442, -4.7674, -4.8365,\n",
      "         -4.3664, -4.5371, -4.3530, -4.5343, -4.6431, -4.3733, -4.4406, -4.7247,\n",
      "         -4.4028, -5.1805, -4.2672, -4.9280, -4.5487, -4.5034, -4.6659, -4.5636,\n",
      "         -4.8256, -4.5951, -4.6149, -5.0917, -4.5703, -4.5091, -4.6280, -4.7866,\n",
      "         -4.4554, -4.7661, -4.8398, -4.5985, -4.3940, -4.1357, -4.5816, -5.0346,\n",
      "         -5.0051, -4.4769, -4.8260, -4.4318, -4.4449, -4.2905, -4.4308, -4.4804,\n",
      "         -4.6508, -4.3099, -4.3078, -4.5606, -4.7294, -4.7174, -4.4631, -3.9683,\n",
      "         -4.4208, -4.6854, -4.7005, -4.4018, -4.8246, -4.4979, -4.6300, -4.6140,\n",
      "         -4.8718, -4.5401, -4.8396, -4.8792, -4.3365, -4.4938, -4.6166, -4.9181,\n",
      "         -4.6655, -4.4306, -4.7517, -4.7870, -4.8400, -4.5744, -4.7753, -4.7154,\n",
      "         -4.9914, -4.4786, -4.6444, -4.7608, -4.8736, -4.2932, -4.2478, -4.8971,\n",
      "         -4.3981]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : blood\n",
      "target index is: [39] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5794, -4.4676, -4.9381, -4.4889, -4.3632, -4.7536, -4.4726, -4.3775,\n",
      "         -4.8151, -4.7343, -5.0039, -4.4260, -4.7209, -4.4619, -4.5108, -4.8657,\n",
      "         -4.6238, -4.7972, -4.3608, -4.3808, -4.7903, -4.8389, -4.7661, -4.4388,\n",
      "         -4.6593, -5.1339, -4.7491, -4.4654, -4.1716, -4.7203, -4.4848, -4.5213,\n",
      "         -4.7160, -4.6472, -4.6888, -5.2991, -4.3704, -4.7230, -4.4293, -4.2498,\n",
      "         -4.4795, -4.4154, -4.6797, -4.1290, -4.8194, -4.1084, -4.9769, -4.6355,\n",
      "         -4.7046, -4.8804, -4.7755, -4.7422, -4.7268, -4.2333, -4.3423, -4.4880,\n",
      "         -4.2563, -4.1969, -4.6908, -4.7261, -4.6302, -4.1896, -4.5671, -4.3041,\n",
      "         -4.5431, -4.5896, -4.7447, -4.2110, -4.7101, -4.1366, -4.4760, -4.5652,\n",
      "         -5.0304, -5.0609, -4.8917, -5.2719, -5.1143, -4.0009, -4.5784, -4.5745,\n",
      "         -5.1144, -4.5998, -5.0159, -5.1154, -5.2572, -4.0553, -4.4217, -4.4850,\n",
      "         -5.2129, -4.3313, -4.8564, -4.5423, -4.7698, -4.4806, -4.3944, -4.4997,\n",
      "         -4.2883]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : warm\n",
      "target index is: [2] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5609, -4.3809, -4.6656, -4.8007, -4.5625, -4.6356, -4.4760, -4.4417,\n",
      "         -4.7404, -5.0327, -4.9782, -4.8010, -4.7340, -4.7888, -4.6234, -4.5070,\n",
      "         -4.6867, -4.9672, -4.5323, -4.3106, -4.8440, -4.2541, -5.2272, -4.4626,\n",
      "         -4.1650, -4.6911, -4.3808, -4.2752, -4.3545, -4.6988, -4.7139, -4.7876,\n",
      "         -4.9550, -4.7964, -4.5602, -4.4364, -4.8032, -4.9347, -4.8737, -4.6855,\n",
      "         -4.7990, -4.5618, -4.6910, -4.5399, -4.7693, -4.2866, -4.8226, -4.8520,\n",
      "         -4.2235, -4.8908, -4.4485, -4.3742, -4.4331, -4.1065, -4.7090, -4.1778,\n",
      "         -4.4552, -4.1332, -4.6737, -4.6466, -4.7874, -4.7889, -4.3076, -4.3720,\n",
      "         -4.8059, -4.4531, -5.1247, -4.5087, -4.6641, -4.3650, -4.0710, -4.6399,\n",
      "         -4.3828, -4.5856, -4.5322, -4.8106, -4.5136, -4.3238, -4.8570, -4.8261,\n",
      "         -4.4981, -4.8218, -4.7943, -4.5889, -4.3342, -4.6872, -4.8002, -5.0563,\n",
      "         -4.5448, -4.0854, -4.7401, -4.5647, -4.7137, -4.7503, -4.2982, -4.6920,\n",
      "         -4.2464]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : when\n",
      "target index is: [85] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5288, -4.3302, -4.7568, -4.9949, -4.2213, -4.7494, -4.3529, -4.4120,\n",
      "         -4.7052, -4.3518, -4.6599, -4.6456, -4.8152, -4.6584, -4.4652, -4.5012,\n",
      "         -4.2872, -4.6428, -4.7777, -4.6314, -4.5153, -4.4083, -4.8805, -4.6769,\n",
      "         -4.5310, -5.0738, -4.3915, -4.3201, -4.8355, -4.6121, -4.6603, -4.5809,\n",
      "         -4.7636, -4.9161, -4.5897, -4.7117, -4.5373, -4.4213, -4.9078, -4.5245,\n",
      "         -4.5265, -4.9360, -4.6639, -4.3626, -4.4133, -4.3536, -4.6883, -4.7889,\n",
      "         -4.5148, -4.6985, -4.4170, -4.8233, -4.6908, -4.2218, -4.6236, -4.6388,\n",
      "         -4.6071, -4.7765, -4.5247, -4.4616, -4.8030, -4.4808, -4.5222, -4.1180,\n",
      "         -4.5124, -4.5108, -4.7490, -4.2901, -4.5599, -4.6141, -4.7422, -5.0269,\n",
      "         -4.9963, -4.2717, -4.7085, -4.9761, -4.5209, -4.6898, -4.7043, -4.6570,\n",
      "         -4.3444, -4.2987, -4.8652, -4.5831, -4.9422, -4.2092, -5.0757, -4.5402,\n",
      "         -4.6228, -4.1984, -4.3155, -4.7433, -4.7642, -4.2009, -4.4978, -4.5950,\n",
      "         -4.6666]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thou\n",
      "target index is: [22] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6576, -4.5640, -4.9482, -4.6703, -4.1887, -4.7772, -4.5124, -4.6889,\n",
      "         -4.6271, -4.5215, -4.6893, -4.2491, -4.8074, -4.6840, -4.7355, -4.3041,\n",
      "         -4.7105, -4.6509, -4.8064, -4.5140, -4.7656, -4.1739, -4.8909, -4.5861,\n",
      "         -4.2525, -4.6920, -4.7531, -4.3471, -4.2875, -4.3580, -4.6894, -4.5691,\n",
      "         -4.7900, -4.8019, -4.5848, -4.5454, -4.6304, -4.8360, -4.9476, -4.3242,\n",
      "         -4.9000, -4.2050, -4.6409, -4.5421, -4.4258, -4.4766, -4.5641, -4.8246,\n",
      "         -4.3680, -5.1551, -4.7070, -4.6713, -4.6539, -4.2162, -4.6006, -4.4076,\n",
      "         -4.2279, -4.5101, -4.6290, -4.4028, -4.6682, -4.5489, -4.3181, -4.5412,\n",
      "         -4.7411, -4.4945, -4.5924, -4.4242, -4.7609, -4.2630, -4.2720, -4.6027,\n",
      "         -4.8870, -4.9031, -4.7987, -4.9538, -4.5322, -4.6176, -4.8128, -4.6631,\n",
      "         -4.6283, -4.3824, -4.5404, -4.3783, -4.7040, -4.1812, -4.7158, -4.8569,\n",
      "         -4.8086, -4.4165, -4.8203, -4.6532, -4.5750, -4.5855, -4.6131, -4.6316,\n",
      "         -4.6767]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : feel'st\n",
      "target index is: [35] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5376, -4.2078, -4.7116, -4.8789, -4.1327, -4.7483, -4.7275, -4.1711,\n",
      "         -4.7995, -4.4775, -4.6893, -4.6041, -4.7497, -4.8705, -4.6880, -4.5364,\n",
      "         -4.6028, -4.3462, -4.5855, -4.4991, -4.5931, -4.4781, -4.5971, -4.8973,\n",
      "         -4.5962, -4.8214, -4.4245, -4.5159, -4.5402, -4.5265, -4.4870, -4.6572,\n",
      "         -4.8623, -4.6046, -4.3284, -4.9063, -4.5169, -4.8151, -4.7718, -4.7836,\n",
      "         -4.5834, -4.8660, -4.5848, -4.6633, -4.4506, -4.3748, -4.4771, -4.5955,\n",
      "         -4.6756, -4.5428, -4.5732, -4.6772, -4.6430, -4.6205, -4.6649, -4.6180,\n",
      "         -4.5546, -4.4052, -4.3781, -4.5008, -4.9281, -4.6380, -4.5457, -4.1543,\n",
      "         -4.5151, -4.5123, -4.5432, -4.5391, -4.5304, -4.6583, -4.6649, -4.5079,\n",
      "         -4.8716, -4.9908, -4.7262, -4.7304, -4.3704, -4.4435, -4.6375, -4.7310,\n",
      "         -4.5462, -4.4810, -4.7248, -4.8965, -4.7703, -4.4060, -4.3777, -4.5531,\n",
      "         -4.6409, -4.0980, -4.4372, -4.5347, -4.8707, -4.3770, -4.5407, -4.6411,\n",
      "         -4.4797]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : it\n",
      "target index is: [88] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5700, -4.3953, -4.7948, -4.6875, -4.1349, -4.8842, -4.6695, -4.2039,\n",
      "         -4.6325, -4.6327, -4.6805, -4.3397, -4.5054, -4.8478, -4.6807, -4.6100,\n",
      "         -4.5125, -5.0295, -4.5444, -4.6607, -4.6713, -4.3568, -5.0453, -4.6095,\n",
      "         -4.1807, -4.8047, -4.1189, -4.6382, -4.0694, -4.6937, -4.6426, -5.2701,\n",
      "         -5.0602, -4.7099, -4.8829, -5.0964, -4.4849, -4.7009, -4.7564, -4.7434,\n",
      "         -4.9541, -4.3979, -4.6350, -4.5955, -4.5432, -4.2858, -4.6724, -4.8694,\n",
      "         -4.4841, -4.7714, -4.6651, -4.1045, -4.9313, -4.3297, -4.8179, -4.4159,\n",
      "         -4.5384, -4.1735, -4.6434, -4.7165, -4.6184, -4.5913, -4.2984, -4.0913,\n",
      "         -4.7389, -4.8104, -4.7549, -4.6394, -4.5143, -4.2996, -4.1230, -4.2872,\n",
      "         -4.8765, -4.7590, -4.7003, -4.7233, -4.8207, -3.9654, -4.8810, -4.8824,\n",
      "         -4.6025, -4.5372, -4.8739, -4.7994, -4.5038, -4.7413, -4.3743, -4.6132,\n",
      "         -4.7764, -4.6317, -4.9278, -4.7345, -4.7415, -4.2876, -4.5210, -4.6498,\n",
      "         -4.2051]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : cold.\n",
      "target index is: [79] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4108, -4.0845, -4.7875, -4.8777, -4.0957, -5.0452, -4.5142, -4.4865,\n",
      "         -4.8246, -4.4649, -4.7679, -4.5492, -4.6819, -4.7648, -5.0642, -4.7303,\n",
      "         -4.5860, -4.1814, -4.8300, -4.4038, -4.7438, -4.3393, -4.7136, -4.8611,\n",
      "         -4.3902, -4.7609, -4.4396, -4.2359, -4.2213, -4.4712, -4.3580, -4.5942,\n",
      "         -4.6982, -4.7083, -4.5205, -4.5216, -4.6906, -4.7579, -4.7317, -4.7014,\n",
      "         -4.6888, -4.5293, -4.5103, -4.3650, -4.4303, -4.2740, -4.4646, -4.7250,\n",
      "         -4.7375, -5.0368, -4.5403, -4.5923, -4.6918, -4.5363, -4.3601, -4.7711,\n",
      "         -4.4265, -4.5038, -4.3052, -4.6795, -4.8752, -4.4374, -4.6047, -4.4594,\n",
      "         -4.5503, -4.9942, -4.6178, -4.2482, -4.5658, -4.4094, -4.6695, -4.6499,\n",
      "         -4.9140, -5.0536, -4.9362, -4.8522, -4.5124, -4.5686, -4.6551, -4.7347,\n",
      "         -4.3061, -4.4624, -4.6103, -4.6553, -4.9040, -4.2633, -4.7903, -4.5479,\n",
      "         -4.8083, -4.4377, -4.6106, -4.5086, -4.7539, -4.4997, -4.4333, -4.6667,\n",
      "         -4.5894]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : winters\n",
      "target index is: [3] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2699, -4.6673, -4.4010, -4.6445, -4.2045, -4.5866, -4.5456, -4.2489,\n",
      "         -4.7433, -4.9141, -4.9579, -4.7892, -4.5641, -4.2745, -4.5623, -4.3699,\n",
      "         -4.1086, -4.6605, -4.6390, -4.8551, -4.8422, -4.6370, -4.7543, -4.5813,\n",
      "         -4.4116, -4.8913, -4.4596, -4.4700, -4.3604, -4.5649, -4.2754, -5.0437,\n",
      "         -4.9025, -4.6077, -4.9177, -4.8853, -4.5692, -4.7057, -5.0300, -4.6666,\n",
      "         -4.9303, -4.3809, -4.8540, -4.3626, -5.1278, -4.3549, -5.1102, -5.1651,\n",
      "         -4.9116, -4.2685, -4.6286, -4.3910, -4.8335, -4.1175, -4.9539, -4.1523,\n",
      "         -4.2499, -4.1764, -4.8484, -4.4045, -4.2789, -4.6419, -4.4439, -4.1038,\n",
      "         -4.5534, -3.9599, -5.3838, -4.4833, -4.8480, -4.6545, -4.5598, -4.2370,\n",
      "         -4.9466, -4.8764, -4.5848, -5.1544, -4.8987, -4.1400, -4.7132, -4.8094,\n",
      "         -4.3649, -4.5658, -4.6999, -5.0769, -4.7358, -4.4024, -4.6823, -4.6364,\n",
      "         -5.0895, -4.3865, -4.4177, -4.6980, -4.6644, -4.6677, -4.4081, -4.7603,\n",
      "         -4.3621]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : shall\n",
      "target index is: [10] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5592, -4.3290, -5.0846, -4.8629, -4.2208, -4.7603, -4.4223, -4.6748,\n",
      "         -4.7621, -4.4444, -4.7097, -4.3874, -4.8155, -4.6892, -5.0533, -4.5216,\n",
      "         -4.7280, -4.5923, -4.6696, -4.5052, -4.5028, -3.9769, -4.6859, -4.4954,\n",
      "         -4.2235, -4.7805, -4.5866, -4.5972, -4.4317, -4.6161, -4.8560, -4.6682,\n",
      "         -4.6277, -4.7893, -4.6847, -4.4528, -4.9296, -4.5138, -5.0151, -4.3922,\n",
      "         -4.9240, -4.7018, -4.6857, -4.7217, -4.3968, -4.4554, -4.6414, -4.6360,\n",
      "         -4.4078, -5.0834, -4.4745, -4.7398, -4.6112, -4.3057, -4.5050, -4.5138,\n",
      "         -4.6525, -4.5565, -4.2331, -4.5632, -4.7935, -4.4423, -4.2424, -4.1057,\n",
      "         -4.4584, -4.7765, -4.6500, -4.5502, -4.6470, -4.1861, -4.3769, -4.6938,\n",
      "         -4.5432, -4.6824, -4.9219, -4.8038, -4.0758, -4.7484, -4.8588, -4.6895,\n",
      "         -4.4295, -4.4947, -4.9188, -4.6051, -4.6028, -4.4510, -4.8533, -4.9429,\n",
      "         -4.7749, -4.3034, -4.6830, -4.9064, -4.5938, -4.2157, -4.6064, -4.7945,\n",
      "         -4.3794]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : besiege\n",
      "target index is: [75] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3770, -4.5130, -4.3943, -4.7751, -4.0742, -4.7770, -4.6005, -4.2641,\n",
      "         -4.6833, -4.7000, -4.9435, -4.7013, -4.6536, -4.5478, -5.0370, -4.6767,\n",
      "         -4.5851, -4.4367, -4.8331, -4.5978, -4.5664, -4.8649, -4.6160, -4.5717,\n",
      "         -4.3877, -4.7379, -4.6738, -4.5830, -4.2547, -4.3578, -4.4836, -4.6094,\n",
      "         -4.7570, -4.6766, -4.8593, -4.7757, -4.6195, -4.6678, -4.6785, -4.4758,\n",
      "         -4.4809, -4.6789, -4.7578, -4.1451, -4.5142, -4.4735, -4.3514, -4.3902,\n",
      "         -4.5542, -4.5926, -4.5876, -4.3286, -4.8017, -4.3669, -4.7340, -4.5461,\n",
      "         -4.5219, -4.5041, -4.4619, -4.6791, -5.0579, -4.4670, -4.5741, -3.7797,\n",
      "         -4.6810, -4.4463, -4.8285, -4.6385, -4.5575, -4.7439, -4.5603, -4.5302,\n",
      "         -4.7889, -4.9421, -4.7689, -4.7342, -4.7456, -4.2521, -4.8372, -4.8685,\n",
      "         -4.6882, -4.5108, -4.6160, -4.9440, -4.7043, -4.2652, -4.3442, -4.7870,\n",
      "         -5.3099, -4.1646, -4.7077, -4.6743, -4.5242, -4.5814, -4.3309, -4.5763,\n",
      "         -4.8143]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2830, -4.5323, -4.7247, -4.9168, -4.0210, -4.6666, -4.8221, -4.3568,\n",
      "         -5.2639, -4.3179, -4.8692, -4.1268, -4.8589, -4.6520, -4.6823, -4.9743,\n",
      "         -4.9115, -4.5961, -4.4800, -4.5075, -4.4718, -4.4818, -4.8240, -4.5223,\n",
      "         -4.8841, -4.8526, -4.1105, -4.5766, -4.5898, -4.5634, -4.6754, -4.8888,\n",
      "         -4.8717, -4.5443, -4.5345, -5.1668, -4.5620, -4.9831, -4.8372, -4.6703,\n",
      "         -4.8385, -4.9512, -4.8340, -4.5635, -4.6513, -4.3100, -4.8385, -4.7928,\n",
      "         -4.7656, -4.6985, -4.3667, -5.0667, -4.3928, -4.3875, -5.0178, -4.2256,\n",
      "         -4.7903, -4.4862, -4.4780, -4.2300, -4.3104, -4.4787, -4.6428, -3.8681,\n",
      "         -4.3063, -4.6832, -5.0750, -4.5719, -4.6876, -4.7167, -4.2953, -4.7358,\n",
      "         -5.1921, -4.7428, -4.4347, -4.9249, -4.3624, -4.2415, -4.4907, -4.5318,\n",
      "         -4.7068, -4.2672, -4.9705, -4.9585, -4.6516, -4.4265, -4.4179, -4.5102,\n",
      "         -4.8345, -4.5631, -4.0825, -4.3931, -4.6081, -4.4417, -4.1452, -4.6650,\n",
      "         -4.5661]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : brow,\n",
      "target index is: [13] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4366, -4.3020, -4.6604, -4.6262, -4.2798, -4.8582, -4.7916, -4.4180,\n",
      "         -4.6947, -4.7534, -4.8700, -4.5313, -4.8097, -4.3931, -4.7583, -4.8856,\n",
      "         -4.6540, -4.7173, -4.5017, -4.4846, -4.7939, -4.9223, -4.7849, -4.3200,\n",
      "         -4.6043, -4.8094, -4.7119, -4.2567, -4.0979, -4.3581, -4.2379, -4.7438,\n",
      "         -4.9098, -4.5435, -4.9130, -5.0229, -4.5256, -4.8939, -4.3500, -4.3449,\n",
      "         -4.7309, -4.5944, -4.4641, -4.1311, -4.6245, -4.1397, -4.7156, -4.8195,\n",
      "         -4.6111, -4.8203, -4.8704, -4.4699, -4.9101, -4.1081, -4.5946, -4.3963,\n",
      "         -4.3877, -4.1057, -4.7226, -4.6320, -4.8702, -4.4210, -4.5332, -4.1157,\n",
      "         -4.7558, -4.5669, -5.0807, -4.5367, -4.6074, -4.4306, -4.3744, -4.5045,\n",
      "         -4.8265, -4.9320, -4.8121, -5.0242, -5.0945, -3.8985, -4.9115, -5.0105,\n",
      "         -5.0017, -4.5379, -4.7360, -5.0925, -4.9949, -4.3998, -4.3727, -4.5371,\n",
      "         -4.9172, -3.9751, -4.8865, -4.5788, -4.6823, -4.5587, -4.2890, -4.8298,\n",
      "         -4.2926]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : And\n",
      "target index is: [6] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4293, -4.3366, -4.6162, -4.7731, -4.1937, -4.8231, -4.7320, -4.4622,\n",
      "         -4.8400, -4.5751, -4.4608, -4.3364, -4.9113, -5.0091, -4.3778, -4.8451,\n",
      "         -4.8604, -4.9824, -4.4731, -4.4665, -4.4026, -4.3499, -4.7398, -4.6276,\n",
      "         -4.6427, -4.6944, -4.3062, -4.4085, -4.3502, -4.9263, -4.5590, -5.2222,\n",
      "         -4.7437, -4.6134, -4.4472, -4.8161, -4.6757, -4.8951, -4.7887, -4.6113,\n",
      "         -4.7991, -4.9530, -4.8981, -4.7265, -4.7141, -4.4767, -4.5138, -4.6016,\n",
      "         -4.4636, -4.9943, -4.5177, -4.6540, -4.4543, -4.7004, -5.1626, -4.5728,\n",
      "         -4.5421, -4.4880, -4.4739, -4.5745, -4.6120, -4.6219, -4.8691, -4.1665,\n",
      "         -4.9430, -4.6496, -4.9673, -4.5686, -4.6140, -4.6813, -4.0790, -4.7859,\n",
      "         -5.0779, -4.6134, -4.2377, -4.8052, -4.7577, -4.3285, -4.7860, -4.2122,\n",
      "         -4.5995, -4.0158, -4.9362, -4.6925, -4.3683, -4.4537, -4.5117, -4.5146,\n",
      "         -4.7835, -4.3034, -4.6035, -4.5218, -4.2712, -4.0853, -4.1263, -4.4150,\n",
      "         -4.5053]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : dig\n",
      "target index is: [42] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4097, -4.6120, -4.7128, -4.9283, -4.2164, -4.8253, -4.7015, -4.5121,\n",
      "         -4.5306, -4.6603, -4.8665, -4.9777, -4.7553, -4.8179, -4.5439, -4.7150,\n",
      "         -4.6651, -4.7497, -4.6930, -4.4209, -4.8656, -4.4951, -5.1061, -4.6846,\n",
      "         -4.4909, -4.9427, -4.4797, -4.4717, -4.1298, -4.7624, -4.5059, -4.8170,\n",
      "         -4.8824, -4.7861, -4.2413, -4.5036, -4.3836, -4.6888, -4.8164, -4.6851,\n",
      "         -4.7959, -4.4364, -4.7449, -4.6146, -4.6923, -4.2198, -4.8774, -4.5005,\n",
      "         -4.6493, -4.8531, -4.3541, -4.7304, -4.6551, -4.5028, -4.7091, -4.5881,\n",
      "         -4.1987, -4.2914, -4.6135, -4.4195, -4.5650, -4.6844, -4.6592, -4.5937,\n",
      "         -4.6593, -4.3793, -5.0030, -4.5502, -4.6254, -4.7978, -4.2170, -4.1471,\n",
      "         -5.0110, -4.8995, -4.7342, -4.7667, -4.7004, -4.1606, -4.7960, -4.4821,\n",
      "         -4.4172, -4.4835, -4.5001, -4.9939, -4.4863, -4.3634, -4.2907, -4.4356,\n",
      "         -4.6980, -4.1760, -4.5053, -4.4094, -4.7669, -4.4338, -4.5679, -4.4132,\n",
      "         -4.2589]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : deep\n",
      "target index is: [76] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5748, -4.8911, -4.6810, -4.6107, -4.2305, -4.8166, -4.3964, -4.1764,\n",
      "         -4.7173, -5.0139, -4.8093, -4.4290, -4.5628, -4.8707, -4.8334, -4.2873,\n",
      "         -4.2428, -4.8141, -4.4642, -4.9467, -4.4905, -4.2184, -4.6498, -4.7167,\n",
      "         -4.1566, -4.9076, -4.4622, -4.7347, -4.6366, -4.4743, -4.7152, -4.6594,\n",
      "         -4.9156, -4.8871, -4.3976, -4.6169, -4.9608, -4.4999, -5.0150, -4.7202,\n",
      "         -4.8188, -4.6540, -4.8795, -4.5472, -4.4142, -4.3318, -4.5478, -4.6283,\n",
      "         -4.4734, -4.3149, -4.5142, -4.1539, -4.7545, -4.4115, -4.6400, -4.4440,\n",
      "         -4.5146, -4.5650, -4.5050, -4.6293, -5.0395, -4.6789, -4.5262, -3.9250,\n",
      "         -4.7031, -4.4522, -4.8712, -4.4001, -4.6889, -4.5662, -4.3674, -4.6697,\n",
      "         -4.6115, -4.5149, -4.6199, -4.9385, -4.5077, -4.5699, -4.9303, -4.7234,\n",
      "         -4.1579, -4.7527, -4.6936, -4.6267, -4.3472, -4.5684, -4.6721, -5.0527,\n",
      "         -4.9428, -4.3747, -4.5298, -4.7283, -4.6847, -4.4013, -4.4466, -4.4573,\n",
      "         -4.5688]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : trenches\n",
      "target index is: [54] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4943, -4.5142, -4.9209, -5.4015, -4.0708, -4.6435, -4.4492, -4.3805,\n",
      "         -4.8272, -4.3979, -4.8862, -4.3865, -4.7998, -4.8288, -4.9627, -4.7224,\n",
      "         -4.4595, -4.6364, -4.6753, -4.6737, -4.5626, -4.2519, -4.9282, -4.5578,\n",
      "         -4.4605, -4.8804, -4.1592, -4.5644, -4.5944, -4.7099, -4.4821, -5.0350,\n",
      "         -4.9257, -4.8899, -4.4999, -4.5718, -4.3561, -4.7615, -5.0200, -4.6737,\n",
      "         -4.8559, -4.8031, -4.5905, -4.5181, -4.4409, -4.4255, -4.5346, -4.7373,\n",
      "         -4.4011, -5.1777, -4.1426, -4.7534, -4.6653, -4.3709, -4.4746, -4.6711,\n",
      "         -4.9056, -4.6502, -4.2937, -4.4701, -4.6856, -4.4166, -4.4943, -4.0819,\n",
      "         -4.5092, -4.6605, -4.7388, -4.4695, -4.4468, -4.3530, -4.6342, -4.6833,\n",
      "         -5.1978, -4.6574, -4.8333, -5.0820, -4.2924, -4.1788, -4.4239, -4.5496,\n",
      "         -4.5603, -4.5237, -4.6307, -4.5136, -4.6854, -4.4286, -4.5133, -4.6771,\n",
      "         -4.6824, -4.6165, -4.1069, -4.5469, -4.7263, -4.2554, -4.5636, -4.7461,\n",
      "         -4.5020]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : in\n",
      "target index is: [95] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7545, -4.4428, -4.5667, -4.5160, -4.1331, -4.6720, -4.7226, -4.2042,\n",
      "         -4.7513, -4.5771, -4.6543, -4.2538, -4.4495, -4.7085, -4.8341, -4.6488,\n",
      "         -4.5938, -4.7380, -4.2007, -4.4929, -4.5236, -4.5521, -4.6166, -4.6395,\n",
      "         -4.2542, -4.9631, -4.4376, -4.8099, -4.3553, -4.4754, -4.7238, -4.6961,\n",
      "         -4.9230, -4.6626, -4.6218, -5.0662, -4.4748, -4.6451, -4.3285, -4.7158,\n",
      "         -4.5019, -4.5758, -4.9449, -4.6859, -4.5157, -4.3851, -4.4783, -4.9073,\n",
      "         -4.8276, -4.5068, -4.6237, -4.1797, -4.6602, -4.2610, -4.7351, -4.4142,\n",
      "         -4.5250, -4.2959, -4.3356, -4.7213, -4.8054, -4.6564, -4.5036, -4.0605,\n",
      "         -4.7805, -4.4394, -4.7159, -4.5926, -4.7955, -4.8316, -4.4262, -4.4888,\n",
      "         -5.0067, -4.7996, -4.8467, -4.8326, -4.6676, -4.3331, -4.7342, -5.0244,\n",
      "         -4.8073, -4.2250, -4.6821, -4.6778, -4.7211, -4.4099, -4.6454, -4.6749,\n",
      "         -4.8533, -4.2805, -4.9107, -4.7256, -4.6346, -4.3136, -4.4826, -4.6008,\n",
      "         -4.5226]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2818, -4.5164, -5.1339, -4.8390, -4.2636, -4.7131, -4.8090, -4.3593,\n",
      "         -5.2593, -4.2391, -4.9055, -4.1992, -4.4799, -4.3746, -4.9857, -5.0783,\n",
      "         -4.6328, -4.6069, -4.6077, -4.4002, -4.5102, -4.5189, -4.6292, -4.5926,\n",
      "         -4.5724, -5.0623, -4.2627, -4.5161, -4.6029, -4.7589, -4.7585, -4.4879,\n",
      "         -4.9684, -4.7782, -4.8283, -5.3795, -4.6799, -4.5583, -4.6411, -4.3377,\n",
      "         -4.5414, -4.6522, -4.3688, -4.4116, -4.2067, -4.1445, -4.6967, -4.6846,\n",
      "         -4.9500, -4.8038, -4.6192, -4.6955, -4.4346, -4.3456, -4.4925, -4.5359,\n",
      "         -4.5955, -4.3585, -4.4245, -4.6528, -4.6810, -4.4455, -4.3323, -4.1912,\n",
      "         -4.0129, -4.8238, -4.8447, -4.5003, -4.6263, -4.2214, -4.3305, -4.6338,\n",
      "         -4.7609, -4.7511, -4.7938, -4.7283, -4.2728, -4.1739, -4.5220, -4.6979,\n",
      "         -4.8254, -4.7548, -4.8385, -5.0200, -5.0893, -4.4493, -4.6840, -4.4939,\n",
      "         -5.1525, -4.6042, -4.4394, -4.7606, -4.9184, -4.3809, -4.2469, -4.8469,\n",
      "         -4.4501]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty's\n",
      "target index is: [80] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2946, -4.4793, -4.7662, -4.5191, -4.1942, -4.9194, -4.5931, -4.3178,\n",
      "         -4.3746, -5.1088, -4.9746, -4.2679, -4.6984, -4.7167, -4.6046, -4.7403,\n",
      "         -4.8697, -5.1447, -4.5506, -4.3942, -4.9364, -4.7318, -4.6341, -4.4803,\n",
      "         -4.2038, -4.6458, -4.6525, -4.4104, -3.8424, -4.5593, -4.8051, -4.6056,\n",
      "         -4.7222, -4.5478, -4.6222, -5.1361, -4.8561, -4.6193, -4.6644, -4.4971,\n",
      "         -4.6705, -4.2233, -4.9893, -4.0436, -4.5105, -4.0833, -4.4211, -4.4829,\n",
      "         -4.5518, -4.8928, -4.7813, -4.4742, -4.7577, -4.3141, -4.6061, -4.3958,\n",
      "         -4.2979, -4.3426, -4.7234, -5.0489, -4.8247, -4.1786, -4.4533, -4.0780,\n",
      "         -5.0332, -4.7943, -5.0912, -4.6595, -4.8276, -4.6378, -4.2738, -4.7036,\n",
      "         -4.5161, -4.8572, -4.7997, -4.8954, -5.1991, -4.2725, -4.7300, -4.4630,\n",
      "         -4.7832, -4.3172, -5.2193, -4.8323, -4.8592, -4.1060, -4.6051, -5.0105,\n",
      "         -5.0196, -4.5837, -5.2361, -4.4847, -4.6055, -4.4774, -4.2731, -4.2879,\n",
      "         -4.5113]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : field,\n",
      "target index is: [77] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.0574, -4.1486, -4.7658, -5.6431, -4.0483, -5.0783, -4.5543, -4.4136,\n",
      "         -4.8844, -4.7845, -4.6849, -5.1284, -5.0811, -4.8856, -4.6552, -4.8027,\n",
      "         -4.8874, -4.7062, -4.7961, -4.6038, -4.7621, -4.3015, -5.1291, -4.6525,\n",
      "         -4.6442, -4.8613, -4.3065, -4.0290, -4.2286, -4.9035, -4.2788, -4.7857,\n",
      "         -4.7911, -4.6684, -4.4924, -4.9525, -4.7174, -5.0179, -4.9743, -4.8051,\n",
      "         -4.5616, -5.1471, -4.8856, -4.6226, -4.5983, -4.0238, -5.0792, -4.4160,\n",
      "         -4.5912, -5.0221, -3.8213, -5.2228, -4.4222, -4.7924, -4.7752, -4.5032,\n",
      "         -4.5240, -4.3879, -4.4704, -4.2508, -4.7532, -4.5224, -4.4036, -3.7354,\n",
      "         -4.4688, -4.5438, -4.9996, -4.6632, -4.4590, -4.4719, -4.5988, -4.4170,\n",
      "         -5.3918, -4.9261, -4.7839, -4.8917, -4.4243, -4.1301, -4.5462, -4.4885,\n",
      "         -4.5552, -4.3725, -5.2383, -5.2323, -4.5355, -4.4781, -4.2486, -4.8316,\n",
      "         -4.6366, -4.2087, -4.1585, -4.3154, -4.9411, -4.1743, -4.4569, -4.8950,\n",
      "         -4.4598]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Thy\n",
      "target index is: [73] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3074, -4.5906, -4.7211, -4.6549, -4.2244, -4.9380, -4.6511, -4.1489,\n",
      "         -4.7327, -4.9157, -4.6653, -4.2375, -4.3633, -4.7356, -4.6359, -4.3615,\n",
      "         -4.6770, -4.8405, -4.1334, -4.6912, -4.5240, -4.2379, -4.8104, -4.7970,\n",
      "         -4.1644, -4.8523, -4.5772, -4.7142, -4.0092, -4.4614, -4.7743, -4.7125,\n",
      "         -4.8802, -4.5688, -4.7025, -5.1114, -4.9086, -4.5535, -4.8026, -4.9517,\n",
      "         -4.7527, -4.4092, -4.9721, -4.6536, -4.4895, -4.4192, -4.6211, -5.0934,\n",
      "         -4.6988, -4.5100, -4.6170, -4.2982, -4.7779, -4.4880, -4.8026, -4.4777,\n",
      "         -4.2198, -4.1851, -4.5604, -4.4316, -4.8240, -4.4148, -4.4939, -3.8923,\n",
      "         -4.8253, -4.6303, -4.7933, -4.8786, -4.8775, -4.6697, -4.3286, -4.3922,\n",
      "         -4.8819, -4.6902, -4.7739, -4.9132, -4.6026, -4.3643, -4.8278, -4.7384,\n",
      "         -4.4937, -4.3015, -5.1121, -4.6838, -4.3456, -4.7476, -4.7062, -4.6527,\n",
      "         -4.6837, -4.6578, -4.7312, -4.6441, -4.7152, -4.1445, -4.4742, -4.5856,\n",
      "         -4.4708]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : youth's\n",
      "target index is: [89] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2350, -4.7379, -4.7421, -4.8520, -4.1191, -4.7255, -4.8974, -4.5421,\n",
      "         -4.8274, -5.0111, -4.8969, -4.4259, -4.7463, -4.3996, -5.0494, -4.8253,\n",
      "         -4.6782, -4.6690, -4.6486, -4.6462, -4.3683, -4.4746, -4.5759, -4.5328,\n",
      "         -4.3230, -4.7344, -4.6886, -4.7742, -4.4854, -4.3841, -5.0071, -4.3681,\n",
      "         -4.9514, -4.6215, -4.6678, -5.1894, -4.7680, -4.7553, -4.8194, -4.3013,\n",
      "         -4.6382, -4.6517, -4.9086, -4.3399, -4.3120, -4.4945, -4.4798, -4.4001,\n",
      "         -4.5439, -4.4615, -4.3865, -4.8362, -4.4939, -4.2114, -4.3990, -4.4116,\n",
      "         -4.4717, -4.5357, -4.5830, -4.4721, -4.7291, -4.4021, -4.4694, -3.6320,\n",
      "         -4.2800, -4.3329, -4.8793, -4.6148, -4.7638, -4.5725, -4.3427, -4.6376,\n",
      "         -4.9219, -4.8264, -4.8625, -4.6347, -4.4477, -4.3096, -4.8761, -4.2815,\n",
      "         -4.7469, -4.7429, -4.9756, -5.2025, -4.5615, -4.2998, -4.4872, -5.0233,\n",
      "         -5.2658, -4.1845, -4.4664, -4.7285, -4.6503, -4.4723, -4.4176, -4.7097,\n",
      "         -4.8652]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : proud\n",
      "target index is: [50] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5589, -4.3365, -4.9492, -5.0866, -4.3672, -4.6377, -4.4125, -4.5137,\n",
      "         -5.3519, -4.4950, -4.8791, -4.4364, -4.8954, -4.5888, -4.6028, -5.1299,\n",
      "         -4.9312, -4.6877, -4.5145, -4.0696, -4.3848, -4.3746, -4.9387, -4.4885,\n",
      "         -4.9163, -4.9150, -4.4486, -4.3665, -4.7615, -4.8638, -4.7527, -4.6075,\n",
      "         -4.8692, -4.8060, -4.3447, -5.1317, -4.6202, -5.0263, -4.6590, -4.1779,\n",
      "         -4.3669, -4.6215, -4.6624, -4.4300, -4.6060, -4.2097, -4.8405, -4.2910,\n",
      "         -4.4575, -5.4044, -4.2808, -5.1071, -4.3037, -4.4788, -4.4962, -4.5318,\n",
      "         -4.8207, -4.4650, -4.3918, -4.7669, -4.6514, -4.2949, -4.6236, -4.3167,\n",
      "         -4.3382, -4.8716, -4.9205, -4.2280, -4.6319, -4.2690, -4.4435, -4.8300,\n",
      "         -4.9397, -4.9811, -4.5863, -4.8184, -4.5714, -4.2649, -4.3053, -4.1266,\n",
      "         -4.8967, -4.8031, -5.1517, -4.8368, -5.0116, -4.3396, -4.5294, -4.5454,\n",
      "         -4.7186, -4.2744, -4.4005, -4.1474, -4.8758, -4.5050, -4.2227, -4.6320,\n",
      "         -4.2538]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : livery\n",
      "target index is: [28] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6649, -4.4199, -5.0045, -4.7363, -4.0775, -5.1309, -4.4539, -4.3433,\n",
      "         -4.5748, -4.4699, -4.8856, -4.5819, -4.7422, -4.8620, -4.3050, -4.5790,\n",
      "         -4.7937, -5.0233, -4.7578, -4.4337, -4.8004, -4.0791, -5.0902, -4.7772,\n",
      "         -4.2229, -4.9044, -4.1581, -4.4307, -4.1119, -4.8321, -4.9322, -5.1332,\n",
      "         -4.9094, -4.7560, -4.6549, -4.7886, -4.5836, -4.7063, -5.0509, -4.5030,\n",
      "         -4.9456, -4.5301, -4.7893, -4.7382, -4.8073, -4.2744, -4.6418, -4.8859,\n",
      "         -4.3950, -5.0459, -4.3692, -4.6442, -4.5371, -4.2720, -4.6699, -4.3527,\n",
      "         -4.3067, -4.2082, -4.6977, -4.9030, -4.5216, -4.4605, -4.2117, -4.4619,\n",
      "         -4.5904, -4.5738, -4.7430, -4.7232, -4.6983, -4.3725, -4.2281, -4.4129,\n",
      "         -4.8179, -4.9233, -4.6487, -4.9137, -4.6332, -4.1615, -4.6952, -4.5391,\n",
      "         -4.5785, -4.6139, -4.9212, -4.6837, -4.4972, -4.3873, -4.4523, -4.8259,\n",
      "         -4.4487, -4.5177, -4.9601, -4.5596, -4.7464, -4.2910, -4.4927, -4.5018,\n",
      "         -3.9820]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : so\n",
      "target index is: [69] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4110, -4.2924, -4.9243, -4.8042, -4.2449, -5.0347, -4.6506, -4.3984,\n",
      "         -4.5619, -4.6591, -4.7858, -4.8125, -4.4604, -5.0128, -4.8534, -4.6135,\n",
      "         -4.7138, -4.4144, -4.5517, -4.5741, -4.4112, -4.2650, -5.0869, -4.8043,\n",
      "         -4.3416, -4.9269, -4.3642, -4.4908, -4.2016, -4.6746, -4.8357, -4.7785,\n",
      "         -4.9738, -4.9672, -4.6070, -4.7753, -4.8674, -4.4341, -4.8396, -4.6914,\n",
      "         -4.6439, -4.6560, -4.6267, -4.5750, -4.3835, -4.2747, -4.4996, -4.5578,\n",
      "         -4.4897, -4.8956, -4.5792, -4.4606, -4.8422, -4.3573, -4.4751, -4.6892,\n",
      "         -4.2123, -4.3688, -4.2987, -4.6508, -4.8873, -4.5266, -4.1985, -4.1534,\n",
      "         -4.4316, -4.8572, -4.4908, -4.4518, -4.3059, -4.4497, -4.2863, -4.4690,\n",
      "         -4.8032, -4.8724, -4.9961, -4.8593, -4.2796, -4.4871, -5.0907, -4.8197,\n",
      "         -4.3790, -4.6220, -4.8556, -4.7468, -4.7156, -4.3996, -4.5615, -4.6452,\n",
      "         -4.7515, -4.2576, -4.7603, -4.8438, -4.7464, -4.1509, -4.6898, -4.6453,\n",
      "         -4.3075]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : gazed\n",
      "target index is: [17] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4643, -4.3307, -4.6909, -4.7820, -4.3061, -4.6392, -4.5510, -4.3446,\n",
      "         -4.5774, -4.7431, -4.6912, -4.5651, -4.5794, -4.6999, -4.7702, -4.6249,\n",
      "         -4.4353, -4.6698, -4.6509, -4.5112, -4.6798, -4.6146, -4.7450, -4.6084,\n",
      "         -4.4031, -4.8689, -4.4302, -4.5695, -4.3292, -4.6124, -4.3978, -4.8348,\n",
      "         -4.8854, -4.7331, -4.5826, -4.6690, -4.5854, -4.6137, -4.7022, -4.5933,\n",
      "         -4.6962, -4.5854, -4.4334, -4.4205, -4.5918, -4.2706, -4.6849, -4.5654,\n",
      "         -4.4450, -4.5956, -4.5461, -4.2858, -4.8714, -4.4890, -4.6597, -4.3771,\n",
      "         -4.5717, -4.3252, -4.5363, -4.7073, -4.7405, -4.6120, -4.6667, -4.3158,\n",
      "         -4.6379, -4.6137, -4.8193, -4.4593, -4.5727, -4.5191, -4.4635, -4.4430,\n",
      "         -4.5041, -4.8352, -4.7124, -4.8343, -4.6584, -4.1806, -4.8935, -4.8679,\n",
      "         -4.6169, -4.6178, -4.6937, -4.8286, -4.5063, -4.4960, -4.3115, -4.6821,\n",
      "         -4.6863, -4.2994, -4.6918, -4.5453, -4.8000, -4.4901, -4.5703, -4.5400,\n",
      "         -4.5019]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : on\n",
      "target index is: [87] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4804, -4.6579, -4.6063, -4.6162, -4.2332, -4.6121, -4.3978, -4.2664,\n",
      "         -4.6763, -4.7063, -4.6296, -4.7795, -4.7530, -4.5820, -4.6682, -4.4685,\n",
      "         -4.3056, -4.6337, -4.6705, -4.7474, -4.8122, -4.6549, -4.7267, -4.5129,\n",
      "         -4.4499, -4.7536, -4.6086, -4.5025, -4.6090, -4.4110, -4.4572, -4.6788,\n",
      "         -4.7526, -4.7102, -4.7401, -4.6374, -4.7163, -4.6633, -4.9499, -4.5846,\n",
      "         -4.7034, -4.5353, -4.8210, -4.2947, -4.6979, -4.3775, -4.6130, -4.5763,\n",
      "         -4.4499, -4.3512, -4.7481, -4.4168, -5.1042, -4.2640, -4.6397, -4.2963,\n",
      "         -4.2504, -4.3448, -4.6327, -4.4883, -4.7295, -4.7350, -4.4569, -4.0270,\n",
      "         -4.8105, -4.2844, -4.8139, -4.5147, -4.5880, -4.5499, -4.4956, -4.6249,\n",
      "         -4.6954, -4.4420, -4.5761, -4.8088, -4.6879, -4.5378, -4.9859, -4.7912,\n",
      "         -4.4194, -4.4596, -4.7656, -4.6972, -4.6402, -4.4797, -4.6124, -4.7552,\n",
      "         -4.9291, -4.2417, -4.5182, -4.3476, -4.7635, -4.6548, -4.5075, -4.6682,\n",
      "         -4.7817]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : now,\n",
      "target index is: [63] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4611, -4.6040, -4.8472, -4.9194, -3.8236, -4.5179, -4.5337, -4.5283,\n",
      "         -4.6693, -4.6432, -4.5817, -4.3872, -5.0745, -4.8363, -4.7735, -4.5211,\n",
      "         -4.5527, -4.7977, -4.6043, -4.4177, -4.5718, -4.0862, -4.9378, -4.9079,\n",
      "         -4.6578, -4.9692, -4.6854, -4.3237, -4.3367, -4.7651, -4.4202, -5.0053,\n",
      "         -4.7184, -4.6374, -4.2487, -4.9031, -4.5292, -4.8756, -5.0978, -4.7316,\n",
      "         -4.6730, -4.4896, -4.7496, -4.4766, -4.6028, -4.3828, -4.3900, -4.8884,\n",
      "         -4.5408, -5.1291, -4.7659, -4.5799, -4.5003, -4.4672, -4.5589, -4.4502,\n",
      "         -4.2214, -4.4771, -4.4205, -4.5378, -4.5027, -4.5853, -4.8082, -4.3051,\n",
      "         -4.4542, -4.4227, -4.6902, -4.5330, -4.6910, -4.4293, -4.4346, -4.5784,\n",
      "         -5.0385, -4.9305, -4.6275, -4.8494, -5.0168, -4.4300, -4.7639, -4.4484,\n",
      "         -4.6268, -4.0770, -4.9041, -4.8200, -4.3246, -4.3229, -4.5692, -4.5409,\n",
      "         -4.8548, -4.4155, -4.6733, -4.2017, -4.7090, -4.3424, -4.5784, -4.5694,\n",
      "         -4.6067]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Will\n",
      "target index is: [36] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4053, -4.7776, -4.8081, -4.8715, -4.1052, -4.6425, -4.6603, -4.2768,\n",
      "         -4.5454, -4.7364, -4.6232, -4.6503, -4.6056, -4.8548, -4.9218, -4.3084,\n",
      "         -4.4752, -4.5861, -4.3634, -4.5608, -4.8239, -4.1466, -4.9720, -5.0489,\n",
      "         -4.1337, -5.0214, -4.4186, -4.4270, -4.2021, -4.4446, -4.4642, -4.8962,\n",
      "         -5.0377, -4.8696, -4.3600, -4.6807, -4.6252, -4.6589, -5.0798, -4.7788,\n",
      "         -4.9789, -4.5718, -4.4395, -4.6216, -4.6880, -4.3593, -4.6909, -4.6849,\n",
      "         -4.5709, -4.8940, -4.3983, -4.5894, -4.9065, -4.5816, -4.6416, -4.4498,\n",
      "         -4.1049, -4.3200, -4.3028, -4.5238, -4.9771, -4.7311, -4.4757, -4.4516,\n",
      "         -4.5237, -4.4368, -4.6915, -4.5591, -4.7356, -4.6875, -4.2802, -4.2951,\n",
      "         -4.8177, -4.9263, -4.7294, -4.7685, -4.4376, -4.3042, -4.7300, -4.7938,\n",
      "         -4.4769, -4.6439, -4.6348, -4.7192, -4.4336, -4.4953, -4.5424, -4.7931,\n",
      "         -4.6565, -4.3270, -4.6699, -4.5225, -4.8061, -4.4873, -4.8249, -4.3818,\n",
      "         -4.3012]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : be\n",
      "target index is: [24] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3542, -4.6592, -4.7645, -4.7605, -4.1553, -4.9905, -4.6049, -4.3324,\n",
      "         -4.7593, -4.7955, -4.6364, -4.2841, -4.6731, -5.0082, -5.0945, -4.3662,\n",
      "         -4.3878, -4.7635, -4.6896, -4.9868, -4.3654, -3.9555, -4.5155, -4.6669,\n",
      "         -4.1145, -5.0923, -4.3245, -4.8100, -4.3911, -4.5819, -4.3683, -5.2335,\n",
      "         -4.8410, -4.7833, -4.5998, -4.5434, -4.6914, -4.5293, -4.9914, -4.8478,\n",
      "         -5.0297, -4.7215, -4.6354, -4.6756, -4.3895, -4.4992, -4.5584, -4.7561,\n",
      "         -4.6007, -4.6089, -4.7224, -4.0747, -5.0897, -4.4252, -4.6832, -4.6518,\n",
      "         -4.5124, -4.5006, -4.3318, -4.6994, -4.9075, -4.5365, -4.5763, -4.0334,\n",
      "         -4.6814, -4.5006, -4.8577, -4.4130, -4.3095, -4.4013, -4.1862, -4.6451,\n",
      "         -4.9460, -4.7562, -5.0834, -5.1908, -4.5001, -4.2722, -4.9250, -4.8990,\n",
      "         -4.1881, -4.5627, -4.6566, -4.4732, -4.3349, -4.4696, -4.3886, -4.8749,\n",
      "         -5.0077, -4.5315, -4.2135, -4.7569, -4.5506, -4.4096, -4.5322, -4.5978,\n",
      "         -4.5385]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : a\n",
      "target index is: [46] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3970, -4.5137, -4.6619, -5.3677, -4.1369, -4.6993, -4.2725, -4.0488,\n",
      "         -4.7785, -4.5539, -4.8465, -4.9054, -4.4042, -4.7549, -4.6874, -4.3012,\n",
      "         -4.2003, -4.6211, -4.6701, -4.5980, -5.0845, -4.3363, -4.9015, -4.9570,\n",
      "         -4.3162, -5.2837, -4.1852, -4.4198, -4.2832, -4.6526, -4.4728, -4.7473,\n",
      "         -4.8879, -5.0234, -4.4460, -4.6527, -4.5270, -4.3817, -4.9060, -4.5727,\n",
      "         -4.8416, -4.6012, -4.9676, -4.3058, -4.9408, -4.1853, -4.8614, -4.7508,\n",
      "         -4.7235, -4.7725, -4.1396, -4.6261, -4.5618, -4.4956, -4.6424, -4.5867,\n",
      "         -4.3169, -4.5471, -4.3863, -4.7379, -4.8516, -4.7136, -4.4648, -4.3230,\n",
      "         -4.6456, -4.3776, -5.0350, -4.3646, -4.7763, -4.8216, -4.7177, -4.4678,\n",
      "         -4.8927, -4.8641, -4.6649, -4.8804, -4.4498, -4.2697, -4.4146, -4.6970,\n",
      "         -4.4080, -4.6059, -4.7274, -4.7201, -4.8690, -4.3537, -4.5968, -4.7197,\n",
      "         -4.7355, -4.3355, -4.5895, -4.3735, -5.0712, -4.3258, -4.7699, -4.3154,\n",
      "         -4.2961]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : totter'd\n",
      "target index is: [20] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7412, -4.6460, -4.9510, -4.8767, -4.3862, -4.7965, -4.6774, -4.0558,\n",
      "         -4.8807, -4.6004, -4.8392, -4.2601, -4.3198, -4.6853, -4.9839, -4.6105,\n",
      "         -4.6919, -4.4378, -4.3080, -4.7182, -4.5990, -4.3668, -4.7252, -4.7931,\n",
      "         -4.1043, -5.1649, -4.4919, -4.7618, -4.1564, -4.3511, -4.4953, -4.7805,\n",
      "         -4.8183, -4.8707, -4.8742, -5.1877, -4.6401, -4.5083, -4.7805, -4.5522,\n",
      "         -4.7377, -4.7418, -4.6786, -4.6227, -4.6260, -4.4154, -4.8435, -4.8105,\n",
      "         -4.8076, -4.7108, -4.3726, -4.4911, -4.8393, -4.5285, -4.5488, -4.4210,\n",
      "         -4.3916, -4.2666, -4.2605, -4.4154, -4.7696, -4.4698, -4.5249, -3.9053,\n",
      "         -4.5434, -4.6388, -4.4420, -4.6688, -4.6312, -4.0348, -4.3958, -4.2650,\n",
      "         -5.0576, -4.8474, -5.0081, -5.0270, -4.2983, -4.3157, -4.4730, -4.9209,\n",
      "         -4.7020, -4.5723, -4.9678, -4.6077, -4.8425, -4.5583, -4.6265, -4.6838,\n",
      "         -4.8159, -4.4506, -4.5483, -4.6926, -4.8264, -4.1044, -4.6631, -4.7013,\n",
      "         -4.2920]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : weed\n",
      "target index is: [29] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6233, -4.7163, -4.5422, -4.6712, -4.1427, -4.7549, -4.5636, -4.3300,\n",
      "         -4.6810, -4.8074, -4.6498, -4.6497, -4.6786, -4.7927, -5.0469, -4.8073,\n",
      "         -4.4180, -4.4259, -4.4457, -4.5641, -4.5573, -4.6585, -4.7291, -4.4687,\n",
      "         -4.2178, -4.8326, -4.5492, -4.7173, -4.5474, -4.4753, -4.2920, -4.5946,\n",
      "         -4.5550, -4.7277, -4.6353, -4.7234, -4.3856, -4.5707, -4.3836, -4.6072,\n",
      "         -4.6246, -4.6766, -4.7965, -4.6046, -4.5266, -4.2616, -4.2438, -4.5304,\n",
      "         -4.6663, -4.4795, -4.7296, -4.3183, -4.8802, -4.3767, -4.4525, -4.5203,\n",
      "         -4.4436, -4.3285, -4.3092, -4.6609, -5.0179, -4.5155, -4.5222, -4.2049,\n",
      "         -4.8436, -4.6712, -4.6554, -4.6039, -4.5111, -4.4734, -4.5481, -4.6278,\n",
      "         -4.8280, -4.9242, -4.8344, -4.7864, -4.6207, -4.2385, -4.9625, -4.8862,\n",
      "         -4.7117, -4.5282, -4.6373, -4.5673, -4.7177, -4.5253, -4.4311, -4.7838,\n",
      "         -4.9829, -4.1591, -4.7082, -4.4834, -4.6713, -4.4814, -4.5347, -4.7788,\n",
      "         -4.5908]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : of\n",
      "target index is: [57] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5427, -4.4041, -4.3598, -4.6200, -3.9175, -4.7302, -5.0192, -4.4716,\n",
      "         -4.7177, -4.6089, -4.6322, -4.2387, -4.8651, -4.8304, -4.6331, -4.5526,\n",
      "         -4.5658, -4.9350, -4.4534, -4.7914, -4.4154, -4.1549, -4.5900, -4.4645,\n",
      "         -4.3957, -4.7343, -4.4515, -4.7100, -4.3775, -4.6119, -4.4573, -5.2681,\n",
      "         -4.7187, -4.2810, -4.6564, -5.0004, -4.5849, -4.8826, -4.6049, -4.8872,\n",
      "         -4.7108, -4.7850, -4.8302, -4.6660, -4.4940, -4.4184, -4.4654, -4.9404,\n",
      "         -4.8142, -4.4435, -4.6342, -4.4687, -4.8568, -4.2987, -4.9792, -4.4936,\n",
      "         -4.6378, -4.4392, -4.4864, -4.4360, -4.7421, -4.8103, -4.7082, -3.7849,\n",
      "         -4.7683, -4.6260, -5.0271, -4.6312, -4.6154, -4.7477, -4.3068, -4.5158,\n",
      "         -4.9793, -4.6970, -4.6379, -4.7680, -4.7518, -4.4331, -4.8625, -4.9037,\n",
      "         -4.6629, -4.0673, -4.8261, -4.7566, -4.4336, -4.5747, -4.4064, -4.5688,\n",
      "         -4.9150, -4.1779, -4.6234, -4.7361, -4.5590, -4.4443, -4.0632, -4.8002,\n",
      "         -4.4317]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : small\n",
      "target index is: [38] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3525, -4.2926, -4.6695, -4.8373, -4.2882, -4.7402, -4.5918, -4.5189,\n",
      "         -4.6804, -4.9172, -4.8756, -4.6489, -4.7780, -4.4910, -4.3024, -4.7479,\n",
      "         -4.8075, -5.0098, -4.5990, -4.2626, -4.8063, -4.5530, -4.7120, -4.4233,\n",
      "         -4.7263, -5.0878, -4.7251, -4.4144, -4.1065, -4.5839, -4.4674, -4.9941,\n",
      "         -4.7741, -4.6435, -4.4350, -4.8574, -4.7655, -4.8429, -4.8978, -4.3877,\n",
      "         -4.6188, -4.5734, -4.9040, -4.1318, -4.8907, -4.1438, -4.9831, -4.4078,\n",
      "         -4.4394, -4.8509, -4.9118, -4.6864, -4.7861, -4.4282, -4.6176, -4.6413,\n",
      "         -4.2511, -4.2754, -4.6290, -4.6465, -4.5972, -4.7096, -4.8081, -4.2668,\n",
      "         -4.9560, -4.4771, -5.1544, -4.2208, -4.6857, -4.7675, -4.2035, -4.6419,\n",
      "         -4.7824, -4.6839, -4.8308, -4.6920, -5.1476, -4.3369, -4.7267, -4.1987,\n",
      "         -4.6946, -4.4187, -4.8090, -4.9804, -4.6274, -4.1031, -4.3151, -4.4196,\n",
      "         -5.0235, -4.1994, -4.5717, -4.2577, -4.6614, -4.5890, -4.2408, -4.3757,\n",
      "         -4.3248]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : worth\n",
      "target index is: [83] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7167, -4.6311, -4.7451, -5.0350, -4.2322, -4.8357, -4.3592, -4.4935,\n",
      "         -4.6969, -4.7010, -5.0793, -4.8024, -4.9060, -4.8255, -4.4516, -4.5351,\n",
      "         -4.5203, -4.8428, -4.5905, -4.4291, -4.7869, -3.9183, -5.2429, -4.6838,\n",
      "         -4.1782, -5.1081, -4.2263, -4.0523, -4.5728, -4.5672, -4.9978, -4.9208,\n",
      "         -5.0642, -4.8883, -4.5358, -4.3008, -4.8112, -4.9121, -5.1890, -4.6537,\n",
      "         -4.9507, -5.1878, -4.8126, -4.6323, -4.7828, -4.4828, -4.7884, -4.9998,\n",
      "         -4.2648, -4.9246, -3.9171, -4.7610, -4.2162, -3.8660, -4.9869, -4.0547,\n",
      "         -4.8179, -4.4179, -4.5128, -4.5240, -4.7926, -4.8190, -4.5336, -4.1418,\n",
      "         -4.8461, -4.1963, -5.0674, -4.5227, -4.8342, -4.6093, -4.1876, -4.7023,\n",
      "         -4.8834, -4.3098, -4.4597, -5.0557, -4.4879, -4.4114, -4.9699, -4.7205,\n",
      "         -4.2613, -4.3307, -4.8044, -4.4765, -4.2710, -4.3305, -5.0538, -5.2423,\n",
      "         -4.5094, -4.2307, -4.5831, -4.7120, -4.5179, -4.3181, -4.3832, -4.8206,\n",
      "         -4.3175]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : held:\n",
      "target index is: [19] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4189, -4.3778, -5.0640, -5.0757, -4.0033, -4.9033, -4.3787, -4.5468,\n",
      "         -4.6463, -4.1499, -5.0394, -4.6076, -4.8693, -4.7526, -4.4207, -4.6623,\n",
      "         -4.6030, -4.6902, -4.9762, -4.4997, -4.3783, -4.3728, -5.0733, -4.7184,\n",
      "         -4.8244, -5.2061, -4.4347, -4.4218, -4.6069, -4.6568, -4.7504, -4.6350,\n",
      "         -4.7550, -5.1829, -4.5918, -4.6094, -4.4937, -4.6512, -4.9589, -4.2423,\n",
      "         -4.5810, -4.6018, -4.4769, -4.2457, -4.2824, -4.5669, -4.6715, -4.5458,\n",
      "         -4.1942, -5.3474, -4.3496, -4.9736, -4.7416, -4.3349, -4.7341, -4.5807,\n",
      "         -4.5840, -4.6496, -4.5184, -4.5763, -4.6517, -4.3936, -4.4201, -4.4476,\n",
      "         -4.4465, -4.7240, -4.7025, -4.2866, -4.5685, -4.3480, -4.5596, -4.9326,\n",
      "         -4.8487, -4.5841, -4.8686, -5.3372, -4.2100, -4.7621, -4.7136, -4.7413,\n",
      "         -4.6607, -4.2219, -4.7942, -4.5403, -5.3123, -3.9281, -5.0813, -4.5426,\n",
      "         -4.7127, -4.0020, -4.5830, -4.8264, -4.8037, -4.1285, -4.6173, -4.3066,\n",
      "         -4.2590]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Then\n",
      "target index is: [65] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4005, -4.4910, -4.8943, -4.7499, -3.9467, -4.8724, -4.6722, -4.7285,\n",
      "         -4.8067, -4.6304, -4.7181, -4.6084, -4.7726, -4.6842, -4.7674, -4.5994,\n",
      "         -4.5307, -4.6846, -5.1204, -4.7427, -4.5863, -4.2274, -4.9816, -4.3236,\n",
      "         -4.4223, -4.7322, -4.7825, -4.2737, -4.3130, -4.3893, -4.6642, -4.5535,\n",
      "         -4.8617, -4.8659, -4.5339, -4.2824, -4.6697, -5.0196, -4.9995, -4.4273,\n",
      "         -4.8895, -4.4104, -4.5164, -4.3567, -4.3241, -4.3431, -4.5136, -4.7196,\n",
      "         -4.3250, -4.9940, -4.6766, -4.5224, -4.9851, -4.0070, -4.5709, -4.3886,\n",
      "         -4.2695, -4.4656, -4.7114, -4.3279, -4.7629, -4.6142, -4.4784, -4.3833,\n",
      "         -4.6701, -4.5864, -4.7557, -4.2700, -4.5979, -4.4520, -4.3942, -4.6906,\n",
      "         -4.8159, -4.7788, -4.9263, -4.9903, -4.4738, -4.5109, -5.1402, -5.0032,\n",
      "         -4.4941, -4.2052, -4.4179, -4.5115, -4.7968, -4.0693, -4.8144, -5.0154,\n",
      "         -4.8488, -4.0929, -4.7326, -4.9160, -4.5438, -4.4051, -4.4967, -4.8754,\n",
      "         -4.7030]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : being\n",
      "target index is: [32] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4014, -4.2549, -4.6135, -5.0688, -4.1638, -4.3893, -4.5229, -4.1052,\n",
      "         -4.9766, -4.4428, -4.8289, -4.3400, -4.6613, -4.4311, -5.0168, -4.4011,\n",
      "         -4.4380, -4.4674, -4.6784, -4.0544, -4.8331, -4.7541, -4.5470, -4.6004,\n",
      "         -4.9057, -4.5760, -4.6273, -4.5273, -4.4098, -4.7691, -4.2728, -4.8267,\n",
      "         -4.8978, -4.5530, -4.5205, -4.7919, -4.4966, -4.9779, -4.9246, -4.8136,\n",
      "         -4.6903, -4.7244, -4.5228, -4.1784, -4.4697, -4.1237, -4.7173, -4.7235,\n",
      "         -4.7677, -4.6705, -4.6959, -4.3656, -4.5411, -4.5170, -4.9845, -4.6714,\n",
      "         -4.5604, -4.6419, -4.5020, -4.5595, -4.8991, -4.8452, -4.7663, -4.2102,\n",
      "         -4.5560, -4.5199, -5.0019, -4.4793, -4.6686, -4.8576, -4.5490, -4.6401,\n",
      "         -4.6876, -5.1065, -4.3749, -4.5374, -4.6585, -4.3968, -4.6593, -4.6783,\n",
      "         -4.6812, -4.4150, -4.4528, -4.9072, -4.8051, -4.4610, -4.3563, -4.2023,\n",
      "         -5.0941, -4.3619, -4.6846, -4.4017, -4.9994, -4.4911, -4.4274, -4.3975,\n",
      "         -4.6623]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : asked,\n",
      "target index is: [23] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2130, -4.6114, -4.5121, -4.6335, -4.1361, -4.8232, -4.7126, -4.3780,\n",
      "         -4.6553, -4.5889, -4.6624, -4.3402, -4.6598, -4.7171, -4.6658, -4.7773,\n",
      "         -4.7238, -5.0577, -4.4354, -4.8055, -4.5267, -4.4744, -4.7439, -4.5885,\n",
      "         -4.4156, -4.8453, -4.5376, -4.4954, -4.3078, -4.5497, -4.5934, -4.8098,\n",
      "         -4.6599, -4.5562, -4.7106, -5.0425, -4.5696, -4.4404, -4.5263, -4.6517,\n",
      "         -4.7445, -4.3959, -4.6589, -4.4811, -4.4035, -4.1906, -4.6440, -4.8633,\n",
      "         -4.7880, -4.5071, -4.5857, -4.3849, -4.8992, -4.4237, -4.8051, -4.3714,\n",
      "         -4.5780, -4.3033, -4.3638, -4.6375, -4.7085, -4.5110, -4.6169, -3.9415,\n",
      "         -4.7791, -4.6101, -4.9437, -4.6599, -4.8622, -4.6382, -4.5013, -4.5763,\n",
      "         -4.9155, -4.5143, -4.6418, -4.9511, -4.7683, -4.2830, -4.7155, -4.9429,\n",
      "         -4.6066, -4.1795, -4.9095, -4.6207, -4.4076, -4.5301, -4.6246, -4.5397,\n",
      "         -5.0138, -4.4479, -4.5413, -4.5032, -4.6548, -4.6140, -4.2605, -4.6931,\n",
      "         -4.4255]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : where\n",
      "target index is: [51] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3820, -4.2757, -4.6758, -4.9591, -4.2442, -4.9337, -4.7703, -4.6347,\n",
      "         -4.8753, -4.6420, -4.9543, -4.5861, -4.8335, -4.6449, -4.6339, -4.9447,\n",
      "         -4.6699, -4.5884, -4.9152, -4.5254, -4.6465, -4.5505, -4.8907, -4.5096,\n",
      "         -4.5921, -4.7474, -4.3576, -4.3842, -4.2953, -4.6325, -4.3287, -4.9219,\n",
      "         -4.7341, -4.6412, -4.5122, -4.9726, -4.4610, -4.6695, -4.7842, -4.5493,\n",
      "         -4.6094, -4.6975, -4.6352, -4.5591, -4.5723, -4.1187, -4.7843, -4.5563,\n",
      "         -4.7439, -4.7869, -4.2367, -4.8958, -4.7437, -4.4901, -4.4763, -4.6926,\n",
      "         -4.5324, -4.4249, -4.5668, -4.5419, -4.5465, -4.4529, -4.5079, -4.3415,\n",
      "         -4.4762, -4.7973, -5.0421, -4.2876, -4.3949, -4.3286, -4.6690, -4.4681,\n",
      "         -5.0693, -5.0063, -4.8368, -4.9423, -4.6366, -4.2026, -4.5140, -4.5051,\n",
      "         -4.4451, -4.3801, -4.7490, -4.9003, -4.8361, -4.2579, -4.3258, -4.4743,\n",
      "         -4.7704, -4.3898, -4.2337, -4.6943, -4.6965, -4.3480, -4.2521, -4.5839,\n",
      "         -4.2090]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : all\n",
      "target index is: [52] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4779, -4.2684, -4.6836, -4.7884, -4.4083, -4.8233, -4.4780, -4.4507,\n",
      "         -4.5392, -4.8699, -5.0112, -4.7154, -4.4967, -4.6038, -4.5955, -4.6333,\n",
      "         -4.6334, -4.7301, -4.5904, -4.2273, -4.8174, -4.7496, -4.7640, -4.4903,\n",
      "         -4.3889, -4.8609, -4.4765, -4.4914, -4.1932, -4.8141, -4.4811, -4.7696,\n",
      "         -4.8631, -4.8124, -4.4839, -4.5367, -4.6014, -4.4852, -4.6510, -4.6031,\n",
      "         -4.7175, -4.5969, -4.7400, -4.4784, -4.8069, -4.1697, -4.8143, -4.6349,\n",
      "         -4.5658, -4.8141, -4.4246, -4.4444, -4.6204, -4.2923, -4.7070, -4.5501,\n",
      "         -4.3713, -4.3986, -4.5793, -4.7462, -4.7715, -4.7128, -4.5575, -4.5390,\n",
      "         -4.7979, -4.5249, -5.0873, -4.3584, -4.6386, -4.6601, -4.4295, -4.4707,\n",
      "         -4.5501, -4.9046, -4.6246, -4.6487, -4.6151, -4.2204, -4.6368, -4.6639,\n",
      "         -4.5340, -4.5823, -4.6559, -4.8438, -4.6401, -4.3415, -4.4735, -4.5828,\n",
      "         -4.7095, -4.3017, -4.6934, -4.6378, -4.6518, -4.5088, -4.3264, -4.4445,\n",
      "         -4.2001]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4554, -4.3512, -4.9436, -4.7872, -4.2668, -4.7851, -4.8886, -4.3834,\n",
      "         -5.0862, -4.2649, -5.0052, -4.3627, -4.5193, -4.6832, -4.6510, -4.7918,\n",
      "         -4.5388, -4.4486, -4.4440, -4.4971, -4.6396, -4.3344, -4.5915, -4.7822,\n",
      "         -4.4517, -5.0773, -4.3351, -4.5191, -4.4797, -4.5048, -4.7258, -4.6636,\n",
      "         -4.8301, -4.6205, -4.8877, -5.0708, -4.6690, -4.6351, -4.8930, -4.6477,\n",
      "         -4.6311, -4.7501, -4.6710, -4.5856, -4.5167, -4.1063, -4.8037, -4.7013,\n",
      "         -4.8661, -4.6695, -4.7512, -4.7667, -4.5890, -4.2568, -4.4573, -4.7694,\n",
      "         -4.3128, -4.4035, -4.4487, -4.5550, -4.7060, -4.5774, -4.2827, -4.2606,\n",
      "         -4.2128, -4.7470, -4.7118, -4.2166, -4.6091, -4.3685, -4.4163, -4.5594,\n",
      "         -4.7984, -4.6199, -4.7726, -4.7457, -4.2223, -4.4365, -4.4725, -4.7035,\n",
      "         -4.5405, -4.5482, -4.7949, -5.0350, -4.8710, -4.4588, -4.7443, -4.6132,\n",
      "         -4.8956, -4.4644, -4.5176, -4.7740, -4.8194, -4.3114, -4.0469, -4.8302,\n",
      "         -4.3565]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty\n",
      "target index is: [0] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4187, -4.6573, -4.8239, -4.9168, -4.2146, -4.6788, -4.4545, -4.2186,\n",
      "         -5.1036, -4.4856, -4.8138, -4.4018, -4.3175, -4.6239, -4.8207, -5.0762,\n",
      "         -4.6658, -4.5625, -4.6687, -4.4809, -4.7699, -4.7216, -4.9338, -4.6297,\n",
      "         -4.4921, -5.1840, -4.3263, -4.4248, -4.2222, -4.6998, -4.5256, -4.3240,\n",
      "         -4.7049, -4.8865, -4.6682, -5.1416, -4.3123, -4.5460, -4.3740, -4.3914,\n",
      "         -4.5374, -4.3636, -4.6180, -4.2767, -4.5365, -4.0450, -4.8775, -4.5828,\n",
      "         -4.8827, -4.8005, -4.4941, -4.6808, -4.8406, -4.5033, -4.5479, -4.5587,\n",
      "         -4.4574, -4.4342, -4.4887, -4.5137, -4.7031, -4.4204, -4.3875, -4.3670,\n",
      "         -4.2984, -5.0106, -4.8356, -4.4016, -4.7854, -4.0306, -4.5573, -4.4406,\n",
      "         -5.0879, -4.9306, -4.7656, -4.7447, -4.5981, -3.9007, -4.4748, -4.7921,\n",
      "         -4.7396, -4.7641, -4.8358, -4.9245, -5.1286, -4.3147, -4.5451, -4.3743,\n",
      "         -5.3203, -4.8325, -4.7763, -4.5471, -4.8915, -4.3418, -4.5047, -4.7928,\n",
      "         -4.2437]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : lies,\n",
      "target index is: [59] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2870, -4.6411, -4.6643, -4.6623, -4.1832, -4.8745, -4.4767, -4.2494,\n",
      "         -4.6568, -5.1549, -4.7785, -4.4172, -4.5365, -4.7844, -4.7808, -4.6491,\n",
      "         -4.4532, -4.9523, -4.8552, -4.9101, -4.4334, -4.5089, -4.7282, -4.4960,\n",
      "         -4.1569, -4.8683, -4.4984, -4.4126, -4.3340, -4.5913, -4.6102, -4.6943,\n",
      "         -4.5353, -5.0925, -4.4862, -4.6408, -4.8888, -4.3129, -4.6751, -4.3668,\n",
      "         -5.0358, -4.2326, -4.7452, -4.4086, -4.4873, -4.1583, -4.4918, -4.5920,\n",
      "         -4.5588, -4.5438, -4.5949, -4.1671, -5.0410, -4.3551, -4.7206, -4.3067,\n",
      "         -4.5737, -4.5044, -4.7418, -4.7801, -4.6688, -4.2751, -4.5116, -4.3361,\n",
      "         -4.6879, -4.6557, -4.7029, -4.3674, -4.6733, -4.4317, -4.4152, -4.6323,\n",
      "         -4.4755, -4.9507, -4.8800, -4.9234, -4.6434, -4.1446, -4.8745, -5.0667,\n",
      "         -4.4035, -4.7113, -4.6814, -4.7941, -4.4193, -4.4632, -4.4568, -5.0393,\n",
      "         -4.9877, -4.5111, -4.7426, -4.6924, -4.4269, -4.6115, -4.6975, -4.5676,\n",
      "         -4.4328]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Where\n",
      "target index is: [18] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5651, -4.4109, -4.3692, -4.5892, -4.2129, -4.9761, -4.7837, -4.4885,\n",
      "         -4.6708, -4.7631, -4.6949, -4.4831, -4.7130, -4.7854, -4.5665, -4.5520,\n",
      "         -4.8567, -4.5984, -4.5556, -4.6174, -4.3713, -4.2995, -4.7870, -4.6331,\n",
      "         -4.4057, -4.7825, -4.6696, -4.4579, -4.3391, -4.5492, -4.7039, -4.6541,\n",
      "         -4.8484, -4.5562, -4.6584, -4.8966, -4.5662, -4.8894, -4.5073, -4.5073,\n",
      "         -4.6638, -4.6561, -4.8609, -4.5263, -4.6588, -4.3932, -4.5597, -4.6709,\n",
      "         -4.4771, -4.8321, -4.5091, -4.8203, -4.6151, -4.6093, -4.7215, -4.7453,\n",
      "         -4.2644, -4.4574, -4.4033, -4.4895, -4.8261, -4.8097, -4.4946, -4.1755,\n",
      "         -4.8969, -4.4302, -4.9214, -4.3571, -4.5784, -4.6909, -4.2929, -4.4338,\n",
      "         -4.8463, -4.9464, -4.8166, -4.7819, -4.3156, -4.2997, -4.9116, -4.5475,\n",
      "         -4.4827, -4.2782, -4.6246, -4.7484, -4.6191, -4.4524, -4.3910, -4.6860,\n",
      "         -4.7789, -4.2342, -4.5655, -4.7044, -4.5678, -4.4139, -4.2597, -4.5042,\n",
      "         -4.5351]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : all\n",
      "target index is: [52] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2991, -4.2344, -4.6194, -4.9146, -4.3092, -4.5982, -4.5819, -4.4477,\n",
      "         -4.7889, -4.9567, -4.8567, -4.4963, -4.7547, -4.6773, -4.4979, -4.7229,\n",
      "         -4.7388, -5.0274, -4.3929, -4.1995, -4.7672, -4.3932, -4.7452, -4.4870,\n",
      "         -4.6099, -4.7302, -4.3923, -4.4741, -4.2181, -4.9671, -4.4547, -4.9351,\n",
      "         -4.8386, -4.6281, -4.3025, -4.7012, -4.5669, -4.7922, -4.7940, -4.7042,\n",
      "         -4.6447, -4.6210, -4.8639, -4.5669, -4.9124, -4.2227, -4.9996, -4.6335,\n",
      "         -4.6142, -4.8634, -4.4184, -4.6352, -4.4325, -4.4879, -4.9953, -4.6066,\n",
      "         -4.6075, -4.4794, -4.6003, -4.7798, -4.5485, -4.6180, -4.6766, -4.3656,\n",
      "         -4.9599, -4.4359, -5.1359, -4.5793, -4.7580, -4.6912, -4.3195, -4.5109,\n",
      "         -4.5831, -4.8544, -4.3783, -4.6124, -4.7357, -4.1775, -4.5663, -4.4036,\n",
      "         -4.5177, -4.4395, -4.8330, -4.9033, -4.4290, -4.4550, -4.3466, -4.5445,\n",
      "         -4.7268, -4.2504, -4.5347, -4.4076, -4.7304, -4.5177, -4.1274, -4.4097,\n",
      "         -4.3377]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : the\n",
      "target index is: [82] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1805, -4.3975, -4.5529, -4.8780, -4.1749, -4.6925, -4.6799, -4.3342,\n",
      "         -4.6253, -4.6969, -4.8809, -4.7391, -4.6397, -4.8061, -4.7044, -4.6463,\n",
      "         -4.4262, -4.5098, -4.4326, -4.6592, -4.8793, -4.4872, -4.8551, -4.6009,\n",
      "         -4.2269, -4.4979, -4.5415, -4.4757, -4.4272, -4.4858, -4.5571, -4.7261,\n",
      "         -4.5626, -4.6306, -4.8711, -4.7713, -4.8343, -4.5468, -4.8672, -4.7959,\n",
      "         -4.6904, -4.5468, -4.7671, -4.3465, -4.6033, -4.1634, -4.6098, -4.5215,\n",
      "         -4.5619, -4.4595, -4.5011, -4.5916, -4.9665, -4.4148, -4.5150, -4.6619,\n",
      "         -4.4232, -4.5376, -4.4075, -4.5577, -5.1413, -4.7445, -4.3779, -4.0234,\n",
      "         -4.8597, -4.7262, -4.7330, -4.4828, -4.6671, -4.7134, -4.7014, -4.5916,\n",
      "         -4.4965, -4.5756, -4.5118, -4.5347, -4.4254, -4.4800, -4.7499, -4.7928,\n",
      "         -4.2701, -4.3351, -4.8675, -4.7756, -4.5743, -4.5772, -4.7595, -4.7927,\n",
      "         -4.9136, -4.3526, -4.6272, -4.5225, -4.6609, -4.5368, -4.3358, -4.5993,\n",
      "         -4.5914]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : treasure\n",
      "target index is: [31] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3954, -4.3496, -4.7296, -4.9650, -4.1127, -4.7595, -4.6843, -4.5654,\n",
      "         -4.7636, -4.5591, -4.6200, -4.2690, -4.8321, -4.8264, -4.8025, -4.8095,\n",
      "         -4.4512, -4.7407, -4.6787, -4.5458, -4.5221, -4.4523, -4.9299, -4.6134,\n",
      "         -4.7637, -4.9728, -4.2831, -4.4362, -4.2890, -4.8903, -4.2480, -5.0033,\n",
      "         -4.6594, -4.5531, -4.4973, -5.0324, -4.4008, -4.6889, -4.7328, -4.7675,\n",
      "         -4.5743, -4.7430, -4.5397, -4.3396, -4.5661, -4.2488, -4.6519, -4.6832,\n",
      "         -4.7443, -4.8937, -4.2858, -4.7678, -4.7753, -4.8159, -4.6733, -4.3848,\n",
      "         -4.5546, -4.3133, -4.4802, -4.6176, -4.5082, -4.3612, -4.7845, -4.1829,\n",
      "         -4.4685, -4.6307, -5.0998, -4.6642, -4.2593, -4.3153, -4.7206, -4.6879,\n",
      "         -4.8785, -4.8855, -4.7513, -5.0170, -4.7320, -4.2637, -4.6738, -4.5565,\n",
      "         -4.6685, -4.1737, -4.8151, -4.9850, -4.6639, -4.4483, -4.3098, -4.2790,\n",
      "         -4.7419, -4.5164, -4.3383, -4.4456, -4.8568, -4.4745, -4.4924, -4.4621,\n",
      "         -4.2745]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : of\n",
      "target index is: [57] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4973, -4.1564, -4.3047, -4.5639, -4.1527, -4.8572, -4.9607, -4.4266,\n",
      "         -4.8173, -4.7644, -5.0781, -4.5437, -4.5851, -4.5794, -4.7922, -4.7500,\n",
      "         -4.6642, -4.5685, -4.5515, -4.5534, -4.5875, -4.3427, -4.7332, -4.3758,\n",
      "         -4.0846, -4.6784, -4.4824, -4.5560, -4.2650, -4.4729, -4.6682, -5.0567,\n",
      "         -5.0337, -4.5359, -4.8661, -4.8883, -4.7901, -4.7358, -4.5609, -4.7112,\n",
      "         -4.8349, -4.4740, -4.6458, -4.4749, -4.5623, -4.3073, -4.7547, -4.9298,\n",
      "         -4.6042, -4.5197, -4.4264, -4.4106, -4.9171, -4.2141, -4.6512, -4.6451,\n",
      "         -4.4385, -4.4321, -4.4533, -4.6955, -4.9007, -4.7199, -4.3675, -4.1083,\n",
      "         -4.7032, -4.6855, -4.9991, -4.5115, -4.7702, -4.6941, -4.5525, -4.4261,\n",
      "         -4.6911, -4.8656, -4.6596, -4.7867, -4.6153, -4.1589, -4.8505, -4.9329,\n",
      "         -4.2893, -4.3481, -4.7596, -4.8122, -4.6014, -4.4849, -4.5944, -4.6901,\n",
      "         -4.7669, -4.2057, -4.6930, -4.8042, -4.6011, -4.3556, -4.2903, -4.6322,\n",
      "         -4.2999]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2025, -4.2769, -4.8992, -5.0255, -4.1762, -4.7492, -4.7705, -4.2479,\n",
      "         -5.2531, -4.3717, -5.1440, -4.1359, -4.5844, -4.3619, -4.7097, -4.9307,\n",
      "         -4.5559, -4.5816, -4.7329, -4.1900, -4.7852, -4.7543, -4.5572, -4.4887,\n",
      "         -4.7348, -4.8556, -4.3686, -4.3310, -4.4165, -4.6691, -4.6905, -4.7457,\n",
      "         -4.9952, -4.7526, -4.8016, -5.2102, -4.5714, -4.5777, -4.9099, -4.4360,\n",
      "         -4.8517, -4.6389, -4.5057, -4.3738, -4.6505, -3.9890, -4.8316, -4.6852,\n",
      "         -4.8351, -4.7296, -4.6108, -4.7382, -4.4615, -4.2917, -4.7869, -4.8005,\n",
      "         -4.4634, -4.5035, -4.6717, -4.6910, -4.6142, -4.6563, -4.2846, -4.4610,\n",
      "         -4.3135, -4.7796, -5.1497, -4.3000, -4.5942, -4.5856, -4.2503, -4.6442,\n",
      "         -4.6801, -5.0637, -4.5359, -4.6902, -4.3198, -4.1866, -4.4330, -4.5935,\n",
      "         -4.5845, -4.5662, -4.6704, -5.0167, -5.1420, -4.2510, -4.6079, -4.2991,\n",
      "         -5.0766, -4.5180, -4.4504, -4.7710, -4.8679, -4.4693, -4.1917, -4.4544,\n",
      "         -4.3331]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : lusty\n",
      "target index is: [30] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2221, -4.5952, -4.4410, -4.9522, -4.2009, -4.6941, -4.5911, -4.1682,\n",
      "         -4.6872, -4.9665, -4.9183, -4.4889, -4.4363, -4.6412, -4.9004, -4.8231,\n",
      "         -4.4206, -4.7317, -4.4238, -4.7964, -4.7131, -5.0406, -4.7569, -4.6704,\n",
      "         -4.4151, -4.7106, -4.5029, -4.4757, -4.1818, -4.5253, -4.2012, -4.6917,\n",
      "         -4.5818, -4.8605, -4.7420, -4.8773, -4.3857, -4.4489, -4.4783, -4.5122,\n",
      "         -4.8196, -4.2700, -4.7883, -4.2937, -4.6685, -4.1387, -4.5080, -4.5781,\n",
      "         -4.7556, -4.5648, -4.6247, -4.3081, -5.0772, -4.4982, -4.8525, -4.7068,\n",
      "         -4.3615, -4.3833, -4.5000, -4.6689, -4.8310, -4.3586, -4.5975, -4.1634,\n",
      "         -4.6910, -4.7668, -4.8519, -4.8026, -4.8169, -4.4067, -4.6291, -4.3808,\n",
      "         -5.0255, -4.9680, -4.7041, -4.6752, -4.9329, -3.8178, -4.6506, -5.0265,\n",
      "         -4.5275, -4.5567, -4.6454, -4.9202, -4.8252, -4.4756, -4.3916, -4.4248,\n",
      "         -5.2381, -4.3839, -4.8251, -4.4992, -4.5566, -4.5745, -4.3874, -4.7615,\n",
      "         -4.3918]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : days;\n",
      "target index is: [48] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5531, -4.7709, -4.3932, -4.4438, -3.7729, -4.7584, -4.5768, -4.4275,\n",
      "         -4.5042, -4.9464, -4.4786, -4.6035, -5.1052, -4.9945, -4.6517, -4.5776,\n",
      "         -4.9417, -5.0665, -4.6057, -4.7613, -4.6197, -4.0470, -4.7645, -4.5157,\n",
      "         -4.4253, -4.8282, -4.5612, -4.4973, -4.5778, -4.5260, -4.5913, -4.6494,\n",
      "         -4.7044, -4.7043, -4.4142, -4.9489, -4.7419, -4.8576, -4.5775, -4.5600,\n",
      "         -4.8064, -4.6511, -5.0729, -4.4459, -4.8738, -4.6928, -4.3598, -4.4286,\n",
      "         -4.2767, -4.3351, -4.4662, -4.6658, -4.7953, -4.4703, -4.7000, -3.8920,\n",
      "         -4.5663, -4.1898, -4.4897, -4.5482, -4.6554, -4.8411, -4.9592, -3.9573,\n",
      "         -5.0311, -4.3689, -4.9365, -4.5067, -4.7381, -5.0431, -4.1958, -4.4857,\n",
      "         -4.8560, -4.9961, -4.4618, -4.9963, -4.7817, -4.5718, -4.7765, -4.6336,\n",
      "         -4.7754, -4.0229, -5.0238, -4.6488, -4.4339, -4.6688, -4.5353, -5.0044,\n",
      "         -4.8488, -4.2485, -4.6935, -4.3764, -4.4950, -4.5335, -4.3920, -4.4530,\n",
      "         -4.5728]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : To\n",
      "target index is: [26] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2693, -4.6310, -5.0014, -4.9500, -4.0415, -4.7846, -4.4921, -4.6844,\n",
      "         -4.5851, -4.6261, -4.9428, -4.4591, -4.8661, -4.5032, -4.8507, -4.6444,\n",
      "         -4.1909, -4.7099, -4.8714, -4.6788, -4.3279, -4.1799, -4.9791, -4.6876,\n",
      "         -4.5363, -4.8483, -4.3708, -4.4319, -4.3747, -4.8321, -4.6214, -4.9219,\n",
      "         -4.9467, -4.9587, -4.5291, -4.5507, -4.5851, -4.5463, -5.1313, -4.6614,\n",
      "         -4.7042, -4.6941, -4.3737, -4.7125, -4.1655, -4.4084, -4.5659, -4.8252,\n",
      "         -4.4368, -5.0109, -4.2466, -4.5708, -4.6522, -4.2336, -4.8140, -4.7173,\n",
      "         -4.6616, -4.6033, -4.5073, -4.5828, -4.6312, -4.4247, -4.5570, -4.2625,\n",
      "         -4.3596, -4.8320, -4.9626, -4.4878, -4.5864, -4.2794, -4.3830, -4.5041,\n",
      "         -4.9197, -4.5264, -4.8616, -5.0084, -4.5907, -4.3439, -4.8856, -4.6681,\n",
      "         -4.1607, -4.3376, -4.5563, -4.7050, -4.4287, -4.3876, -4.6417, -4.7231,\n",
      "         -4.8536, -4.5765, -4.4883, -4.9847, -4.5182, -4.2130, -4.3938, -4.7457,\n",
      "         -4.3710]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : say,\n",
      "target index is: [96] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.8037, -4.3283, -4.6513, -4.9247, -3.9659, -4.7241, -4.6296, -4.2731,\n",
      "         -4.7612, -4.4907, -4.7600, -4.6087, -4.6806, -4.7861, -4.5854, -4.8428,\n",
      "         -4.8244, -4.3601, -4.7271, -4.2311, -4.6931, -4.5833, -4.7803, -4.7219,\n",
      "         -4.4835, -4.8463, -4.4279, -4.5097, -4.2627, -4.5192, -4.6182, -4.6158,\n",
      "         -4.8560, -4.7439, -4.5128, -4.8477, -4.4916, -4.8415, -4.5432, -4.4629,\n",
      "         -4.5831, -4.6839, -4.6744, -4.4165, -4.6810, -4.4552, -4.3946, -4.4948,\n",
      "         -4.5279, -4.6866, -4.3505, -4.8180, -4.6778, -4.5478, -4.7377, -4.3918,\n",
      "         -4.6448, -4.4263, -4.4860, -4.6680, -4.6880, -4.6606, -4.5597, -4.1916,\n",
      "         -4.5665, -4.4633, -4.5367, -4.6032, -4.5692, -4.8395, -4.6370, -4.4527,\n",
      "         -4.8159, -5.1705, -4.6681, -4.7430, -4.4108, -4.5085, -4.6780, -4.8601,\n",
      "         -4.8081, -4.3789, -4.7049, -4.6688, -4.9415, -4.2121, -4.3996, -4.7208,\n",
      "         -4.6367, -4.1325, -4.7423, -4.5466, -4.6350, -4.2749, -4.6883, -4.4065,\n",
      "         -4.4652]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : within\n",
      "target index is: [34] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2426, -4.3273, -4.7330, -4.8946, -4.4848, -4.8577, -4.5459, -4.0764,\n",
      "         -5.1392, -4.5624, -4.9858, -4.3853, -4.2894, -4.6292, -5.1624, -5.0283,\n",
      "         -4.5429, -4.5808, -4.7311, -4.5831, -4.5313, -4.7125, -4.7885, -4.9260,\n",
      "         -4.4950, -4.9409, -4.1887, -4.3707, -4.1061, -4.5170, -4.5533, -4.6562,\n",
      "         -4.9418, -4.8275, -4.8151, -4.9859, -4.7542, -4.3434, -4.5550, -4.5368,\n",
      "         -4.6890, -4.6468, -4.4046, -4.3221, -4.3375, -4.0013, -4.7006, -4.7648,\n",
      "         -4.6429, -4.7619, -4.6426, -4.1922, -4.6810, -4.5844, -4.5312, -4.6300,\n",
      "         -4.6319, -4.2431, -4.4004, -4.9791, -4.8478, -4.5906, -4.5092, -4.3786,\n",
      "         -4.3562, -4.9388, -4.9718, -4.5202, -4.5312, -4.1558, -4.4171, -4.5658,\n",
      "         -4.7518, -4.7748, -4.6982, -4.8820, -4.5261, -4.0256, -4.5614, -5.0799,\n",
      "         -4.3970, -4.7231, -4.6133, -4.9360, -4.9011, -4.6672, -4.6790, -4.3819,\n",
      "         -5.1270, -4.5943, -4.5423, -4.4212, -4.8091, -4.5352, -4.4265, -4.5352,\n",
      "         -4.3882]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thine\n",
      "target index is: [56] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1459, -4.9109, -4.1344, -4.5786, -4.0903, -4.7083, -4.8793, -4.3147,\n",
      "         -4.7061, -4.8679, -4.7947, -4.8080, -4.7368, -4.7415, -4.7615, -4.6730,\n",
      "         -4.6175, -4.7402, -4.4912, -4.9763, -4.8274, -4.5890, -4.8495, -4.4543,\n",
      "         -4.3419, -4.7477, -4.6772, -4.5016, -4.2843, -4.3648, -4.3470, -4.5560,\n",
      "         -4.6404, -4.5009, -4.6804, -4.8771, -4.3722, -4.8423, -4.6700, -4.6897,\n",
      "         -4.9913, -4.2933, -4.9564, -4.2199, -4.8588, -4.2815, -4.6027, -4.4652,\n",
      "         -4.7985, -4.3165, -4.5545, -4.7108, -5.2099, -4.5576, -4.9006, -4.5857,\n",
      "         -4.1595, -4.3716, -4.4078, -4.2976, -4.7250, -4.5965, -4.6016, -4.0346,\n",
      "         -4.7641, -4.4477, -5.0904, -4.7424, -4.9417, -4.9775, -4.4643, -4.3971,\n",
      "         -5.2543, -5.0348, -4.5654, -4.7876, -4.7102, -4.0858, -4.7387, -4.8269,\n",
      "         -4.5076, -4.0707, -4.6635, -4.8277, -4.6523, -4.6234, -4.3876, -4.5345,\n",
      "         -5.2595, -4.3058, -4.4298, -4.3767, -4.5440, -4.7954, -4.2318, -4.7035,\n",
      "         -4.4481]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : own\n",
      "target index is: [92] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4164, -4.4177, -4.4638, -4.9302, -3.7347, -4.4319, -4.7341, -4.6086,\n",
      "         -4.9147, -5.0447, -4.8537, -4.6199, -5.1356, -4.8396, -4.7841, -4.6971,\n",
      "         -4.5788, -5.1315, -4.4838, -4.3544, -4.4588, -4.0442, -4.7999, -4.5957,\n",
      "         -4.7785, -4.7549, -4.5370, -4.5959, -4.5935, -5.0318, -4.1906, -4.8362,\n",
      "         -4.6455, -4.3693, -4.1998, -4.8722, -4.6382, -5.1297, -4.8662, -4.8302,\n",
      "         -4.4765, -4.7470, -5.0811, -4.2539, -4.9523, -4.3860, -4.5977, -4.4968,\n",
      "         -4.7343, -4.6889, -4.6212, -4.7837, -4.6847, -4.5767, -4.9385, -4.1933,\n",
      "         -4.8041, -4.4643, -4.4775, -4.5604, -4.4689, -4.7337, -5.0298, -3.7882,\n",
      "         -4.7555, -4.4717, -5.1686, -4.5608, -4.6289, -4.9512, -4.4714, -4.4766,\n",
      "         -4.6126, -5.1338, -4.3951, -4.6248, -4.9476, -4.5968, -4.7244, -4.4084,\n",
      "         -4.7619, -4.1915, -4.9407, -4.8832, -4.2201, -4.5574, -4.1520, -4.5911,\n",
      "         -4.8328, -4.3783, -4.4110, -4.3440, -4.7433, -4.6366, -3.9208, -4.6644,\n",
      "         -4.3056]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : deep\n",
      "target index is: [76] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3287, -4.6502, -4.6649, -4.7938, -4.2382, -4.5370, -4.3848, -4.2434,\n",
      "         -4.6909, -4.9171, -5.0643, -4.3741, -4.5097, -4.4786, -4.6786, -4.4143,\n",
      "         -4.0898, -4.7300, -4.6417, -4.6516, -4.5802, -4.5875, -4.7084, -4.6424,\n",
      "         -4.4744, -4.6384, -4.5693, -4.5093, -4.4506, -4.6057, -4.6442, -4.8834,\n",
      "         -4.9010, -4.8652, -4.6975, -4.8119, -4.7929, -4.4469, -5.1246, -4.7298,\n",
      "         -4.7107, -4.4987, -4.8916, -4.3974, -4.5385, -4.3540, -4.6270, -4.7837,\n",
      "         -4.5262, -4.4501, -4.6052, -4.3104, -4.7939, -4.3119, -4.9311, -4.6468,\n",
      "         -4.4077, -4.6453, -4.7419, -4.6023, -4.7916, -4.6376, -4.4310, -3.9715,\n",
      "         -4.6006, -4.4690, -4.9043, -4.4300, -4.5683, -4.6131, -4.4163, -4.6220,\n",
      "         -4.5436, -4.4158, -4.4743, -4.6121, -4.7077, -4.5842, -4.7397, -4.7097,\n",
      "         -4.0775, -4.5174, -4.6876, -4.7498, -4.4689, -4.4297, -4.7871, -4.7219,\n",
      "         -4.9952, -4.4753, -4.5451, -4.8511, -4.6684, -4.6473, -4.2235, -4.5733,\n",
      "         -4.6235]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : sunken\n",
      "target index is: [91] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4570, -4.5329, -4.6906, -4.8459, -4.1778, -4.8678, -4.6130, -4.7393,\n",
      "         -4.7267, -4.4312, -4.9299, -4.4763, -4.8263, -4.6971, -4.6668, -4.8318,\n",
      "         -4.8985, -4.7859, -4.7345, -4.3530, -4.4758, -4.1936, -4.9960, -4.5205,\n",
      "         -4.5687, -4.9057, -4.3799, -4.6471, -4.3341, -4.6460, -4.8843, -4.6393,\n",
      "         -4.6595, -4.7660, -4.7418, -5.0151, -4.7135, -4.6885, -4.7805, -4.2361,\n",
      "         -4.7971, -4.7365, -4.8622, -4.3674, -4.5072, -4.5749, -4.6905, -4.5559,\n",
      "         -4.3128, -4.9335, -3.9547, -5.2245, -4.4107, -4.4487, -4.7573, -4.2513,\n",
      "         -4.7899, -4.4859, -4.4674, -4.4850, -4.5287, -4.4486, -4.6268, -3.9469,\n",
      "         -4.5154, -4.6438, -4.9888, -4.5566, -4.6257, -4.5261, -4.4142, -4.5804,\n",
      "         -4.8334, -4.8080, -4.5510, -5.0396, -4.2214, -4.5768, -4.6371, -4.5291,\n",
      "         -4.6629, -4.1695, -4.9208, -4.5773, -4.7867, -4.2960, -4.7706, -4.8262,\n",
      "         -4.7621, -4.2861, -4.4282, -4.7028, -4.5300, -4.3385, -4.5083, -4.2777,\n",
      "         -4.3711]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : eyes,\n",
      "target index is: [58] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3086, -4.4767, -5.0926, -5.3250, -3.8464, -4.6393, -4.3809, -4.4936,\n",
      "         -4.7270, -4.6028, -5.1240, -4.6373, -4.8303, -4.5911, -4.6149, -4.6810,\n",
      "         -4.5614, -4.7206, -4.9976, -4.5441, -4.7447, -4.3195, -5.1081, -4.6121,\n",
      "         -4.5559, -4.8471, -4.4240, -4.3386, -4.3299, -4.7016, -4.7642, -4.5503,\n",
      "         -4.6616, -5.0555, -4.5890, -4.7183, -4.5108, -4.5644, -5.0887, -4.2868,\n",
      "         -4.5733, -4.3571, -4.7699, -4.3964, -4.6106, -4.2856, -4.8380, -4.4549,\n",
      "         -4.4804, -5.0573, -4.3035, -4.9589, -4.5258, -4.2508, -4.4627, -4.6705,\n",
      "         -4.5466, -4.7882, -4.6273, -4.4242, -4.5701, -4.3390, -4.1069, -4.4334,\n",
      "         -4.2594, -4.7119, -4.7205, -4.5363, -4.6248, -4.2738, -4.4959, -4.5803,\n",
      "         -4.8977, -4.8280, -4.7724, -4.8086, -4.4706, -4.4868, -4.7164, -4.7263,\n",
      "         -4.4424, -4.4948, -4.9227, -4.9056, -4.9060, -4.0352, -4.6233, -4.6379,\n",
      "         -4.6835, -4.4398, -4.8157, -4.6416, -4.8480, -4.1879, -4.6836, -4.6109,\n",
      "         -4.2392]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Were\n",
      "target index is: [37] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2592, -4.4895, -4.7029, -4.6558, -4.2103, -4.7050, -4.4456, -4.2896,\n",
      "         -4.7986, -4.9115, -4.5916, -4.4413, -4.5451, -4.8213, -4.9949, -4.6744,\n",
      "         -4.7019, -4.5613, -4.6802, -4.6931, -4.3328, -4.4449, -4.9236, -5.0190,\n",
      "         -4.3093, -4.9305, -4.5694, -4.4073, -4.1778, -4.4261, -4.6101, -4.6431,\n",
      "         -4.5726, -4.8639, -4.3542, -4.8289, -4.8581, -4.3761, -4.7541, -4.3698,\n",
      "         -4.7120, -4.5253, -4.6823, -4.6593, -4.5685, -4.1927, -4.2585, -4.7893,\n",
      "         -4.4877, -4.8686, -4.7170, -4.3097, -4.8196, -4.4937, -4.4693, -4.4566,\n",
      "         -4.3841, -4.4300, -4.4382, -4.8927, -4.6405, -4.1305, -4.5637, -4.3172,\n",
      "         -4.4998, -4.6911, -4.6081, -4.3555, -4.7096, -4.1576, -4.5207, -4.5577,\n",
      "         -4.6929, -5.1072, -4.9842, -4.9343, -4.6443, -4.2652, -4.8117, -4.8926,\n",
      "         -4.5754, -4.6853, -4.7525, -4.7962, -4.6224, -4.3377, -4.4476, -4.8161,\n",
      "         -4.8906, -4.4086, -4.8021, -4.4873, -4.6244, -4.5262, -4.8341, -4.6803,\n",
      "         -4.6044]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : an\n",
      "target index is: [74] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5205, -4.6860, -4.6732, -4.4997, -4.0932, -4.9869, -4.6736, -4.5323,\n",
      "         -4.7092, -4.4795, -4.9681, -4.7134, -4.8454, -4.9260, -4.7730, -4.8492,\n",
      "         -4.8073, -4.5796, -4.6664, -4.7453, -4.3790, -4.0617, -4.8798, -4.8662,\n",
      "         -4.4343, -5.2003, -4.3538, -4.1988, -4.6226, -4.3582, -4.8319, -4.5435,\n",
      "         -4.8642, -4.9114, -4.3870, -4.7098, -4.7481, -4.5779, -4.7647, -4.4633,\n",
      "         -4.9041, -4.7540, -4.5859, -4.5155, -4.4329, -4.4133, -4.5416, -4.5562,\n",
      "         -4.3397, -4.9976, -4.4179, -4.4472, -4.6717, -4.3751, -4.4379, -4.3394,\n",
      "         -4.4495, -4.3538, -4.2132, -4.8104, -4.6126, -4.5739, -4.5839, -4.3158,\n",
      "         -4.6030, -4.3800, -4.8434, -4.2823, -4.7220, -4.5626, -4.3641, -4.6289,\n",
      "         -4.8387, -4.8403, -5.0233, -5.1133, -4.3542, -4.2413, -4.6355, -4.8715,\n",
      "         -4.3823, -4.5703, -4.4512, -4.8003, -4.5114, -4.2885, -4.6560, -5.0316,\n",
      "         -4.8044, -4.5599, -4.3932, -4.4364, -4.5667, -4.5323, -4.6162, -4.4879,\n",
      "         -4.3551]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : all-eating\n",
      "target index is: [60] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4867, -4.5548, -4.8574, -4.7441, -3.9436, -4.7234, -4.7454, -4.4064,\n",
      "         -4.8238, -4.4153, -5.0350, -4.6634, -4.8956, -4.6123, -4.7083, -4.6996,\n",
      "         -4.4572, -4.4404, -4.8181, -4.5257, -4.7469, -4.5890, -4.9620, -4.8910,\n",
      "         -4.7146, -4.9164, -4.6897, -4.2480, -4.2424, -4.4014, -4.5360, -4.5430,\n",
      "         -4.8628, -4.9074, -4.3619, -4.7476, -4.2960, -4.9395, -4.8136, -4.6020,\n",
      "         -4.7666, -4.5222, -4.4686, -4.5417, -4.3896, -4.4304, -4.5268, -4.6310,\n",
      "         -4.6710, -4.8586, -4.4994, -4.8098, -4.8651, -4.2165, -4.6470, -4.7594,\n",
      "         -4.3043, -4.4343, -4.6401, -4.4737, -4.6742, -4.6338, -4.4609, -4.4462,\n",
      "         -4.4340, -4.4150, -4.5949, -4.2757, -4.7651, -4.5810, -4.3854, -4.2330,\n",
      "         -5.0662, -4.9236, -4.7532, -4.8075, -4.3848, -4.3272, -4.6365, -5.0196,\n",
      "         -4.4267, -4.3093, -4.3103, -4.9339, -4.9718, -4.0451, -4.7241, -4.5524,\n",
      "         -4.8763, -4.2061, -4.5283, -4.6553, -4.7488, -4.4728, -4.6003, -4.5539,\n",
      "         -4.5507]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : shame,\n",
      "target index is: [41] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6951, -4.7232, -4.8653, -4.5002, -4.1627, -4.6007, -4.6884, -4.4319,\n",
      "         -4.5910, -4.6310, -4.5893, -4.4899, -4.8613, -4.7389, -4.7786, -4.4910,\n",
      "         -4.4420, -4.9021, -4.5643, -4.5253, -4.5618, -4.2298, -4.7839, -4.5985,\n",
      "         -4.5516, -4.9638, -4.3798, -4.5144, -4.4887, -4.5940, -4.4125, -5.0015,\n",
      "         -5.1230, -4.7803, -4.5522, -4.7133, -4.5117, -5.0316, -4.8267, -4.7132,\n",
      "         -4.8094, -4.3746, -4.5075, -4.5777, -4.5770, -4.4776, -4.6311, -4.6542,\n",
      "         -4.4139, -4.6533, -4.8535, -4.2228, -4.8507, -4.3176, -4.8913, -4.1440,\n",
      "         -4.4580, -4.3189, -4.4204, -4.4780, -4.6414, -5.0141, -4.6899, -4.1991,\n",
      "         -4.7710, -4.2412, -5.0327, -4.4937, -4.6256, -4.6715, -3.9655, -4.4269,\n",
      "         -4.7570, -4.6109, -4.6015, -4.8632, -4.9205, -4.3118, -5.0429, -4.8571,\n",
      "         -4.6685, -4.4536, -4.4532, -4.5834, -4.3101, -4.5357, -4.3826, -4.7545,\n",
      "         -4.7620, -4.1715, -4.7247, -4.4043, -4.7401, -4.6456, -4.4753, -4.7312,\n",
      "         -4.4532]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : and\n",
      "target index is: [44] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7140, -4.4980, -4.5524, -4.6195, -4.1893, -4.7403, -4.5359, -4.3882,\n",
      "         -4.7102, -4.7962, -4.4659, -4.4621, -4.8408, -4.8656, -4.5341, -4.5010,\n",
      "         -4.6192, -4.9005, -4.6284, -4.5900, -4.3524, -4.2977, -4.5363, -4.4685,\n",
      "         -4.5228, -4.7068, -4.3826, -4.4393, -4.6231, -4.5375, -4.6421, -4.8326,\n",
      "         -4.8153, -4.7238, -4.4013, -4.4900, -4.7822, -4.9123, -4.6207, -4.5304,\n",
      "         -4.7792, -4.6776, -4.8583, -4.5771, -4.5803, -4.6049, -4.3805, -4.5908,\n",
      "         -4.2746, -4.5410, -4.6074, -4.5626, -4.6348, -4.3648, -4.9089, -4.4705,\n",
      "         -4.7285, -4.6598, -4.6232, -4.6555, -4.8152, -4.7615, -4.7753, -4.1677,\n",
      "         -4.9154, -4.4383, -4.8669, -4.3761, -4.6359, -4.8324, -4.2903, -4.7697,\n",
      "         -4.6158, -4.6450, -4.3929, -4.7426, -4.6185, -4.4642, -4.8791, -4.4208,\n",
      "         -4.4706, -4.3404, -4.6777, -4.6642, -4.5939, -4.3557, -4.6002, -4.7980,\n",
      "         -4.8721, -4.1321, -4.8258, -4.7548, -4.3153, -4.3350, -4.4269, -4.4151,\n",
      "         -4.5634]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thriftless\n",
      "target index is: [43] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4056, -4.4393, -4.5466, -4.7415, -4.0874, -4.5581, -4.6789, -4.4685,\n",
      "         -4.7286, -4.5109, -4.9316, -4.4011, -4.7953, -4.6440, -4.6340, -4.9009,\n",
      "         -4.8722, -4.5470, -4.8730, -4.1858, -4.6810, -4.7966, -4.6658, -4.6136,\n",
      "         -4.8530, -4.7490, -4.5528, -4.4451, -4.1746, -4.7117, -4.6771, -4.5123,\n",
      "         -4.7348, -4.5442, -4.6301, -5.0292, -4.6354, -4.9073, -4.5280, -4.4644,\n",
      "         -4.5422, -4.5880, -4.7472, -4.1884, -4.4634, -4.2816, -4.4627, -4.1472,\n",
      "         -4.5490, -4.6950, -4.8455, -4.9243, -4.6548, -4.6274, -4.9053, -4.7351,\n",
      "         -4.3986, -4.4839, -4.5329, -4.6885, -4.5712, -4.7373, -4.5627, -4.3651,\n",
      "         -4.6516, -4.8214, -4.9147, -4.3907, -4.4842, -4.7094, -4.1920, -4.6474,\n",
      "         -4.7769, -5.1013, -4.5741, -4.5692, -4.4970, -4.4880, -4.6141, -4.3573,\n",
      "         -4.7555, -4.3113, -4.5207, -4.8024, -5.0319, -4.2948, -4.4785, -4.5106,\n",
      "         -5.2543, -4.4300, -4.7486, -4.4387, -4.5368, -4.5414, -4.2032, -4.2691,\n",
      "         -4.5894]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : praise.\n",
      "target index is: [94] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-3.9424, -5.0416, -4.7162, -5.1122, -3.7723, -4.7186, -4.8508, -4.3886,\n",
      "         -4.6827, -4.9975, -4.6670, -4.3076, -4.6291, -4.5854, -4.7904, -4.5509,\n",
      "         -4.8687, -5.0567, -4.6968, -4.5263, -4.7829, -4.0360, -5.1748, -4.9570,\n",
      "         -4.4554, -4.8458, -4.4846, -4.0844, -3.8931, -4.8570, -4.5803, -4.7965,\n",
      "         -4.8453, -4.7624, -4.4291, -5.2869, -4.7075, -4.6484, -4.9867, -4.9130,\n",
      "         -4.6529, -4.3191, -4.9428, -4.5481, -4.7060, -4.3947, -4.8357, -4.6400,\n",
      "         -4.7286, -4.8301, -4.3086, -4.8053, -4.4630, -4.6104, -4.8449, -4.5195,\n",
      "         -3.9188, -4.4389, -4.5080, -4.7146, -4.3985, -4.4657, -4.3216, -4.2677,\n",
      "         -4.5706, -4.6249, -5.0762, -4.9629, -4.8776, -4.8494, -4.1722, -4.2453,\n",
      "         -4.8899, -5.1240, -4.5629, -4.5251, -4.8165, -4.0548, -4.6096, -4.4515,\n",
      "         -4.6031, -4.1956, -5.2119, -5.0512, -4.1002, -4.6353, -4.2756, -4.7589,\n",
      "         -5.1973, -4.9527, -5.0639, -4.2525, -4.7531, -4.3605, -4.5242, -4.4132,\n",
      "         -4.4595]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : How\n",
      "target index is: [12] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2064, -4.6664, -4.5137, -5.0551, -4.0014, -4.9861, -4.6680, -4.3760,\n",
      "         -5.1386, -4.9361, -5.0283, -5.0919, -4.7616, -4.5211, -5.3225, -5.0672,\n",
      "         -4.8410, -4.4232, -4.7861, -4.7039, -4.6353, -4.8458, -4.8747, -5.0172,\n",
      "         -4.4526, -5.1331, -4.5691, -4.1769, -4.2542, -4.5995, -4.3094, -3.9781,\n",
      "         -4.6263, -4.6988, -4.4381, -5.1738, -4.5324, -4.5061, -4.5093, -4.5118,\n",
      "         -4.3572, -4.8676, -4.7923, -4.1625, -4.6055, -3.9772, -4.4886, -4.1332,\n",
      "         -5.0534, -4.5346, -4.4071, -4.7731, -4.6985, -4.7316, -4.5162, -4.7852,\n",
      "         -4.4130, -4.4943, -4.2633, -4.6814, -4.6745, -4.3203, -4.2527, -4.1771,\n",
      "         -4.5289, -4.8823, -4.6896, -4.3285, -4.4370, -4.4139, -4.5448, -4.2892,\n",
      "         -5.2976, -5.3596, -4.9453, -4.7672, -4.5723, -4.0876, -4.6268, -4.5623,\n",
      "         -4.6729, -4.9492, -4.6800, -5.1616, -4.9842, -4.1081, -4.1284, -4.8190,\n",
      "         -5.5625, -4.4058, -4.4648, -4.1208, -4.8424, -4.8329, -4.3952, -4.7744,\n",
      "         -4.5317]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : much\n",
      "target index is: [68] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4810, -5.0021, -4.6428, -4.4343, -3.5797, -4.4879, -4.7771, -4.2648,\n",
      "         -4.9866, -4.5231, -4.5041, -4.4703, -4.8768, -4.8278, -4.9682, -4.7850,\n",
      "         -4.7860, -4.8495, -4.0928, -4.8706, -4.7443, -4.1034, -5.0704, -4.8149,\n",
      "         -4.5469, -5.0902, -4.5308, -4.3496, -4.5754, -4.6035, -4.2203, -4.9731,\n",
      "         -4.6732, -4.4839, -4.4394, -5.3172, -4.4763, -5.0509, -4.7084, -4.9860,\n",
      "         -4.8601, -4.5845, -4.9613, -4.6174, -4.8623, -4.3875, -4.6372, -5.1089,\n",
      "         -4.9781, -4.5991, -4.8937, -4.4332, -5.0612, -4.1044, -4.5806, -3.9728,\n",
      "         -4.2118, -4.0233, -4.2189, -4.1839, -4.5432, -4.8314, -4.5607, -3.8158,\n",
      "         -4.6096, -4.3597, -4.6797, -4.4760, -5.1179, -4.7375, -4.4307, -4.2609,\n",
      "         -5.4932, -5.0711, -4.5710, -5.0474, -4.9511, -4.1494, -4.6739, -5.1589,\n",
      "         -4.9140, -4.1036, -4.9590, -4.8578, -4.3188, -4.5883, -4.5633, -4.8415,\n",
      "         -5.2985, -4.4888, -4.8819, -4.0995, -4.6875, -4.6047, -4.2977, -5.1564,\n",
      "         -4.3558]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : more\n",
      "target index is: [4] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3416, -4.8172, -4.7085, -4.3836, -4.1563, -4.6179, -4.8878, -4.4330,\n",
      "         -4.8702, -4.4805, -4.8770, -4.3160, -4.7433, -4.3988, -4.8314, -4.7696,\n",
      "         -4.5862, -4.7753, -4.6827, -4.6554, -4.4297, -4.4501, -4.6991, -4.6210,\n",
      "         -4.5789, -4.8084, -4.5897, -4.4461, -4.3770, -4.5626, -4.7659, -4.6833,\n",
      "         -4.8819, -4.5470, -4.9004, -4.9981, -4.8984, -4.6766, -4.7639, -4.6476,\n",
      "         -4.6070, -4.5442, -4.6051, -4.5016, -4.0844, -4.3444, -4.5239, -4.7004,\n",
      "         -4.7017, -4.5458, -4.9324, -4.3097, -4.7724, -4.3336, -4.8099, -4.3824,\n",
      "         -4.4710, -4.2349, -4.4712, -4.6668, -4.6071, -4.6292, -4.5876, -3.8727,\n",
      "         -4.4902, -4.6074, -4.8369, -4.5891, -4.6446, -4.5902, -4.0113, -4.5475,\n",
      "         -4.6981, -4.4720, -4.4944, -4.8278, -4.6968, -4.4958, -4.7736, -4.8119,\n",
      "         -4.5440, -4.2518, -4.6615, -4.7813, -4.5250, -4.5742, -4.7665, -4.7238,\n",
      "         -5.2195, -4.4940, -4.7213, -4.6889, -4.6423, -4.5431, -4.1039, -4.9183,\n",
      "         -4.5200]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : praise\n",
      "target index is: [45] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4681, -4.4816, -4.7334, -5.2005, -4.0270, -4.5875, -4.5019, -4.2534,\n",
      "         -5.2263, -4.5857, -4.8362, -4.3345, -4.8059, -4.5741, -5.0790, -4.8124,\n",
      "         -4.6462, -4.4832, -4.7723, -4.2023, -4.7158, -4.6869, -4.9896, -4.7585,\n",
      "         -4.9435, -4.9148, -4.5049, -4.2295, -4.3205, -4.6219, -4.2987, -4.4211,\n",
      "         -4.8440, -4.8290, -4.4763, -5.1774, -4.3414, -5.0424, -4.5085, -4.5859,\n",
      "         -4.4861, -4.5882, -4.7318, -4.1482, -4.6515, -4.0897, -4.7312, -4.3894,\n",
      "         -4.8199, -5.1202, -4.2393, -5.0815, -4.4556, -4.7371, -4.5561, -4.6429,\n",
      "         -4.3627, -4.5297, -4.4306, -4.5443, -4.5464, -4.3261, -4.6098, -4.3568,\n",
      "         -4.3051, -4.6237, -5.2052, -4.5503, -4.5825, -4.3263, -4.6899, -4.6116,\n",
      "         -5.2160, -5.3127, -4.6780, -4.9035, -4.5763, -4.0861, -4.4272, -4.4389,\n",
      "         -4.8990, -4.6354, -4.7330, -5.0268, -4.9838, -4.2425, -4.1803, -4.2828,\n",
      "         -5.1195, -4.6623, -4.5927, -4.0142, -5.0568, -4.5101, -4.6527, -4.3839,\n",
      "         -4.3593]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : deserv'd\n",
      "target index is: [66] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4324, -4.6990, -4.5784, -4.3424, -4.0698, -4.7272, -4.6671, -4.3524,\n",
      "         -4.8462, -4.8281, -4.4663, -4.7402, -4.7917, -4.7448, -4.8896, -4.8085,\n",
      "         -4.8123, -4.8457, -4.4980, -4.8980, -4.4283, -4.4676, -4.8279, -4.6336,\n",
      "         -4.2928, -5.0934, -4.6825, -4.5056, -4.3121, -4.6568, -4.2121, -4.7024,\n",
      "         -4.8108, -4.7393, -4.5561, -5.2209, -4.5093, -4.6581, -4.5495, -4.6095,\n",
      "         -4.7967, -4.5886, -4.8306, -4.5168, -4.8325, -4.2535, -4.7482, -4.5564,\n",
      "         -4.7936, -4.4580, -4.8230, -4.3168, -5.1572, -4.4209, -4.5684, -4.4607,\n",
      "         -4.0572, -4.1962, -4.2406, -4.4478, -4.6480, -4.4658, -4.5998, -4.1988,\n",
      "         -4.6303, -4.4267, -4.6453, -4.2743, -4.5610, -4.3408, -4.5224, -4.4480,\n",
      "         -5.2511, -4.9405, -4.8715, -4.9527, -4.9842, -3.9826, -4.9033, -4.9009,\n",
      "         -4.6270, -4.4652, -4.8796, -4.8697, -4.6532, -4.2930, -4.1760, -4.6422,\n",
      "         -5.2001, -4.3063, -4.4619, -4.4857, -4.7640, -4.6883, -4.2464, -4.8178,\n",
      "         -4.3692]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3519, -4.2279, -4.9134, -4.6734, -4.2415, -4.7711, -4.8863, -4.2100,\n",
      "         -5.0405, -4.7789, -5.3351, -4.4914, -4.4159, -4.6986, -4.5992, -4.7369,\n",
      "         -4.4872, -4.5433, -4.3556, -4.4547, -4.6341, -4.2312, -4.7672, -4.7186,\n",
      "         -4.3775, -5.0093, -4.3001, -4.4660, -4.5460, -4.6386, -4.7778, -4.8001,\n",
      "         -5.2098, -4.6634, -4.6231, -5.0487, -4.6936, -4.7822, -5.0227, -4.8643,\n",
      "         -4.8452, -4.7000, -4.7993, -4.5770, -4.7565, -4.0074, -4.8322, -4.8981,\n",
      "         -4.8282, -4.5045, -4.8329, -4.3280, -4.5588, -4.1769, -4.4817, -4.7557,\n",
      "         -4.3073, -4.2030, -4.5563, -4.5987, -4.7546, -4.7016, -4.1222, -4.3609,\n",
      "         -4.4347, -4.6989, -4.8778, -4.2088, -4.8322, -4.7768, -4.3066, -4.4769,\n",
      "         -4.7796, -4.8482, -4.6968, -4.6448, -4.3479, -4.2978, -4.5310, -4.7409,\n",
      "         -4.1667, -4.6494, -4.7862, -5.0763, -4.6360, -4.4388, -4.7464, -4.8885,\n",
      "         -4.7748, -4.4088, -4.6126, -4.7459, -4.9492, -4.2771, -3.8346, -4.9257,\n",
      "         -4.1338]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty's\n",
      "target index is: [80] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2957, -4.4859, -4.7721, -4.5241, -4.1908, -4.9246, -4.5999, -4.3253,\n",
      "         -4.3801, -5.1136, -4.9792, -4.2753, -4.6830, -4.7223, -4.6101, -4.7474,\n",
      "         -4.8770, -5.1435, -4.5413, -4.3922, -4.9333, -4.7403, -4.6388, -4.4778,\n",
      "         -4.2056, -4.6503, -4.6477, -4.4181, -3.8400, -4.5585, -4.8015, -4.5980,\n",
      "         -4.7174, -4.5540, -4.6244, -5.1413, -4.8519, -4.6147, -4.6605, -4.5021,\n",
      "         -4.6770, -4.2232, -4.9935, -4.0424, -4.5107, -4.0796, -4.4229, -4.4895,\n",
      "         -4.5387, -4.8985, -4.7744, -4.4655, -4.7529, -4.3215, -4.6115, -4.4024,\n",
      "         -4.2953, -4.3325, -4.7217, -5.0408, -4.8232, -4.1854, -4.4596, -4.0774,\n",
      "         -5.0398, -4.7927, -5.0844, -4.6675, -4.8202, -4.6300, -4.2810, -4.7102,\n",
      "         -4.5212, -4.8520, -4.7954, -4.8999, -5.1918, -4.2398, -4.6999, -4.4689,\n",
      "         -4.7827, -4.3253, -5.2108, -4.8156, -4.8656, -4.1148, -4.6100, -5.0074,\n",
      "         -5.0224, -4.5783, -5.2406, -4.4795, -4.5954, -4.4829, -4.2681, -4.2941,\n",
      "         -4.5141]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : use,\n",
      "target index is: [11] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1989, -4.6088, -4.9785, -5.2707, -3.7354, -5.0854, -4.6901, -4.6155,\n",
      "         -4.7137, -4.5741, -4.9099, -4.7656, -5.3157, -4.8708, -4.6480, -4.8283,\n",
      "         -5.0111, -4.4813, -4.7073, -4.3977, -4.8193, -4.0938, -5.2540, -4.6473,\n",
      "         -4.3753, -4.8806, -4.2470, -4.1689, -4.0735, -5.0192, -4.7333, -4.6010,\n",
      "         -4.7907, -4.6216, -4.9555, -5.1850, -5.0996, -4.7795, -5.1133, -4.6853,\n",
      "         -4.6713, -5.3127, -4.9593, -4.6048, -4.7209, -4.4217, -4.7799, -4.3375,\n",
      "         -4.3991, -4.8697, -3.9693, -5.4883, -4.3252, -4.5032, -4.8501, -4.3333,\n",
      "         -4.4885, -4.3948, -4.3437, -4.2060, -4.6678, -4.5434, -4.3322, -3.6029,\n",
      "         -4.5628, -4.8520, -4.9171, -4.8567, -4.3715, -4.4930, -4.2051, -4.5578,\n",
      "         -5.1104, -4.7032, -4.6697, -4.8447, -4.1369, -4.6213, -4.7402, -4.4731,\n",
      "         -4.6315, -4.0285, -5.4908, -5.0632, -4.5959, -4.6274, -4.6225, -4.9732,\n",
      "         -4.7782, -4.3379, -4.3266, -4.4176, -4.6256, -4.0634, -4.2805, -4.6217,\n",
      "         -4.6084]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : If\n",
      "target index is: [61] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7414, -4.3026, -4.9199, -4.9546, -4.4428, -4.7679, -4.8138, -4.2731,\n",
      "         -4.6207, -4.7733, -4.8231, -4.1593, -4.7370, -4.4813, -4.8498, -4.8375,\n",
      "         -4.3827, -4.6298, -4.9046, -4.4729, -4.4974, -4.8968, -4.9234, -4.5860,\n",
      "         -4.5767, -4.8474, -4.4946, -4.2645, -4.3266, -4.4848, -4.4053, -4.7664,\n",
      "         -5.2178, -4.6936, -4.9591, -5.3561, -4.4008, -4.9298, -4.4689, -4.4726,\n",
      "         -4.2954, -4.8340, -4.2551, -4.4543, -4.2483, -4.3527, -4.5170, -4.7792,\n",
      "         -4.5634, -4.8357, -4.3229, -4.3731, -4.6249, -4.3567, -4.5240, -4.5082,\n",
      "         -4.5964, -4.4028, -4.8434, -4.6198, -4.6024, -4.2964, -4.4534, -3.7140,\n",
      "         -4.4002, -4.4130, -4.7628, -4.6372, -4.3218, -3.9833, -4.4952, -4.5297,\n",
      "         -4.8776, -4.8830, -5.0761, -5.0221, -4.8263, -4.0468, -4.8541, -4.7971,\n",
      "         -5.0501, -4.5513, -4.9054, -5.1404, -5.0044, -4.3273, -4.4087, -4.5652,\n",
      "         -5.0622, -4.1540, -4.7050, -4.8620, -4.9395, -4.2660, -4.6267, -4.8030,\n",
      "         -4.6303]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thou\n",
      "target index is: [22] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5607, -4.4335, -4.9620, -4.6237, -4.3955, -4.8759, -4.4891, -4.3746,\n",
      "         -4.4311, -4.7309, -4.5972, -4.4665, -4.7623, -4.8944, -4.6047, -4.5768,\n",
      "         -4.7378, -5.0969, -4.5232, -4.3930, -4.5573, -4.4474, -4.8697, -4.3314,\n",
      "         -4.2608, -4.5676, -4.4728, -4.6682, -4.5122, -4.7125, -4.8840, -4.9392,\n",
      "         -4.6959, -4.7285, -4.3485, -4.5205, -4.5382, -4.6685, -4.7063, -4.4980,\n",
      "         -5.0420, -4.1583, -4.8405, -4.7377, -4.4834, -4.3701, -4.3527, -4.5896,\n",
      "         -4.1474, -5.1536, -4.8548, -4.2638, -4.7435, -4.3516, -4.6887, -4.4293,\n",
      "         -4.5349, -4.4711, -4.4986, -4.7096, -4.7422, -4.4842, -4.2869, -4.4129,\n",
      "         -4.9368, -4.6428, -4.5573, -4.4627, -4.5918, -4.4606, -4.1655, -4.9107,\n",
      "         -4.5222, -4.7392, -4.6712, -4.8955, -4.5458, -4.3950, -4.8035, -4.4279,\n",
      "         -4.6316, -4.5755, -4.8611, -4.4668, -4.5280, -4.6117, -4.6951, -4.7062,\n",
      "         -4.7774, -4.2984, -5.0315, -4.3980, -4.5609, -4.5237, -4.6486, -4.5180,\n",
      "         -4.4643]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : couldst\n",
      "target index is: [47] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4895, -4.3418, -4.4805, -4.7820, -4.2069, -4.8088, -4.7860, -4.3714,\n",
      "         -4.6272, -4.7766, -4.6204, -4.5029, -4.6226, -4.8682, -4.6951, -4.3000,\n",
      "         -4.5637, -4.5439, -4.4437, -4.5836, -4.5219, -4.3061, -4.7276, -4.7717,\n",
      "         -4.2876, -4.5879, -4.4473, -4.6143, -4.2835, -4.6820, -4.5449, -4.8142,\n",
      "         -4.8132, -4.4846, -4.6449, -4.8206, -4.5847, -4.7946, -4.7662, -4.8368,\n",
      "         -4.5964, -4.7289, -4.7849, -4.6758, -4.6316, -4.5547, -4.6599, -4.7688,\n",
      "         -4.5804, -4.6036, -4.4929, -4.6301, -4.6401, -4.5279, -4.7469, -4.6461,\n",
      "         -4.4340, -4.5049, -4.4281, -4.4805, -4.7853, -4.6293, -4.4220, -4.1415,\n",
      "         -4.7510, -4.4634, -4.7965, -4.6986, -4.4972, -4.5981, -4.3736, -4.3801,\n",
      "         -4.7678, -4.8402, -4.7126, -4.7161, -4.3843, -4.3711, -4.8581, -4.6518,\n",
      "         -4.4851, -4.4046, -4.7927, -4.8071, -4.5011, -4.6170, -4.3781, -4.6682,\n",
      "         -4.6245, -4.3280, -4.5449, -4.7470, -4.6527, -4.2724, -4.4219, -4.5949,\n",
      "         -4.5776]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : answer\n",
      "target index is: [53] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4080, -4.7299, -4.7305, -4.7798, -4.2118, -4.5541, -4.7075, -4.2958,\n",
      "         -4.8031, -4.8114, -4.7339, -4.4088, -4.5356, -4.7196, -4.8295, -4.6647,\n",
      "         -4.2551, -4.6381, -4.3751, -4.6746, -4.5750, -4.3815, -4.6402, -4.5144,\n",
      "         -4.2975, -5.0269, -4.3273, -4.8116, -4.5549, -4.5154, -4.5491, -4.7354,\n",
      "         -4.7921, -4.7148, -4.3844, -4.8751, -4.5626, -4.3488, -4.7961, -4.7943,\n",
      "         -4.7795, -4.6227, -4.8008, -4.6422, -4.3856, -4.3198, -4.5490, -4.7132,\n",
      "         -4.7604, -4.3440, -4.7884, -4.4449, -4.8306, -4.3721, -4.5910, -4.5239,\n",
      "         -4.6097, -4.4482, -4.4162, -4.4539, -4.6065, -4.5747, -4.4547, -3.9802,\n",
      "         -4.5480, -4.6025, -4.8073, -4.6106, -4.6392, -4.5598, -4.4114, -4.5761,\n",
      "         -4.8023, -4.6653, -4.8370, -4.7660, -4.4102, -4.2930, -4.6574, -4.9209,\n",
      "         -4.4036, -4.6123, -4.6937, -4.8330, -4.6339, -4.7103, -4.4880, -4.5651,\n",
      "         -5.0962, -4.3341, -4.4443, -4.6750, -4.7609, -4.5077, -4.4921, -4.8145,\n",
      "         -4.3224]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : 'This\n",
      "target index is: [9] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4281, -4.6968, -4.8643, -4.6976, -3.7132, -4.6337, -4.4261, -4.3413,\n",
      "         -4.8990, -4.8391, -4.9127, -4.5891, -4.8726, -4.7618, -4.7788, -4.8136,\n",
      "         -4.4361, -4.8594, -4.7151, -4.5343, -4.4758, -4.3957, -4.8819, -4.3958,\n",
      "         -4.5547, -4.9699, -4.4529, -4.4500, -4.5511, -4.7530, -4.5271, -4.6776,\n",
      "         -4.6073, -4.9126, -4.3063, -4.6485, -4.5542, -4.7652, -4.8385, -4.3714,\n",
      "         -4.8120, -4.2224, -4.7228, -4.3860, -4.7279, -4.1485, -4.5100, -4.5552,\n",
      "         -4.6041, -4.8336, -4.9192, -4.4887, -5.0029, -3.9983, -4.4209, -4.2437,\n",
      "         -4.5970, -4.3919, -4.6490, -4.5685, -4.5021, -4.4307, -4.6377, -4.4476,\n",
      "         -4.4654, -4.6758, -4.4614, -4.2167, -4.6728, -4.7549, -4.3822, -4.5630,\n",
      "         -4.7872, -5.0631, -4.8969, -5.0171, -4.7694, -4.3996, -4.7869, -4.7890,\n",
      "         -4.7485, -4.4673, -4.7038, -4.8114, -4.6290, -4.2188, -4.3963, -4.8356,\n",
      "         -4.9337, -4.3739, -4.7086, -4.4692, -4.6067, -4.6625, -4.5145, -4.6971,\n",
      "         -4.3149]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : fair\n",
      "target index is: [21] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4052, -4.4355, -4.8734, -4.5995, -4.0981, -4.6311, -4.8348, -4.2899,\n",
      "         -4.6836, -4.4053, -4.8273, -4.4712, -4.6280, -4.6727, -4.7585, -4.5917,\n",
      "         -4.6228, -4.4847, -4.5910, -4.3751, -4.5652, -4.2511, -4.9333, -4.9051,\n",
      "         -4.4793, -4.7702, -4.4432, -4.3825, -4.2864, -4.6344, -4.6122, -4.6993,\n",
      "         -4.9868, -4.7799, -4.4859, -4.6645, -4.7903, -4.7893, -5.1425, -4.8372,\n",
      "         -4.7540, -4.5576, -4.4624, -4.6847, -4.4266, -4.2508, -4.5906, -4.8131,\n",
      "         -4.5452, -4.8626, -4.7001, -4.2978, -4.7093, -4.3809, -4.7006, -4.6871,\n",
      "         -4.2641, -4.3905, -4.4996, -4.5785, -4.6747, -4.5563, -4.5804, -4.4419,\n",
      "         -4.4501, -4.7226, -4.6884, -4.5367, -4.7983, -4.6417, -4.3414, -4.5869,\n",
      "         -4.6167, -4.8805, -4.5903, -4.6556, -4.5236, -4.4967, -4.7280, -4.7498,\n",
      "         -4.3981, -4.3206, -4.5271, -4.7045, -4.5790, -4.2682, -4.7858, -4.7404,\n",
      "         -4.7285, -4.3785, -4.8586, -4.8010, -4.7540, -4.1860, -4.3715, -4.6607,\n",
      "         -4.3982]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : child\n",
      "target index is: [5] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3808, -4.4239, -5.0048, -4.6470, -4.1085, -4.7699, -4.6314, -4.6828,\n",
      "         -4.7026, -4.4797, -4.9951, -4.5517, -4.8910, -4.7609, -4.7627, -4.8677,\n",
      "         -4.5601, -4.6841, -4.7978, -4.4646, -4.5491, -4.3774, -4.9404, -4.6273,\n",
      "         -4.7417, -5.2255, -4.5569, -4.4694, -4.1506, -4.7100, -4.4829, -4.7839,\n",
      "         -4.7029, -4.6858, -4.5500, -4.8022, -4.4673, -4.6689, -4.7039, -4.5112,\n",
      "         -4.6464, -4.4614, -4.5010, -4.3864, -4.5875, -4.2432, -4.7137, -4.5782,\n",
      "         -4.6004, -4.8982, -4.7443, -4.6058, -5.0467, -4.3544, -4.3912, -4.2322,\n",
      "         -4.3339, -4.2793, -4.5636, -4.7608, -4.5270, -4.3986, -4.7682, -4.4105,\n",
      "         -4.4405, -4.5794, -4.7820, -4.3024, -4.4611, -4.3995, -4.4018, -4.5236,\n",
      "         -4.8046, -4.9836, -5.0133, -5.2076, -4.8590, -4.2639, -4.7267, -4.7777,\n",
      "         -4.6299, -4.3724, -4.6580, -5.0065, -4.7126, -4.1587, -4.3830, -4.3002,\n",
      "         -4.8648, -4.4219, -4.4544, -4.3633, -4.6451, -4.5268, -4.6161, -4.5586,\n",
      "         -4.1700]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : of\n",
      "target index is: [57] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6210, -4.0512, -4.5579, -4.7191, -4.0875, -4.8326, -4.8506, -4.5217,\n",
      "         -4.7539, -4.8541, -5.0956, -4.4897, -4.5740, -4.5530, -4.6702, -4.5776,\n",
      "         -4.7518, -4.5626, -4.6609, -4.4199, -4.4962, -4.1812, -4.8341, -4.4434,\n",
      "         -4.2696, -4.5969, -4.4680, -4.4606, -4.2262, -4.7379, -4.7077, -4.9759,\n",
      "         -5.0844, -4.5347, -4.7111, -4.7194, -4.8465, -4.8736, -4.8592, -4.7499,\n",
      "         -4.6988, -4.4192, -4.5977, -4.5578, -4.5519, -4.2825, -4.8394, -4.9133,\n",
      "         -4.5000, -4.7509, -4.4870, -4.4579, -4.6416, -4.2974, -4.7752, -4.7217,\n",
      "         -4.3820, -4.4688, -4.4834, -4.5565, -4.8662, -4.8211, -4.3959, -4.2361,\n",
      "         -4.6193, -4.7137, -5.0415, -4.4436, -4.7678, -4.7071, -4.5143, -4.4981,\n",
      "         -4.6350, -4.9445, -4.5970, -4.7263, -4.5605, -4.3831, -4.8606, -4.8082,\n",
      "         -4.1878, -4.3699, -4.6292, -4.6552, -4.4519, -4.3643, -4.6207, -4.8213,\n",
      "         -4.5083, -4.2728, -4.8817, -4.8469, -4.6239, -4.1976, -4.1710, -4.7685,\n",
      "         -4.3315]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : mine\n",
      "target index is: [86] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1143, -4.3406, -4.6120, -5.0061, -4.1091, -4.6311, -4.8272, -4.4804,\n",
      "         -4.6951, -4.7835, -5.0344, -4.3182, -4.9401, -4.5532, -4.5882, -4.7646,\n",
      "         -4.6679, -4.8542, -4.5604, -4.1892, -4.9316, -4.7043, -4.6085, -4.1309,\n",
      "         -4.5254, -4.4730, -4.6690, -4.4542, -4.1974, -4.6033, -4.6005, -5.0017,\n",
      "         -4.7657, -4.4731, -4.6331, -4.6755, -4.6459, -4.7541, -4.8136, -4.7100,\n",
      "         -4.8651, -4.4511, -4.8000, -4.5170, -4.8055, -4.1605, -4.8487, -4.6137,\n",
      "         -4.5582, -4.5954, -4.6592, -4.8628, -4.6412, -4.3370, -4.7978, -4.6597,\n",
      "         -4.3139, -4.4622, -4.6774, -4.5597, -4.5821, -4.6301, -4.4014, -4.3348,\n",
      "         -4.7404, -4.6126, -5.1795, -4.7973, -4.6342, -4.7733, -4.2696, -4.5269,\n",
      "         -4.5847, -4.9431, -4.5863, -4.5924, -4.6440, -4.2309, -4.7380, -4.4749,\n",
      "         -4.6763, -4.3281, -4.7319, -4.8241, -4.6554, -4.4707, -4.4175, -4.4116,\n",
      "         -4.8918, -4.2426, -4.5654, -4.6040, -4.5323, -4.5175, -4.3223, -4.5849,\n",
      "         -4.3802]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Shall\n",
      "target index is: [81] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2738, -4.3606, -4.5841, -5.0831, -4.0281, -4.7163, -4.7005, -4.5371,\n",
      "         -4.7314, -4.9492, -4.7666, -4.2906, -4.6783, -4.7845, -4.7241, -4.6003,\n",
      "         -4.3181, -4.7037, -4.4940, -4.6251, -4.5834, -4.5052, -4.7402, -4.4163,\n",
      "         -4.4049, -4.5378, -4.3536, -4.4658, -4.4100, -4.8477, -4.1578, -5.0079,\n",
      "         -4.5547, -4.6098, -4.5593, -4.9766, -4.4563, -4.6484, -4.8738, -4.9582,\n",
      "         -4.6428, -4.7555, -4.7735, -4.6054, -4.6415, -4.1672, -4.5064, -4.6969,\n",
      "         -4.7694, -4.6476, -4.5633, -4.5896, -4.7164, -4.4308, -4.5642, -4.9719,\n",
      "         -4.5853, -4.6598, -4.5192, -4.5053, -4.6698, -4.5586, -4.6240, -4.1093,\n",
      "         -4.7711, -4.7285, -4.8229, -4.5365, -4.5208, -4.3664, -4.7711, -4.6050,\n",
      "         -4.8393, -4.8537, -4.7124, -4.5424, -4.6736, -4.1703, -4.6442, -4.5199,\n",
      "         -4.5386, -4.3660, -4.7894, -5.0777, -4.5408, -4.5657, -4.1721, -4.5687,\n",
      "         -4.9212, -4.3798, -4.5504, -4.7603, -4.7898, -4.3745, -4.1235, -4.6970,\n",
      "         -4.4524]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : sum\n",
      "target index is: [70] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3162, -4.3825, -4.6808, -4.8215, -4.1646, -4.8716, -4.5813, -4.3693,\n",
      "         -4.6436, -4.7734, -4.7032, -4.3277, -4.5640, -4.9601, -4.8210, -4.6740,\n",
      "         -4.5172, -5.1645, -4.7329, -4.6436, -4.6040, -4.3077, -4.7470, -4.5811,\n",
      "         -4.3026, -4.9669, -4.3010, -4.5044, -4.4519, -4.6199, -4.5691, -4.8815,\n",
      "         -4.8688, -4.9071, -4.3114, -4.4648, -4.7087, -4.4512, -4.6866, -4.5859,\n",
      "         -5.0444, -4.3831, -4.5991, -4.5137, -4.4261, -4.2086, -4.4270, -4.6293,\n",
      "         -4.3375, -4.7806, -4.5957, -4.1271, -4.9810, -4.4138, -4.7046, -4.5434,\n",
      "         -4.6265, -4.4763, -4.5757, -4.9399, -4.8204, -4.5720, -4.6614, -4.2890,\n",
      "         -4.9416, -4.5890, -4.8412, -4.3867, -4.5799, -4.6118, -4.3171, -4.7699,\n",
      "         -4.5456, -4.8223, -4.6628, -4.8003, -4.5860, -4.1674, -4.8043, -4.8454,\n",
      "         -4.3519, -4.6488, -4.5586, -4.6509, -4.2606, -4.6152, -4.4918, -4.6905,\n",
      "         -5.0149, -4.4232, -4.7188, -4.5450, -4.5516, -4.6725, -4.4728, -4.4213,\n",
      "         -4.3993]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : my\n",
      "target index is: [90] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4211, -4.3688, -4.6018, -5.1536, -4.1972, -5.1474, -4.4945, -4.4578,\n",
      "         -4.7361, -4.6095, -5.1390, -4.5700, -4.7640, -4.7969, -4.3570, -4.6163,\n",
      "         -4.6184, -4.6862, -4.9302, -4.3825, -4.8425, -4.2618, -4.8461, -4.5890,\n",
      "         -4.4077, -5.0119, -4.2104, -4.4590, -4.1219, -4.5921, -4.6795, -4.8565,\n",
      "         -4.7782, -4.8756, -4.7407, -4.5659, -4.6696, -4.4304, -4.8636, -4.5125,\n",
      "         -4.9244, -4.7689, -4.8865, -4.3665, -4.8640, -4.2927, -4.8115, -4.6355,\n",
      "         -4.5208, -5.1662, -4.0891, -5.0865, -4.4722, -4.5417, -4.7075, -4.5018,\n",
      "         -4.5187, -4.4765, -4.3227, -5.0230, -4.6174, -4.4051, -4.4764, -4.2335,\n",
      "         -4.6316, -4.3905, -5.0924, -4.5797, -4.3966, -4.5742, -4.5757, -4.5690,\n",
      "         -4.7451, -4.7727, -4.7222, -5.0214, -4.4124, -4.3136, -4.5349, -4.6503,\n",
      "         -4.4530, -4.4790, -4.8436, -4.4499, -4.6694, -4.1923, -4.5151, -4.8383,\n",
      "         -4.4857, -4.5845, -4.4220, -4.5491, -4.7044, -4.3027, -4.6188, -4.3087,\n",
      "         -4.1581]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : count,\n",
      "target index is: [55] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6040, -4.2262, -4.7385, -4.9432, -4.4601, -4.9406, -4.6953, -4.4222,\n",
      "         -4.6113, -4.8720, -4.9925, -4.6420, -4.6957, -4.7481, -4.7321, -4.6588,\n",
      "         -4.5572, -4.6073, -4.8558, -4.6627, -4.6236, -4.6712, -5.0088, -4.3685,\n",
      "         -4.4260, -4.7043, -4.4827, -4.2105, -4.2873, -4.6215, -4.2148, -4.8686,\n",
      "         -5.0353, -4.7648, -4.8375, -4.6425, -4.5502, -4.8185, -4.7161, -4.4865,\n",
      "         -4.6231, -4.6398, -4.3694, -4.5515, -4.5633, -4.2058, -4.9856, -4.6614,\n",
      "         -4.6431, -4.9600, -4.2656, -4.6395, -4.8072, -4.3153, -4.6178, -4.4425,\n",
      "         -4.1985, -4.2807, -4.6504, -4.4610, -4.5946, -4.5453, -4.2953, -4.1345,\n",
      "         -4.6099, -4.5133, -4.9795, -4.4023, -4.2178, -4.1847, -4.4390, -4.4985,\n",
      "         -4.7907, -4.8505, -4.9962, -5.1150, -4.3815, -4.2153, -4.8936, -4.9393,\n",
      "         -4.7070, -4.7255, -4.8523, -4.8647, -4.7570, -4.3250, -4.1912, -4.5506,\n",
      "         -4.7768, -4.3122, -4.3837, -4.9232, -4.7802, -4.2971, -4.5299, -4.7177,\n",
      "         -4.3824]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : and\n",
      "target index is: [44] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6866, -4.4613, -4.6988, -4.6732, -4.1713, -4.9001, -4.4484, -4.2615,\n",
      "         -4.7496, -4.9920, -4.6507, -4.4982, -4.6318, -4.8790, -4.7796, -4.3990,\n",
      "         -4.3158, -4.8288, -4.5558, -4.7073, -4.4860, -4.2787, -4.5176, -4.5331,\n",
      "         -4.1936, -4.8308, -4.4592, -4.5194, -4.7418, -4.4342, -4.6090, -4.8547,\n",
      "         -4.8287, -4.8139, -4.3522, -4.2719, -4.9083, -4.7933, -4.8352, -4.6557,\n",
      "         -4.9605, -4.6128, -4.8811, -4.5869, -4.4666, -4.5123, -4.3274, -4.8194,\n",
      "         -4.2411, -4.5762, -4.6536, -4.3091, -4.8355, -4.1731, -4.5819, -4.5844,\n",
      "         -4.5111, -4.6168, -4.6780, -4.7649, -4.9807, -4.7001, -4.3612, -4.1253,\n",
      "         -4.9425, -4.4710, -4.7032, -4.1387, -4.6561, -4.8261, -4.5320, -4.8405,\n",
      "         -4.3749, -4.6529, -4.7707, -4.8633, -4.3245, -4.4726, -4.8991, -4.4756,\n",
      "         -4.3397, -4.5200, -4.7801, -4.8118, -4.6402, -4.5209, -4.7013, -4.7848,\n",
      "         -4.9633, -4.1217, -4.9017, -4.9451, -4.3306, -4.4042, -4.4685, -4.4494,\n",
      "         -4.5520]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : make\n",
      "target index is: [14] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4832, -4.2507, -4.7310, -5.1148, -4.3173, -4.6337, -4.6096, -4.3860,\n",
      "         -4.6776, -4.6709, -4.7923, -4.5428, -4.8474, -4.6707, -4.4038, -4.5899,\n",
      "         -4.6109, -4.7322, -4.7295, -4.1995, -4.8745, -4.6611, -4.9721, -4.4063,\n",
      "         -4.7357, -4.6754, -4.4104, -4.3383, -4.3063, -4.6513, -4.5731, -4.7913,\n",
      "         -4.8879, -4.7359, -4.4433, -4.4416, -4.5276, -4.9895, -4.7883, -4.5908,\n",
      "         -4.6956, -4.6294, -4.6472, -4.4442, -4.7973, -4.3189, -5.0485, -4.5220,\n",
      "         -4.3988, -4.9941, -4.2131, -4.8590, -4.2751, -4.5451, -4.9796, -4.2686,\n",
      "         -4.5014, -4.3953, -4.8247, -4.4570, -4.5762, -4.6533, -4.3750, -4.4100,\n",
      "         -4.6204, -4.4665, -5.2497, -4.8591, -4.4329, -4.5639, -4.1989, -4.6377,\n",
      "         -4.5642, -4.9070, -4.4728, -4.7849, -4.5352, -4.2563, -4.8363, -4.7143,\n",
      "         -4.6849, -4.6231, -4.7117, -4.7617, -4.5901, -4.4847, -4.4587, -4.5530,\n",
      "         -4.5062, -4.1456, -4.6249, -4.3889, -4.7797, -4.4507, -4.6181, -4.5254,\n",
      "         -4.3596]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : my\n",
      "target index is: [90] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3757, -4.2314, -4.8750, -5.0503, -4.1777, -5.0098, -4.3661, -4.3896,\n",
      "         -4.8322, -4.6818, -4.6715, -4.3952, -4.6331, -4.9935, -4.7756, -4.4684,\n",
      "         -4.3687, -4.8159, -4.7584, -4.6330, -4.8138, -4.1239, -4.7928, -4.9033,\n",
      "         -4.2583, -5.0358, -4.1558, -4.5487, -4.1507, -4.7034, -4.3622, -4.8890,\n",
      "         -4.5894, -4.6888, -4.7283, -4.6565, -4.8474, -4.3563, -5.0290, -4.8422,\n",
      "         -4.6947, -4.8814, -4.6489, -4.5502, -4.5361, -4.2714, -4.5965, -4.8775,\n",
      "         -4.6226, -4.7767, -4.5053, -4.5899, -4.6957, -4.6155, -4.5135, -4.7346,\n",
      "         -4.7525, -4.5469, -4.4981, -4.8696, -4.8013, -4.1826, -4.4992, -3.9902,\n",
      "         -4.7242, -4.8772, -4.8276, -4.5072, -4.4731, -4.0668, -4.6999, -4.7057,\n",
      "         -4.6265, -4.5974, -4.7836, -4.9559, -4.4699, -4.4565, -4.4681, -4.5762,\n",
      "         -4.5103, -4.4605, -5.0093, -4.7441, -4.6673, -4.6431, -4.6532, -4.5650,\n",
      "         -4.6235, -4.2751, -4.5279, -4.7553, -4.7990, -4.2051, -4.3204, -4.4655,\n",
      "         -4.2967]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : old\n",
      "target index is: [84] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.0893, -4.3191, -4.4071, -5.0342, -4.2267, -5.2515, -4.4279, -4.4168,\n",
      "         -4.5143, -4.9244, -4.9743, -4.7957, -4.2881, -4.7960, -4.9249, -4.4214,\n",
      "         -4.5087, -4.6140, -4.8792, -4.7560, -4.7375, -4.2494, -5.1202, -4.7248,\n",
      "         -4.0655, -4.8597, -4.3226, -4.5097, -3.9096, -4.7193, -4.5945, -4.6873,\n",
      "         -4.6443, -4.9574, -4.8556, -4.5948, -4.7682, -4.3446, -4.7203, -4.5357,\n",
      "         -4.8439, -4.4826, -4.7757, -4.2566, -4.5370, -4.3783, -4.8357, -4.5609,\n",
      "         -4.6221, -4.9091, -4.0634, -4.7136, -4.9477, -4.6653, -4.7225, -4.5818,\n",
      "         -4.2420, -4.5827, -4.4050, -4.8369, -4.9507, -4.3954, -4.3766, -4.2595,\n",
      "         -4.7681, -4.7432, -4.8963, -4.5737, -4.5039, -4.3959, -4.5541, -4.3937,\n",
      "         -4.7584, -4.8984, -4.7517, -4.9693, -4.3427, -4.3488, -4.8571, -4.8956,\n",
      "         -4.1377, -4.5521, -4.8149, -4.7346, -4.5065, -4.5117, -4.6044, -4.7683,\n",
      "         -4.8577, -4.5484, -4.5869, -4.6074, -4.6139, -4.4324, -4.8162, -4.3684,\n",
      "         -4.4051]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : excuse,'\n",
      "target index is: [64] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5007, -4.4301, -4.5225, -4.7918, -4.1500, -4.9079, -4.6469, -4.3527,\n",
      "         -4.7633, -4.8017, -4.7494, -4.6524, -4.4935, -4.5181, -4.8323, -4.6109,\n",
      "         -4.7340, -4.2867, -4.6366, -4.6044, -4.4161, -4.6665, -4.5567, -4.7594,\n",
      "         -4.2770, -4.7983, -4.5929, -4.5523, -4.3553, -4.2528, -4.6417, -4.6778,\n",
      "         -4.8891, -4.7168, -4.6796, -5.2127, -4.7836, -4.6621, -4.6054, -4.5244,\n",
      "         -4.3773, -4.7926, -4.7992, -4.6232, -4.5866, -4.5782, -4.5482, -4.4381,\n",
      "         -4.4987, -4.4595, -4.3407, -4.5071, -4.5181, -4.4836, -4.5739, -4.4278,\n",
      "         -4.6047, -4.4701, -4.3829, -4.6057, -4.9482, -4.5426, -4.5235, -3.7349,\n",
      "         -4.6833, -4.4177, -4.6764, -4.3425, -4.5391, -4.6159, -4.5936, -4.5520,\n",
      "         -4.9457, -4.8777, -4.8482, -4.6430, -4.6319, -4.4902, -4.6426, -4.5643,\n",
      "         -4.7703, -4.6829, -4.9373, -4.9297, -4.6649, -4.2112, -4.4073, -4.9509,\n",
      "         -4.9041, -4.1583, -4.5001, -4.6989, -4.5916, -4.4812, -4.6525, -4.5490,\n",
      "         -4.8441]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Proving\n",
      "target index is: [25] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5134, -4.6026, -4.9674, -4.7098, -4.4689, -4.6828, -4.6807, -4.4483,\n",
      "         -4.6017, -4.5631, -4.9750, -4.3985, -4.4505, -4.5485, -4.5387, -4.8606,\n",
      "         -4.5725, -4.8606, -4.3797, -4.6295, -4.4866, -4.4564, -4.8405, -4.4732,\n",
      "         -4.4402, -4.7035, -4.2025, -4.5648, -4.4621, -4.4859, -5.0792, -4.8190,\n",
      "         -4.8287, -4.7870, -4.9620, -5.0137, -4.4459, -4.7259, -4.6157, -4.3574,\n",
      "         -4.7677, -4.5773, -4.6272, -4.6816, -4.3679, -4.3755, -4.7177, -4.8193,\n",
      "         -4.4536, -5.0337, -4.3152, -4.5202, -4.5351, -4.1203, -4.5479, -4.2543,\n",
      "         -4.6820, -4.3758, -4.5744, -4.3751, -4.4756, -4.3764, -4.3683, -4.0053,\n",
      "         -4.4144, -4.6010, -4.7119, -4.6812, -4.9307, -4.1807, -4.0047, -4.5162,\n",
      "         -5.0865, -4.3889, -4.7963, -4.9846, -4.3656, -4.4366, -4.5893, -4.6254,\n",
      "         -4.7586, -4.6103, -4.9146, -4.8885, -4.8705, -4.5940, -5.1014, -4.9742,\n",
      "         -4.8212, -4.4048, -4.6403, -4.6828, -4.7310, -4.2137, -4.5918, -4.8478,\n",
      "         -4.3595]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : his\n",
      "target index is: [49] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7511, -4.3123, -4.9239, -5.1138, -4.2491, -4.5889, -4.2602, -4.3538,\n",
      "         -4.9748, -4.4389, -4.7083, -4.2992, -4.7265, -4.7013, -4.9021, -4.5535,\n",
      "         -4.4862, -4.4667, -4.6727, -4.3534, -4.4779, -4.3798, -4.6163, -4.6538,\n",
      "         -4.6481, -4.7806, -4.4063, -4.5427, -4.7807, -4.5573, -4.7036, -4.5752,\n",
      "         -4.7749, -4.7494, -4.5070, -4.6973, -4.5086, -4.8431, -4.7204, -4.3356,\n",
      "         -4.4150, -4.5053, -4.4738, -4.3027, -4.4920, -4.6510, -4.4494, -4.3975,\n",
      "         -4.3493, -5.1958, -4.4441, -4.7446, -4.3909, -4.3271, -4.5960, -4.5418,\n",
      "         -4.8965, -4.7434, -4.2455, -4.7037, -4.9169, -4.5036, -4.5118, -4.3259,\n",
      "         -4.4497, -4.6897, -4.5689, -4.3521, -4.6695, -4.2938, -4.7552, -4.8553,\n",
      "         -4.7386, -4.8417, -4.6853, -4.9537, -4.4199, -4.5026, -4.4679, -4.4899,\n",
      "         -4.8295, -4.6553, -4.8400, -4.5693, -5.0025, -4.3689, -4.7052, -4.5852,\n",
      "         -4.8388, -4.2503, -4.6529, -4.2819, -4.9217, -4.5254, -4.6867, -4.6286,\n",
      "         -4.5089]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty\n",
      "target index is: [0] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6080, -4.4636, -4.8565, -4.6912, -4.4038, -4.7288, -4.7438, -4.0810,\n",
      "         -4.7930, -4.4671, -4.6284, -4.3114, -4.4156, -4.7750, -4.7580, -4.7095,\n",
      "         -4.6778, -4.5049, -4.3118, -4.4497, -4.5953, -4.4359, -4.7821, -4.9134,\n",
      "         -4.3169, -5.2784, -4.2799, -4.7415, -4.0093, -4.4796, -4.6249, -4.6030,\n",
      "         -4.9770, -4.6694, -4.5342, -5.0238, -4.4575, -4.5959, -4.6475, -4.8172,\n",
      "         -4.7203, -4.6305, -4.7275, -4.7021, -4.5997, -4.4205, -4.7710, -5.0085,\n",
      "         -4.8554, -4.8086, -4.6478, -4.4593, -4.8578, -4.5730, -4.6557, -4.5691,\n",
      "         -4.2511, -4.1617, -4.4136, -4.4028, -4.6606, -4.5502, -4.5273, -4.3593,\n",
      "         -4.4210, -4.6907, -4.6239, -4.7081, -4.6572, -4.3429, -4.4476, -4.4517,\n",
      "         -5.1462, -4.6189, -4.9235, -4.9076, -4.4301, -4.2176, -4.4727, -4.9112,\n",
      "         -4.4926, -4.4030, -4.6784, -4.7972, -4.7870, -4.5026, -4.6828, -4.2620,\n",
      "         -4.7671, -4.5846, -4.6060, -4.5569, -4.8613, -4.2895, -4.6095, -4.6189,\n",
      "         -4.2097]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : by\n",
      "target index is: [62] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.0379, -4.6593, -4.7012, -4.6674, -3.8846, -4.7203, -4.4817, -4.1755,\n",
      "         -4.8817, -4.9177, -4.7257, -4.5072, -4.4338, -4.6863, -4.7691, -4.7828,\n",
      "         -4.4048, -4.6793, -4.5751, -4.7834, -4.7313, -4.4271, -4.9687, -4.7082,\n",
      "         -4.1685, -4.7850, -4.4918, -4.3778, -4.4904, -4.7243, -4.5545, -4.4562,\n",
      "         -4.5563, -4.9161, -4.5736, -5.1216, -4.7873, -4.2429, -4.6977, -4.3864,\n",
      "         -4.6767, -4.4528, -4.8116, -4.3187, -4.5004, -3.8922, -4.4920, -4.7462,\n",
      "         -4.8936, -4.5137, -4.7422, -4.3789, -4.8869, -4.2443, -4.3999, -4.4543,\n",
      "         -4.3026, -4.4366, -4.6628, -4.7990, -4.8325, -4.2279, -4.3399, -4.3358,\n",
      "         -4.5567, -4.8140, -4.5816, -4.2024, -4.9946, -4.6351, -4.6974, -4.7127,\n",
      "         -4.5206, -5.0167, -4.7496, -4.8018, -4.6699, -4.3261, -4.7589, -5.0221,\n",
      "         -4.3983, -4.4852, -5.0051, -5.0118, -4.6687, -4.3112, -4.7462, -5.0914,\n",
      "         -5.1394, -4.5992, -4.8955, -4.7080, -4.5121, -4.4805, -4.6030, -4.7850,\n",
      "         -4.4926]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : succession\n",
      "target index is: [7] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6635, -4.3897, -4.6736, -4.6787, -4.1890, -4.6716, -4.7403, -4.4147,\n",
      "         -4.7034, -4.5479, -4.7138, -4.2486, -4.7836, -4.5107, -4.9583, -4.6688,\n",
      "         -4.6268, -4.4924, -4.8374, -4.5064, -4.3332, -4.5640, -4.8722, -4.8692,\n",
      "         -4.5506, -4.7216, -4.4786, -4.2519, -4.1780, -4.4508, -4.4618, -4.7556,\n",
      "         -4.9479, -4.5208, -4.8870, -5.2057, -4.5470, -4.9393, -4.5412, -4.5124,\n",
      "         -4.3448, -4.6877, -4.4316, -4.7015, -4.3184, -4.5305, -4.3235, -4.8069,\n",
      "         -4.4159, -4.8652, -4.5294, -4.5209, -4.5808, -4.3914, -4.6605, -4.5022,\n",
      "         -4.5794, -4.3905, -4.5923, -4.7240, -4.4996, -4.4314, -4.4107, -3.8644,\n",
      "         -4.3810, -4.5264, -4.6160, -4.5257, -4.4251, -4.1122, -4.3670, -4.3981,\n",
      "         -4.9832, -4.8360, -4.8070, -4.9239, -4.7840, -4.3300, -4.7313, -4.8894,\n",
      "         -4.9938, -4.5118, -4.7018, -4.8865, -4.7319, -4.4144, -4.4424, -4.5829,\n",
      "         -4.9902, -4.4593, -4.7628, -4.6355, -4.7938, -4.6958, -4.5744, -4.9973,\n",
      "         -4.7006]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thine!\n",
      "target index is: [40] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6555, -4.3738, -4.6910, -4.4528, -4.2226, -4.7513, -4.6187, -4.2739,\n",
      "         -4.7074, -4.6248, -4.6316, -4.4110, -4.7262, -4.7705, -4.4787, -4.8039,\n",
      "         -4.8847, -5.0309, -4.6153, -4.6040, -4.5368, -4.5462, -4.6917, -4.5275,\n",
      "         -4.5197, -4.6000, -4.2238, -4.3761, -4.4021, -4.6535, -4.8741, -4.8470,\n",
      "         -4.9094, -4.5278, -4.5093, -4.8634, -4.7676, -4.7605, -4.5825, -4.4253,\n",
      "         -4.7139, -4.6184, -4.6539, -4.5832, -4.6348, -4.4671, -4.5537, -4.5473,\n",
      "         -4.3105, -4.7387, -4.3786, -4.4559, -4.5199, -4.4927, -4.9656, -4.1445,\n",
      "         -4.7517, -4.3165, -4.6986, -4.7560, -4.5236, -4.5347, -4.6074, -4.1603,\n",
      "         -4.8561, -4.5323, -4.7221, -4.5921, -4.7772, -4.6563, -4.1562, -4.7586,\n",
      "         -4.8004, -4.5661, -4.3191, -4.9221, -4.7192, -4.4280, -4.6164, -4.4490,\n",
      "         -4.7294, -4.3399, -4.9424, -4.8364, -4.7202, -4.4438, -4.8668, -4.7933,\n",
      "         -4.7161, -4.3852, -4.8090, -4.3244, -4.5680, -4.2751, -4.5383, -4.2560,\n",
      "         -4.6530]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : This\n",
      "target index is: [1] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4853, -4.3356, -4.7535, -4.7637, -4.1898, -4.5647, -4.7873, -4.4445,\n",
      "         -4.5407, -4.5470, -4.7933, -4.6819, -4.8574, -4.6946, -4.4267, -4.7233,\n",
      "         -4.5966, -4.6218, -4.8201, -4.3983, -4.6823, -4.6109, -5.1129, -4.4924,\n",
      "         -4.5948, -4.6491, -4.5051, -4.3946, -4.2704, -4.7080, -4.5667, -4.7745,\n",
      "         -4.7884, -4.6661, -4.6128, -4.8662, -4.4517, -4.8709, -4.6855, -4.6203,\n",
      "         -4.6126, -4.4061, -4.6526, -4.6250, -4.6257, -4.2290, -4.7278, -4.5646,\n",
      "         -4.3057, -4.7597, -4.4619, -4.7042, -4.6796, -4.5391, -4.7758, -4.4302,\n",
      "         -4.2914, -4.2526, -4.7142, -4.3137, -4.5998, -4.7430, -4.3610, -4.2728,\n",
      "         -4.5547, -4.7645, -4.9313, -4.7421, -4.4688, -4.3637, -4.1529, -4.3034,\n",
      "         -4.9527, -4.9288, -4.6349, -4.8067, -4.4894, -4.3585, -4.8225, -4.6758,\n",
      "         -4.5784, -4.4378, -4.5936, -4.8225, -4.7408, -4.5624, -4.5316, -4.4848,\n",
      "         -4.7467, -4.2757, -4.6078, -4.5393, -4.8962, -4.4502, -4.4787, -4.7505,\n",
      "         -4.4861]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : were\n",
      "target index is: [93] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2744, -4.4749, -4.7678, -4.8876, -3.8247, -4.5642, -4.4202, -4.2812,\n",
      "         -4.6512, -4.8763, -4.6181, -4.4781, -4.6733, -4.9308, -4.7644, -4.5136,\n",
      "         -4.4786, -4.9769, -4.5802, -4.4280, -4.8645, -4.1461, -4.7683, -4.9570,\n",
      "         -4.3732, -4.6839, -4.4142, -4.3466, -4.2537, -4.8549, -4.3911, -4.9204,\n",
      "         -4.6515, -4.5808, -4.2920, -4.8300, -4.9354, -4.5576, -5.1219, -4.7750,\n",
      "         -4.6668, -4.6757, -4.7913, -4.5805, -4.8071, -4.2246, -4.2503, -4.7186,\n",
      "         -4.4673, -4.7390, -4.8241, -4.3273, -4.7700, -4.6051, -4.6026, -4.4298,\n",
      "         -4.3691, -4.4317, -4.4057, -4.7458, -4.6216, -4.5030, -4.8334, -4.0384,\n",
      "         -4.7341, -4.6766, -4.7508, -4.5707, -4.7794, -4.5210, -4.5774, -4.5794,\n",
      "         -4.3941, -4.8259, -4.6769, -4.5212, -4.7957, -4.7100, -4.7046, -4.4436,\n",
      "         -4.7109, -4.5059, -5.0595, -4.8024, -4.2422, -4.6259, -4.4397, -4.7584,\n",
      "         -4.7457, -4.4437, -4.7781, -4.5520, -4.7996, -4.4467, -4.4867, -4.4946,\n",
      "         -4.5201]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : to\n",
      "target index is: [72] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5831, -4.5254, -4.7226, -4.4737, -4.4736, -4.7742, -4.9976, -4.2478,\n",
      "         -4.7244, -4.6938, -4.6354, -4.6185, -4.5808, -4.7306, -4.7862, -4.5505,\n",
      "         -4.7475, -4.2482, -4.6097, -4.5767, -4.3650, -4.4745, -5.1078, -4.8292,\n",
      "         -4.4463, -4.9909, -4.5106, -4.2599, -4.1693, -4.7382, -4.6250, -4.2668,\n",
      "         -5.0951, -4.7480, -4.5730, -5.1630, -4.5221, -4.7106, -4.6171, -4.7338,\n",
      "         -4.4904, -4.5243, -4.5856, -4.5603, -4.5276, -4.3071, -4.6999, -4.7172,\n",
      "         -4.7610, -4.6808, -4.3782, -4.5760, -4.7021, -4.7955, -4.8306, -4.6651,\n",
      "         -3.9707, -4.1823, -4.4849, -4.3464, -4.5424, -4.4878, -4.3000, -4.1167,\n",
      "         -4.4476, -4.5261, -4.8865, -4.9297, -4.4923, -4.4203, -4.1479, -4.1471,\n",
      "         -5.1834, -5.0260, -4.8870, -4.9120, -4.3176, -4.2398, -4.8056, -4.6820,\n",
      "         -4.5302, -4.5572, -4.5488, -4.9751, -4.7652, -4.5648, -4.5249, -4.5060,\n",
      "         -5.0642, -4.5116, -4.6515, -4.6519, -5.1159, -4.2739, -4.5177, -4.8561,\n",
      "         -4.5852]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : be\n",
      "target index is: [24] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2035, -4.8223, -4.7948, -5.0636, -4.0112, -4.8037, -4.6604, -4.2150,\n",
      "         -4.8889, -5.1101, -4.9527, -4.3012, -4.6645, -4.9102, -5.0012, -4.5515,\n",
      "         -3.9568, -5.0204, -4.6054, -5.0408, -4.3678, -4.2098, -4.6808, -4.4727,\n",
      "         -4.2848, -5.0047, -4.0474, -4.7318, -4.5638, -4.7352, -4.1857, -5.3407,\n",
      "         -4.8479, -5.0706, -4.3145, -4.6949, -4.8135, -4.4395, -5.0684, -4.9692,\n",
      "         -5.0603, -4.3992, -4.6630, -4.4708, -4.2798, -4.0855, -4.5068, -4.6784,\n",
      "         -4.5928, -4.4567, -4.4592, -4.1017, -5.2725, -4.3571, -4.7399, -4.6600,\n",
      "         -4.8294, -4.5001, -4.5362, -4.8967, -4.9601, -4.5619, -4.6743, -3.8917,\n",
      "         -4.6397, -4.7195, -4.9715, -4.4399, -4.4035, -4.5135, -4.3354, -4.7084,\n",
      "         -4.6872, -4.8370, -4.6852, -4.8676, -4.7859, -4.0288, -4.8383, -5.0423,\n",
      "         -4.1604, -4.8009, -4.7105, -4.6635, -4.3352, -4.8649, -4.3065, -4.9248,\n",
      "         -4.9940, -4.4495, -4.3913, -4.6756, -4.7671, -4.5707, -4.3037, -4.6569,\n",
      "         -4.3125]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : new\n",
      "target index is: [27] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5625, -4.4805, -4.3510, -4.7120, -4.1624, -4.7233, -4.6669, -4.3811,\n",
      "         -4.6105, -4.6448, -4.8641, -4.5227, -4.6260, -4.7679, -4.5941, -4.6284,\n",
      "         -4.5574, -4.5545, -4.4649, -4.6142, -4.7851, -4.5962, -4.5882, -4.4793,\n",
      "         -4.3848, -4.6619, -4.4831, -4.6388, -4.4443, -4.4009, -4.5195, -4.6452,\n",
      "         -4.8418, -4.6850, -4.5705, -4.6971, -4.6270, -4.6760, -4.5815, -4.6990,\n",
      "         -4.6510, -4.5317, -4.9875, -4.6314, -4.7184, -4.5878, -4.6550, -4.5475,\n",
      "         -4.5365, -4.3572, -4.3202, -4.5341, -4.7019, -4.3265, -4.7248, -4.4771,\n",
      "         -4.5097, -4.6163, -4.5314, -4.6418, -4.7267, -4.6259, -4.5448, -4.0782,\n",
      "         -4.9812, -4.4498, -4.8712, -4.4275, -4.7046, -4.9838, -4.5617, -4.5671,\n",
      "         -4.7172, -4.7658, -4.6427, -4.6901, -4.5000, -4.4301, -4.6451, -4.8192,\n",
      "         -4.4610, -4.3423, -4.6099, -4.7727, -4.6777, -4.3179, -4.5684, -4.7561,\n",
      "         -4.7735, -4.1788, -4.6261, -4.8124, -4.4017, -4.5355, -4.3734, -4.4153,\n",
      "         -4.6709]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : made\n",
      "target index is: [16] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3781, -4.6202, -4.7611, -4.8429, -4.2316, -4.6664, -4.4466, -4.5189,\n",
      "         -4.6772, -4.4051, -4.8852, -4.4557, -4.6675, -4.5765, -4.6912, -4.8037,\n",
      "         -4.4395, -4.7002, -4.5989, -4.5993, -4.3426, -4.3830, -4.7796, -4.5538,\n",
      "         -4.6474, -5.1422, -4.1316, -4.6888, -4.6297, -4.7379, -4.5395, -4.8705,\n",
      "         -4.5540, -4.9087, -4.5063, -4.9603, -4.5305, -4.3695, -4.6338, -4.4004,\n",
      "         -4.6287, -4.5293, -4.5503, -4.4047, -4.4790, -4.4455, -4.6956, -4.5225,\n",
      "         -4.5813, -4.8635, -4.3718, -4.7902, -4.8439, -4.4649, -4.6045, -4.4202,\n",
      "         -4.7810, -4.5842, -4.4084, -4.6073, -4.5607, -4.5063, -4.5801, -4.2090,\n",
      "         -4.3252, -4.8791, -4.8204, -4.3533, -4.6057, -4.3821, -4.5590, -4.6438,\n",
      "         -4.8111, -4.7061, -4.7620, -4.8786, -4.5203, -4.3617, -4.3900, -4.5964,\n",
      "         -4.4843, -4.5779, -4.7410, -4.7549, -4.7812, -4.4282, -4.7241, -4.5120,\n",
      "         -4.9464, -4.6343, -4.3576, -4.5926, -4.6659, -4.5177, -4.5177, -4.4784,\n",
      "         -4.3310]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : when\n",
      "target index is: [85] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4787, -4.5499, -4.8583, -4.7643, -4.2367, -4.6450, -4.3127, -4.3801,\n",
      "         -4.8574, -4.5325, -4.9541, -4.4571, -4.7126, -4.6072, -4.4800, -4.5347,\n",
      "         -4.2443, -4.6555, -4.7301, -4.4815, -4.4783, -4.3572, -4.9019, -4.7374,\n",
      "         -4.6292, -5.0748, -4.5047, -4.2462, -4.7798, -4.7572, -4.6987, -4.5737,\n",
      "         -4.7394, -5.0090, -4.4613, -4.7641, -4.3670, -4.5860, -4.8507, -4.3678,\n",
      "         -4.5803, -4.6971, -4.6556, -4.3643, -4.6127, -4.1352, -4.7422, -4.8755,\n",
      "         -4.7171, -4.9589, -4.5666, -4.6491, -4.5313, -3.7882, -4.3846, -4.5819,\n",
      "         -4.5715, -4.5932, -4.5751, -4.6089, -4.6042, -4.4819, -4.4017, -4.5641,\n",
      "         -4.4427, -4.4672, -4.9016, -4.1612, -4.7507, -4.5138, -4.5886, -4.8532,\n",
      "         -4.8442, -4.7899, -4.8827, -5.0063, -4.5136, -4.3991, -4.5615, -4.8580,\n",
      "         -4.5180, -4.4253, -4.6385, -4.7433, -4.9109, -4.0999, -4.9551, -4.9179,\n",
      "         -4.8107, -4.3670, -4.4641, -4.6651, -4.7334, -4.4656, -4.4615, -4.7204,\n",
      "         -4.2634]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thou\n",
      "target index is: [22] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6520, -4.5684, -4.9543, -4.6674, -4.1887, -4.7740, -4.5110, -4.6922,\n",
      "         -4.6345, -4.5249, -4.6895, -4.2470, -4.8048, -4.6861, -4.7335, -4.3097,\n",
      "         -4.7129, -4.6503, -4.8073, -4.5084, -4.7657, -4.1737, -4.8807, -4.5887,\n",
      "         -4.2442, -4.6949, -4.7538, -4.3520, -4.2895, -4.3572, -4.6943, -4.5689,\n",
      "         -4.7791, -4.8080, -4.5861, -4.5333, -4.6245, -4.8318, -4.9483, -4.3321,\n",
      "         -4.8978, -4.2022, -4.6422, -4.5427, -4.4173, -4.4801, -4.5641, -4.8206,\n",
      "         -4.3683, -5.1528, -4.7097, -4.6743, -4.6506, -4.2200, -4.6014, -4.4096,\n",
      "         -4.2341, -4.5034, -4.6288, -4.4047, -4.6669, -4.5467, -4.3215, -4.5447,\n",
      "         -4.7395, -4.4887, -4.5900, -4.4319, -4.7637, -4.2604, -4.2774, -4.6097,\n",
      "         -4.8866, -4.8994, -4.7976, -4.9475, -4.5260, -4.6157, -4.7933, -4.6618,\n",
      "         -4.6283, -4.3866, -4.5418, -4.3784, -4.7047, -4.1875, -4.7175, -4.8595,\n",
      "         -4.8106, -4.4196, -4.8138, -4.6545, -4.5745, -4.5857, -4.6163, -4.6292,\n",
      "         -4.6771]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : art\n",
      "target index is: [15] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3702, -4.4548, -4.7467, -4.9172, -4.2332, -4.7820, -4.5845, -4.3691,\n",
      "         -4.6778, -4.8109, -4.6813, -4.4265, -4.4618, -4.7797, -4.7567, -4.2522,\n",
      "         -4.4911, -4.4931, -4.2598, -4.5838, -4.6076, -4.2231, -4.8727, -4.8734,\n",
      "         -4.2377, -4.7218, -4.4169, -4.5335, -4.1692, -4.5874, -4.5266, -4.8392,\n",
      "         -4.8652, -4.5871, -4.5710, -4.9267, -4.6362, -4.6196, -4.9393, -4.9206,\n",
      "         -4.8258, -4.8445, -4.7671, -4.7848, -4.6368, -4.4651, -4.6516, -4.9575,\n",
      "         -4.5919, -4.6651, -4.4416, -4.7616, -4.5200, -4.5249, -4.7632, -4.6675,\n",
      "         -4.3527, -4.4431, -4.4757, -4.4138, -4.6851, -4.4184, -4.3899, -4.1102,\n",
      "         -4.6314, -4.4555, -4.8320, -4.8088, -4.6249, -4.4568, -4.5064, -4.4917,\n",
      "         -4.9110, -4.7613, -4.6147, -4.8088, -4.4092, -4.3963, -4.7618, -4.6588,\n",
      "         -4.4553, -4.4439, -4.9461, -4.8466, -4.4454, -4.6756, -4.5496, -4.6426,\n",
      "         -4.5337, -4.3769, -4.5411, -4.7062, -4.5845, -4.1626, -4.6671, -4.5242,\n",
      "         -4.4800]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : old,\n",
      "target index is: [8] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4728, -4.5346, -4.9821, -4.6980, -4.3043, -4.7122, -4.6151, -4.3348,\n",
      "         -4.7073, -4.6028, -4.7700, -4.3667, -4.5715, -4.9561, -5.0463, -4.9453,\n",
      "         -4.6761, -4.7706, -4.5812, -4.6545, -4.3226, -4.2923, -4.8254, -4.5827,\n",
      "         -4.3874, -5.1308, -4.2855, -4.7187, -4.6425, -4.6034, -4.6843, -4.7621,\n",
      "         -4.6905, -4.8474, -4.4746, -4.8516, -4.7297, -4.3851, -4.5960, -4.3513,\n",
      "         -4.6360, -4.5591, -4.6286, -4.5541, -4.2773, -4.2885, -4.4727, -4.3920,\n",
      "         -4.4760, -4.9198, -4.7728, -4.2491, -4.9104, -4.3511, -4.3377, -4.3852,\n",
      "         -4.5901, -4.2811, -4.2680, -4.7602, -4.7615, -4.3933, -4.4547, -4.1681,\n",
      "         -4.5095, -4.7536, -4.6877, -4.3945, -4.3805, -4.1683, -4.3769, -4.7039,\n",
      "         -4.6435, -4.8632, -4.9499, -4.9689, -4.4580, -4.3256, -4.8214, -4.8303,\n",
      "         -4.6622, -4.7285, -4.8608, -4.7212, -4.5889, -4.5870, -4.5875, -4.8450,\n",
      "         -5.0292, -4.3179, -4.7817, -4.6812, -4.6699, -4.2705, -4.6458, -4.7038,\n",
      "         -4.2716]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : And\n",
      "target index is: [6] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4845, -4.3503, -4.5057, -4.5649, -4.3304, -5.0179, -4.5627, -4.4596,\n",
      "         -4.6372, -4.7973, -4.8427, -4.3901, -4.5433, -4.6302, -4.6645, -4.7106,\n",
      "         -4.6588, -4.6278, -4.9729, -4.5663, -4.4783, -4.5097, -4.6359, -4.5788,\n",
      "         -4.1969, -4.7069, -4.6073, -4.4268, -4.2696, -4.5223, -4.7151, -4.7741,\n",
      "         -4.6653, -4.7003, -4.6126, -4.5398, -4.7692, -4.5905, -4.5576, -4.4046,\n",
      "         -4.8554, -4.3743, -4.7060, -4.4151, -4.4961, -4.3712, -4.4408, -4.6226,\n",
      "         -4.5323, -4.7804, -4.5338, -4.4565, -4.9361, -4.3147, -4.5933, -4.5343,\n",
      "         -4.4291, -4.5959, -4.5652, -4.8029, -4.7024, -4.4756, -4.5166, -4.3785,\n",
      "         -4.7197, -4.6583, -4.7480, -4.2774, -4.7046, -4.6119, -4.5944, -4.6636,\n",
      "         -4.5275, -4.9515, -4.7981, -4.7990, -4.5790, -4.3072, -4.8143, -4.7711,\n",
      "         -4.2994, -4.4462, -4.5908, -4.7235, -4.5386, -4.3236, -4.6104, -4.7653,\n",
      "         -4.8615, -4.4969, -4.8163, -4.7653, -4.2898, -4.5203, -4.5341, -4.5238,\n",
      "         -4.5115]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : see\n",
      "target index is: [67] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4467, -4.5333, -4.7744, -4.9869, -4.4212, -4.7252, -4.5783, -4.4256,\n",
      "         -4.7900, -4.6072, -5.0520, -4.8518, -4.6625, -4.7314, -4.6797, -4.7172,\n",
      "         -4.5275, -4.5495, -4.7062, -4.3992, -4.7810, -4.7168, -5.0217, -4.7309,\n",
      "         -4.6697, -4.9109, -4.5520, -4.3177, -4.3589, -4.7546, -4.5227, -4.7090,\n",
      "         -5.0327, -4.8940, -4.2794, -4.5778, -4.2314, -4.5658, -4.7226, -4.7345,\n",
      "         -4.7546, -4.6201, -4.5688, -4.5993, -4.5312, -4.0722, -4.7846, -4.7067,\n",
      "         -4.7941, -4.8518, -4.2412, -4.5752, -4.6396, -4.3452, -4.7239, -4.7648,\n",
      "         -4.4031, -4.3440, -4.6279, -4.4517, -4.7626, -4.5868, -4.4414, -4.5758,\n",
      "         -4.5531, -4.4635, -5.1091, -4.4215, -4.5496, -4.6858, -4.2376, -4.1153,\n",
      "         -5.0174, -4.9726, -4.7674, -4.8661, -4.3944, -4.0772, -4.5872, -4.7514,\n",
      "         -4.3157, -4.7168, -4.3566, -4.9521, -4.7390, -4.3497, -4.4706, -4.5155,\n",
      "         -4.7300, -4.2811, -4.2982, -4.5319, -4.9469, -4.3773, -4.4251, -4.5657,\n",
      "         -4.1442]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6682, -4.4027, -4.9706, -4.5733, -4.2015, -4.6637, -4.6785, -4.2389,\n",
      "         -5.1330, -4.3922, -4.7474, -4.1783, -4.3064, -4.6354, -4.7683, -4.8395,\n",
      "         -4.3673, -4.5362, -4.3575, -4.5397, -4.6432, -4.3775, -4.4261, -4.7263,\n",
      "         -4.3977, -5.1773, -4.2691, -4.9276, -4.5538, -4.4981, -4.6615, -4.5666,\n",
      "         -4.8269, -4.6030, -4.6124, -5.0944, -4.5746, -4.5125, -4.6241, -4.7724,\n",
      "         -4.4565, -4.7706, -4.8430, -4.6042, -4.3961, -4.1391, -4.5819, -5.0369,\n",
      "         -5.0085, -4.4751, -4.8273, -4.4292, -4.4413, -4.2958, -4.4313, -4.4839,\n",
      "         -4.6497, -4.3008, -4.3094, -4.5555, -4.7303, -4.7187, -4.4576, -3.9788,\n",
      "         -4.4258, -4.6865, -4.7005, -4.4049, -4.8238, -4.5006, -4.6355, -4.6240,\n",
      "         -4.8720, -4.5420, -4.8400, -4.8749, -4.3395, -4.4996, -4.5729, -4.9164,\n",
      "         -4.6390, -4.4371, -4.7540, -4.7932, -4.8381, -4.5742, -4.7751, -4.7184,\n",
      "         -4.9895, -4.4758, -4.6436, -4.7655, -4.8744, -4.3013, -4.2524, -4.8988,\n",
      "         -4.4066]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : blood\n",
      "target index is: [39] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5752, -4.4709, -4.9161, -4.4914, -4.3652, -4.7562, -4.4523, -4.3748,\n",
      "         -4.8196, -4.7386, -4.9970, -4.4168, -4.7155, -4.4622, -4.5127, -4.8675,\n",
      "         -4.6303, -4.7986, -4.3587, -4.3866, -4.7900, -4.8359, -4.7415, -4.4412,\n",
      "         -4.6556, -5.1346, -4.7562, -4.4725, -4.1688, -4.7205, -4.4830, -4.5252,\n",
      "         -4.7171, -4.6560, -4.6914, -5.3006, -4.3712, -4.7198, -4.4335, -4.2536,\n",
      "         -4.4798, -4.4179, -4.6831, -4.1379, -4.8130, -4.1170, -4.9857, -4.6384,\n",
      "         -4.6985, -4.8773, -4.7767, -4.7426, -4.7236, -4.2435, -4.3506, -4.4916,\n",
      "         -4.2588, -4.1780, -4.6959, -4.7142, -4.6328, -4.1959, -4.5701, -4.3131,\n",
      "         -4.5465, -4.5902, -4.7351, -4.2155, -4.7055, -4.1348, -4.4799, -4.5752,\n",
      "         -5.0313, -5.0570, -4.8905, -5.2754, -5.1048, -3.9941, -4.5270, -4.5729,\n",
      "         -5.1026, -4.6022, -5.0135, -5.1046, -5.2586, -4.0534, -4.4265, -4.4868,\n",
      "         -5.2152, -4.3386, -4.8511, -4.5498, -4.7685, -4.4859, -4.3993, -4.5043,\n",
      "         -4.2964]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : warm\n",
      "target index is: [2] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5575, -4.3819, -4.6668, -4.8042, -4.5667, -4.6367, -4.4662, -4.4471,\n",
      "         -4.7452, -5.0374, -4.9742, -4.7990, -4.7326, -4.7896, -4.6210, -4.5067,\n",
      "         -4.6904, -4.9685, -4.5339, -4.2935, -4.8441, -4.2587, -5.2062, -4.4656,\n",
      "         -4.1602, -4.6961, -4.3835, -4.2763, -4.3538, -4.7026, -4.7163, -4.7853,\n",
      "         -4.9515, -4.8061, -4.5654, -4.4344, -4.8042, -4.9358, -4.8753, -4.6920,\n",
      "         -4.8044, -4.5648, -4.6880, -4.5413, -4.7555, -4.2918, -4.8271, -4.8477,\n",
      "         -4.2268, -4.8867, -4.4513, -4.3784, -4.4297, -4.1147, -4.7072, -4.1799,\n",
      "         -4.4603, -4.1324, -4.6758, -4.6522, -4.7866, -4.7814, -4.3176, -4.3778,\n",
      "         -4.8054, -4.4539, -5.1266, -4.5144, -4.6679, -4.3595, -4.0785, -4.6503,\n",
      "         -4.3837, -4.5733, -4.5385, -4.8083, -4.5000, -4.3242, -4.8131, -4.8234,\n",
      "         -4.4879, -4.8242, -4.7866, -4.5849, -4.3364, -4.6662, -4.7971, -5.0582,\n",
      "         -4.5478, -4.0914, -4.7215, -4.5636, -4.7163, -4.7524, -4.3064, -4.6930,\n",
      "         -4.2482]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : when\n",
      "target index is: [85] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5197, -4.3313, -4.7568, -4.9926, -4.2271, -4.7499, -4.3501, -4.4141,\n",
      "         -4.7073, -4.3550, -4.6582, -4.6506, -4.8184, -4.6527, -4.4624, -4.5012,\n",
      "         -4.2900, -4.6424, -4.7827, -4.6212, -4.5105, -4.4137, -4.8407, -4.6779,\n",
      "         -4.5305, -5.0722, -4.3953, -4.3277, -4.8355, -4.6128, -4.6603, -4.5802,\n",
      "         -4.7589, -4.9226, -4.5908, -4.7093, -4.5355, -4.4176, -4.9089, -4.5264,\n",
      "         -4.5316, -4.9340, -4.6633, -4.3626, -4.4099, -4.3591, -4.6883, -4.7896,\n",
      "         -4.5211, -4.6966, -4.4213, -4.8270, -4.6893, -4.2295, -4.6251, -4.6375,\n",
      "         -4.6132, -4.7692, -4.5232, -4.4671, -4.8032, -4.4736, -4.5247, -4.1187,\n",
      "         -4.5139, -4.4982, -4.7473, -4.2958, -4.5621, -4.6172, -4.7472, -5.0357,\n",
      "         -4.9954, -4.2628, -4.7109, -4.9728, -4.5152, -4.6967, -4.6818, -4.6614,\n",
      "         -4.3397, -4.3047, -4.8670, -4.5810, -4.9377, -4.2050, -5.0792, -4.5448,\n",
      "         -4.6217, -4.2026, -4.3132, -4.7405, -4.7658, -4.2056, -4.5018, -4.5917,\n",
      "         -4.6681]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thou\n",
      "target index is: [22] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6528, -4.5700, -4.9486, -4.6679, -4.1897, -4.7743, -4.5057, -4.6927,\n",
      "         -4.6291, -4.5256, -4.6895, -4.2474, -4.8058, -4.6863, -4.7339, -4.2918,\n",
      "         -4.7131, -4.6510, -4.8081, -4.5097, -4.7664, -4.1740, -4.8731, -4.5894,\n",
      "         -4.2451, -4.6954, -4.7552, -4.3531, -4.2904, -4.3578, -4.6951, -4.5699,\n",
      "         -4.7798, -4.8085, -4.5870, -4.5336, -4.6252, -4.8326, -4.9495, -4.3280,\n",
      "         -4.8987, -4.2020, -4.6427, -4.5433, -4.4184, -4.4812, -4.5653, -4.8213,\n",
      "         -4.3691, -5.1536, -4.7107, -4.6754, -4.6516, -4.2214, -4.6030, -4.4109,\n",
      "         -4.2344, -4.5049, -4.6298, -4.4056, -4.6680, -4.5476, -4.3222, -4.5457,\n",
      "         -4.7397, -4.4887, -4.5904, -4.4271, -4.7649, -4.2613, -4.2782, -4.6107,\n",
      "         -4.8872, -4.9007, -4.7983, -4.9486, -4.5267, -4.6167, -4.7894, -4.6621,\n",
      "         -4.6290, -4.3875, -4.5427, -4.3794, -4.7056, -4.1778, -4.7184, -4.8604,\n",
      "         -4.8124, -4.4206, -4.8152, -4.6551, -4.5753, -4.5871, -4.6173, -4.6295,\n",
      "         -4.6785]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : feel'st\n",
      "target index is: [35] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5284, -4.2100, -4.7140, -4.8762, -4.1337, -4.7463, -4.7260, -4.1759,\n",
      "         -4.7962, -4.4792, -4.6926, -4.6094, -4.7518, -4.8646, -4.6878, -4.5399,\n",
      "         -4.6049, -4.3443, -4.5899, -4.4983, -4.5910, -4.4825, -4.5820, -4.8942,\n",
      "         -4.5884, -4.8175, -4.4252, -4.5179, -4.5432, -4.5253, -4.4868, -4.6573,\n",
      "         -4.8625, -4.6116, -4.3252, -4.9085, -4.5167, -4.8149, -4.7700, -4.7826,\n",
      "         -4.5840, -4.8654, -4.5834, -4.6662, -4.4463, -4.3806, -4.4769, -4.5993,\n",
      "         -4.6808, -4.5454, -4.5754, -4.6807, -4.6368, -4.6210, -4.6673, -4.6189,\n",
      "         -4.5576, -4.3968, -4.3810, -4.5032, -4.9276, -4.6316, -4.5442, -4.1610,\n",
      "         -4.5195, -4.5112, -4.5398, -4.5454, -4.5270, -4.6606, -4.6661, -4.5166,\n",
      "         -4.8695, -4.9799, -4.7277, -4.7291, -4.3638, -4.4515, -4.6051, -4.7328,\n",
      "         -4.5355, -4.4849, -4.7243, -4.8976, -4.7685, -4.4072, -4.3798, -4.5545,\n",
      "         -4.6322, -4.1021, -4.4341, -4.5391, -4.8720, -4.3803, -4.5429, -4.6415,\n",
      "         -4.4851]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : it\n",
      "target index is: [88] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5663, -4.3961, -4.7929, -4.6910, -4.1335, -4.8835, -4.6552, -4.2074,\n",
      "         -4.6324, -4.6325, -4.6775, -4.3397, -4.4995, -4.8449, -4.6816, -4.6115,\n",
      "         -4.5171, -5.0291, -4.5442, -4.6593, -4.6727, -4.3602, -5.0353, -4.6137,\n",
      "         -4.1754, -4.8079, -4.1227, -4.6347, -4.0757, -4.6927, -4.6432, -5.2731,\n",
      "         -5.0609, -4.7177, -4.8860, -5.0984, -4.4877, -4.7020, -4.7521, -4.7426,\n",
      "         -4.9531, -4.4038, -4.6339, -4.6006, -4.5331, -4.2900, -4.6729, -4.8675,\n",
      "         -4.4810, -4.7694, -4.6715, -4.1047, -4.9251, -4.3342, -4.8182, -4.4197,\n",
      "         -4.5385, -4.1644, -4.6488, -4.7109, -4.6224, -4.5904, -4.2994, -4.1038,\n",
      "         -4.7379, -4.8160, -4.7544, -4.6435, -4.5177, -4.2910, -4.1280, -4.2977,\n",
      "         -4.8760, -4.7565, -4.7017, -4.7220, -4.8151, -3.9670, -4.8330, -4.8650,\n",
      "         -4.5894, -4.5424, -4.8728, -4.8016, -4.5038, -4.7366, -4.3745, -4.6142,\n",
      "         -4.7786, -4.6316, -4.9175, -4.7391, -4.7418, -4.2902, -4.5290, -4.6498,\n",
      "         -4.2079]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : cold.\n",
      "target index is: [79] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4018, -4.0906, -4.7877, -4.8658, -4.0989, -5.0414, -4.5091, -4.4883,\n",
      "         -4.8257, -4.4689, -4.7729, -4.5508, -4.6827, -4.7643, -5.0642, -4.7283,\n",
      "         -4.5907, -4.1780, -4.8319, -4.4054, -4.7421, -4.3425, -4.7011, -4.8595,\n",
      "         -4.3820, -4.7604, -4.4443, -4.2398, -4.2247, -4.4700, -4.3599, -4.5933,\n",
      "         -4.6957, -4.7146, -4.5219, -4.5196, -4.6895, -4.7560, -4.7308, -4.7001,\n",
      "         -4.6875, -4.5285, -4.5127, -4.3706, -4.4303, -4.2789, -4.4634, -4.7256,\n",
      "         -4.7389, -5.0402, -4.5455, -4.5940, -4.6872, -4.5399, -4.3633, -4.7726,\n",
      "         -4.4273, -4.4918, -4.3085, -4.6788, -4.8730, -4.4349, -4.6039, -4.4671,\n",
      "         -4.5497, -4.9925, -4.6126, -4.2504, -4.5611, -4.4107, -4.6715, -4.6574,\n",
      "         -4.9137, -5.0482, -4.9338, -4.8463, -4.5101, -4.5717, -4.6227, -4.7363,\n",
      "         -4.2971, -4.4678, -4.6134, -4.6571, -4.9005, -4.2642, -4.7914, -4.5511,\n",
      "         -4.8065, -4.4425, -4.6095, -4.5133, -4.7532, -4.5040, -4.4337, -4.6650,\n",
      "         -4.5930]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : winters\n",
      "target index is: [3] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2717, -4.6682, -4.3970, -4.6512, -4.2024, -4.5886, -4.5385, -4.2498,\n",
      "         -4.7442, -4.9138, -4.9348, -4.7896, -4.5591, -4.2710, -4.5645, -4.3724,\n",
      "         -4.1108, -4.6656, -4.6385, -4.8481, -4.8384, -4.6376, -4.7312, -4.5838,\n",
      "         -4.4056, -4.8926, -4.4606, -4.4721, -4.3661, -4.5661, -4.2745, -5.0453,\n",
      "         -4.9016, -4.6157, -4.9220, -4.8871, -4.5704, -4.7049, -5.0289, -4.6701,\n",
      "         -4.9344, -4.3816, -4.8553, -4.3670, -5.1177, -4.3589, -5.1146, -5.1711,\n",
      "         -4.9088, -4.2639, -4.6308, -4.3905, -4.8314, -4.1253, -4.9545, -4.1517,\n",
      "         -4.2562, -4.1687, -4.8516, -4.4026, -4.2815, -4.6431, -4.4477, -4.1057,\n",
      "         -4.5557, -3.9635, -5.3833, -4.4891, -4.8498, -4.6527, -4.5661, -4.2483,\n",
      "         -4.9460, -4.8720, -4.5895, -5.1587, -4.8880, -4.1424, -4.6668, -4.8070,\n",
      "         -4.3557, -4.5671, -4.6977, -5.0725, -4.7389, -4.3968, -4.6847, -4.6389,\n",
      "         -5.0925, -4.3876, -4.4107, -4.6945, -4.6589, -4.6727, -4.4180, -4.7646,\n",
      "         -4.3667]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : shall\n",
      "target index is: [10] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5481, -4.3340, -5.0885, -4.8598, -4.2273, -4.7577, -4.4155, -4.6791,\n",
      "         -4.7614, -4.4442, -4.7145, -4.3919, -4.8134, -4.6872, -5.0509, -4.5187,\n",
      "         -4.7319, -4.5883, -4.6723, -4.5008, -4.5061, -3.9812, -4.6721, -4.5010,\n",
      "         -4.2161, -4.7808, -4.5894, -4.5993, -4.4333, -4.6143, -4.8597, -4.6692,\n",
      "         -4.6230, -4.7978, -4.6872, -4.4491, -4.9306, -4.5100, -5.0146, -4.3908,\n",
      "         -4.9259, -4.7058, -4.6856, -4.7244, -4.3953, -4.4603, -4.6392, -4.6332,\n",
      "         -4.4133, -5.0811, -4.4740, -4.7447, -4.6055, -4.3087, -4.5044, -4.5163,\n",
      "         -4.6560, -4.5501, -4.2305, -4.5649, -4.7930, -4.4331, -4.2453, -4.1152,\n",
      "         -4.4571, -4.7725, -4.6506, -4.5541, -4.6505, -4.1864, -4.3815, -4.7039,\n",
      "         -4.5428, -4.6774, -4.9224, -4.7884, -4.0731, -4.7528, -4.8325, -4.6900,\n",
      "         -4.4190, -4.5004, -4.9217, -4.6106, -4.5997, -4.4462, -4.8529, -4.9476,\n",
      "         -4.7762, -4.3058, -4.6775, -4.9091, -4.5963, -4.2195, -4.6113, -4.7914,\n",
      "         -4.3793]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : besiege\n",
      "target index is: [75] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3760, -4.5162, -4.3938, -4.7748, -4.0812, -4.7775, -4.5905, -4.2641,\n",
      "         -4.6845, -4.7025, -4.9442, -4.6947, -4.6544, -4.5496, -5.0355, -4.6785,\n",
      "         -4.5832, -4.4363, -4.8322, -4.5999, -4.5664, -4.8679, -4.6026, -4.5700,\n",
      "         -4.3864, -4.7320, -4.6741, -4.5854, -4.2619, -4.3601, -4.4856, -4.6080,\n",
      "         -4.7541, -4.6843, -4.8586, -4.7777, -4.6220, -4.6678, -4.6786, -4.4796,\n",
      "         -4.4780, -4.6796, -4.7596, -4.1483, -4.5109, -4.4753, -4.3511, -4.3923,\n",
      "         -4.5503, -4.5946, -4.5829, -4.3301, -4.7948, -4.3706, -4.7330, -4.5486,\n",
      "         -4.5243, -4.4935, -4.4627, -4.6818, -5.0585, -4.4658, -4.5799, -3.7842,\n",
      "         -4.6810, -4.4502, -4.8274, -4.6409, -4.5485, -4.7510, -4.5639, -4.5393,\n",
      "         -4.7892, -4.9397, -4.7680, -4.7344, -4.7413, -4.2488, -4.7856, -4.8710,\n",
      "         -4.6866, -4.5124, -4.6177, -4.9397, -4.7070, -4.2668, -4.3466, -4.7874,\n",
      "         -5.3089, -4.1689, -4.7035, -4.6740, -4.5191, -4.5853, -4.3298, -4.5780,\n",
      "         -4.8178]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2654, -4.5269, -4.7282, -4.9227, -4.0167, -4.6683, -4.8207, -4.3660,\n",
      "         -5.2631, -4.3216, -4.8700, -4.1331, -4.8523, -4.6183, -4.6891, -4.9849,\n",
      "         -4.9123, -4.6024, -4.4905, -4.4996, -4.4758, -4.4937, -4.8077, -4.5189,\n",
      "         -4.8821, -4.8514, -4.1067, -4.5824, -4.5850, -4.5652, -4.6632, -4.8911,\n",
      "         -4.8774, -4.5575, -4.5351, -5.1723, -4.5632, -4.9842, -4.8293, -4.6674,\n",
      "         -4.8442, -4.9537, -4.8175, -4.5656, -4.6511, -4.3136, -4.8459, -4.7996,\n",
      "         -4.7740, -4.6954, -4.3653, -5.0640, -4.3798, -4.3957, -5.0247, -4.2267,\n",
      "         -4.7952, -4.4788, -4.4720, -4.2294, -4.3087, -4.4557, -4.6441, -3.8858,\n",
      "         -4.3161, -4.6861, -5.0696, -4.5847, -4.6878, -4.7198, -4.3018, -4.7511,\n",
      "         -5.1951, -4.7244, -4.4452, -4.9270, -4.3534, -4.2512, -4.4517, -4.5349,\n",
      "         -4.6792, -4.2702, -4.9677, -4.9617, -4.6540, -4.4208, -4.4227, -4.5165,\n",
      "         -4.8334, -4.5676, -4.0761, -4.3987, -4.6052, -4.4478, -4.1466, -4.6619,\n",
      "         -4.5713]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : brow,\n",
      "target index is: [13] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4358, -4.3040, -4.6496, -4.6294, -4.2820, -4.8611, -4.7670, -4.4194,\n",
      "         -4.7008, -4.7573, -4.8639, -4.5209, -4.8103, -4.3944, -4.7578, -4.8864,\n",
      "         -4.6599, -4.7207, -4.5003, -4.4841, -4.7955, -4.9210, -4.7635, -4.3216,\n",
      "         -4.6054, -4.8109, -4.7165, -4.2593, -4.0974, -4.3613, -4.2391, -4.7438,\n",
      "         -4.9044, -4.5525, -4.9169, -5.0235, -4.5281, -4.8952, -4.3488, -4.3498,\n",
      "         -4.7288, -4.5962, -4.4665, -4.1345, -4.6107, -4.1426, -4.7213, -4.8200,\n",
      "         -4.6034, -4.8168, -4.8703, -4.4713, -4.9048, -4.1175, -4.5989, -4.4013,\n",
      "         -4.3909, -4.0928, -4.7267, -4.6305, -4.8729, -4.4249, -4.5400, -4.1213,\n",
      "         -4.7592, -4.5714, -5.0777, -4.5398, -4.6045, -4.4313, -4.3785, -4.5149,\n",
      "         -4.8297, -4.9279, -4.8131, -5.0275, -5.0857, -3.8910, -4.8543, -5.0064,\n",
      "         -4.9954, -4.5391, -4.7347, -5.0809, -5.0006, -4.3938, -4.3732, -4.5362,\n",
      "         -4.9197, -3.9832, -4.8771, -4.5822, -4.6786, -4.5612, -4.2947, -4.8331,\n",
      "         -4.2987]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : And\n",
      "target index is: [6] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4225, -4.3323, -4.6207, -4.7785, -4.1946, -4.8240, -4.7300, -4.4731,\n",
      "         -4.8399, -4.5771, -4.4637, -4.3377, -4.9045, -4.9904, -4.3763, -4.8513,\n",
      "         -4.8633, -4.9854, -4.4809, -4.4536, -4.4063, -4.3586, -4.7274, -4.6260,\n",
      "         -4.6435, -4.6966, -4.3026, -4.4121, -4.3457, -4.9321, -4.5566, -5.2239,\n",
      "         -4.7463, -4.6242, -4.4508, -4.8191, -4.6712, -4.8971, -4.7821, -4.6149,\n",
      "         -4.8037, -4.9569, -4.8740, -4.7220, -4.7091, -4.4794, -4.5172, -4.6009,\n",
      "         -4.4695, -4.9944, -4.5189, -4.6573, -4.4427, -4.7039, -5.1664, -4.5745,\n",
      "         -4.5492, -4.4825, -4.4711, -4.5811, -4.6124, -4.6038, -4.8751, -4.1796,\n",
      "         -4.9478, -4.6524, -4.9650, -4.5774, -4.6204, -4.6804, -4.0822, -4.7976,\n",
      "         -5.0734, -4.5983, -4.2442, -4.8056, -4.7399, -4.3333, -4.7568, -4.2131,\n",
      "         -4.5908, -4.0180, -4.9277, -4.6876, -4.3694, -4.4464, -4.5132, -4.5198,\n",
      "         -4.7830, -4.3064, -4.5940, -4.5244, -4.2710, -4.0903, -4.1272, -4.4127,\n",
      "         -4.5050]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : dig\n",
      "target index is: [42] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4101, -4.6159, -4.7096, -4.9305, -4.2218, -4.8254, -4.6963, -4.5164,\n",
      "         -4.5295, -4.6629, -4.8622, -4.9789, -4.7492, -4.8181, -4.5456, -4.7157,\n",
      "         -4.6679, -4.7473, -4.6946, -4.4184, -4.8604, -4.4946, -5.0930, -4.6865,\n",
      "         -4.4792, -4.9458, -4.4828, -4.4760, -4.1300, -4.7659, -4.5083, -4.8185,\n",
      "         -4.8825, -4.7926, -4.2421, -4.5042, -4.3815, -4.6843, -4.8199, -4.6929,\n",
      "         -4.7985, -4.4359, -4.7436, -4.6196, -4.6817, -4.2293, -4.8823, -4.5000,\n",
      "         -4.6494, -4.8534, -4.3584, -4.7352, -4.6472, -4.5065, -4.7133, -4.5873,\n",
      "         -4.2046, -4.2793, -4.6162, -4.4190, -4.5659, -4.6804, -4.6623, -4.6002,\n",
      "         -4.6590, -4.3786, -4.9971, -4.5546, -4.6244, -4.7943, -4.2201, -4.1568,\n",
      "         -5.0109, -4.8889, -4.7368, -4.7689, -4.6794, -4.1653, -4.7564, -4.4816,\n",
      "         -4.4152, -4.4822, -4.4964, -4.9878, -4.4898, -4.3594, -4.2945, -4.4367,\n",
      "         -4.6976, -4.1823, -4.4933, -4.4143, -4.7653, -4.4323, -4.5707, -4.4140,\n",
      "         -4.2624]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : deep\n",
      "target index is: [76] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5730, -4.8934, -4.6846, -4.6130, -4.2352, -4.8163, -4.3915, -4.1769,\n",
      "         -4.7166, -5.0115, -4.8079, -4.4308, -4.5647, -4.8730, -4.8257, -4.2898,\n",
      "         -4.2430, -4.8130, -4.4617, -4.9412, -4.4905, -4.2219, -4.6370, -4.7184,\n",
      "         -4.1532, -4.9064, -4.4599, -4.7292, -4.6445, -4.4732, -4.7186, -4.6599,\n",
      "         -4.9124, -4.8943, -4.4008, -4.6177, -4.9634, -4.5033, -5.0139, -4.7206,\n",
      "         -4.8221, -4.6568, -4.8792, -4.5462, -4.4105, -4.3332, -4.5417, -4.6269,\n",
      "         -4.4739, -4.3148, -4.5120, -4.1572, -4.7510, -4.4144, -4.6291, -4.4478,\n",
      "         -4.5179, -4.5627, -4.5057, -4.6354, -5.0377, -4.6785, -4.5308, -3.9283,\n",
      "         -4.7004, -4.4542, -4.8748, -4.4029, -4.6894, -4.5692, -4.3725, -4.6791,\n",
      "         -4.6091, -4.5140, -4.6195, -4.9340, -4.5052, -4.5729, -4.8968, -4.7223,\n",
      "         -4.1521, -4.7588, -4.6945, -4.6284, -4.3471, -4.5623, -4.6714, -5.0551,\n",
      "         -4.9430, -4.3739, -4.5230, -4.7237, -4.6852, -4.4075, -4.4524, -4.4570,\n",
      "         -4.5687]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : trenches\n",
      "target index is: [54] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4822, -4.5185, -4.9233, -5.4008, -4.0751, -4.6468, -4.4448, -4.3895,\n",
      "         -4.8254, -4.4006, -4.8883, -4.3928, -4.7999, -4.8196, -4.9632, -4.7208,\n",
      "         -4.4626, -4.6376, -4.6791, -4.6666, -4.5597, -4.2557, -4.9054, -4.5589,\n",
      "         -4.4560, -4.8808, -4.1630, -4.5645, -4.5911, -4.7091, -4.4839, -5.0388,\n",
      "         -4.9246, -4.8981, -4.5001, -4.5720, -4.3563, -4.7564, -5.0209, -4.6768,\n",
      "         -4.8553, -4.8030, -4.5874, -4.5217, -4.4351, -4.4354, -4.5327, -4.7381,\n",
      "         -4.4039, -5.1751, -4.1447, -4.7581, -4.6554, -4.3749, -4.4772, -4.6708,\n",
      "         -4.9094, -4.6429, -4.2922, -4.4705, -4.6845, -4.4081, -4.4961, -4.0943,\n",
      "         -4.5098, -4.6562, -4.7314, -4.4770, -4.4483, -4.3541, -4.6357, -4.6944,\n",
      "         -5.1992, -4.6435, -4.8379, -5.0770, -4.2849, -4.1893, -4.3943, -4.5486,\n",
      "         -4.5558, -4.5288, -4.6322, -4.5174, -4.6833, -4.4228, -4.5193, -4.6823,\n",
      "         -4.6823, -4.6242, -4.0994, -4.5517, -4.7262, -4.2598, -4.5691, -4.7312,\n",
      "         -4.5004]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : in\n",
      "target index is: [95] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7490, -4.4413, -4.5666, -4.5171, -4.1300, -4.6713, -4.7142, -4.2018,\n",
      "         -4.7496, -4.5756, -4.6536, -4.2534, -4.4504, -4.7025, -4.8341, -4.6516,\n",
      "         -4.5913, -4.7376, -4.2033, -4.4991, -4.5231, -4.5560, -4.6055, -4.6408,\n",
      "         -4.2509, -4.9587, -4.4347, -4.8104, -4.3631, -4.4725, -4.7229, -4.6990,\n",
      "         -4.9229, -4.6705, -4.6174, -5.0698, -4.4793, -4.6492, -4.3236, -4.7080,\n",
      "         -4.5026, -4.5807, -4.9465, -4.6900, -4.5156, -4.3889, -4.4777, -4.9082,\n",
      "         -4.8280, -4.5071, -4.6248, -4.1763, -4.6550, -4.2643, -4.7348, -4.4178,\n",
      "         -4.5274, -4.2857, -4.3363, -4.7204, -4.8077, -4.6587, -4.5004, -4.0691,\n",
      "         -4.7833, -4.4424, -4.7161, -4.5957, -4.7944, -4.8343, -4.4328, -4.4988,\n",
      "         -5.0068, -4.8027, -4.8462, -4.8312, -4.6673, -4.3356, -4.6785, -5.0212,\n",
      "         -4.7933, -4.2294, -4.6835, -4.6827, -4.7236, -4.4135, -4.6468, -4.6772,\n",
      "         -4.8519, -4.2752, -4.9090, -4.7314, -4.6301, -4.3203, -4.4853, -4.6040,\n",
      "         -4.5315]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2660, -4.5169, -5.1295, -4.8396, -4.2664, -4.7132, -4.7966, -4.3584,\n",
      "         -5.2614, -4.2381, -4.9052, -4.2029, -4.4774, -4.3644, -4.9897, -5.0854,\n",
      "         -4.6363, -4.6055, -4.6122, -4.4053, -4.5146, -4.5238, -4.6138, -4.5944,\n",
      "         -4.5673, -5.0609, -4.2684, -4.5174, -4.6014, -4.7557, -4.7476, -4.4915,\n",
      "         -4.9721, -4.7880, -4.8298, -5.3837, -4.6855, -4.5577, -4.6404, -4.3317,\n",
      "         -4.5440, -4.6565, -4.3702, -4.4198, -4.2067, -4.1452, -4.7006, -4.6888,\n",
      "         -4.9523, -4.7979, -4.6163, -4.6938, -4.4302, -4.3550, -4.4968, -4.5404,\n",
      "         -4.5908, -4.3483, -4.4264, -4.6426, -4.6822, -4.4405, -4.3318, -4.2044,\n",
      "         -4.0191, -4.8251, -4.8397, -4.5048, -4.6213, -4.2244, -4.3358, -4.6440,\n",
      "         -4.7642, -4.7471, -4.7952, -4.7268, -4.2734, -4.1789, -4.4811, -4.6974,\n",
      "         -4.7898, -4.7574, -4.8391, -5.0235, -5.0882, -4.4455, -4.6862, -4.4977,\n",
      "         -5.1523, -4.6077, -4.4365, -4.7655, -4.9209, -4.3869, -4.2499, -4.8499,\n",
      "         -4.4559]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty's\n",
      "target index is: [80] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2942, -4.4790, -4.7564, -4.5226, -4.1993, -4.9217, -4.5770, -4.3132,\n",
      "         -4.3816, -5.1144, -4.9724, -4.2397, -4.6883, -4.7200, -4.6051, -4.7409,\n",
      "         -4.8741, -5.1487, -4.5474, -4.3984, -4.9381, -4.7346, -4.6207, -4.4840,\n",
      "         -4.2048, -4.6471, -4.6549, -4.4177, -3.8463, -4.5642, -4.8059, -4.6036,\n",
      "         -4.7216, -4.5583, -4.6298, -5.1371, -4.8569, -4.6202, -4.6650, -4.5025,\n",
      "         -4.6734, -4.2293, -4.9884, -4.0488, -4.5084, -4.0870, -4.4291, -4.4816,\n",
      "         -4.5460, -4.8922, -4.7801, -4.4723, -4.7569, -4.3258, -4.6085, -4.3981,\n",
      "         -4.3028, -4.3294, -4.7266, -5.0472, -4.8278, -4.1801, -4.4602, -4.0862,\n",
      "         -5.0332, -4.7977, -5.0885, -4.6626, -4.8254, -4.6350, -4.2814, -4.7156,\n",
      "         -4.5133, -4.8576, -4.7995, -4.8986, -5.1895, -4.2480, -4.6738, -4.4620,\n",
      "         -4.7780, -4.3166, -5.2172, -4.8189, -4.8612, -4.1040, -4.6062, -5.0104,\n",
      "         -5.0247, -4.5862, -5.2259, -4.4857, -4.6000, -4.4832, -4.2741, -4.2974,\n",
      "         -4.5213]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : field,\n",
      "target index is: [77] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.0446, -4.1521, -4.7690, -5.6461, -4.0556, -5.0824, -4.5507, -4.4263,\n",
      "         -4.8823, -4.7931, -4.6843, -5.1334, -5.0748, -4.8711, -4.6608, -4.8070,\n",
      "         -4.8938, -4.7075, -4.8056, -4.5893, -4.7592, -4.3134, -5.1001, -4.6553,\n",
      "         -4.6302, -4.8610, -4.3084, -4.0374, -4.2208, -4.9068, -4.2792, -4.7833,\n",
      "         -4.7933, -4.6830, -4.4942, -4.9528, -4.7149, -5.0114, -4.9738, -4.8158,\n",
      "         -4.5632, -5.1494, -4.8747, -4.6297, -4.5849, -4.0368, -5.0850, -4.4187,\n",
      "         -4.5999, -5.0181, -3.8231, -5.2276, -4.4088, -4.7967, -4.7821, -4.5013,\n",
      "         -4.5323, -4.3780, -4.4705, -4.2557, -4.7541, -4.4902, -4.4111, -3.7506,\n",
      "         -4.4713, -4.5413, -4.9900, -4.6783, -4.4556, -4.4696, -4.6020, -4.4342,\n",
      "         -5.3909, -4.8817, -4.7944, -4.8889, -4.4040, -4.1404, -4.5036, -4.4919,\n",
      "         -4.5441, -4.3758, -5.2324, -5.2306, -4.5316, -4.4688, -4.2561, -4.8368,\n",
      "         -4.6318, -4.2189, -4.1442, -4.3218, -4.9409, -4.1730, -4.4628, -4.8893,\n",
      "         -4.4639]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Thy\n",
      "target index is: [73] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3059, -4.5923, -4.7227, -4.6571, -4.2246, -4.9367, -4.6480, -4.1486,\n",
      "         -4.7290, -4.9126, -4.6615, -4.2355, -4.3541, -4.7317, -4.6364, -4.3643,\n",
      "         -4.6773, -4.8378, -4.1353, -4.6932, -4.5260, -4.2448, -4.8040, -4.8009,\n",
      "         -4.1543, -4.8525, -4.5767, -4.7159, -4.0198, -4.4567, -4.7753, -4.7113,\n",
      "         -4.8810, -4.5771, -4.7057, -5.1129, -4.9099, -4.5558, -4.7974, -4.9483,\n",
      "         -4.7551, -4.4159, -4.9702, -4.6573, -4.4903, -4.4210, -4.6206, -5.0940,\n",
      "         -4.6988, -4.5082, -4.6173, -4.2965, -4.7758, -4.4898, -4.7991, -4.4815,\n",
      "         -4.2238, -4.1768, -4.5618, -4.4319, -4.8296, -4.4100, -4.4909, -3.9007,\n",
      "         -4.8243, -4.6348, -4.7955, -4.8829, -4.8816, -4.6686, -4.3340, -4.4029,\n",
      "         -4.8767, -4.6905, -4.7733, -4.9108, -4.5973, -4.3633, -4.7875, -4.7340,\n",
      "         -4.4818, -4.3027, -5.1127, -4.6870, -4.3460, -4.7487, -4.7071, -4.6571,\n",
      "         -4.6839, -4.6435, -4.7298, -4.6438, -4.7108, -4.1478, -4.4791, -4.5905,\n",
      "         -4.4761]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : youth's\n",
      "target index is: [89] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2285, -4.7405, -4.7409, -4.8569, -4.1292, -4.7303, -4.8864, -4.5438,\n",
      "         -4.8269, -5.0093, -4.8957, -4.4241, -4.7426, -4.3938, -5.0462, -4.8314,\n",
      "         -4.6789, -4.6699, -4.6500, -4.6469, -4.3739, -4.4802, -4.5587, -4.5355,\n",
      "         -4.3187, -4.7273, -4.6864, -4.7758, -4.4853, -4.3853, -5.0056, -4.3693,\n",
      "         -4.9489, -4.6318, -4.6695, -5.1931, -4.7714, -4.7547, -4.8184, -4.3032,\n",
      "         -4.6379, -4.6551, -4.9074, -4.3421, -4.3097, -4.4943, -4.4806, -4.4027,\n",
      "         -4.5444, -4.4550, -4.3653, -4.8410, -4.4834, -4.2180, -4.3973, -4.4169,\n",
      "         -4.4764, -4.5306, -4.5771, -4.4754, -4.7319, -4.3941, -4.4776, -3.6410,\n",
      "         -4.2842, -4.3373, -4.8782, -4.6190, -4.7554, -4.5812, -4.3456, -4.6494,\n",
      "         -4.9231, -4.8180, -4.8639, -4.6328, -4.4408, -4.3098, -4.8342, -4.2862,\n",
      "         -4.7325, -4.7434, -4.9765, -5.1992, -4.5662, -4.2982, -4.4898, -5.0283,\n",
      "         -5.2639, -4.1880, -4.4624, -4.7276, -4.6474, -4.4776, -4.4201, -4.7099,\n",
      "         -4.8679]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : proud\n",
      "target index is: [50] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5419, -4.3364, -4.9439, -5.0887, -4.3723, -4.6423, -4.4028, -4.5221,\n",
      "         -5.3557, -4.5004, -4.8822, -4.4370, -4.8927, -4.5762, -4.6057, -5.1331,\n",
      "         -4.9385, -4.6919, -4.5211, -4.0638, -4.3881, -4.3772, -4.9140, -4.4875,\n",
      "         -4.9155, -4.9191, -4.4525, -4.3718, -4.7407, -4.8677, -4.7474, -4.6113,\n",
      "         -4.8710, -4.8169, -4.3471, -5.1328, -4.6184, -5.0215, -4.6610, -4.1828,\n",
      "         -4.3707, -4.6241, -4.6527, -4.4344, -4.6012, -4.2186, -4.8496, -4.2909,\n",
      "         -4.4622, -5.3993, -4.2817, -5.1113, -4.2936, -4.4893, -4.5045, -4.5340,\n",
      "         -4.8243, -4.4515, -4.3914, -4.7637, -4.6528, -4.2852, -4.6298, -4.3312,\n",
      "         -4.3465, -4.8691, -4.9087, -4.2375, -4.6333, -4.2687, -4.4447, -4.8420,\n",
      "         -4.9422, -4.9635, -4.5925, -4.8160, -4.5539, -4.2685, -4.2740, -4.1301,\n",
      "         -4.8809, -4.8050, -5.1427, -4.8306, -5.0124, -4.3271, -4.5345, -4.5503,\n",
      "         -4.7188, -4.2860, -4.3892, -4.1552, -4.8790, -4.5081, -4.2245, -4.6274,\n",
      "         -4.2582]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : livery\n",
      "target index is: [28] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6602, -4.4202, -5.0017, -4.7393, -4.0785, -5.1278, -4.4466, -4.3478,\n",
      "         -4.5743, -4.4745, -4.8810, -4.5814, -4.7335, -4.8585, -4.3080, -4.5784,\n",
      "         -4.7987, -5.0223, -4.7610, -4.4236, -4.7961, -4.0840, -5.0733, -4.7828,\n",
      "         -4.2155, -4.9085, -4.1632, -4.4354, -4.1148, -4.8339, -4.9316, -5.1370,\n",
      "         -4.9114, -4.7646, -4.6567, -4.7882, -4.5841, -4.7026, -5.0514, -4.5051,\n",
      "         -4.9473, -4.5339, -4.7858, -4.7436, -4.7992, -4.2836, -4.6472, -4.8846,\n",
      "         -4.3990, -5.0435, -4.3791, -4.6465, -4.5337, -4.2778, -4.6736, -4.3478,\n",
      "         -4.3120, -4.1993, -4.7005, -4.8997, -4.5229, -4.4539, -4.2142, -4.4743,\n",
      "         -4.5878, -4.5717, -4.7402, -4.7283, -4.7037, -4.3556, -4.2361, -4.4240,\n",
      "         -4.8161, -4.9150, -4.6521, -4.9121, -4.6234, -4.1638, -4.6535, -4.5298,\n",
      "         -4.5652, -4.6191, -4.9158, -4.6831, -4.4947, -4.3789, -4.4528, -4.8286,\n",
      "         -4.4502, -4.5193, -4.9470, -4.5651, -4.7511, -4.2960, -4.5017, -4.5036,\n",
      "         -3.9864]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : so\n",
      "target index is: [69] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4052, -4.2993, -4.9247, -4.8009, -4.2534, -5.0310, -4.6409, -4.4000,\n",
      "         -4.5601, -4.6587, -4.7892, -4.8178, -4.4611, -5.0148, -4.8522, -4.6141,\n",
      "         -4.7187, -4.4007, -4.5532, -4.5757, -4.4115, -4.2683, -5.0724, -4.8090,\n",
      "         -4.3280, -4.9262, -4.3706, -4.4932, -4.2077, -4.6729, -4.8362, -4.7784,\n",
      "         -4.9704, -4.9754, -4.6070, -4.7770, -4.8709, -4.4307, -4.8411, -4.6928,\n",
      "         -4.6444, -4.6586, -4.6302, -4.5813, -4.3779, -4.2809, -4.4982, -4.5557,\n",
      "         -4.4937, -4.8948, -4.5811, -4.4668, -4.8361, -4.3592, -4.4744, -4.6907,\n",
      "         -4.2131, -4.3573, -4.3023, -4.6501, -4.8865, -4.5208, -4.1989, -4.1616,\n",
      "         -4.4267, -4.8549, -4.4889, -4.4530, -4.3020, -4.4485, -4.2923, -4.4786,\n",
      "         -4.8039, -4.8686, -4.9929, -4.8531, -4.2756, -4.4937, -5.0471, -4.8177,\n",
      "         -4.3661, -4.6254, -4.8593, -4.7496, -4.7153, -4.3981, -4.5614, -4.6467,\n",
      "         -4.7495, -4.2601, -4.7556, -4.8483, -4.7486, -4.1530, -4.6927, -4.6478,\n",
      "         -4.3108]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : gazed\n",
      "target index is: [17] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4641, -4.3331, -4.6890, -4.7829, -4.3091, -4.6389, -4.5411, -4.3458,\n",
      "         -4.5775, -4.7437, -4.6905, -4.5641, -4.5807, -4.7027, -4.7695, -4.6259,\n",
      "         -4.4382, -4.6684, -4.6493, -4.5117, -4.6788, -4.6142, -4.7342, -4.6082,\n",
      "         -4.3983, -4.8693, -4.4320, -4.5663, -4.3331, -4.6128, -4.3997, -4.8359,\n",
      "         -4.8831, -4.7385, -4.5832, -4.6706, -4.5862, -4.6137, -4.7019, -4.5947,\n",
      "         -4.6962, -4.5880, -4.4353, -4.4239, -4.5824, -4.2754, -4.6839, -4.5663,\n",
      "         -4.4441, -4.5974, -4.5484, -4.2888, -4.8687, -4.4920, -4.6599, -4.3791,\n",
      "         -4.5721, -4.3139, -4.5422, -4.7082, -4.7413, -4.6154, -4.6693, -4.3208,\n",
      "         -4.6385, -4.6157, -4.8183, -4.4618, -4.5715, -4.5183, -4.4658, -4.4498,\n",
      "         -4.5029, -4.8334, -4.7110, -4.8353, -4.6510, -4.1822, -4.8571, -4.8636,\n",
      "         -4.6129, -4.6199, -4.6923, -4.8267, -4.5073, -4.4933, -4.3115, -4.6776,\n",
      "         -4.6854, -4.3029, -4.6834, -4.5479, -4.8015, -4.4933, -4.5752, -4.5421,\n",
      "         -4.5046]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : on\n",
      "target index is: [87] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4802, -4.6585, -4.6066, -4.6184, -4.2335, -4.6126, -4.3916, -4.2670,\n",
      "         -4.6784, -4.7075, -4.6228, -4.7793, -4.7555, -4.5831, -4.6660, -4.4687,\n",
      "         -4.3063, -4.6342, -4.6722, -4.7427, -4.8106, -4.6565, -4.7063, -4.5130,\n",
      "         -4.4474, -4.7545, -4.6063, -4.5055, -4.6142, -4.4142, -4.4594, -4.6757,\n",
      "         -4.7468, -4.7166, -4.7438, -4.6355, -4.7153, -4.6636, -4.9500, -4.5890,\n",
      "         -4.7063, -4.5347, -4.8205, -4.2951, -4.6901, -4.3786, -4.6135, -4.5764,\n",
      "         -4.4496, -4.3499, -4.7498, -4.4186, -5.1041, -4.2697, -4.6384, -4.3002,\n",
      "         -4.2567, -4.3371, -4.6355, -4.4942, -4.7310, -4.7310, -4.4622, -4.0224,\n",
      "         -4.8117, -4.2836, -4.8150, -4.5199, -4.5873, -4.5542, -4.5012, -4.6334,\n",
      "         -4.6921, -4.4369, -4.5786, -4.8099, -4.6800, -4.5383, -4.9547, -4.7931,\n",
      "         -4.4181, -4.4617, -4.7672, -4.6921, -4.6435, -4.4761, -4.6160, -4.7569,\n",
      "         -4.9294, -4.2445, -4.5141, -4.3447, -4.7599, -4.6547, -4.5112, -4.6709,\n",
      "         -4.7852]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : now,\n",
      "target index is: [63] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4568, -4.6071, -4.8470, -4.9185, -3.8194, -4.5154, -4.5316, -4.5319,\n",
      "         -4.6679, -4.6465, -4.5812, -4.3880, -5.0641, -4.8311, -4.7759, -4.5159,\n",
      "         -4.5578, -4.8003, -4.6097, -4.4136, -4.5725, -4.0877, -4.9175, -4.9081,\n",
      "         -4.6478, -4.9723, -4.6836, -4.3312, -4.3362, -4.7682, -4.4257, -5.0072,\n",
      "         -4.7162, -4.6452, -4.2509, -4.8965, -4.5119, -4.8726, -5.0978, -4.7358,\n",
      "         -4.6725, -4.4876, -4.7413, -4.4784, -4.5969, -4.3879, -4.3937, -4.8878,\n",
      "         -4.5433, -5.1315, -4.7698, -4.5826, -4.4979, -4.4731, -4.5651, -4.4539,\n",
      "         -4.2290, -4.4620, -4.4235, -4.5424, -4.5037, -4.5769, -4.8105, -4.3122,\n",
      "         -4.4583, -4.4196, -4.6826, -4.5408, -4.6936, -4.4291, -4.4371, -4.5885,\n",
      "         -5.0301, -4.9199, -4.6268, -4.8480, -4.9970, -4.4327, -4.7436, -4.4501,\n",
      "         -4.6282, -4.0822, -4.9034, -4.8176, -4.3254, -4.3206, -4.5751, -4.5450,\n",
      "         -4.8546, -4.4187, -4.6706, -4.2048, -4.7092, -4.3439, -4.5810, -4.5671,\n",
      "         -4.6084]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Will\n",
      "target index is: [36] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4034, -4.7833, -4.8100, -4.8710, -4.1052, -4.6385, -4.6567, -4.2795,\n",
      "         -4.5428, -4.7387, -4.6212, -4.6538, -4.5997, -4.8577, -4.9228, -4.3048,\n",
      "         -4.4801, -4.5832, -4.3658, -4.5562, -4.8188, -4.1489, -4.9596, -5.0499,\n",
      "         -4.1143, -5.0227, -4.4199, -4.4272, -4.2080, -4.4419, -4.4705, -4.8969,\n",
      "         -5.0368, -4.8769, -4.3613, -4.6780, -4.6211, -4.6590, -5.0817, -4.7827,\n",
      "         -4.9792, -4.5719, -4.4411, -4.6258, -4.6796, -4.3677, -4.6898, -4.6841,\n",
      "         -4.5727, -4.8955, -4.4036, -4.5939, -4.9052, -4.5849, -4.6411, -4.4516,\n",
      "         -4.1090, -4.3119, -4.3086, -4.5261, -4.9763, -4.7275, -4.4756, -4.4585,\n",
      "         -4.5217, -4.4377, -4.6884, -4.5657, -4.7357, -4.6839, -4.2853, -4.3049,\n",
      "         -4.8130, -4.9183, -4.7285, -4.7655, -4.4272, -4.3107, -4.6973, -4.7908,\n",
      "         -4.4730, -4.6499, -4.6359, -4.7218, -4.4338, -4.4911, -4.5458, -4.7941,\n",
      "         -4.6557, -4.3295, -4.6636, -4.5262, -4.8074, -4.4901, -4.8324, -4.3806,\n",
      "         -4.3043]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : be\n",
      "target index is: [24] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3526, -4.6640, -4.7696, -4.7583, -4.1588, -4.9906, -4.5962, -4.3375,\n",
      "         -4.7574, -4.7919, -4.6371, -4.2888, -4.6766, -5.0081, -5.0906, -4.3665,\n",
      "         -4.3905, -4.7600, -4.6874, -4.9857, -4.3667, -3.9588, -4.5046, -4.6706,\n",
      "         -4.1092, -5.0896, -4.3242, -4.7995, -4.4002, -4.5775, -4.3733, -5.2371,\n",
      "         -4.8378, -4.7900, -4.6014, -4.5442, -4.6933, -4.5344, -4.9850, -4.8461,\n",
      "         -5.0292, -4.7269, -4.6348, -4.6770, -4.3812, -4.5033, -4.5417, -4.7570,\n",
      "         -4.6034, -4.6119, -4.7242, -4.0763, -5.0798, -4.4243, -4.6766, -4.6537,\n",
      "         -4.5140, -4.4891, -4.3333, -4.7036, -4.9049, -4.5372, -4.5768, -4.0414,\n",
      "         -4.6786, -4.5029, -4.8608, -4.4151, -4.3104, -4.4040, -4.1890, -4.6547,\n",
      "         -4.9446, -4.7549, -5.0811, -5.1840, -4.4980, -4.2801, -4.8861, -4.8951,\n",
      "         -4.1825, -4.5702, -4.6591, -4.4780, -4.3307, -4.4679, -4.3892, -4.8758,\n",
      "         -5.0067, -4.5306, -4.2088, -4.7593, -4.5498, -4.4165, -4.5397, -4.5938,\n",
      "         -4.5382]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : a\n",
      "target index is: [46] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3903, -4.5156, -4.6614, -5.3670, -4.1404, -4.6992, -4.2712, -4.0495,\n",
      "         -4.7747, -4.5556, -4.8396, -4.9075, -4.4007, -4.7533, -4.6886, -4.3034,\n",
      "         -4.2014, -4.6221, -4.6722, -4.5932, -5.0663, -4.3408, -4.8780, -4.9557,\n",
      "         -4.3076, -5.2811, -4.1887, -4.4226, -4.2888, -4.6517, -4.4731, -4.7497,\n",
      "         -4.8912, -5.0325, -4.4449, -4.6543, -4.5281, -4.3765, -4.9107, -4.5743,\n",
      "         -4.8468, -4.6017, -4.9683, -4.3133, -4.9366, -4.1973, -4.8630, -4.7541,\n",
      "         -4.7229, -4.7752, -4.1466, -4.6288, -4.5615, -4.5020, -4.6449, -4.5810,\n",
      "         -4.3208, -4.5389, -4.3901, -4.7372, -4.8513, -4.7112, -4.4649, -4.3299,\n",
      "         -4.6421, -4.3743, -5.0273, -4.3721, -4.7739, -4.8180, -4.7230, -4.4792,\n",
      "         -4.8897, -4.8535, -4.6659, -4.8812, -4.4414, -4.2770, -4.3691, -4.6975,\n",
      "         -4.3999, -4.6100, -4.7253, -4.7195, -4.8655, -4.3499, -4.6015, -4.7218,\n",
      "         -4.7333, -4.3399, -4.5797, -4.3771, -5.0714, -4.3336, -4.7772, -4.3138,\n",
      "         -4.3038]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : totter'd\n",
      "target index is: [20] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7315, -4.6525, -4.9498, -4.8757, -4.3864, -4.7970, -4.6683, -4.0579,\n",
      "         -4.8783, -4.5999, -4.8369, -4.2645, -4.3195, -4.6845, -4.9872, -4.6098,\n",
      "         -4.6969, -4.4342, -4.3080, -4.7205, -4.5975, -4.3713, -4.7073, -4.7984,\n",
      "         -4.0906, -5.1623, -4.4966, -4.7616, -4.1619, -4.3358, -4.4995, -4.7837,\n",
      "         -4.8187, -4.8782, -4.8733, -5.1885, -4.6432, -4.5086, -4.7801, -4.5478,\n",
      "         -4.7364, -4.7465, -4.6843, -4.6316, -4.6210, -4.4222, -4.8387, -4.8136,\n",
      "         -4.8074, -4.7068, -4.3745, -4.4913, -4.8356, -4.5310, -4.5472, -4.4226,\n",
      "         -4.3927, -4.2537, -4.2624, -4.4115, -4.7728, -4.4702, -4.5185, -3.9154,\n",
      "         -4.5419, -4.6385, -4.4395, -4.6745, -4.6303, -4.0344, -4.4003, -4.2760,\n",
      "         -5.0588, -4.8451, -5.0062, -5.0218, -4.3002, -4.3225, -4.4332, -4.9166,\n",
      "         -4.6904, -4.5803, -4.9732, -4.6138, -4.8394, -4.5585, -4.6309, -4.6881,\n",
      "         -4.8147, -4.4471, -4.5489, -4.6968, -4.8271, -4.1105, -4.6718, -4.6997,\n",
      "         -4.2970]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : weed\n",
      "target index is: [29] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6197, -4.7209, -4.5413, -4.6694, -4.1438, -4.7564, -4.5524, -4.3287,\n",
      "         -4.6818, -4.8068, -4.6512, -4.6489, -4.6816, -4.7955, -5.0452, -4.8077,\n",
      "         -4.4195, -4.4237, -4.4444, -4.5688, -4.5566, -4.6582, -4.7183, -4.4690,\n",
      "         -4.2120, -4.8318, -4.5491, -4.7168, -4.5518, -4.4721, -4.2957, -4.5945,\n",
      "         -4.5530, -4.7344, -4.6351, -4.7235, -4.3871, -4.5735, -4.3829, -4.6064,\n",
      "         -4.6251, -4.6810, -4.8007, -4.6090, -4.5229, -4.2669, -4.2411, -4.5290,\n",
      "         -4.6636, -4.4811, -4.7309, -4.3193, -4.8771, -4.3800, -4.4513, -4.5239,\n",
      "         -4.4456, -4.3119, -4.3130, -4.6604, -5.0194, -4.5189, -4.5228, -4.2096,\n",
      "         -4.8438, -4.6741, -4.6540, -4.6066, -4.5050, -4.4770, -4.5505, -4.6362,\n",
      "         -4.8292, -4.9240, -4.8322, -4.7846, -4.6169, -4.2402, -4.9183, -4.8859,\n",
      "         -4.7060, -4.5322, -4.6401, -4.5689, -4.7182, -4.5254, -4.4341, -4.7847,\n",
      "         -4.9815, -4.1597, -4.7044, -4.4886, -4.6670, -4.4849, -4.5374, -4.7811,\n",
      "         -4.5968]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : of\n",
      "target index is: [57] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5385, -4.4030, -4.3624, -4.6222, -3.9148, -4.7296, -5.0104, -4.4770,\n",
      "         -4.7176, -4.6075, -4.6320, -4.2406, -4.8632, -4.8189, -4.6322, -4.5572,\n",
      "         -4.5665, -4.9366, -4.4583, -4.7891, -4.4199, -4.1614, -4.5818, -4.4647,\n",
      "         -4.3950, -4.7346, -4.4467, -4.7060, -4.3825, -4.6126, -4.4566, -5.2683,\n",
      "         -4.7179, -4.2895, -4.6572, -5.0031, -4.5851, -4.8876, -4.5885, -4.8831,\n",
      "         -4.7110, -4.7919, -4.8219, -4.6652, -4.4872, -4.4182, -4.4614, -4.9438,\n",
      "         -4.8182, -4.4454, -4.6349, -4.4664, -4.8454, -4.3015, -4.9801, -4.4976,\n",
      "         -4.6439, -4.4297, -4.4868, -4.4399, -4.7445, -4.8029, -4.7096, -3.7944,\n",
      "         -4.7732, -4.6311, -5.0300, -4.6365, -4.6183, -4.7486, -4.3088, -4.5251,\n",
      "         -4.9771, -4.6922, -4.6419, -4.7678, -4.7418, -4.4370, -4.8175, -4.8999,\n",
      "         -4.6496, -4.0710, -4.8240, -4.7582, -4.4337, -4.5741, -4.4038, -4.5714,\n",
      "         -4.9131, -4.1747, -4.6191, -4.7396, -4.5553, -4.4508, -4.0686, -4.8024,\n",
      "         -4.4365]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : small\n",
      "target index is: [38] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3529, -4.2928, -4.6622, -4.8420, -4.2955, -4.7424, -4.5806, -4.5213,\n",
      "         -4.6844, -4.9204, -4.8713, -4.6384, -4.7763, -4.4907, -4.3002, -4.7520,\n",
      "         -4.8120, -5.0131, -4.6006, -4.2593, -4.8068, -4.5536, -4.6918, -4.4215,\n",
      "         -4.7271, -5.0895, -4.7282, -4.4191, -4.1037, -4.5910, -4.4670, -4.9949,\n",
      "         -4.7736, -4.6514, -4.4401, -4.8594, -4.7629, -4.8414, -4.8996, -4.3960,\n",
      "         -4.6229, -4.5772, -4.8966, -4.1332, -4.8812, -4.1474, -4.9889, -4.4092,\n",
      "         -4.4388, -4.8525, -4.9113, -4.6898, -4.7794, -4.4372, -4.6215, -4.6435,\n",
      "         -4.2579, -4.2617, -4.6328, -4.6495, -4.6005, -4.7090, -4.8163, -4.2700,\n",
      "         -4.9616, -4.4781, -5.1512, -4.2257, -4.6851, -4.7688, -4.2069, -4.6518,\n",
      "         -4.7799, -4.6784, -4.8338, -4.6977, -5.1274, -4.3295, -4.6847, -4.2017,\n",
      "         -4.6926, -4.4156, -4.8012, -4.9574, -4.6314, -4.0969, -4.3179, -4.4207,\n",
      "         -5.0243, -4.2060, -4.5608, -4.2574, -4.6593, -4.5914, -4.2406, -4.3815,\n",
      "         -4.3298]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : worth\n",
      "target index is: [83] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7098, -4.6290, -4.7515, -5.0401, -4.2369, -4.8363, -4.3565, -4.5021,\n",
      "         -4.6980, -4.7080, -5.0726, -4.8089, -4.9035, -4.8139, -4.4495, -4.5362,\n",
      "         -4.5243, -4.8468, -4.5978, -4.3911, -4.7840, -3.9301, -5.2064, -4.6882,\n",
      "         -4.1758, -5.1112, -4.2271, -4.0582, -4.5702, -4.5719, -4.9985, -4.9196,\n",
      "         -5.0600, -4.9003, -4.5403, -4.2991, -4.8091, -4.9112, -5.1889, -4.6611,\n",
      "         -4.9577, -5.1872, -4.8007, -4.6293, -4.7687, -4.4886, -4.7919, -4.9997,\n",
      "         -4.2723, -4.9167, -3.9224, -4.7665, -4.2120, -3.8751, -4.9847, -4.0513,\n",
      "         -4.8275, -4.4197, -4.5098, -4.5335, -4.7887, -4.7985, -4.5456, -4.1500,\n",
      "         -4.8470, -4.1914, -5.0688, -4.5339, -4.8429, -4.6029, -4.1970, -4.7172,\n",
      "         -4.8828, -4.2888, -4.4702, -5.0522, -4.4751, -4.4199, -4.9302, -4.7209,\n",
      "         -4.2509, -4.3375, -4.7968, -4.4745, -4.2713, -4.3102, -5.0522, -5.2472,\n",
      "         -4.5125, -4.2376, -4.5658, -4.7079, -4.5218, -4.3249, -4.3943, -4.8163,\n",
      "         -4.3133]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : held:\n",
      "target index is: [19] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4072, -4.3804, -5.0632, -5.0739, -4.0119, -4.9026, -4.3726, -4.5512,\n",
      "         -4.6500, -4.1551, -5.0415, -4.6117, -4.8708, -4.7474, -4.4209, -4.6593,\n",
      "         -4.6059, -4.6883, -4.9816, -4.4914, -4.3761, -4.3758, -5.0349, -4.7221,\n",
      "         -4.8212, -5.2072, -4.4379, -4.4307, -4.6060, -4.6567, -4.7503, -4.6366,\n",
      "         -4.7468, -5.1907, -4.5918, -4.6047, -4.4923, -4.6421, -4.9636, -4.2456,\n",
      "         -4.5840, -4.5981, -4.4783, -4.2470, -4.2776, -4.5732, -4.6748, -4.5445,\n",
      "         -4.2014, -5.3434, -4.3529, -4.9804, -4.7359, -4.3436, -4.7372, -4.5777,\n",
      "         -4.5893, -4.6394, -4.5139, -4.5788, -4.6486, -4.3849, -4.4226, -4.4525,\n",
      "         -4.4471, -4.7028, -4.6977, -4.2922, -4.5710, -4.3488, -4.5691, -4.9435,\n",
      "         -4.8505, -4.5748, -4.8709, -5.3314, -4.2040, -4.7680, -4.6870, -4.7460,\n",
      "         -4.6563, -4.2263, -4.7977, -4.5408, -5.3096, -3.9225, -5.0868, -4.5480,\n",
      "         -4.7138, -4.0104, -4.5774, -4.8274, -4.8072, -4.1331, -4.6197, -4.3024,\n",
      "         -4.2599]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Then\n",
      "target index is: [65] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3973, -4.4955, -4.8957, -4.7484, -3.9484, -4.8694, -4.6602, -4.7331,\n",
      "         -4.8099, -4.6328, -4.7190, -4.6100, -4.7775, -4.6853, -4.7634, -4.5918,\n",
      "         -4.5338, -4.6832, -5.1204, -4.7371, -4.5883, -4.2248, -4.9576, -4.3271,\n",
      "         -4.4204, -4.7341, -4.7827, -4.2781, -4.3165, -4.3930, -4.6694, -4.5541,\n",
      "         -4.8424, -4.8738, -4.5349, -4.2753, -4.6676, -5.0164, -4.9981, -4.4307,\n",
      "         -4.8889, -4.4069, -4.5189, -4.3561, -4.3127, -4.3451, -4.5118, -4.7166,\n",
      "         -4.3266, -4.9911, -4.6769, -4.5264, -4.9785, -4.0129, -4.5709, -4.3929,\n",
      "         -4.2769, -4.4567, -4.7102, -4.3337, -4.7620, -4.6147, -4.4858, -4.3853,\n",
      "         -4.6714, -4.5811, -4.7572, -4.2715, -4.6020, -4.4553, -4.4019, -4.7007,\n",
      "         -4.8173, -4.7775, -4.9264, -4.9846, -4.4663, -4.5136, -5.1041, -5.0020,\n",
      "         -4.4920, -4.2093, -4.4212, -4.5114, -4.8009, -4.0642, -4.8129, -5.0176,\n",
      "         -4.8515, -4.0983, -4.7264, -4.9174, -4.5416, -4.4072, -4.5010, -4.8741,\n",
      "         -4.7014]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : being\n",
      "target index is: [32] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3923, -4.2575, -4.6154, -5.0662, -4.1658, -4.3859, -4.5204, -4.1110,\n",
      "         -4.9749, -4.4455, -4.8308, -4.3400, -4.6615, -4.4237, -5.0166, -4.4050,\n",
      "         -4.4388, -4.4703, -4.6844, -4.0549, -4.8315, -4.7587, -4.5313, -4.5836,\n",
      "         -4.9013, -4.5756, -4.6310, -4.5286, -4.4120, -4.7730, -4.2682, -4.8264,\n",
      "         -4.8995, -4.5612, -4.5206, -4.7939, -4.4943, -4.9779, -4.9240, -4.8148,\n",
      "         -4.6925, -4.7244, -4.5181, -4.1816, -4.4660, -4.1261, -4.7205, -4.7266,\n",
      "         -4.7681, -4.6749, -4.6992, -4.3700, -4.5375, -4.5210, -4.9882, -4.6758,\n",
      "         -4.5608, -4.6330, -4.5081, -4.5605, -4.9010, -4.8429, -4.7686, -4.2166,\n",
      "         -4.5631, -4.5222, -4.9929, -4.4861, -4.6660, -4.8627, -4.5482, -4.6491,\n",
      "         -4.6838, -5.0990, -4.3779, -4.5395, -4.6462, -4.4009, -4.6201, -4.6810,\n",
      "         -4.6712, -4.4136, -4.4480, -4.9024, -4.8062, -4.4609, -4.3579, -4.2045,\n",
      "         -5.0903, -4.3685, -4.6781, -4.4039, -4.9984, -4.4960, -4.4245, -4.3989,\n",
      "         -4.6682]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : asked,\n",
      "target index is: [23] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2104, -4.6096, -4.5101, -4.6362, -4.1302, -4.8245, -4.7038, -4.3779,\n",
      "         -4.6589, -4.5896, -4.6583, -4.3339, -4.6549, -4.7107, -4.6707, -4.7816,\n",
      "         -4.7263, -5.0622, -4.4362, -4.8077, -4.5292, -4.4783, -4.7360, -4.5909,\n",
      "         -4.4149, -4.8472, -4.5359, -4.4947, -4.3134, -4.5492, -4.5917, -4.8102,\n",
      "         -4.6617, -4.5637, -4.7137, -5.0447, -4.5719, -4.4438, -4.5196, -4.6498,\n",
      "         -4.7476, -4.4009, -4.6569, -4.4854, -4.4014, -4.1916, -4.6455, -4.8651,\n",
      "         -4.7861, -4.5076, -4.5890, -4.3761, -4.8973, -4.4310, -4.8072, -4.3737,\n",
      "         -4.5799, -4.2933, -4.3653, -4.6340, -4.7087, -4.5106, -4.6165, -3.9487,\n",
      "         -4.7807, -4.6135, -4.9445, -4.6645, -4.8630, -4.6379, -4.5070, -4.5849,\n",
      "         -4.9159, -4.5136, -4.6441, -4.9531, -4.7645, -4.2790, -4.6738, -4.9399,\n",
      "         -4.5954, -4.1822, -4.9092, -4.6208, -4.4085, -4.5288, -4.6270, -4.5411,\n",
      "         -5.0166, -4.4452, -4.5370, -4.5062, -4.6475, -4.6195, -4.2656, -4.6969,\n",
      "         -4.4317]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : where\n",
      "target index is: [51] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3780, -4.2794, -4.6744, -4.9590, -4.2506, -4.9354, -4.7634, -4.6406,\n",
      "         -4.8759, -4.6438, -4.9538, -4.5902, -4.8334, -4.6372, -4.6360, -4.9477,\n",
      "         -4.6737, -4.5883, -4.9182, -4.5237, -4.6483, -4.5540, -4.8767, -4.5118,\n",
      "         -4.5901, -4.7475, -4.3619, -4.3853, -4.2922, -4.6349, -4.3267, -4.9247,\n",
      "         -4.7346, -4.6483, -4.5125, -4.9753, -4.4630, -4.6672, -4.7830, -4.5522,\n",
      "         -4.6100, -4.6989, -4.6321, -4.5637, -4.5643, -4.1245, -4.7865, -4.5608,\n",
      "         -4.7469, -4.7870, -4.2378, -4.8978, -4.7278, -4.4926, -4.4813, -4.6916,\n",
      "         -4.5349, -4.4140, -4.5659, -4.5398, -4.5471, -4.4478, -4.5106, -4.3517,\n",
      "         -4.4780, -4.7977, -5.0375, -4.2907, -4.3950, -4.3289, -4.6682, -4.4761,\n",
      "         -5.0712, -4.9954, -4.8405, -4.9423, -4.6261, -4.2086, -4.4810, -4.5047,\n",
      "         -4.4365, -4.3817, -4.7462, -4.8974, -4.8358, -4.2540, -4.3258, -4.4774,\n",
      "         -4.7691, -4.3962, -4.2283, -4.6983, -4.6966, -4.3507, -4.2545, -4.5820,\n",
      "         -4.2099]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : all\n",
      "target index is: [52] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4769, -4.2699, -4.6805, -4.7891, -4.4145, -4.8229, -4.4707, -4.4518,\n",
      "         -4.5404, -4.8725, -5.0080, -4.7117, -4.4970, -4.6055, -4.5940, -4.6361,\n",
      "         -4.6347, -4.7305, -4.5900, -4.2250, -4.8121, -4.7511, -4.7499, -4.4894,\n",
      "         -4.3866, -4.8619, -4.4813, -4.4922, -4.1949, -4.8189, -4.4797, -4.7708,\n",
      "         -4.8637, -4.8190, -4.4851, -4.5395, -4.6049, -4.4845, -4.6535, -4.6051,\n",
      "         -4.7210, -4.6000, -4.7405, -4.4823, -4.7992, -4.1779, -4.8186, -4.6356,\n",
      "         -4.5657, -4.8165, -4.4288, -4.4478, -4.6162, -4.2980, -4.7091, -4.5486,\n",
      "         -4.3738, -4.3916, -4.5839, -4.7452, -4.7720, -4.7158, -4.5620, -4.5454,\n",
      "         -4.7985, -4.5261, -5.0849, -4.3598, -4.6385, -4.6569, -4.4326, -4.4785,\n",
      "         -4.5510, -4.9007, -4.6267, -4.6514, -4.6042, -4.2199, -4.5885, -4.6633,\n",
      "         -4.5249, -4.5808, -4.6487, -4.8372, -4.6415, -4.3352, -4.4714, -4.5808,\n",
      "         -4.7096, -4.3075, -4.6793, -4.6396, -4.6525, -4.5139, -4.3298, -4.4495,\n",
      "         -4.2061]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4378, -4.3531, -4.9430, -4.7854, -4.2685, -4.7833, -4.8826, -4.3851,\n",
      "         -5.0858, -4.2654, -5.0057, -4.3682, -4.5187, -4.6712, -4.6534, -4.7976,\n",
      "         -4.5413, -4.4458, -4.4505, -4.4975, -4.6413, -4.3432, -4.5784, -4.7845,\n",
      "         -4.4450, -5.0762, -4.3404, -4.5216, -4.4823, -4.5017, -4.7164, -4.6636,\n",
      "         -4.8324, -4.6303, -4.8887, -5.0747, -4.6745, -4.6350, -4.8901, -4.6405,\n",
      "         -4.6346, -4.7541, -4.6707, -4.5909, -4.5177, -4.1090, -4.8060, -4.7044,\n",
      "         -4.8716, -4.6655, -4.7512, -4.7665, -4.5828, -4.2628, -4.4596, -4.7710,\n",
      "         -4.3115, -4.3979, -4.4498, -4.5503, -4.7054, -4.5682, -4.2798, -4.2719,\n",
      "         -4.2170, -4.7476, -4.7111, -4.2214, -4.6059, -4.3695, -4.4222, -4.5694,\n",
      "         -4.8002, -4.6139, -4.7755, -4.7419, -4.2246, -4.4439, -4.4347, -4.7041,\n",
      "         -4.5088, -4.5518, -4.7964, -5.0390, -4.8684, -4.4561, -4.7434, -4.6176,\n",
      "         -4.8945, -4.4654, -4.5159, -4.7779, -4.8206, -4.3174, -4.0496, -4.8318,\n",
      "         -4.3627]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty\n",
      "target index is: [0] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4072, -4.6633, -4.8113, -4.9168, -4.2155, -4.6805, -4.4406, -4.2160,\n",
      "         -5.1059, -4.4862, -4.8094, -4.4029, -4.3098, -4.6186, -4.8265, -5.0804,\n",
      "         -4.6728, -4.5617, -4.6687, -4.4898, -4.7694, -4.7230, -4.9184, -4.6327,\n",
      "         -4.4837, -5.1857, -4.3354, -4.4288, -4.2217, -4.6956, -4.5195, -4.3286,\n",
      "         -4.7097, -4.8957, -4.6705, -5.1450, -4.3172, -4.5415, -4.3773, -4.3879,\n",
      "         -4.5401, -4.3673, -4.6226, -4.2886, -4.5363, -4.0543, -4.8843, -4.5854,\n",
      "         -4.8763, -4.7966, -4.4982, -4.6782, -4.8376, -4.5126, -4.5546, -4.5625,\n",
      "         -4.4540, -4.4180, -4.4938, -4.4925, -4.7059, -4.4228, -4.3843, -4.3807,\n",
      "         -4.2990, -5.0114, -4.8233, -4.4065, -4.7802, -4.0297, -4.5617, -4.4517,\n",
      "         -5.0924, -4.9279, -4.7645, -4.7438, -4.5959, -3.9029, -4.4272, -4.7876,\n",
      "         -4.7155, -4.7677, -4.8383, -4.9254, -5.1283, -4.3122, -4.5504, -4.3792,\n",
      "         -5.3229, -4.8365, -4.7722, -4.5553, -4.8884, -4.3464, -4.5092, -4.7940,\n",
      "         -4.2506]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : lies,\n",
      "target index is: [59] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2895, -4.6461, -4.6617, -4.6642, -4.1868, -4.8780, -4.4615, -4.2449,\n",
      "         -4.6602, -5.1536, -4.7750, -4.4111, -4.5363, -4.7894, -4.7765, -4.6491,\n",
      "         -4.4567, -4.9520, -4.8428, -4.9103, -4.4333, -4.5044, -4.7169, -4.5007,\n",
      "         -4.1554, -4.8702, -4.4998, -4.4069, -4.3408, -4.5917, -4.6130, -4.6964,\n",
      "         -4.5328, -5.0995, -4.4904, -4.6429, -4.8921, -4.3131, -4.6771, -4.3706,\n",
      "         -5.0379, -4.2365, -4.7488, -4.4119, -4.4820, -4.1629, -4.4900, -4.5904,\n",
      "         -4.5542, -4.5438, -4.5953, -4.1677, -5.0379, -4.3623, -4.7159, -4.3102,\n",
      "         -4.5751, -4.4949, -4.7457, -4.7784, -4.6676, -4.2814, -4.5162, -4.3420,\n",
      "         -4.6834, -4.6590, -4.7044, -4.3658, -4.6717, -4.4315, -4.4198, -4.6417,\n",
      "         -4.4759, -4.9525, -4.8751, -4.9237, -4.6401, -4.1418, -4.8349, -5.0622,\n",
      "         -4.4014, -4.7154, -4.6834, -4.7919, -4.4214, -4.4571, -4.4584, -5.0388,\n",
      "         -4.9905, -4.5138, -4.7326, -4.6919, -4.4270, -4.6165, -4.7031, -4.5695,\n",
      "         -4.4349]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Where\n",
      "target index is: [18] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5616, -4.4139, -4.3716, -4.5900, -4.2175, -4.9762, -4.7785, -4.4942,\n",
      "         -4.6694, -4.7645, -4.6965, -4.4864, -4.7131, -4.7800, -4.5641, -4.5523,\n",
      "         -4.8555, -4.5974, -4.5579, -4.6162, -4.3745, -4.3037, -4.7788, -4.6354,\n",
      "         -4.4008, -4.7800, -4.6668, -4.4604, -4.3405, -4.5519, -4.7059, -4.6552,\n",
      "         -4.8458, -4.5631, -4.6561, -4.8972, -4.5674, -4.8916, -4.5041, -4.5094,\n",
      "         -4.6626, -4.6579, -4.8568, -4.5253, -4.6522, -4.3967, -4.5582, -4.6720,\n",
      "         -4.4809, -4.8323, -4.5057, -4.8229, -4.5982, -4.6080, -4.7214, -4.7471,\n",
      "         -4.2695, -4.4524, -4.3993, -4.4933, -4.8242, -4.8030, -4.4980, -4.1832,\n",
      "         -4.8974, -4.4318, -4.9215, -4.3586, -4.5779, -4.6954, -4.2953, -4.4421,\n",
      "         -4.8483, -4.9403, -4.8186, -4.7795, -4.3067, -4.3044, -4.8753, -4.5485,\n",
      "         -4.4783, -4.2806, -4.6241, -4.7484, -4.6221, -4.4518, -4.3893, -4.6906,\n",
      "         -4.7779, -4.2369, -4.5599, -4.7078, -4.5646, -4.4167, -4.2595, -4.5032,\n",
      "         -4.5381]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : all\n",
      "target index is: [52] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2960, -4.2338, -4.6178, -4.9198, -4.3150, -4.6003, -4.5772, -4.4533,\n",
      "         -4.7900, -4.9596, -4.8532, -4.4935, -4.7492, -4.6716, -4.4988, -4.7304,\n",
      "         -4.7413, -5.0321, -4.3971, -4.1933, -4.7669, -4.3979, -4.7330, -4.4840,\n",
      "         -4.6093, -4.7331, -4.3945, -4.4741, -4.2129, -4.9724, -4.4518, -4.9358,\n",
      "         -4.8430, -4.6377, -4.3052, -4.7054, -4.5672, -4.7915, -4.7935, -4.7088,\n",
      "         -4.6511, -4.6261, -4.8549, -4.5694, -4.9043, -4.2302, -5.0048, -4.6344,\n",
      "         -4.6162, -4.8648, -4.4203, -4.6376, -4.4253, -4.4938, -4.9991, -4.6061,\n",
      "         -4.6129, -4.4721, -4.6031, -4.7809, -4.5522, -4.6132, -4.6833, -4.3753,\n",
      "         -4.9653, -4.4407, -5.1318, -4.5863, -4.7594, -4.6885, -4.3193, -4.5211,\n",
      "         -4.5819, -4.8428, -4.3842, -4.6153, -4.7155, -4.1770, -4.5244, -4.4048,\n",
      "         -4.5082, -4.4370, -4.8193, -4.8935, -4.4304, -4.4460, -4.3467, -4.5454,\n",
      "         -4.7271, -4.2560, -4.5194, -4.4105, -4.7310, -4.5222, -4.1314, -4.4128,\n",
      "         -4.3426]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : the\n",
      "target index is: [82] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1758, -4.3989, -4.5555, -4.8777, -4.1763, -4.6923, -4.6770, -4.3338,\n",
      "         -4.6268, -4.7003, -4.8801, -4.7357, -4.6380, -4.8048, -4.7031, -4.6486,\n",
      "         -4.4267, -4.5094, -4.4358, -4.6555, -4.8792, -4.4929, -4.8460, -4.6012,\n",
      "         -4.2224, -4.4985, -4.5416, -4.4792, -4.4323, -4.4881, -4.5571, -4.7166,\n",
      "         -4.5614, -4.6385, -4.8740, -4.7713, -4.8362, -4.5466, -4.8668, -4.7990,\n",
      "         -4.6944, -4.5477, -4.7668, -4.3487, -4.6028, -4.1650, -4.6133, -4.5213,\n",
      "         -4.5615, -4.4591, -4.5017, -4.5922, -4.9652, -4.4196, -4.5145, -4.6642,\n",
      "         -4.4267, -4.5342, -4.4100, -4.5608, -5.1420, -4.7341, -4.3831, -4.0262,\n",
      "         -4.8581, -4.7280, -4.7337, -4.4874, -4.6645, -4.7161, -4.7055, -4.5999,\n",
      "         -4.4945, -4.5678, -4.5154, -4.5341, -4.4197, -4.4777, -4.7165, -4.7950,\n",
      "         -4.2618, -4.3350, -4.8683, -4.7747, -4.5754, -4.5744, -4.7611, -4.7958,\n",
      "         -4.9134, -4.3538, -4.6230, -4.5212, -4.6570, -4.5373, -4.3362, -4.6015,\n",
      "         -4.5966]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : treasure\n",
      "target index is: [31] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3905, -4.3523, -4.7276, -4.9654, -4.1137, -4.7604, -4.6789, -4.5707,\n",
      "         -4.7629, -4.5614, -4.6195, -4.2707, -4.8257, -4.8183, -4.8072, -4.8125,\n",
      "         -4.4559, -4.7422, -4.6819, -4.5475, -4.5226, -4.4566, -4.9165, -4.6125,\n",
      "         -4.7565, -4.9741, -4.2846, -4.4378, -4.2876, -4.8912, -4.2482, -5.0073,\n",
      "         -4.6618, -4.5610, -4.4975, -5.0334, -4.3964, -4.6883, -4.7296, -4.7694,\n",
      "         -4.5745, -4.7464, -4.5344, -4.3458, -4.5609, -4.2554, -4.6524, -4.6879,\n",
      "         -4.7467, -4.8966, -4.2900, -4.7670, -4.7672, -4.8195, -4.6790, -4.3849,\n",
      "         -4.5567, -4.2916, -4.4822, -4.6158, -4.5089, -4.3562, -4.7836, -4.1932,\n",
      "         -4.4718, -4.6305, -5.0901, -4.6708, -4.2599, -4.3152, -4.7209, -4.6965,\n",
      "         -4.8749, -4.8758, -4.7525, -5.0166, -4.7190, -4.2678, -4.6469, -4.5558,\n",
      "         -4.6621, -4.1768, -4.8131, -4.9830, -4.6612, -4.4478, -4.3143, -4.2807,\n",
      "         -4.7401, -4.5200, -4.3334, -4.4517, -4.8559, -4.4765, -4.4963, -4.4609,\n",
      "         -4.2779]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : of\n",
      "target index is: [57] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4945, -4.1590, -4.3058, -4.5637, -4.1552, -4.8566, -4.9487, -4.4272,\n",
      "         -4.8179, -4.7644, -5.0769, -4.5438, -4.5877, -4.5759, -4.7902, -4.7534,\n",
      "         -4.6647, -4.5666, -4.5530, -4.5525, -4.5895, -4.3479, -4.7250, -4.3789,\n",
      "         -4.0818, -4.6786, -4.4849, -4.5532, -4.2712, -4.4755, -4.6660, -5.0552,\n",
      "         -5.0319, -4.5444, -4.8657, -4.8921, -4.7952, -4.7392, -4.5544, -4.7092,\n",
      "         -4.8353, -4.4803, -4.6468, -4.4781, -4.5555, -4.3094, -4.7536, -4.9311,\n",
      "         -4.6062, -4.5201, -4.4261, -4.4109, -4.9059, -4.2177, -4.6509, -4.6459,\n",
      "         -4.4406, -4.4261, -4.4555, -4.6962, -4.9009, -4.7193, -4.3702, -4.1182,\n",
      "         -4.7032, -4.6912, -5.0017, -4.5108, -4.7701, -4.6941, -4.5560, -4.4343,\n",
      "         -4.6938, -4.8644, -4.6618, -4.7862, -4.6116, -4.1600, -4.7918, -4.9291,\n",
      "         -4.2730, -4.3491, -4.7582, -4.8135, -4.6032, -4.4820, -4.5874, -4.6905,\n",
      "         -4.7670, -4.2057, -4.6850, -4.8063, -4.5991, -4.3621, -4.2944, -4.6366,\n",
      "         -4.3049]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1888, -4.2768, -4.8963, -5.0278, -4.1825, -4.7485, -4.7653, -4.2496,\n",
      "         -5.2540, -4.3735, -5.1416, -4.1384, -4.5813, -4.3481, -4.7122, -4.9401,\n",
      "         -4.5569, -4.5831, -4.7392, -4.1905, -4.7859, -4.7618, -4.5411, -4.4848,\n",
      "         -4.7336, -4.8551, -4.3746, -4.3345, -4.4154, -4.6727, -4.6734, -4.7485,\n",
      "         -4.9999, -4.7638, -4.8032, -5.2163, -4.5764, -4.5750, -4.9114, -4.4355,\n",
      "         -4.8586, -4.6412, -4.5014, -4.3796, -4.6502, -3.9922, -4.8384, -4.6910,\n",
      "         -4.8385, -4.7270, -4.6120, -4.7386, -4.4550, -4.3008, -4.7934, -4.8021,\n",
      "         -4.4615, -4.4974, -4.6734, -4.6836, -4.6154, -4.6490, -4.2877, -4.4736,\n",
      "         -4.3206, -4.7804, -5.1442, -4.3057, -4.5916, -4.5882, -4.2548, -4.6555,\n",
      "         -4.6822, -5.0569, -4.5404, -4.6924, -4.3154, -4.1914, -4.3892, -4.5963,\n",
      "         -4.5544, -4.5637, -4.6657, -5.0143, -5.1427, -4.2474, -4.6086, -4.3025,\n",
      "         -5.0772, -4.5243, -4.4425, -4.7739, -4.8694, -4.4762, -4.1911, -4.4574,\n",
      "         -4.3389]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : lusty\n",
      "target index is: [30] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2213, -4.6009, -4.4328, -4.9542, -4.2037, -4.6974, -4.5772, -4.1671,\n",
      "         -4.6886, -4.9670, -4.9124, -4.4826, -4.4282, -4.6439, -4.9015, -4.8262,\n",
      "         -4.4248, -4.7334, -4.4195, -4.8013, -4.7116, -5.0414, -4.7472, -4.6715,\n",
      "         -4.4098, -4.7116, -4.5083, -4.4762, -4.1864, -4.5237, -4.2025, -4.6919,\n",
      "         -4.5842, -4.8683, -4.7465, -4.8801, -4.3879, -4.4494, -4.4804, -4.5161,\n",
      "         -4.8201, -4.2721, -4.7920, -4.3009, -4.6657, -4.1443, -4.5122, -4.5792,\n",
      "         -4.7402, -4.5624, -4.6245, -4.3072, -5.0759, -4.5063, -4.8540, -4.7124,\n",
      "         -4.3605, -4.3710, -4.5064, -4.6618, -4.8355, -4.3628, -4.6010, -4.1707,\n",
      "         -4.6898, -4.7732, -4.8449, -4.8064, -4.8097, -4.4095, -4.6311, -4.3924,\n",
      "         -5.0264, -4.9670, -4.7017, -4.6781, -4.9275, -3.8138, -4.6011, -5.0220,\n",
      "         -4.5204, -4.5581, -4.6478, -4.9160, -4.8287, -4.4740, -4.3962, -4.4268,\n",
      "         -5.2410, -4.3864, -4.8191, -4.5002, -4.5498, -4.5775, -4.3912, -4.7626,\n",
      "         -4.3975]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : days;\n",
      "target index is: [48] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5510, -4.7653, -4.3972, -4.4487, -3.7669, -4.7597, -4.5723, -4.4308,\n",
      "         -4.5036, -4.9483, -4.4784, -4.6026, -5.0992, -4.9847, -4.6506, -4.5812,\n",
      "         -4.9401, -5.0704, -4.6084, -4.7563, -4.6214, -4.0495, -4.7557, -4.5180,\n",
      "         -4.4235, -4.8278, -4.5427, -4.5002, -4.5795, -4.5300, -4.5929, -4.6506,\n",
      "         -4.7026, -4.7150, -4.4122, -4.9498, -4.7385, -4.8616, -4.5706, -4.5628,\n",
      "         -4.8106, -4.6527, -5.0631, -4.4430, -4.8686, -4.6961, -4.3603, -4.4289,\n",
      "         -4.2816, -4.3369, -4.4648, -4.6649, -4.7872, -4.4747, -4.7004, -3.8946,\n",
      "         -4.5763, -4.1794, -4.4855, -4.5563, -4.6526, -4.8280, -4.9663, -3.9629,\n",
      "         -5.0343, -4.3716, -4.9373, -4.5144, -4.7389, -5.0461, -4.2021, -4.4981,\n",
      "         -4.8509, -4.9872, -4.4661, -4.9969, -4.7655, -4.5746, -4.7373, -4.6352,\n",
      "         -4.7719, -4.0281, -5.0224, -4.6480, -4.4387, -4.6656, -4.5400, -5.0075,\n",
      "         -4.8478, -4.2493, -4.6873, -4.3825, -4.4883, -4.5375, -4.3943, -4.4544,\n",
      "         -4.5791]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : To\n",
      "target index is: [26] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2668, -4.6358, -5.0050, -4.9512, -4.0493, -4.7837, -4.4874, -4.6904,\n",
      "         -4.5840, -4.6269, -4.9424, -4.4641, -4.8640, -4.4998, -4.8502, -4.6439,\n",
      "         -4.1967, -4.7094, -4.8725, -4.6693, -4.3311, -4.1824, -4.9599, -4.6912,\n",
      "         -4.5317, -4.8513, -4.3755, -4.4293, -4.3743, -4.8336, -4.6238, -4.9239,\n",
      "         -4.9423, -4.9658, -4.5347, -4.5506, -4.5835, -4.5427, -5.1319, -4.6666,\n",
      "         -4.7041, -4.6938, -4.3691, -4.7140, -4.1576, -4.4114, -4.5643, -4.8258,\n",
      "         -4.4391, -5.0076, -4.2477, -4.5765, -4.6441, -4.2374, -4.8124, -4.7194,\n",
      "         -4.6639, -4.5956, -4.5066, -4.5858, -4.6297, -4.4171, -4.5616, -4.2708,\n",
      "         -4.3587, -4.8297, -4.9616, -4.4922, -4.5906, -4.2800, -4.3858, -4.5136,\n",
      "         -4.9186, -4.5190, -4.8636, -5.0033, -4.5818, -4.3508, -4.8639, -4.6669,\n",
      "         -4.1585, -4.3414, -4.5574, -4.7066, -4.4288, -4.3799, -4.6427, -4.7254,\n",
      "         -4.8563, -4.5805, -4.4828, -4.9822, -4.5206, -4.2148, -4.3986, -4.7395,\n",
      "         -4.3595]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : say,\n",
      "target index is: [96] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7967, -4.3270, -4.6517, -4.9236, -3.9661, -4.7226, -4.6255, -4.2760,\n",
      "         -4.7587, -4.4937, -4.7625, -4.6129, -4.6806, -4.7791, -4.5873, -4.8441,\n",
      "         -4.8229, -4.3594, -4.7322, -4.2318, -4.6898, -4.5856, -4.7640, -4.7211,\n",
      "         -4.4790, -4.8408, -4.4252, -4.5150, -4.2658, -4.5194, -4.6174, -4.6192,\n",
      "         -4.8548, -4.7520, -4.5027, -4.8487, -4.4917, -4.8401, -4.5429, -4.4623,\n",
      "         -4.5834, -4.6810, -4.6741, -4.4199, -4.6778, -4.4635, -4.3982, -4.4979,\n",
      "         -4.5320, -4.6886, -4.3517, -4.8209, -4.6692, -4.5505, -4.7419, -4.3900,\n",
      "         -4.6495, -4.4179, -4.4849, -4.6694, -4.6862, -4.6551, -4.5602, -4.1997,\n",
      "         -4.5691, -4.4611, -4.5308, -4.6068, -4.5665, -4.8411, -4.6422, -4.4624,\n",
      "         -4.8150, -5.1651, -4.6697, -4.7415, -4.4026, -4.5156, -4.6361, -4.8613,\n",
      "         -4.7998, -4.3832, -4.7050, -4.6710, -4.9444, -4.2135, -4.4015, -4.7226,\n",
      "         -4.6324, -4.1378, -4.7374, -4.5542, -4.6343, -4.2804, -4.6885, -4.4057,\n",
      "         -4.4726]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : within\n",
      "target index is: [34] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2345, -4.3291, -4.7301, -4.8927, -4.4901, -4.8566, -4.5343, -4.0760,\n",
      "         -5.1413, -4.5641, -4.9873, -4.3859, -4.2880, -4.6279, -5.1654, -5.0343,\n",
      "         -4.5476, -4.5789, -4.7299, -4.5867, -4.5312, -4.7183, -4.7793, -4.9251,\n",
      "         -4.4894, -4.9400, -4.1971, -4.3690, -4.1097, -4.5163, -4.5482, -4.6577,\n",
      "         -4.9456, -4.8351, -4.8185, -4.9901, -4.7589, -4.3466, -4.5571, -4.5348,\n",
      "         -4.6889, -4.6497, -4.4078, -4.3294, -4.3363, -4.0027, -4.7013, -4.7669,\n",
      "         -4.6391, -4.7613, -4.6450, -4.1925, -4.6799, -4.5920, -4.5323, -4.6349,\n",
      "         -4.6200, -4.2326, -4.4067, -4.9716, -4.8466, -4.5913, -4.5086, -4.3890,\n",
      "         -4.3564, -4.9421, -4.9668, -4.5231, -4.5246, -4.1584, -4.4219, -4.5744,\n",
      "         -4.7541, -4.7741, -4.6957, -4.8826, -4.5278, -4.0274, -4.5200, -5.0758,\n",
      "         -4.3765, -4.7268, -4.6148, -4.9364, -4.9009, -4.6638, -4.6808, -4.3820,\n",
      "         -5.1275, -4.5985, -4.5355, -4.4243, -4.8108, -4.5398, -4.4268, -4.5382,\n",
      "         -4.3915]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thine\n",
      "target index is: [56] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1457, -4.9143, -4.1332, -4.5816, -4.0871, -4.7104, -4.8723, -4.3166,\n",
      "         -4.7070, -4.8687, -4.7882, -4.8032, -4.7293, -4.7353, -4.7643, -4.6748,\n",
      "         -4.6161, -4.7428, -4.4926, -4.9798, -4.8283, -4.5918, -4.8421, -4.4546,\n",
      "         -4.3340, -4.7490, -4.6729, -4.5048, -4.2897, -4.3676, -4.3489, -4.5538,\n",
      "         -4.6387, -4.5101, -4.6819, -4.8784, -4.3736, -4.8450, -4.6661, -4.6931,\n",
      "         -4.9948, -4.2957, -4.9560, -4.2253, -4.8558, -4.2852, -4.6050, -4.4670,\n",
      "         -4.7930, -4.3163, -4.5537, -4.7076, -5.2013, -4.5616, -4.9024, -4.5898,\n",
      "         -4.1659, -4.3597, -4.4087, -4.2974, -4.7264, -4.5927, -4.6048, -4.0405,\n",
      "         -4.7656, -4.4543, -5.0874, -4.7473, -4.9373, -4.9831, -4.4681, -4.4100,\n",
      "         -5.2547, -5.0309, -4.5700, -4.7901, -4.6973, -4.0851, -4.6851, -4.8280,\n",
      "         -4.5022, -4.0693, -4.6659, -4.8255, -4.6588, -4.6237, -4.3920, -4.5402,\n",
      "         -5.2619, -4.3050, -4.4252, -4.3795, -4.5242, -4.7968, -4.2324, -4.7051,\n",
      "         -4.4562]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : own\n",
      "target index is: [92] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4141, -4.4189, -4.4654, -4.9342, -3.7348, -4.4324, -4.7293, -4.6136,\n",
      "         -4.9157, -5.0457, -4.8521, -4.6192, -5.1266, -4.8305, -4.7854, -4.7023,\n",
      "         -4.5828, -5.1371, -4.4893, -4.3503, -4.4629, -4.0454, -4.7866, -4.5920,\n",
      "         -4.7756, -4.7578, -4.5300, -4.5947, -4.5889, -5.0379, -4.1923, -4.8358,\n",
      "         -4.6463, -4.3811, -4.2018, -4.8741, -4.6305, -5.1307, -4.8588, -4.8343,\n",
      "         -4.4813, -4.7511, -5.0697, -4.2548, -4.9439, -4.3895, -4.6001, -4.4992,\n",
      "         -4.7394, -4.6937, -4.6201, -4.7852, -4.6740, -4.5827, -4.9418, -4.1983,\n",
      "         -4.8136, -4.4477, -4.4790, -4.5667, -4.4713, -4.7240, -5.0386, -3.7971,\n",
      "         -4.7624, -4.4770, -5.1631, -4.5698, -4.6297, -4.9554, -4.4697, -4.4877,\n",
      "         -4.6034, -5.1215, -4.3998, -4.6245, -4.9134, -4.5980, -4.6873, -4.4121,\n",
      "         -4.7557, -4.1921, -4.9313, -4.8759, -4.2222, -4.5499, -4.1533, -4.5933,\n",
      "         -4.8321, -4.3823, -4.4025, -4.3472, -4.7396, -4.6399, -3.9231, -4.6656,\n",
      "         -4.3096]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : deep\n",
      "target index is: [76] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3273, -4.6525, -4.6670, -4.7966, -4.2443, -4.5377, -4.3823, -4.2441,\n",
      "         -4.6919, -4.9171, -5.0581, -4.3719, -4.5079, -4.4780, -4.6745, -4.4175,\n",
      "         -4.0912, -4.7326, -4.6416, -4.6440, -4.5804, -4.5919, -4.6922, -4.6417,\n",
      "         -4.4735, -4.6384, -4.5722, -4.5085, -4.4554, -4.6078, -4.6431, -4.8808,\n",
      "         -4.8990, -4.8724, -4.7029, -4.8128, -4.7923, -4.4466, -5.1250, -4.7336,\n",
      "         -4.7139, -4.5000, -4.8892, -4.3975, -4.5359, -4.3527, -4.6282, -4.7846,\n",
      "         -4.5249, -4.4486, -4.6025, -4.3125, -4.7927, -4.3184, -4.9258, -4.6497,\n",
      "         -4.4109, -4.6442, -4.7433, -4.6064, -4.7938, -4.6340, -4.4373, -3.9737,\n",
      "         -4.6007, -4.4705, -4.9057, -4.4336, -4.5705, -4.6165, -4.4197, -4.6299,\n",
      "         -4.5414, -4.4131, -4.4761, -4.6124, -4.7026, -4.5823, -4.7111, -4.7113,\n",
      "         -4.0722, -4.5182, -4.6860, -4.7456, -4.4698, -4.4242, -4.7876, -4.7248,\n",
      "         -4.9975, -4.4757, -4.5403, -4.8405, -4.6681, -4.6512, -4.2260, -4.5745,\n",
      "         -4.6213]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : sunken\n",
      "target index is: [91] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4490, -4.5320, -4.6944, -4.8488, -4.1838, -4.8705, -4.6094, -4.7458,\n",
      "         -4.7269, -4.4334, -4.9316, -4.4796, -4.8222, -4.6837, -4.6688, -4.8333,\n",
      "         -4.8987, -4.7874, -4.7389, -4.3451, -4.4780, -4.2003, -4.9779, -4.5258,\n",
      "         -4.5682, -4.9031, -4.3767, -4.6524, -4.3324, -4.6457, -4.8833, -4.6418,\n",
      "         -4.6572, -4.7753, -4.7408, -5.0148, -4.7146, -4.6868, -4.7792, -4.2378,\n",
      "         -4.8002, -4.7378, -4.8562, -4.3670, -4.5053, -4.5788, -4.6922, -4.5578,\n",
      "         -4.3201, -4.9285, -3.9497, -5.2274, -4.3992, -4.4531, -4.7588, -4.2490,\n",
      "         -4.7961, -4.4812, -4.4548, -4.4893, -4.5266, -4.4335, -4.6323, -3.9579,\n",
      "         -4.5159, -4.6381, -4.9872, -4.5617, -4.6293, -4.5287, -4.4214, -4.5928,\n",
      "         -4.8358, -4.7982, -4.5564, -5.0354, -4.2149, -4.5819, -4.6098, -4.5328,\n",
      "         -4.6552, -4.1736, -4.9212, -4.5794, -4.7871, -4.2907, -4.7727, -4.8327,\n",
      "         -4.7643, -4.2894, -4.4220, -4.7049, -4.5289, -4.3440, -4.5104, -4.2742,\n",
      "         -4.3721]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : eyes,\n",
      "target index is: [58] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3003, -4.4826, -5.0885, -5.3254, -3.8546, -4.6395, -4.3744, -4.4953,\n",
      "         -4.7264, -4.6059, -5.1217, -4.6391, -4.8232, -4.5902, -4.6171, -4.6783,\n",
      "         -4.5671, -4.7175, -4.9995, -4.5415, -4.7412, -4.3189, -5.0837, -4.6163,\n",
      "         -4.5488, -4.8490, -4.4293, -4.3462, -4.3283, -4.7030, -4.7637, -4.5517,\n",
      "         -4.6584, -5.0638, -4.5905, -4.7162, -4.5096, -4.5490, -5.0933, -4.2922,\n",
      "         -4.5747, -4.3559, -4.7726, -4.4034, -4.6059, -4.2955, -4.8440, -4.4553,\n",
      "         -4.4820, -5.0534, -4.3065, -4.9643, -4.5217, -4.2575, -4.4678, -4.6699,\n",
      "         -4.5518, -4.7782, -4.6279, -4.4201, -4.5727, -4.3305, -4.1101, -4.4417,\n",
      "         -4.2575, -4.7037, -4.7117, -4.5416, -4.6253, -4.2703, -4.5002, -4.5905,\n",
      "         -4.8979, -4.8177, -4.7732, -4.8035, -4.4596, -4.4911, -4.6876, -4.7264,\n",
      "         -4.4360, -4.4975, -4.9245, -4.9050, -4.9052, -4.0316, -4.6286, -4.6429,\n",
      "         -4.6857, -4.4463, -4.8095, -4.6450, -4.8494, -4.1893, -4.6872, -4.6078,\n",
      "         -4.2403]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Were\n",
      "target index is: [37] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2581, -4.4955, -4.7005, -4.6535, -4.2140, -4.7035, -4.4354, -4.2863,\n",
      "         -4.7980, -4.9108, -4.5924, -4.4407, -4.5427, -4.8253, -4.9942, -4.6737,\n",
      "         -4.7068, -4.5572, -4.6747, -4.6973, -4.3313, -4.4439, -4.9121, -5.0215,\n",
      "         -4.3027, -4.9295, -4.5720, -4.4069, -4.1846, -4.4227, -4.6132, -4.6458,\n",
      "         -4.5718, -4.8698, -4.3555, -4.8288, -4.8567, -4.3760, -4.7558, -4.3712,\n",
      "         -4.7103, -4.5270, -4.6855, -4.6641, -4.5671, -4.1983, -4.2560, -4.7894,\n",
      "         -4.4848, -4.8708, -4.7184, -4.3134, -4.8175, -4.4979, -4.4687, -4.4595,\n",
      "         -4.3839, -4.4143, -4.4434, -4.8904, -4.6388, -4.1341, -4.5625, -4.3236,\n",
      "         -4.4977, -4.6911, -4.6055, -4.3572, -4.7036, -4.1599, -4.5233, -4.5654,\n",
      "         -4.6900, -5.1090, -4.9727, -4.9322, -4.6420, -4.2661, -4.7789, -4.8912,\n",
      "         -4.5725, -4.6919, -4.7556, -4.7967, -4.6213, -4.3391, -4.4506, -4.8157,\n",
      "         -4.8899, -4.4103, -4.8008, -4.4896, -4.6260, -4.5306, -4.8380, -4.6828,\n",
      "         -4.6069]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : an\n",
      "target index is: [74] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5160, -4.6874, -4.6753, -4.4988, -4.0946, -4.9858, -4.6668, -4.5351,\n",
      "         -4.7126, -4.4834, -4.9705, -4.7149, -4.8449, -4.9209, -4.7750, -4.8501,\n",
      "         -4.8101, -4.5792, -4.6661, -4.7379, -4.3795, -4.0653, -4.8632, -4.8703,\n",
      "         -4.4284, -5.2006, -4.3528, -4.2008, -4.6258, -4.3605, -4.8328, -4.5457,\n",
      "         -4.8619, -4.9191, -4.3878, -4.7099, -4.7492, -4.5805, -4.7664, -4.4659,\n",
      "         -4.9053, -4.7519, -4.5845, -4.5177, -4.4291, -4.4167, -4.5408, -4.5579,\n",
      "         -4.3444, -4.9978, -4.4192, -4.4505, -4.6641, -4.3814, -4.4379, -4.3377,\n",
      "         -4.4517, -4.3451, -4.2118, -4.8136, -4.5999, -4.5679, -4.5866, -4.3239,\n",
      "         -4.6014, -4.3772, -4.8428, -4.2846, -4.7188, -4.5628, -4.3726, -4.6381,\n",
      "         -4.8402, -4.8359, -5.0234, -5.1115, -4.3494, -4.2454, -4.6001, -4.8731,\n",
      "         -4.3754, -4.5771, -4.4541, -4.8018, -4.5142, -4.2827, -4.6571, -5.0344,\n",
      "         -4.8057, -4.5658, -4.3862, -4.4397, -4.5658, -4.5387, -4.6177, -4.4868,\n",
      "         -4.3564]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : all-eating\n",
      "target index is: [60] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4841, -4.5576, -4.8567, -4.7437, -3.9432, -4.7210, -4.7403, -4.4094,\n",
      "         -4.8251, -4.4210, -5.0320, -4.6662, -4.8956, -4.6106, -4.7104, -4.6964,\n",
      "         -4.4597, -4.4397, -4.8220, -4.5204, -4.7447, -4.5879, -4.9388, -4.8910,\n",
      "         -4.7073, -4.9165, -4.6906, -4.2537, -4.2447, -4.4053, -4.5361, -4.5435,\n",
      "         -4.8565, -4.9149, -4.3605, -4.7438, -4.2942, -4.9357, -4.8174, -4.6068,\n",
      "         -4.7645, -4.5102, -4.4697, -4.5448, -4.3826, -4.4349, -4.5311, -4.6338,\n",
      "         -4.6710, -4.8574, -4.5023, -4.8148, -4.8594, -4.2231, -4.6513, -4.7605,\n",
      "         -4.3088, -4.4268, -4.6411, -4.4753, -4.6711, -4.6294, -4.4645, -4.4509,\n",
      "         -4.4352, -4.4102, -4.5897, -4.2798, -4.7613, -4.5825, -4.3915, -4.2433,\n",
      "         -5.0659, -4.9165, -4.7550, -4.8089, -4.3754, -4.3332, -4.6010, -5.0217,\n",
      "         -4.4241, -4.3134, -4.3119, -4.9316, -4.9775, -4.0429, -4.7273, -4.5551,\n",
      "         -4.8744, -4.2144, -4.5252, -4.6583, -4.7465, -4.4741, -4.6013, -4.5526,\n",
      "         -4.5523]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : shame,\n",
      "target index is: [41] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6950, -4.7247, -4.8674, -4.5045, -4.1594, -4.5997, -4.6790, -4.4380,\n",
      "         -4.5916, -4.6323, -4.5852, -4.4926, -4.8627, -4.7374, -4.7785, -4.4893,\n",
      "         -4.4456, -4.9037, -4.5656, -4.5187, -4.5643, -4.2279, -4.7680, -4.5994,\n",
      "         -4.5465, -4.9656, -4.3770, -4.5119, -4.4904, -4.5971, -4.4167, -5.0055,\n",
      "         -5.1169, -4.7871, -4.5528, -4.7114, -4.5076, -5.0338, -4.8231, -4.7167,\n",
      "         -4.8081, -4.3752, -4.5038, -4.5764, -4.5576, -4.4797, -4.6285, -4.6536,\n",
      "         -4.4156, -4.6512, -4.8558, -4.2250, -4.8443, -4.3203, -4.8899, -4.1489,\n",
      "         -4.4636, -4.3105, -4.4231, -4.4830, -4.6417, -5.0146, -4.6948, -4.2033,\n",
      "         -4.7751, -4.2435, -5.0326, -4.4988, -4.6298, -4.6725, -3.9710, -4.4357,\n",
      "         -4.7556, -4.6077, -4.6049, -4.8641, -4.9065, -4.3164, -5.0079, -4.8529,\n",
      "         -4.6664, -4.4572, -4.4513, -4.5814, -4.3152, -4.5283, -4.3821, -4.7545,\n",
      "         -4.7636, -4.1761, -4.7163, -4.4063, -4.7385, -4.6469, -4.4823, -4.7306,\n",
      "         -4.4529]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : and\n",
      "target index is: [44] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7092, -4.4952, -4.5559, -4.6232, -4.1919, -4.7408, -4.5318, -4.3938,\n",
      "         -4.7105, -4.7977, -4.4664, -4.4640, -4.8413, -4.8590, -4.5252, -4.5041,\n",
      "         -4.6193, -4.9027, -4.6312, -4.5799, -4.3540, -4.3022, -4.5219, -4.4683,\n",
      "         -4.5261, -4.7066, -4.3776, -4.4402, -4.6241, -4.5429, -4.6427, -4.8338,\n",
      "         -4.8124, -4.7320, -4.4013, -4.4914, -4.7812, -4.9139, -4.6171, -4.5330,\n",
      "         -4.7822, -4.6786, -4.8473, -4.5688, -4.5741, -4.6064, -4.3799, -4.5886,\n",
      "         -4.2778, -4.5401, -4.6059, -4.5666, -4.6267, -4.3690, -4.9073, -4.4729,\n",
      "         -4.7355, -4.6582, -4.6218, -4.6625, -4.8145, -4.7545, -4.7827, -4.1739,\n",
      "         -4.9178, -4.4379, -4.8684, -4.3800, -4.6398, -4.8349, -4.2949, -4.7793,\n",
      "         -4.6148, -4.6397, -4.3958, -4.7420, -4.6094, -4.4673, -4.8494, -4.4212,\n",
      "         -4.4669, -4.3434, -4.6738, -4.6612, -4.5968, -4.3504, -4.6002, -4.8013,\n",
      "         -4.8713, -4.1354, -4.8183, -4.7547, -4.3160, -4.3408, -4.4297, -4.4137,\n",
      "         -4.5645]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thriftless\n",
      "target index is: [43] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3983, -4.4381, -4.5468, -4.7408, -4.0925, -4.5576, -4.6759, -4.4719,\n",
      "         -4.7306, -4.5142, -4.9363, -4.3972, -4.7892, -4.6361, -4.6348, -4.9046,\n",
      "         -4.8723, -4.5481, -4.8773, -4.1886, -4.6833, -4.8008, -4.6570, -4.6088,\n",
      "         -4.8504, -4.7493, -4.5517, -4.4534, -4.1736, -4.7183, -4.6724, -4.5115,\n",
      "         -4.7351, -4.5526, -4.6304, -5.0315, -4.6347, -4.9067, -4.5293, -4.4677,\n",
      "         -4.5448, -4.5867, -4.7404, -4.1903, -4.4661, -4.2825, -4.4686, -4.1481,\n",
      "         -4.5499, -4.6970, -4.8449, -4.9278, -4.6470, -4.6334, -4.9108, -4.7399,\n",
      "         -4.3999, -4.4747, -4.5319, -4.6890, -4.5700, -4.7274, -4.5675, -4.3723,\n",
      "         -4.6561, -4.8215, -4.9070, -4.3955, -4.4785, -4.7153, -4.1966, -4.6566,\n",
      "         -4.7765, -5.0940, -4.5762, -4.5700, -4.4866, -4.4872, -4.5822, -4.3625,\n",
      "         -4.7470, -4.3087, -4.5199, -4.7963, -5.0361, -4.2954, -4.4825, -4.5151,\n",
      "         -5.2543, -4.4358, -4.7439, -4.4428, -4.5305, -4.5415, -4.1911, -4.2714,\n",
      "         -4.5946]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : praise.\n",
      "target index is: [94] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-3.9405, -5.0436, -4.7137, -5.1172, -3.7704, -4.7178, -4.8483, -4.3914,\n",
      "         -4.6803, -5.0000, -4.6618, -4.3009, -4.5952, -4.5774, -4.7981, -4.5554,\n",
      "         -4.8740, -5.0604, -4.6986, -4.5271, -4.7815, -4.0436, -5.1729, -4.9592,\n",
      "         -4.4394, -4.8493, -4.4847, -4.0915, -3.8973, -4.8595, -4.5790, -4.7986,\n",
      "         -4.8525, -4.7733, -4.4333, -5.2876, -4.7012, -4.6454, -4.9862, -4.9187,\n",
      "         -4.6559, -4.3244, -4.9349, -4.5567, -4.7070, -4.4016, -4.8440, -4.6436,\n",
      "         -4.7263, -4.8327, -4.3104, -4.8032, -4.4609, -4.6181, -4.8524, -4.5198,\n",
      "         -3.9236, -4.4260, -4.5096, -4.7088, -4.4005, -4.4513, -4.3240, -4.2831,\n",
      "         -4.5703, -4.6320, -5.0659, -4.9712, -4.8766, -4.8431, -4.1765, -4.2577,\n",
      "         -4.8823, -5.1140, -4.5643, -4.5262, -4.7981, -4.0510, -4.5695, -4.4482,\n",
      "         -4.5909, -4.1963, -5.2084, -5.0488, -4.1021, -4.6351, -4.2813, -4.7635,\n",
      "         -5.2006, -4.9500, -5.0553, -4.2565, -4.7465, -4.3627, -4.5276, -4.4171,\n",
      "         -4.4648]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : How\n",
      "target index is: [12] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1998, -4.6743, -4.5069, -5.0502, -4.0070, -4.9887, -4.6580, -4.3723,\n",
      "         -5.1394, -4.9409, -5.0303, -5.0893, -4.7574, -4.5204, -5.3252, -5.0741,\n",
      "         -4.8427, -4.4198, -4.7844, -4.7099, -4.6337, -4.8499, -4.8600, -5.0163,\n",
      "         -4.4393, -5.1259, -4.5718, -4.1798, -4.2594, -4.5971, -4.3085, -3.9770,\n",
      "         -4.6313, -4.7081, -4.4399, -5.1775, -4.5380, -4.5060, -4.5135, -4.5157,\n",
      "         -4.3558, -4.8655, -4.7970, -4.1717, -4.6067, -3.9837, -4.4907, -4.1390,\n",
      "         -5.0469, -4.5360, -4.4011, -4.7749, -4.6918, -4.7389, -4.5194, -4.7899,\n",
      "         -4.4120, -4.4762, -4.2682, -4.6772, -4.6711, -4.3132, -4.2558, -4.1863,\n",
      "         -4.5282, -4.8883, -4.6784, -4.3345, -4.4060, -4.4219, -4.5471, -4.3019,\n",
      "         -5.2970, -5.3466, -4.9419, -4.7693, -4.5656, -4.0901, -4.5682, -4.5660,\n",
      "         -4.6563, -4.9537, -4.6835, -5.1582, -4.9866, -4.1113, -4.1385, -4.8211,\n",
      "         -5.5579, -4.4158, -4.4647, -4.1274, -4.8369, -4.8381, -4.3930, -4.7771,\n",
      "         -4.5403]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : much\n",
      "target index is: [68] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4727, -5.0003, -4.6396, -4.4378, -3.5512, -4.4853, -4.7684, -4.2660,\n",
      "         -4.9879, -4.5283, -4.4981, -4.4705, -4.8662, -4.8125, -4.9747, -4.7872,\n",
      "         -4.7909, -4.8567, -4.0983, -4.8662, -4.7458, -4.1045, -5.0551, -4.8151,\n",
      "         -4.5343, -5.0955, -4.5232, -4.3551, -4.5797, -4.6030, -4.2220, -4.9741,\n",
      "         -4.6751, -4.4972, -4.4400, -5.3168, -4.4702, -5.0562, -4.6995, -4.9831,\n",
      "         -4.8606, -4.5830, -4.9552, -4.6222, -4.8560, -4.3919, -4.6439, -5.1139,\n",
      "         -4.9781, -4.5983, -4.9005, -4.4277, -5.0574, -4.1150, -4.5870, -3.9794,\n",
      "         -4.2204, -4.0080, -4.2247, -4.1810, -4.5419, -4.8238, -4.5601, -3.8279,\n",
      "         -4.6184, -4.3674, -4.6758, -4.4888, -5.1168, -4.7367, -4.4379, -4.2760,\n",
      "         -5.4897, -5.0633, -4.5763, -5.0503, -4.9376, -4.1530, -4.6151, -5.1543,\n",
      "         -4.8962, -4.1120, -4.9601, -4.8610, -4.3266, -4.5844, -4.5688, -4.8460,\n",
      "         -5.2993, -4.4900, -4.8809, -4.1090, -4.6803, -4.6104, -4.3060, -5.1571,\n",
      "         -4.3662]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : more\n",
      "target index is: [4] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3366, -4.8156, -4.7100, -4.3872, -4.1556, -4.6155, -4.8802, -4.4340,\n",
      "         -4.8734, -4.4805, -4.8748, -4.3132, -4.7388, -4.3933, -4.8318, -4.7745,\n",
      "         -4.5894, -4.7775, -4.6858, -4.6538, -4.4360, -4.4558, -4.6903, -4.6226,\n",
      "         -4.5755, -4.8098, -4.5885, -4.4477, -4.3821, -4.5640, -4.7636, -4.6832,\n",
      "         -4.8799, -4.5547, -4.9056, -5.0000, -4.8981, -4.6799, -4.7597, -4.6469,\n",
      "         -4.6076, -4.5456, -4.6002, -4.5033, -4.0818, -4.3344, -4.5247, -4.7032,\n",
      "         -4.7023, -4.5417, -4.9291, -4.3086, -4.7703, -4.3416, -4.8088, -4.3898,\n",
      "         -4.4717, -4.2275, -4.4722, -4.6696, -4.6067, -4.6218, -4.5908, -3.8780,\n",
      "         -4.4938, -4.6114, -4.8394, -4.5934, -4.6443, -4.5950, -4.0183, -4.5565,\n",
      "         -4.6970, -4.4701, -4.4966, -4.8290, -4.6920, -4.4941, -4.7404, -4.8116,\n",
      "         -4.5280, -4.2534, -4.6633, -4.7796, -4.5288, -4.5716, -4.7664, -4.7270,\n",
      "         -5.2215, -4.4927, -4.7195, -4.6868, -4.6400, -4.5463, -4.1031, -4.9228,\n",
      "         -4.5207]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : praise\n",
      "target index is: [45] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4556, -4.4872, -4.7264, -5.1995, -4.0287, -4.5893, -4.4965, -4.2585,\n",
      "         -5.2246, -4.5916, -4.8351, -4.3337, -4.7951, -4.5652, -5.0852, -4.8149,\n",
      "         -4.6518, -4.4859, -4.7758, -4.2070, -4.7113, -4.6901, -4.9704, -4.7523,\n",
      "         -4.9306, -4.9146, -4.5096, -4.2361, -4.3141, -4.6231, -4.2952, -4.4256,\n",
      "         -4.8493, -4.8391, -4.4752, -5.1776, -4.3380, -5.0359, -4.5127, -4.5902,\n",
      "         -4.4859, -4.5876, -4.7279, -4.1587, -4.6478, -4.1011, -4.7381, -4.3942,\n",
      "         -4.8173, -5.1212, -4.2411, -5.0843, -4.4493, -4.7445, -4.5655, -4.6430,\n",
      "         -4.3635, -4.5093, -4.4341, -4.5355, -4.5456, -4.3201, -4.6098, -4.3704,\n",
      "         -4.3092, -4.6230, -5.1820, -4.5588, -4.5740, -4.3266, -4.6908, -4.6234,\n",
      "         -5.2150, -5.2971, -4.6791, -4.9043, -4.5618, -4.0899, -4.3881, -4.4410,\n",
      "         -4.8873, -4.6370, -4.7310, -5.0224, -4.9841, -4.2420, -4.1899, -4.2869,\n",
      "         -5.1173, -4.6722, -4.5854, -4.0234, -5.0537, -4.5121, -4.6522, -4.3813,\n",
      "         -4.3664]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : deserv'd\n",
      "target index is: [66] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4307, -4.7031, -4.5698, -4.3416, -4.0650, -4.7286, -4.6509, -4.3516,\n",
      "         -4.8486, -4.8297, -4.4623, -4.7372, -4.7897, -4.7447, -4.8911, -4.8116,\n",
      "         -4.8187, -4.8455, -4.4953, -4.9043, -4.4280, -4.4664, -4.8144, -4.6370,\n",
      "         -4.2828, -5.0944, -4.6839, -4.5046, -4.3167, -4.6548, -4.2151, -4.7046,\n",
      "         -4.8105, -4.7476, -4.5570, -5.2232, -4.5089, -4.6618, -4.5475, -4.6098,\n",
      "         -4.7963, -4.5938, -4.8347, -4.5249, -4.8238, -4.2606, -4.7469, -4.5591,\n",
      "         -4.7896, -4.4614, -4.8270, -4.3149, -5.1509, -4.4272, -4.5705, -4.4654,\n",
      "         -4.0599, -4.1760, -4.2480, -4.4417, -4.6470, -4.4704, -4.5986, -4.2074,\n",
      "         -4.6319, -4.4319, -4.6417, -4.2777, -4.5546, -4.3408, -4.5261, -4.4584,\n",
      "         -5.2528, -4.9377, -4.8696, -4.9550, -4.9763, -3.9835, -4.8425, -4.8955,\n",
      "         -4.6173, -4.4716, -4.8799, -4.8670, -4.6551, -4.2932, -4.1799, -4.6425,\n",
      "         -5.1989, -4.3090, -4.4580, -4.4930, -4.7593, -4.6943, -4.2524, -4.8227,\n",
      "         -4.3788]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3376, -4.2297, -4.9159, -4.6736, -4.2398, -4.7670, -4.8815, -4.2107,\n",
      "         -5.0403, -4.7803, -5.3324, -4.4978, -4.4145, -4.6876, -4.6002, -4.7461,\n",
      "         -4.4893, -4.5424, -4.3633, -4.4502, -4.6352, -4.2404, -4.7556, -4.7186,\n",
      "         -4.3687, -5.0106, -4.3054, -4.4659, -4.5508, -4.6400, -4.7684, -4.7989,\n",
      "         -5.2148, -4.6754, -4.6246, -5.0548, -4.6997, -4.7842, -5.0208, -4.8568,\n",
      "         -4.8513, -4.7038, -4.7989, -4.5822, -4.7554, -4.0101, -4.8364, -4.9026,\n",
      "         -4.8344, -4.5024, -4.8347, -4.3290, -4.5527, -4.1847, -4.4819, -4.7583,\n",
      "         -4.3072, -4.1999, -4.5620, -4.5953, -4.7541, -4.6950, -4.1220, -4.3745,\n",
      "         -4.4400, -4.7048, -4.8793, -4.2138, -4.8298, -4.7758, -4.3127, -4.4882,\n",
      "         -4.7816, -4.8428, -4.7025, -4.6433, -4.3452, -4.3052, -4.4772, -4.7398,\n",
      "         -4.1274, -4.6521, -4.7827, -5.0803, -4.6363, -4.4315, -4.7401, -4.8910,\n",
      "         -4.7739, -4.4108, -4.6053, -4.7483, -4.9517, -4.2858, -3.8387, -4.9304,\n",
      "         -4.1416]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty's\n",
      "target index is: [80] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2953, -4.4856, -4.7623, -4.5277, -4.1958, -4.9270, -4.5838, -4.3207,\n",
      "         -4.3870, -5.1193, -4.9771, -4.2471, -4.6730, -4.7256, -4.6107, -4.7481,\n",
      "         -4.8815, -5.1476, -4.5381, -4.3964, -4.9351, -4.7431, -4.6254, -4.4815,\n",
      "         -4.2067, -4.6517, -4.6501, -4.4254, -3.8438, -4.5634, -4.8024, -4.5959,\n",
      "         -4.7169, -4.5644, -4.6320, -5.1424, -4.8528, -4.6156, -4.6611, -4.5076,\n",
      "         -4.6800, -4.2292, -4.9927, -4.0476, -4.5086, -4.0833, -4.4310, -4.4882,\n",
      "         -4.5328, -4.8979, -4.7733, -4.4636, -4.7522, -4.3332, -4.6139, -4.4048,\n",
      "         -4.3002, -4.3195, -4.7249, -5.0392, -4.8263, -4.1869, -4.4664, -4.0855,\n",
      "         -5.0399, -4.7961, -5.0818, -4.6707, -4.8181, -4.6272, -4.2886, -4.7221,\n",
      "         -4.5185, -4.8524, -4.7953, -4.9032, -5.1824, -4.2153, -4.6441, -4.4679,\n",
      "         -4.7776, -4.3247, -5.2088, -4.8024, -4.8676, -4.1129, -4.6111, -5.0073,\n",
      "         -5.0276, -4.5809, -5.2305, -4.4805, -4.5899, -4.4888, -4.2692, -4.3036,\n",
      "         -4.5241]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : use,\n",
      "target index is: [11] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1853, -4.6075, -4.9866, -5.2749, -3.7405, -5.0866, -4.6914, -4.6260,\n",
      "         -4.7099, -4.5814, -4.9132, -4.7705, -5.3020, -4.8478, -4.6538, -4.8342,\n",
      "         -5.0129, -4.4825, -4.7201, -4.3816, -4.8227, -4.1102, -5.2350, -4.6523,\n",
      "         -4.3636, -4.8804, -4.2426, -4.1808, -4.0716, -5.0225, -4.7296, -4.5960,\n",
      "         -4.7936, -4.6369, -4.9577, -5.1861, -5.0959, -4.7734, -5.1100, -4.6944,\n",
      "         -4.6756, -5.3168, -4.9421, -4.6079, -4.7187, -4.4266, -4.7867, -4.3402,\n",
      "         -4.4111, -4.8639, -3.9660, -5.4924, -4.3125, -4.5078, -4.8557, -4.3327,\n",
      "         -4.4977, -4.3899, -4.3372, -4.2130, -4.6654, -4.4959, -4.3406, -3.6191,\n",
      "         -4.5640, -4.8500, -4.9135, -4.8707, -4.3698, -4.4927, -4.2126, -4.5756,\n",
      "         -5.1065, -4.6677, -4.6802, -4.8395, -4.1201, -4.6300, -4.7059, -4.4787,\n",
      "         -4.6143, -4.0307, -5.4899, -5.0677, -4.5948, -4.6209, -4.6288, -4.9827,\n",
      "         -4.7772, -4.3424, -4.3175, -4.4215, -4.6253, -4.0636, -4.2803, -4.6188,\n",
      "         -4.6098]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : If\n",
      "target index is: [61] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7356, -4.3057, -4.9126, -4.9587, -4.4501, -4.7713, -4.7985, -4.2778,\n",
      "         -4.6208, -4.7756, -4.8190, -4.1605, -4.7373, -4.4791, -4.8511, -4.8382,\n",
      "         -4.3873, -4.6294, -4.9059, -4.4725, -4.5002, -4.9013, -4.8897, -4.5879,\n",
      "         -4.5718, -4.8413, -4.5016, -4.2675, -4.3266, -4.4803, -4.4057, -4.7705,\n",
      "         -5.2141, -4.7007, -4.9580, -5.3566, -4.4029, -4.9281, -4.4684, -4.4751,\n",
      "         -4.2890, -4.8357, -4.2586, -4.4591, -4.2344, -4.3568, -4.5180, -4.7828,\n",
      "         -4.5624, -4.8276, -4.3171, -4.3759, -4.6180, -4.3612, -4.5267, -4.5103,\n",
      "         -4.5978, -4.3912, -4.8441, -4.6185, -4.6061, -4.2956, -4.4563, -3.7221,\n",
      "         -4.4039, -4.4127, -4.7565, -4.6414, -4.3190, -3.9862, -4.4973, -4.5386,\n",
      "         -4.8794, -4.8745, -5.0765, -5.0227, -4.8232, -4.0495, -4.8162, -4.7937,\n",
      "         -5.0412, -4.5560, -4.9075, -5.1393, -5.0039, -4.3261, -4.4115, -4.5668,\n",
      "         -5.0605, -4.1595, -4.7014, -4.8635, -4.9418, -4.2694, -4.6337, -4.8015,\n",
      "         -4.6317]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thou\n",
      "target index is: [22] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5563, -4.4335, -4.9612, -4.6248, -4.3999, -4.8781, -4.4783, -4.3768,\n",
      "         -4.4335, -4.7312, -4.5986, -4.4617, -4.7598, -4.8951, -4.5992, -4.5745,\n",
      "         -4.7407, -5.0945, -4.5228, -4.3914, -4.5590, -4.4477, -4.8596, -4.3357,\n",
      "         -4.2588, -4.5720, -4.4726, -4.6705, -4.5127, -4.7151, -4.8864, -4.9389,\n",
      "         -4.6928, -4.7360, -4.3523, -4.5178, -4.5389, -4.6675, -4.7082, -4.5024,\n",
      "         -5.0461, -4.1631, -4.8368, -4.7377, -4.4781, -4.3757, -4.3546, -4.5766,\n",
      "         -4.1479, -5.1498, -4.8568, -4.2675, -4.7407, -4.3578, -4.6889, -4.4335,\n",
      "         -4.5400, -4.4655, -4.4992, -4.7099, -4.7433, -4.4807, -4.2919, -4.4190,\n",
      "         -4.9347, -4.6415, -4.5572, -4.4651, -4.5955, -4.4574, -4.1718, -4.9198,\n",
      "         -4.5233, -4.7349, -4.6720, -4.8913, -4.5370, -4.3924, -4.7712, -4.4248,\n",
      "         -4.6280, -4.5769, -4.8592, -4.4648, -4.5302, -4.6035, -4.6984, -4.7095,\n",
      "         -4.7808, -4.3010, -5.0189, -4.4016, -4.5602, -4.5247, -4.6512, -4.5176,\n",
      "         -4.4689]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : couldst\n",
      "target index is: [47] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4869, -4.3451, -4.4844, -4.7829, -4.2108, -4.8076, -4.7842, -4.3774,\n",
      "         -4.6219, -4.7765, -4.6216, -4.5065, -4.6206, -4.8647, -4.6942, -4.3012,\n",
      "         -4.5638, -4.5407, -4.4468, -4.5823, -4.5219, -4.3105, -4.7212, -4.7725,\n",
      "         -4.2786, -4.5854, -4.4471, -4.6144, -4.2878, -4.6820, -4.5479, -4.8145,\n",
      "         -4.8135, -4.4913, -4.6438, -4.8223, -4.5849, -4.7955, -4.7625, -4.8384,\n",
      "         -4.5956, -4.7321, -4.7816, -4.6777, -4.6242, -4.5603, -4.6569, -4.7710,\n",
      "         -4.5839, -4.6054, -4.4936, -4.6338, -4.6292, -4.5229, -4.7463, -4.6477,\n",
      "         -4.4387, -4.4991, -4.4287, -4.4839, -4.7872, -4.6213, -4.4235, -4.1490,\n",
      "         -4.7506, -4.4665, -4.7961, -4.7028, -4.4984, -4.5989, -4.3737, -4.3890,\n",
      "         -4.7652, -4.8317, -4.7145, -4.7131, -4.3749, -4.3775, -4.8266, -4.6510,\n",
      "         -4.4803, -4.4064, -4.7916, -4.8096, -4.5006, -4.6173, -4.3781, -4.6702,\n",
      "         -4.6212, -4.3278, -4.5411, -4.7504, -4.6510, -4.2729, -4.4255, -4.5945,\n",
      "         -4.5797]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : answer\n",
      "target index is: [53] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4032, -4.7342, -4.7314, -4.7816, -4.2147, -4.5546, -4.7000, -4.2963,\n",
      "         -4.8006, -4.8028, -4.7323, -4.4131, -4.5333, -4.7148, -4.8276, -4.6699,\n",
      "         -4.2569, -4.6360, -4.3745, -4.6793, -4.5758, -4.3835, -4.6325, -4.5168,\n",
      "         -4.2921, -5.0268, -4.3288, -4.8064, -4.5597, -4.5130, -4.5485, -4.7380,\n",
      "         -4.7944, -4.7224, -4.3869, -4.8796, -4.5654, -4.3491, -4.7932, -4.7899,\n",
      "         -4.7828, -4.6282, -4.8008, -4.6461, -4.3843, -4.3223, -4.5460, -4.7141,\n",
      "         -4.7593, -4.3435, -4.7864, -4.4461, -4.8255, -4.3745, -4.5897, -4.5291,\n",
      "         -4.6109, -4.4392, -4.4179, -4.4514, -4.6087, -4.5744, -4.4538, -3.9883,\n",
      "         -4.5493, -4.6064, -4.8074, -4.6134, -4.6389, -4.5638, -4.4119, -4.5848,\n",
      "         -4.8019, -4.6640, -4.8356, -4.7635, -4.4051, -4.2990, -4.6237, -4.9188,\n",
      "         -4.3899, -4.6141, -4.6943, -4.8354, -4.6351, -4.7085, -4.4907, -4.5676,\n",
      "         -5.0951, -4.3319, -4.4408, -4.6773, -4.7588, -4.5118, -4.4959, -4.8147,\n",
      "         -4.3250]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : 'This\n",
      "target index is: [9] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4267, -4.7005, -4.8580, -4.6981, -3.7114, -4.6336, -4.4112, -4.3384,\n",
      "         -4.9028, -4.8389, -4.9099, -4.5885, -4.8739, -4.7628, -4.7755, -4.8122,\n",
      "         -4.4424, -4.8606, -4.7109, -4.5365, -4.4756, -4.3826, -4.8632, -4.3975,\n",
      "         -4.5531, -4.9734, -4.4521, -4.4498, -4.5512, -4.7576, -4.5305, -4.6804,\n",
      "         -4.6011, -4.9214, -4.3072, -4.6475, -4.5518, -4.7618, -4.8405, -4.3736,\n",
      "         -4.8142, -4.2210, -4.7252, -4.3892, -4.7206, -4.1557, -4.5126, -4.5536,\n",
      "         -4.6023, -4.8356, -4.9222, -4.4925, -4.9980, -4.0069, -4.4234, -4.2493,\n",
      "         -4.6037, -4.3753, -4.6530, -4.5678, -4.5030, -4.4367, -4.6440, -4.4526,\n",
      "         -4.4680, -4.6752, -4.4578, -4.2195, -4.6736, -4.7574, -4.3853, -4.5731,\n",
      "         -4.7860, -5.0631, -4.8937, -5.0175, -4.7535, -4.4016, -4.7458, -4.7879,\n",
      "         -4.7468, -4.4716, -4.7034, -4.8064, -4.6335, -4.2137, -4.3995, -4.8363,\n",
      "         -4.9345, -4.3815, -4.7025, -4.4740, -4.6056, -4.6673, -4.5189, -4.6980,\n",
      "         -4.3183]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : fair\n",
      "target index is: [21] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3990, -4.4383, -4.8763, -4.5970, -4.0967, -4.6203, -4.8330, -4.2916,\n",
      "         -4.6821, -4.4072, -4.8283, -4.4748, -4.6238, -4.6692, -4.7592, -4.5911,\n",
      "         -4.6262, -4.4825, -4.5964, -4.3728, -4.5654, -4.2546, -4.9224, -4.9030,\n",
      "         -4.4684, -4.7719, -4.4463, -4.3861, -4.2926, -4.6349, -4.6120, -4.7001,\n",
      "         -4.9845, -4.7872, -4.4859, -4.6636, -4.7873, -4.7894, -5.1415, -4.8354,\n",
      "         -4.7550, -4.5562, -4.4613, -4.6882, -4.4249, -4.2519, -4.5919, -4.8153,\n",
      "         -4.5492, -4.8642, -4.7053, -4.3008, -4.7077, -4.3844, -4.7022, -4.6894,\n",
      "         -4.2659, -4.3832, -4.5038, -4.5801, -4.6730, -4.5519, -4.5798, -4.4496,\n",
      "         -4.4525, -4.7217, -4.6866, -4.5409, -4.8003, -4.6407, -4.3463, -4.5954,\n",
      "         -4.6119, -4.8782, -4.5904, -4.6520, -4.5174, -4.5017, -4.6979, -4.7493,\n",
      "         -4.3838, -4.3247, -4.5278, -4.7073, -4.5787, -4.2670, -4.7830, -4.7428,\n",
      "         -4.7271, -4.3798, -4.8558, -4.8029, -4.7565, -4.1905, -4.3733, -4.6628,\n",
      "         -4.4004]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : child\n",
      "target index is: [5] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3799, -4.4282, -4.9974, -4.6464, -4.1111, -4.7689, -4.6193, -4.6831,\n",
      "         -4.7056, -4.4817, -4.9921, -4.5516, -4.8890, -4.7608, -4.7659, -4.8682,\n",
      "         -4.5659, -4.6819, -4.7971, -4.4686, -4.5494, -4.3743, -4.9243, -4.6286,\n",
      "         -4.7354, -5.2279, -4.5603, -4.4723, -4.1518, -4.7111, -4.4844, -4.7869,\n",
      "         -4.7007, -4.6925, -4.5519, -4.8026, -4.4650, -4.6658, -4.7051, -4.5141,\n",
      "         -4.6471, -4.4616, -4.5034, -4.3926, -4.5801, -4.2476, -4.7153, -4.5802,\n",
      "         -4.6006, -4.8991, -4.7488, -4.6070, -5.0421, -4.3596, -4.3958, -4.2338,\n",
      "         -4.3364, -4.2555, -4.5678, -4.7565, -4.5263, -4.4011, -4.7693, -4.4163,\n",
      "         -4.4408, -4.5772, -4.7763, -4.3052, -4.4590, -4.3996, -4.4055, -4.5315,\n",
      "         -4.8043, -4.9819, -5.0108, -5.2084, -4.8473, -4.2648, -4.6917, -4.7776,\n",
      "         -4.6257, -4.3747, -4.6585, -5.0015, -4.7139, -4.1576, -4.3861, -4.3006,\n",
      "         -4.8655, -4.4270, -4.4495, -4.3687, -4.6443, -4.5285, -4.6186, -4.5623,\n",
      "         -4.1726]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : of\n",
      "target index is: [57] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6177, -4.0550, -4.5607, -4.7183, -4.0916, -4.8284, -4.8425, -4.5257,\n",
      "         -4.7536, -4.8556, -5.0964, -4.4913, -4.5753, -4.5498, -4.6675, -4.5786,\n",
      "         -4.7541, -4.5611, -4.6639, -4.4147, -4.4985, -4.1867, -4.8237, -4.4435,\n",
      "         -4.2659, -4.5983, -4.4714, -4.4598, -4.2303, -4.7416, -4.7077, -4.9757,\n",
      "         -5.0800, -4.5428, -4.7105, -4.7200, -4.8493, -4.8747, -4.8533, -4.7493,\n",
      "         -4.6989, -4.4228, -4.5969, -4.5602, -4.5429, -4.2840, -4.8394, -4.9160,\n",
      "         -4.5044, -4.7521, -4.4880, -4.4616, -4.6298, -4.2995, -4.7751, -4.7227,\n",
      "         -4.3870, -4.4651, -4.4854, -4.5598, -4.8653, -4.8188, -4.4004, -4.2461,\n",
      "         -4.6207, -4.7178, -5.0434, -4.4444, -4.7710, -4.7062, -4.5175, -4.5077,\n",
      "         -4.6350, -4.9411, -4.6005, -4.7242, -4.5530, -4.3856, -4.8113, -4.8057,\n",
      "         -4.1730, -4.3711, -4.6257, -4.6554, -4.4537, -4.3589, -4.6094, -4.8227,\n",
      "         -4.5081, -4.2744, -4.8731, -4.8471, -4.6246, -4.2031, -4.1751, -4.7713,\n",
      "         -4.3328]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : mine\n",
      "target index is: [86] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1117, -4.3414, -4.6109, -5.0094, -4.1157, -4.6323, -4.8220, -4.4843,\n",
      "         -4.6951, -4.7833, -5.0305, -4.3144, -4.9335, -4.5486, -4.5891, -4.7703,\n",
      "         -4.6677, -4.8558, -4.5633, -4.1896, -4.9318, -4.7086, -4.6014, -4.1289,\n",
      "         -4.5227, -4.4756, -4.6712, -4.4578, -4.1981, -4.6094, -4.5957, -5.0007,\n",
      "         -4.7669, -4.4826, -4.6363, -4.6794, -4.6462, -4.7515, -4.8128, -4.7150,\n",
      "         -4.8717, -4.4562, -4.7953, -4.5216, -4.8009, -4.1631, -4.8544, -4.6148,\n",
      "         -4.5581, -4.5959, -4.6586, -4.8644, -4.6351, -4.3416, -4.8015, -4.6618,\n",
      "         -4.3185, -4.4536, -4.6783, -4.5601, -4.5866, -4.6231, -4.4081, -4.3417,\n",
      "         -4.7444, -4.6161, -5.1765, -4.8007, -4.6353, -4.7748, -4.2713, -4.5366,\n",
      "         -4.5846, -4.9347, -4.5916, -4.5945, -4.6288, -4.2293, -4.6983, -4.4778,\n",
      "         -4.6662, -4.3185, -4.7261, -4.8169, -4.6590, -4.4673, -4.4171, -4.4134,\n",
      "         -4.8930, -4.2447, -4.5529, -4.6054, -4.5271, -4.5180, -4.3213, -4.5883,\n",
      "         -4.3840]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Shall\n",
      "target index is: [81] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2689, -4.3661, -4.5824, -5.0833, -4.0332, -4.7175, -4.6953, -4.5411,\n",
      "         -4.7280, -4.9484, -4.7659, -4.2926, -4.6738, -4.7808, -4.7227, -4.6040,\n",
      "         -4.3218, -4.7047, -4.4961, -4.6267, -4.5848, -4.5081, -4.7299, -4.4146,\n",
      "         -4.4010, -4.5374, -4.3576, -4.4635, -4.4098, -4.8488, -4.1576, -5.0080,\n",
      "         -4.5573, -4.6174, -4.5615, -4.9794, -4.4556, -4.6466, -4.8704, -4.9595,\n",
      "         -4.6436, -4.7597, -4.7705, -4.6094, -4.6365, -4.1735, -4.5078, -4.6991,\n",
      "         -4.7676, -4.6491, -4.5626, -4.5931, -4.7059, -4.4322, -4.5670, -4.9759,\n",
      "         -4.5885, -4.6503, -4.5228, -4.5037, -4.6753, -4.5545, -4.6267, -4.1192,\n",
      "         -4.7741, -4.7334, -4.8183, -4.5418, -4.5195, -4.3682, -4.7630, -4.6128,\n",
      "         -4.8364, -4.8452, -4.7139, -4.5407, -4.6603, -4.1735, -4.6110, -4.5181,\n",
      "         -4.5301, -4.3662, -4.7850, -5.0760, -4.5391, -4.5641, -4.1738, -4.5716,\n",
      "         -4.9187, -4.3827, -4.5461, -4.7632, -4.7888, -4.3764, -4.1276, -4.6950,\n",
      "         -4.4545]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : sum\n",
      "target index is: [70] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3145, -4.3835, -4.6825, -4.8227, -4.1697, -4.8725, -4.5704, -4.3693,\n",
      "         -4.6461, -4.7724, -4.7042, -4.3252, -4.5647, -4.9614, -4.8169, -4.6768,\n",
      "         -4.5188, -5.1648, -4.7279, -4.6422, -4.6029, -4.3085, -4.7393, -4.5822,\n",
      "         -4.3031, -4.9681, -4.3022, -4.4966, -4.4559, -4.6230, -4.5698, -4.8835,\n",
      "         -4.8687, -4.9143, -4.3142, -4.4677, -4.7115, -4.4539, -4.6863, -4.5872,\n",
      "         -5.0480, -4.3885, -4.5977, -4.5150, -4.4218, -4.2132, -4.4226, -4.6271,\n",
      "         -4.3366, -4.7836, -4.5980, -4.1274, -4.9760, -4.4199, -4.7018, -4.5450,\n",
      "         -4.6259, -4.4682, -4.5797, -4.9402, -4.8177, -4.5757, -4.6661, -4.2973,\n",
      "         -4.9394, -4.5919, -4.8425, -4.3871, -4.5798, -4.6114, -4.3212, -4.7783,\n",
      "         -4.5466, -4.8234, -4.6620, -4.7996, -4.5803, -4.1678, -4.7630, -4.8411,\n",
      "         -4.3452, -4.6520, -4.5563, -4.6500, -4.2611, -4.6086, -4.4918, -4.6895,\n",
      "         -5.0167, -4.4268, -4.7028, -4.5467, -4.5522, -4.6790, -4.4767, -4.4218,\n",
      "         -4.4023]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : my\n",
      "target index is: [90] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4164, -4.3708, -4.6020, -5.1541, -4.2046, -5.1479, -4.4923, -4.4634,\n",
      "         -4.7356, -4.6146, -5.1361, -4.5715, -4.7583, -4.7900, -4.3619, -4.6182,\n",
      "         -4.6203, -4.6856, -4.9341, -4.3731, -4.8345, -4.2702, -4.8277, -4.5925,\n",
      "         -4.4035, -5.0096, -4.2142, -4.4630, -4.1250, -4.5933, -4.6777, -4.8599,\n",
      "         -4.7802, -4.8838, -4.7399, -4.5665, -4.6718, -4.4264, -4.8655, -4.5155,\n",
      "         -4.9281, -4.7715, -4.8837, -4.3719, -4.8589, -4.3034, -4.8124, -4.6394,\n",
      "         -4.5258, -5.1677, -4.0954, -5.0883, -4.4656, -4.5452, -4.7109, -4.4885,\n",
      "         -4.5229, -4.4677, -4.3205, -5.0228, -4.6140, -4.3961, -4.4786, -4.2445,\n",
      "         -4.6268, -4.3856, -5.0865, -4.5837, -4.3984, -4.5664, -4.5819, -4.5785,\n",
      "         -4.7449, -4.7622, -4.7258, -5.0198, -4.4053, -4.3177, -4.4987, -4.6503,\n",
      "         -4.4461, -4.4836, -4.8404, -4.4491, -4.6643, -4.1884, -4.5162, -4.8414,\n",
      "         -4.4860, -4.5897, -4.4109, -4.5522, -4.7061, -4.3107, -4.6242, -4.3086,\n",
      "         -4.1618]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : count,\n",
      "target index is: [55] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6009, -4.2318, -4.7346, -4.9452, -4.4685, -4.9429, -4.6820, -4.4288,\n",
      "         -4.6128, -4.8739, -4.9875, -4.6451, -4.6962, -4.7497, -4.7320, -4.6576,\n",
      "         -4.5616, -4.6034, -4.8562, -4.6589, -4.6214, -4.6728, -4.9830, -4.3746,\n",
      "         -4.4197, -4.7038, -4.4906, -4.2119, -4.2884, -4.6204, -4.2169, -4.8707,\n",
      "         -5.0306, -4.7711, -4.8395, -4.6426, -4.5543, -4.8164, -4.7179, -4.4921,\n",
      "         -4.6218, -4.6426, -4.3730, -4.5573, -4.5427, -4.2129, -4.9855, -4.6626,\n",
      "         -4.6439, -4.9559, -4.2671, -4.6445, -4.7978, -4.3175, -4.6189, -4.4423,\n",
      "         -4.2029, -4.2708, -4.6509, -4.4602, -4.5964, -4.5426, -4.3005, -4.1403,\n",
      "         -4.6061, -4.5109, -4.9756, -4.4039, -4.2183, -4.1827, -4.4443, -4.5082,\n",
      "         -4.7952, -4.8398, -4.9985, -5.1150, -4.3738, -4.2199, -4.8501, -4.9344,\n",
      "         -4.7025, -4.7267, -4.8517, -4.8622, -4.7571, -4.3191, -4.1920, -4.5521,\n",
      "         -4.7769, -4.3184, -4.3729, -4.9255, -4.7816, -4.2981, -4.5374, -4.7190,\n",
      "         -4.3854]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : and\n",
      "target index is: [44] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6816, -4.4633, -4.7012, -4.6741, -4.1779, -4.9005, -4.4406, -4.2629,\n",
      "         -4.7493, -4.9919, -4.6511, -4.4979, -4.6359, -4.8802, -4.7628, -4.4002,\n",
      "         -4.3158, -4.8272, -4.5545, -4.7002, -4.4868, -4.2811, -4.5003, -4.5351,\n",
      "         -4.1952, -4.8311, -4.4592, -4.5173, -4.7468, -4.4384, -4.6109, -4.8529,\n",
      "         -4.8238, -4.8220, -4.3542, -4.2724, -4.9114, -4.7941, -4.8335, -4.6575,\n",
      "         -4.9641, -4.6160, -4.8771, -4.5808, -4.4616, -4.5168, -4.3246, -4.8135,\n",
      "         -4.2430, -4.5752, -4.6519, -4.3147, -4.8289, -4.1781, -4.5764, -4.5877,\n",
      "         -4.5176, -4.6151, -4.6798, -4.7716, -4.9800, -4.6992, -4.3683, -4.1303,\n",
      "         -4.9425, -4.4700, -4.7066, -4.1388, -4.6595, -4.8280, -4.5365, -4.8499,\n",
      "         -4.3739, -4.6515, -4.7714, -4.8593, -4.3199, -4.4735, -4.8595, -4.4744,\n",
      "         -4.3338, -4.5233, -4.7789, -4.8093, -4.6406, -4.5153, -4.6999, -4.7873,\n",
      "         -4.9636, -4.1254, -4.8931, -4.9429, -4.3329, -4.4114, -4.4729, -4.4500,\n",
      "         -4.5540]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : make\n",
      "target index is: [14] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4767, -4.2513, -4.7318, -5.1196, -4.3239, -4.6352, -4.6049, -4.3939,\n",
      "         -4.6772, -4.6750, -4.7885, -4.5458, -4.8433, -4.6656, -4.4070, -4.5902,\n",
      "         -4.6120, -4.7337, -4.7347, -4.1917, -4.8712, -4.6658, -4.9527, -4.4071,\n",
      "         -4.7284, -4.6783, -4.4133, -4.3438, -4.3019, -4.6552, -4.5725, -4.7920,\n",
      "         -4.8870, -4.7448, -4.4436, -4.4404, -4.5263, -4.9842, -4.7908, -4.5978,\n",
      "         -4.6991, -4.6323, -4.6423, -4.4475, -4.7851, -4.3270, -5.0537, -4.5216,\n",
      "         -4.4024, -4.9902, -4.2166, -4.8638, -4.2688, -4.5491, -4.9829, -4.2672,\n",
      "         -4.5070, -4.3879, -4.8238, -4.4596, -4.5785, -4.6421, -4.3806, -4.4174,\n",
      "         -4.6223, -4.4630, -5.2429, -4.8654, -4.4368, -4.5609, -4.2045, -4.6480,\n",
      "         -4.5664, -4.8897, -4.4806, -4.7843, -4.5191, -4.2610, -4.8058, -4.7155,\n",
      "         -4.6801, -4.6206, -4.7061, -4.7595, -4.5920, -4.4757, -4.4608, -4.5550,\n",
      "         -4.5072, -4.1524, -4.6056, -4.3927, -4.7804, -4.4485, -4.6212, -4.5245,\n",
      "         -4.3627]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : my\n",
      "target index is: [90] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3670, -4.2334, -4.8757, -5.0471, -4.1845, -5.0080, -4.3612, -4.3939,\n",
      "         -4.8295, -4.6815, -4.6727, -4.3966, -4.6309, -4.9908, -4.7752, -4.4711,\n",
      "         -4.3737, -4.8141, -4.7613, -4.6294, -4.8104, -4.1303, -4.7766, -4.9059,\n",
      "         -4.2560, -5.0341, -4.1609, -4.5478, -4.1547, -4.7012, -4.3627, -4.8904,\n",
      "         -4.5913, -4.6963, -4.7313, -4.6574, -4.8481, -4.3548, -5.0263, -4.8398,\n",
      "         -4.6977, -4.8879, -4.6468, -4.5553, -4.5348, -4.2792, -4.5923, -4.8781,\n",
      "         -4.6267, -4.7790, -4.5116, -4.5925, -4.6921, -4.6183, -4.5141, -4.7311,\n",
      "         -4.7535, -4.5368, -4.4997, -4.8697, -4.8035, -4.1770, -4.4996, -3.9996,\n",
      "         -4.7223, -4.8745, -4.8256, -4.5134, -4.4752, -4.0628, -4.7004, -4.7147,\n",
      "         -4.6211, -4.5912, -4.7823, -4.9486, -4.4659, -4.4606, -4.4403, -4.5734,\n",
      "         -4.4985, -4.4669, -5.0067, -4.7447, -4.6541, -4.6404, -4.6535, -4.5673,\n",
      "         -4.6213, -4.2748, -4.5222, -4.7567, -4.8029, -4.2128, -4.3274, -4.4656,\n",
      "         -4.2997]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : old\n",
      "target index is: [84] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.0887, -4.3256, -4.4078, -5.0330, -4.2369, -5.2513, -4.4210, -4.4169,\n",
      "         -4.5137, -4.9251, -4.9731, -4.7960, -4.2827, -4.7990, -4.9256, -4.4210,\n",
      "         -4.5114, -4.6066, -4.8764, -4.7544, -4.7326, -4.2538, -5.1099, -4.7304,\n",
      "         -4.0561, -4.8597, -4.3272, -4.5103, -3.9180, -4.7187, -4.5966, -4.6867,\n",
      "         -4.6438, -4.9638, -4.8590, -4.5955, -4.7725, -4.3409, -4.7231, -4.5403,\n",
      "         -4.8455, -4.4864, -4.7783, -4.2628, -4.5326, -4.3861, -4.8340, -4.5606,\n",
      "         -4.6209, -4.9096, -4.0661, -4.7169, -4.9416, -4.6674, -4.7208, -4.5788,\n",
      "         -4.2441, -4.5738, -4.4058, -4.8350, -4.9504, -4.3888, -4.3795, -4.2668,\n",
      "         -4.7534, -4.7428, -4.8940, -4.5745, -4.5006, -4.3930, -4.5597, -4.4023,\n",
      "         -4.7598, -4.8939, -4.7493, -4.9658, -4.3388, -4.3504, -4.8166, -4.8925,\n",
      "         -4.1342, -4.5556, -4.8179, -4.7374, -4.5049, -4.5093, -4.6061, -4.7705,\n",
      "         -4.8593, -4.5492, -4.5780, -4.6091, -4.6126, -4.4338, -4.8211, -4.3696,\n",
      "         -4.4085]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : excuse,'\n",
      "target index is: [64] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4968, -4.4304, -4.5223, -4.7922, -4.1554, -4.9099, -4.6413, -4.3536,\n",
      "         -4.7610, -4.8037, -4.7480, -4.6524, -4.4937, -4.5143, -4.8316, -4.6143,\n",
      "         -4.7315, -4.2858, -4.6381, -4.6051, -4.4142, -4.6726, -4.5401, -4.7608,\n",
      "         -4.2742, -4.7859, -4.5918, -4.5543, -4.3605, -4.2504, -4.6422, -4.6792,\n",
      "         -4.8894, -4.7246, -4.6758, -5.2158, -4.7892, -4.6640, -4.6049, -4.5247,\n",
      "         -4.3752, -4.7932, -4.8009, -4.6261, -4.5831, -4.5835, -4.5477, -4.4438,\n",
      "         -4.4995, -4.4595, -4.3335, -4.5087, -4.5110, -4.4853, -4.5733, -4.4273,\n",
      "         -4.6079, -4.4649, -4.3822, -4.6081, -4.9467, -4.5385, -4.5263, -3.7408,\n",
      "         -4.6838, -4.4191, -4.6755, -4.3461, -4.5313, -4.6213, -4.5973, -4.5616,\n",
      "         -4.9450, -4.8725, -4.8476, -4.6438, -4.6317, -4.4931, -4.6007, -4.5667,\n",
      "         -4.7630, -4.6878, -4.9392, -4.9298, -4.6664, -4.2139, -4.4107, -4.9525,\n",
      "         -4.8999, -4.1604, -4.4994, -4.7006, -4.5912, -4.4877, -4.6559, -4.5504,\n",
      "         -4.8499]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Proving\n",
      "target index is: [25] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5026, -4.6020, -4.9658, -4.7155, -4.4708, -4.6849, -4.6698, -4.4532,\n",
      "         -4.6026, -4.5639, -4.9692, -4.4005, -4.4495, -4.5406, -4.5395, -4.8612,\n",
      "         -4.5764, -4.8614, -4.3824, -4.6206, -4.4912, -4.4617, -4.8162, -4.4806,\n",
      "         -4.4365, -4.7053, -4.2071, -4.5702, -4.4595, -4.4817, -5.0770, -4.8189,\n",
      "         -4.8265, -4.7955, -4.9665, -5.0134, -4.4505, -4.7242, -4.6166, -4.3588,\n",
      "         -4.7689, -4.5787, -4.6264, -4.6828, -4.3600, -4.3765, -4.7230, -4.8183,\n",
      "         -4.4533, -5.0130, -4.3099, -4.5230, -4.5325, -4.1265, -4.5478, -4.2575,\n",
      "         -4.6856, -4.3749, -4.5693, -4.3737, -4.4783, -4.3682, -4.3719, -4.0122,\n",
      "         -4.4179, -4.5988, -4.7120, -4.6872, -4.9353, -4.1828, -4.0139, -4.5275,\n",
      "         -5.0904, -4.3785, -4.8012, -4.9829, -4.3653, -4.4406, -4.5607, -4.6225,\n",
      "         -4.7423, -4.6126, -4.9166, -4.8890, -4.8739, -4.5846, -5.1045, -4.9803,\n",
      "         -4.8253, -4.4071, -4.6355, -4.6831, -4.7305, -4.2146, -4.5989, -4.8452,\n",
      "         -4.3599]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : his\n",
      "target index is: [49] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7325, -4.3135, -4.9222, -5.1109, -4.2525, -4.5904, -4.2533, -4.3594,\n",
      "         -4.9769, -4.4433, -4.7121, -4.3010, -4.7278, -4.6973, -4.9016, -4.5505,\n",
      "         -4.4903, -4.4687, -4.6779, -4.3498, -4.4755, -4.3818, -4.5910, -4.6512,\n",
      "         -4.6454, -4.7811, -4.4093, -4.5480, -4.7730, -4.5568, -4.7045, -4.5770,\n",
      "         -4.7720, -4.7570, -4.5070, -4.6932, -4.5058, -4.8382, -4.7238, -4.3371,\n",
      "         -4.4154, -4.5055, -4.4739, -4.3051, -4.4892, -4.6590, -4.4531, -4.3947,\n",
      "         -4.3513, -5.1929, -4.4463, -4.7506, -4.3888, -4.3346, -4.6006, -4.5434,\n",
      "         -4.8992, -4.7351, -4.2472, -4.7034, -4.9171, -4.5004, -4.5135, -4.3338,\n",
      "         -4.4533, -4.6827, -4.5602, -4.3592, -4.6700, -4.2956, -4.7577, -4.8643,\n",
      "         -4.7391, -4.8315, -4.6866, -4.9481, -4.4134, -4.5066, -4.4447, -4.4913,\n",
      "         -4.8245, -4.6603, -4.8404, -4.5701, -5.0005, -4.3636, -4.7107, -4.5889,\n",
      "         -4.8378, -4.2589, -4.6462, -4.2868, -4.9239, -4.5297, -4.6894, -4.6212,\n",
      "         -4.5129]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty\n",
      "target index is: [0] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5985, -4.4674, -4.8544, -4.6890, -4.4022, -4.7268, -4.7384, -4.0828,\n",
      "         -4.7898, -4.4662, -4.6268, -4.3169, -4.4125, -4.7683, -4.7618, -4.7112,\n",
      "         -4.6823, -4.5014, -4.3151, -4.4549, -4.5939, -4.4414, -4.7708, -4.9157,\n",
      "         -4.3035, -5.2786, -4.2852, -4.7445, -4.0155, -4.4714, -4.6243, -4.6072,\n",
      "         -4.9800, -4.6762, -4.5331, -5.0251, -4.4589, -4.5966, -4.6465, -4.8105,\n",
      "         -4.7216, -4.6342, -4.7291, -4.7097, -4.6002, -4.4268, -4.7708, -5.0108,\n",
      "         -4.8566, -4.8078, -4.6532, -4.4582, -4.8540, -4.5760, -4.6577, -4.5703,\n",
      "         -4.2510, -4.1490, -4.4166, -4.3955, -4.6621, -4.5495, -4.5156, -4.3690,\n",
      "         -4.4223, -4.6907, -4.6198, -4.7125, -4.6575, -4.3426, -4.4530, -4.4604,\n",
      "         -5.1467, -4.6179, -4.9221, -4.9044, -4.4303, -4.2241, -4.4361, -4.9078,\n",
      "         -4.4758, -4.4096, -4.6815, -4.8019, -4.7854, -4.5038, -4.6866, -4.2666,\n",
      "         -4.7652, -4.5803, -4.6059, -4.5624, -4.8597, -4.2938, -4.6144, -4.6191,\n",
      "         -4.2154]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : by\n",
      "target index is: [62] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.0353, -4.6631, -4.6951, -4.6685, -3.8840, -4.7190, -4.4705, -4.1612,\n",
      "         -4.8850, -4.9188, -4.7217, -4.5008, -4.4294, -4.6876, -4.7682, -4.7856,\n",
      "         -4.4074, -4.6791, -4.5698, -4.7879, -4.7307, -4.4239, -4.9529, -4.7128,\n",
      "         -4.1638, -4.7853, -4.4924, -4.3804, -4.4978, -4.7242, -4.5533, -4.4556,\n",
      "         -4.5558, -4.9257, -4.5757, -5.1245, -4.7910, -4.2419, -4.7015, -4.3845,\n",
      "         -4.6802, -4.4536, -4.8181, -4.3249, -4.5038, -3.8971, -4.4973, -4.7482,\n",
      "         -4.8907, -4.5142, -4.7432, -4.3778, -4.8879, -4.2552, -4.4001, -4.4583,\n",
      "         -4.3049, -4.4249, -4.6677, -4.7945, -4.8339, -4.2308, -4.3429, -4.3425,\n",
      "         -4.5552, -4.8168, -4.5808, -4.2034, -4.9894, -4.6371, -4.7034, -4.7239,\n",
      "         -4.5172, -5.0191, -4.7454, -4.8029, -4.6671, -4.3217, -4.7107, -5.0214,\n",
      "         -4.3840, -4.4895, -5.0087, -5.0112, -4.6710, -4.3097, -4.7491, -5.0939,\n",
      "         -5.1419, -4.6005, -4.8936, -4.7095, -4.5116, -4.4881, -4.6065, -4.7908,\n",
      "         -4.5001]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : succession\n",
      "target index is: [7] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6587, -4.3932, -4.6705, -4.6790, -4.1894, -4.6713, -4.7313, -4.4186,\n",
      "         -4.7034, -4.5524, -4.7139, -4.2485, -4.7811, -4.5094, -4.9602, -4.6680,\n",
      "         -4.6303, -4.4932, -4.8397, -4.5072, -4.3363, -4.5678, -4.8556, -4.8706,\n",
      "         -4.5436, -4.7176, -4.4820, -4.2550, -4.1807, -4.4496, -4.4647, -4.7583,\n",
      "         -4.9455, -4.5273, -4.8861, -5.2041, -4.5462, -4.9390, -4.5392, -4.5139,\n",
      "         -4.3339, -4.6861, -4.4332, -4.7062, -4.3105, -4.5320, -4.3242, -4.8104,\n",
      "         -4.4149, -4.8624, -4.5273, -4.5231, -4.5740, -4.3941, -4.6632, -4.5069,\n",
      "         -4.5797, -4.3806, -4.5944, -4.7229, -4.5002, -4.4275, -4.4119, -3.8734,\n",
      "         -4.3834, -4.5285, -4.6107, -4.5295, -4.4213, -4.1133, -4.3697, -4.4061,\n",
      "         -4.9834, -4.8298, -4.8056, -4.9227, -4.7806, -4.3316, -4.6999, -4.8859,\n",
      "         -4.9885, -4.5173, -4.7042, -4.8869, -4.7333, -4.4150, -4.4448, -4.5858,\n",
      "         -4.9891, -4.4638, -4.7623, -4.6400, -4.7947, -4.6965, -4.5771, -4.9954,\n",
      "         -4.7015]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thine!\n",
      "target index is: [40] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6478, -4.3622, -4.6906, -4.4578, -4.2212, -4.7516, -4.6138, -4.2767,\n",
      "         -4.7091, -4.6298, -4.6318, -4.4077, -4.7217, -4.7596, -4.4795, -4.8097,\n",
      "         -4.8852, -5.0356, -4.6202, -4.5971, -4.5384, -4.5529, -4.6786, -4.5283,\n",
      "         -4.5215, -4.6000, -4.2184, -4.3816, -4.4012, -4.6567, -4.8707, -4.8481,\n",
      "         -4.9116, -4.5364, -4.5097, -4.8666, -4.7686, -4.7624, -4.5800, -4.4271,\n",
      "         -4.7172, -4.6202, -4.6444, -4.5812, -4.6316, -4.4688, -4.5597, -4.5475,\n",
      "         -4.3145, -4.7347, -4.3800, -4.4547, -4.5168, -4.5001, -4.9686, -4.1456,\n",
      "         -4.7560, -4.3126, -4.6973, -4.7577, -4.5221, -4.5238, -4.6113, -4.1679,\n",
      "         -4.8605, -4.5325, -4.7225, -4.5991, -4.7795, -4.6545, -4.1641, -4.7684,\n",
      "         -4.7988, -4.5579, -4.3238, -4.9245, -4.7127, -4.4273, -4.5825, -4.4478,\n",
      "         -4.7183, -4.3430, -4.9391, -4.8340, -4.7228, -4.4394, -4.8698, -4.7957,\n",
      "         -4.7162, -4.3873, -4.7997, -4.3286, -4.5685, -4.2800, -4.5394, -4.2585,\n",
      "         -4.6588]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : This\n",
      "target index is: [1] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4819, -4.3387, -4.7533, -4.7669, -4.1925, -4.5647, -4.7815, -4.4506,\n",
      "         -4.5405, -4.5498, -4.7914, -4.6843, -4.8512, -4.6922, -4.4305, -4.7223,\n",
      "         -4.5999, -4.6196, -4.8235, -4.3975, -4.6838, -4.6132, -5.1011, -4.4953,\n",
      "         -4.5821, -4.6540, -4.5073, -4.4006, -4.2692, -4.7115, -4.5680, -4.7726,\n",
      "         -4.7850, -4.6743, -4.6151, -4.8646, -4.4501, -4.8669, -4.6866, -4.6270,\n",
      "         -4.6124, -4.4066, -4.6503, -4.6291, -4.6157, -4.2324, -4.7329, -4.5644,\n",
      "         -4.3067, -4.7554, -4.4633, -4.7083, -4.6729, -4.5414, -4.7796, -4.4345,\n",
      "         -4.2956, -4.2420, -4.7154, -4.3135, -4.6021, -4.7307, -4.3643, -4.2781,\n",
      "         -4.5554, -4.7635, -4.9260, -4.7475, -4.4697, -4.3629, -4.1581, -4.3130,\n",
      "         -4.9530, -4.9155, -4.6391, -4.8056, -4.4754, -4.3614, -4.7938, -4.6748,\n",
      "         -4.5730, -4.4358, -4.5948, -4.8213, -4.7449, -4.5587, -4.5359, -4.4886,\n",
      "         -4.7470, -4.2795, -4.5982, -4.5441, -4.8930, -4.4409, -4.4800, -4.7509,\n",
      "         -4.4885]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : were\n",
      "target index is: [93] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2724, -4.4747, -4.7688, -4.8889, -3.8253, -4.5601, -4.4185, -4.2811,\n",
      "         -4.6487, -4.8767, -4.6175, -4.4740, -4.6631, -4.9298, -4.7638, -4.5175,\n",
      "         -4.4821, -4.9783, -4.5823, -4.4274, -4.8629, -4.1486, -4.7595, -4.9545,\n",
      "         -4.3679, -4.6837, -4.4114, -4.3479, -4.2593, -4.8570, -4.3922, -4.9204,\n",
      "         -4.6533, -4.5894, -4.2945, -4.8306, -4.9290, -4.5577, -5.1197, -4.7770,\n",
      "         -4.6698, -4.6787, -4.7852, -4.5829, -4.8059, -4.2296, -4.2515, -4.7199,\n",
      "         -4.4688, -4.7441, -4.8276, -4.3295, -4.7706, -4.6091, -4.6047, -4.4328,\n",
      "         -4.3742, -4.4212, -4.4119, -4.7494, -4.6239, -4.4972, -4.8361, -4.0448,\n",
      "         -4.7364, -4.6800, -4.7481, -4.5772, -4.7794, -4.5192, -4.5788, -4.5892,\n",
      "         -4.3778, -4.8211, -4.6736, -4.5206, -4.7808, -4.7090, -4.6772, -4.4429,\n",
      "         -4.7050, -4.5094, -5.0558, -4.7978, -4.2389, -4.6255, -4.4426, -4.7589,\n",
      "         -4.7435, -4.4428, -4.7752, -4.5533, -4.8006, -4.4521, -4.4904, -4.4989,\n",
      "         -4.5245]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : to\n",
      "target index is: [72] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5780, -4.5327, -4.7213, -4.4737, -4.4757, -4.7723, -4.9932, -4.2505,\n",
      "         -4.7214, -4.6953, -4.6330, -4.6234, -4.5724, -4.7288, -4.7908, -4.5525,\n",
      "         -4.7529, -4.2417, -4.6119, -4.5818, -4.3665, -4.4804, -5.0984, -4.8329,\n",
      "         -4.4212, -4.9907, -4.5166, -4.2663, -4.1739, -4.7346, -4.6273, -4.2676,\n",
      "         -5.0965, -4.7564, -4.5729, -5.1646, -4.5233, -4.7106, -4.6181, -4.7349,\n",
      "         -4.4886, -4.5267, -4.5882, -4.5685, -4.5222, -4.3113, -4.7020, -4.7221,\n",
      "         -4.7613, -4.6787, -4.3772, -4.5778, -4.6943, -4.7953, -4.8324, -4.6680,\n",
      "         -3.9716, -4.1676, -4.4882, -4.3418, -4.5430, -4.4794, -4.2967, -4.1268,\n",
      "         -4.4475, -4.5290, -4.8801, -4.9337, -4.4862, -4.4221, -4.1529, -4.1572,\n",
      "         -5.1859, -5.0185, -4.8870, -4.9101, -4.3107, -4.2459, -4.7640, -4.6816,\n",
      "         -4.5162, -4.5599, -4.5539, -4.9780, -4.7682, -4.5675, -4.5284, -4.5108,\n",
      "         -5.0617, -4.5105, -4.6496, -4.6573, -5.1117, -4.2706, -4.5197, -4.8599,\n",
      "         -4.5906]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : be\n",
      "target index is: [24] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2029, -4.8270, -4.7984, -5.0652, -4.0156, -4.8056, -4.6468, -4.2185,\n",
      "         -4.8894, -5.1049, -4.9506, -4.3045, -4.6661, -4.9102, -4.9970, -4.5557,\n",
      "         -3.9613, -5.0212, -4.5996, -5.0385, -4.3684, -4.2097, -4.6702, -4.4736,\n",
      "         -4.2819, -5.0059, -4.0499, -4.7123, -4.5687, -4.7339, -4.1885, -5.3427,\n",
      "         -4.8481, -5.0792, -4.3190, -4.6993, -4.8167, -4.4436, -5.0630, -4.9692,\n",
      "         -5.0622, -4.4058, -4.6628, -4.4740, -4.2691, -4.0896, -4.4966, -4.6799,\n",
      "         -4.5906, -4.4597, -4.4609, -4.1030, -5.2638, -4.3612, -4.7337, -4.6657,\n",
      "         -4.8281, -4.4885, -4.5416, -4.8976, -4.9603, -4.5659, -4.6793, -3.9024,\n",
      "         -4.6388, -4.7268, -4.9735, -4.4421, -4.4027, -4.5149, -4.3346, -4.7188,\n",
      "         -4.6873, -4.8353, -4.6851, -4.8662, -4.7770, -4.0360, -4.7904, -5.0345,\n",
      "         -4.1510, -4.8061, -4.7084, -4.6645, -4.3338, -4.8560, -4.3063, -4.9235,\n",
      "         -4.9944, -4.4515, -4.3783, -4.6756, -4.7675, -4.5779, -4.3118, -4.6540,\n",
      "         -4.3115]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : new\n",
      "target index is: [27] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5596, -4.4799, -4.3529, -4.7141, -4.1653, -4.7241, -4.6643, -4.3822,\n",
      "         -4.6095, -4.6454, -4.8621, -4.5222, -4.6257, -4.7612, -4.5923, -4.6312,\n",
      "         -4.5497, -4.5558, -4.4676, -4.6131, -4.7818, -4.6015, -4.5786, -4.4793,\n",
      "         -4.3861, -4.6578, -4.4795, -4.6408, -4.4500, -4.4039, -4.5171, -4.6455,\n",
      "         -4.8418, -4.6925, -4.5676, -4.6998, -4.6316, -4.6773, -4.5794, -4.6998,\n",
      "         -4.6533, -4.5339, -4.9852, -4.6319, -4.7168, -4.5920, -4.6560, -4.5497,\n",
      "         -4.5373, -4.3590, -4.3192, -4.5350, -4.6940, -4.3284, -4.7249, -4.4772,\n",
      "         -4.5152, -4.6139, -4.5298, -4.6453, -4.7268, -4.6210, -4.5484, -4.0830,\n",
      "         -4.9814, -4.4517, -4.8719, -4.4293, -4.7033, -4.9867, -4.5662, -4.5760,\n",
      "         -4.7174, -4.7624, -4.6456, -4.6908, -4.4956, -4.4322, -4.6021, -4.8206,\n",
      "         -4.4549, -4.3429, -4.6088, -4.7732, -4.6809, -4.3185, -4.5689, -4.7593,\n",
      "         -4.7736, -4.1792, -4.6200, -4.8144, -4.3977, -4.5405, -4.3741, -4.4151,\n",
      "         -4.6773]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : made\n",
      "target index is: [16] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3725, -4.6224, -4.7591, -4.8449, -4.2344, -4.6693, -4.4396, -4.5206,\n",
      "         -4.6788, -4.4040, -4.8838, -4.4581, -4.6672, -4.5707, -4.6919, -4.8061,\n",
      "         -4.4438, -4.7015, -4.5985, -4.5992, -4.3436, -4.3826, -4.7637, -4.5560,\n",
      "         -4.6473, -5.1432, -4.1348, -4.6884, -4.6262, -4.7377, -4.5378, -4.8739,\n",
      "         -4.5550, -4.9146, -4.5086, -4.9621, -4.5309, -4.3673, -4.6349, -4.4014,\n",
      "         -4.6316, -4.5302, -4.5484, -4.4075, -4.4770, -4.4495, -4.6966, -4.5237,\n",
      "         -4.5823, -4.8605, -4.3719, -4.7916, -4.8384, -4.4710, -4.6066, -4.4215,\n",
      "         -4.7816, -4.5751, -4.4070, -4.6039, -4.5603, -4.5054, -4.5810, -4.2165,\n",
      "         -4.3272, -4.8762, -4.8161, -4.3565, -4.6067, -4.3847, -4.5611, -4.6508,\n",
      "         -4.8131, -4.7034, -4.7627, -4.8773, -4.5153, -4.3659, -4.3722, -4.5976,\n",
      "         -4.4769, -4.5807, -4.7413, -4.7535, -4.7814, -4.4215, -4.7276, -4.5147,\n",
      "         -4.9478, -4.6386, -4.3544, -4.5934, -4.6654, -4.5216, -4.5202, -4.4751,\n",
      "         -4.3301]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : when\n",
      "target index is: [85] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4724, -4.5535, -4.8534, -4.7632, -4.2379, -4.6452, -4.3038, -4.3784,\n",
      "         -4.8625, -4.5358, -4.9476, -4.4598, -4.7159, -4.6065, -4.4799, -4.5326,\n",
      "         -4.2483, -4.6574, -4.7310, -4.4720, -4.4744, -4.3542, -4.8623, -4.7393,\n",
      "         -4.6280, -5.0768, -4.5090, -4.2506, -4.7775, -4.7600, -4.6983, -4.5766,\n",
      "         -4.7334, -5.0161, -4.4638, -4.7619, -4.3666, -4.5828, -4.8556, -4.3682,\n",
      "         -4.5842, -4.6937, -4.6590, -4.3670, -4.6062, -4.1430, -4.7452, -4.8778,\n",
      "         -4.7197, -4.9556, -4.5717, -4.6539, -4.5297, -3.7987, -4.3864, -4.5807,\n",
      "         -4.5769, -4.5841, -4.5762, -4.6096, -4.6013, -4.4854, -4.4066, -4.5663,\n",
      "         -4.4458, -4.4582, -4.8979, -4.1651, -4.7536, -4.5141, -4.5946, -4.8619,\n",
      "         -4.8452, -4.7871, -4.8837, -5.0055, -4.5054, -4.4044, -4.5263, -4.8606,\n",
      "         -4.5116, -4.4306, -4.6382, -4.7403, -4.9123, -4.0908, -4.9561, -4.9211,\n",
      "         -4.8131, -4.3754, -4.4569, -4.6641, -4.7352, -4.4728, -4.4675, -4.7189,\n",
      "         -4.2655]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thou\n",
      "target index is: [22] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6473, -4.5745, -4.9548, -4.6650, -4.1896, -4.7712, -4.5044, -4.6960,\n",
      "         -4.6366, -4.5290, -4.6897, -4.2454, -4.8034, -4.6885, -4.7319, -4.2974,\n",
      "         -4.7155, -4.6505, -4.8090, -4.5041, -4.7665, -4.1737, -4.8630, -4.5920,\n",
      "         -4.2369, -4.6983, -4.7558, -4.3580, -4.2924, -4.3570, -4.7000, -4.5697,\n",
      "         -4.7690, -4.8146, -4.5883, -4.5216, -4.6193, -4.8284, -4.9503, -4.3358,\n",
      "         -4.8965, -4.1993, -4.6440, -4.5440, -4.4099, -4.4848, -4.5654, -4.8173,\n",
      "         -4.3694, -5.1514, -4.7133, -4.6785, -4.6484, -4.2251, -4.6039, -4.4129,\n",
      "         -4.2406, -4.4983, -4.6296, -4.4074, -4.6667, -4.5455, -4.3257, -4.5491,\n",
      "         -4.7382, -4.4829, -4.5880, -4.4347, -4.7678, -4.2587, -4.2835, -4.6177,\n",
      "         -4.8869, -4.8970, -4.7973, -4.9423, -4.5205, -4.6148, -4.7703, -4.6609,\n",
      "         -4.6292, -4.3916, -4.5441, -4.3795, -4.7063, -4.1841, -4.7201, -4.8631,\n",
      "         -4.8145, -4.4236, -4.8088, -4.6564, -4.5749, -4.5873, -4.6205, -4.6271,\n",
      "         -4.6789]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : art\n",
      "target index is: [15] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3671, -4.4583, -4.7507, -4.9192, -4.2376, -4.7808, -4.5847, -4.3738,\n",
      "         -4.6685, -4.8101, -4.6793, -4.4319, -4.4552, -4.7754, -4.7564, -4.2531,\n",
      "         -4.4920, -4.4906, -4.2637, -4.5796, -4.6049, -4.2299, -4.8615, -4.8753,\n",
      "         -4.2264, -4.7195, -4.4183, -4.5353, -4.1747, -4.5855, -4.5290, -4.8409,\n",
      "         -4.8674, -4.5944, -4.5718, -4.9280, -4.6343, -4.6177, -4.9379, -4.9221,\n",
      "         -4.8262, -4.8468, -4.7634, -4.7874, -4.6315, -4.4719, -4.6504, -4.9591,\n",
      "         -4.5944, -4.6647, -4.4426, -4.7656, -4.5146, -4.5230, -4.7627, -4.6675,\n",
      "         -4.3574, -4.4387, -4.4762, -4.4164, -4.6879, -4.4086, -4.3893, -4.1184,\n",
      "         -4.6304, -4.4569, -4.8305, -4.8144, -4.6263, -4.4555, -4.5076, -4.5012,\n",
      "         -4.9077, -4.7528, -4.6159, -4.8055, -4.4023, -4.4036, -4.7348, -4.6573,\n",
      "         -4.4492, -4.4471, -4.9457, -4.8501, -4.4448, -4.6750, -4.5517, -4.6459,\n",
      "         -4.5312, -4.3743, -4.5375, -4.7077, -4.5860, -4.1651, -4.6729, -4.5235,\n",
      "         -4.4807]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : old,\n",
      "target index is: [8] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4653, -4.5386, -4.9811, -4.6962, -4.3095, -4.7126, -4.5974, -4.3352,\n",
      "         -4.7092, -4.5998, -4.7740, -4.3702, -4.5733, -4.9562, -5.0447, -4.9472,\n",
      "         -4.6814, -4.7650, -4.5786, -4.6578, -4.3249, -4.2927, -4.8122, -4.5881,\n",
      "         -4.3827, -5.1309, -4.2885, -4.7154, -4.6438, -4.6002, -4.6858, -4.7664,\n",
      "         -4.6889, -4.8549, -4.4765, -4.8536, -4.7327, -4.3854, -4.5955, -4.3479,\n",
      "         -4.6369, -4.5651, -4.6313, -4.5583, -4.2737, -4.2932, -4.4682, -4.3896,\n",
      "         -4.4770, -4.9188, -4.7727, -4.2520, -4.9044, -4.3572, -4.3366, -4.3891,\n",
      "         -4.5884, -4.2659, -4.2696, -4.7561, -4.7603, -4.3950, -4.4546, -4.1778,\n",
      "         -4.5093, -4.7523, -4.6866, -4.3956, -4.3789, -4.1692, -4.3808, -4.7122,\n",
      "         -4.6453, -4.8640, -4.9452, -4.9622, -4.4563, -4.3306, -4.7834, -4.8264,\n",
      "         -4.6486, -4.7351, -4.8633, -4.7239, -4.5883, -4.5831, -4.5896, -4.8463,\n",
      "         -5.0287, -4.3214, -4.7750, -4.6864, -4.6733, -4.2754, -4.6505, -4.7036,\n",
      "         -4.2745]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : And\n",
      "target index is: [6] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4848, -4.3530, -4.5046, -4.5639, -4.3362, -5.0172, -4.5528, -4.4581,\n",
      "         -4.6391, -4.7981, -4.8428, -4.3862, -4.5454, -4.6307, -4.6599, -4.7102,\n",
      "         -4.6598, -4.6272, -4.9685, -4.5663, -4.4794, -4.5102, -4.6270, -4.5816,\n",
      "         -4.1983, -4.7063, -4.6099, -4.4264, -4.2753, -4.5252, -4.7154, -4.7759,\n",
      "         -4.6624, -4.7061, -4.6136, -4.5403, -4.7722, -4.5905, -4.5570, -4.4055,\n",
      "         -4.8559, -4.3765, -4.7076, -4.4171, -4.4938, -4.3741, -4.4408, -4.6216,\n",
      "         -4.5317, -4.7816, -4.5337, -4.4575, -4.9292, -4.3192, -4.5923, -4.5343,\n",
      "         -4.4308, -4.5898, -4.5657, -4.8032, -4.6994, -4.4792, -4.5194, -4.3849,\n",
      "         -4.7173, -4.6591, -4.7492, -4.2723, -4.7044, -4.6127, -4.5974, -4.6696,\n",
      "         -4.5296, -4.9540, -4.7958, -4.7979, -4.5776, -4.3052, -4.7784, -4.7701,\n",
      "         -4.2952, -4.4485, -4.5914, -4.7220, -4.5408, -4.3213, -4.6085, -4.7656,\n",
      "         -4.8633, -4.4990, -4.8100, -4.7664, -4.2893, -4.5261, -4.5353, -4.5268,\n",
      "         -4.5132]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : see\n",
      "target index is: [67] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4428, -4.5376, -4.7739, -4.9888, -4.4256, -4.7265, -4.5733, -4.4309,\n",
      "         -4.7899, -4.6100, -5.0482, -4.8569, -4.6625, -4.7292, -4.6817, -4.7200,\n",
      "         -4.5297, -4.5485, -4.7086, -4.3946, -4.7765, -4.7186, -5.0046, -4.7301,\n",
      "         -4.6606, -4.9132, -4.5569, -4.3188, -4.3581, -4.7577, -4.5209, -4.7106,\n",
      "         -5.0334, -4.9009, -4.2804, -4.5800, -4.2339, -4.5630, -4.7263, -4.7397,\n",
      "         -4.7578, -4.6185, -4.5691, -4.6038, -4.5213, -4.0800, -4.7882, -4.7089,\n",
      "         -4.7942, -4.8512, -4.2447, -4.5799, -4.6310, -4.3498, -4.7260, -4.7642,\n",
      "         -4.4055, -4.3369, -4.6309, -4.4499, -4.7612, -4.5842, -4.4441, -4.5832,\n",
      "         -4.5541, -4.4633, -5.1033, -4.4262, -4.5464, -4.6852, -4.2414, -4.1244,\n",
      "         -5.0216, -4.9626, -4.7722, -4.8687, -4.3823, -4.0850, -4.5441, -4.7516,\n",
      "         -4.3068, -4.7161, -4.3540, -4.9501, -4.7429, -4.3431, -4.4724, -4.5169,\n",
      "         -4.7291, -4.2900, -4.2868, -4.5343, -4.9460, -4.3782, -4.4286, -4.5637,\n",
      "         -4.1461]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6547, -4.4034, -4.9690, -4.5716, -4.1974, -4.6612, -4.6705, -4.2362,\n",
      "         -5.1321, -4.3900, -4.7469, -4.1825, -4.3086, -4.6269, -4.7692, -4.8427,\n",
      "         -4.3681, -4.5354, -4.3619, -4.5452, -4.6433, -4.3816, -4.4118, -4.7280,\n",
      "         -4.3928, -5.1742, -4.2710, -4.9272, -4.5589, -4.4929, -4.6574, -4.5696,\n",
      "         -4.8283, -4.6107, -4.6099, -5.0972, -4.5789, -4.5161, -4.6203, -4.7584,\n",
      "         -4.4577, -4.7752, -4.8463, -4.6098, -4.3982, -4.1425, -4.5822, -5.0394,\n",
      "         -5.0119, -4.4733, -4.8286, -4.4266, -4.4377, -4.3010, -4.4320, -4.4875,\n",
      "         -4.6486, -4.2919, -4.3111, -4.5504, -4.7312, -4.7202, -4.4521, -3.9891,\n",
      "         -4.4308, -4.6876, -4.7004, -4.4081, -4.8231, -4.5034, -4.6411, -4.6339,\n",
      "         -4.8723, -4.5440, -4.8404, -4.8708, -4.3426, -4.5054, -4.5296, -4.9148,\n",
      "         -4.6127, -4.4436, -4.7564, -4.7994, -4.8364, -4.5741, -4.7749, -4.7214,\n",
      "         -4.9878, -4.4731, -4.6431, -4.7702, -4.8752, -4.3094, -4.2570, -4.9007,\n",
      "         -4.4152]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : blood\n",
      "target index is: [39] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5712, -4.4742, -4.8942, -4.4941, -4.3671, -4.7589, -4.4322, -4.3722,\n",
      "         -4.8241, -4.7429, -4.9902, -4.4077, -4.7101, -4.4625, -4.5147, -4.8693,\n",
      "         -4.6369, -4.8000, -4.3566, -4.3925, -4.7899, -4.8331, -4.7171, -4.4436,\n",
      "         -4.6521, -5.1354, -4.7635, -4.4796, -4.1659, -4.7208, -4.4813, -4.5291,\n",
      "         -4.7182, -4.6649, -4.6941, -5.3022, -4.3720, -4.7167, -4.4376, -4.2573,\n",
      "         -4.4802, -4.4204, -4.6866, -4.1466, -4.8069, -4.1256, -4.9945, -4.6413,\n",
      "         -4.6926, -4.8743, -4.7780, -4.7429, -4.7205, -4.2536, -4.3589, -4.4952,\n",
      "         -4.2613, -4.1594, -4.7010, -4.7023, -4.6355, -4.2022, -4.5731, -4.3220,\n",
      "         -4.5500, -4.5908, -4.7257, -4.2200, -4.7010, -4.1330, -4.4837, -4.5851,\n",
      "         -5.0325, -5.0534, -4.8894, -5.2790, -5.0955, -3.9872, -4.4762, -4.5714,\n",
      "         -5.0911, -4.6048, -5.0113, -5.0941, -5.2601, -4.0516, -4.4313, -4.4887,\n",
      "         -5.2177, -4.3458, -4.8460, -4.5573, -4.7674, -4.4912, -4.4043, -4.5089,\n",
      "         -4.3044]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : warm\n",
      "target index is: [2] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5542, -4.3829, -4.6681, -4.8079, -4.5710, -4.6379, -4.4566, -4.4526,\n",
      "         -4.7500, -5.0421, -4.9701, -4.7970, -4.7314, -4.7904, -4.6185, -4.5065,\n",
      "         -4.6940, -4.9701, -4.5356, -4.2763, -4.8444, -4.2633, -5.1854, -4.4688,\n",
      "         -4.1553, -4.7012, -4.3863, -4.2772, -4.3531, -4.7064, -4.7189, -4.7831,\n",
      "         -4.9481, -4.8158, -4.5707, -4.4325, -4.8053, -4.9370, -4.8771, -4.6984,\n",
      "         -4.8098, -4.5679, -4.6851, -4.5427, -4.7419, -4.2971, -4.8317, -4.8435,\n",
      "         -4.2301, -4.8827, -4.4540, -4.3827, -4.4263, -4.1230, -4.7053, -4.1821,\n",
      "         -4.4653, -4.1316, -4.6781, -4.6578, -4.7858, -4.7741, -4.3275, -4.3836,\n",
      "         -4.8051, -4.4547, -5.1285, -4.5201, -4.6718, -4.3541, -4.0859, -4.6609,\n",
      "         -4.3845, -4.5612, -4.5448, -4.8062, -4.4867, -4.3246, -4.7697, -4.8207,\n",
      "         -4.4779, -4.8266, -4.7789, -4.5810, -4.3386, -4.6454, -4.7941, -5.0600,\n",
      "         -4.5509, -4.0973, -4.7032, -4.5625, -4.7190, -4.7545, -4.3145, -4.6943,\n",
      "         -4.2500]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : when\n",
      "target index is: [85] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5107, -4.3324, -4.7568, -4.9904, -4.2328, -4.7504, -4.3473, -4.4162,\n",
      "         -4.7093, -4.3581, -4.6566, -4.6556, -4.8217, -4.6471, -4.4596, -4.5013,\n",
      "         -4.2928, -4.6420, -4.7877, -4.6112, -4.5058, -4.4190, -4.8012, -4.6789,\n",
      "         -4.5302, -5.0707, -4.3990, -4.3352, -4.8356, -4.6135, -4.6603, -4.5795,\n",
      "         -4.7544, -4.9291, -4.5920, -4.7070, -4.5337, -4.4139, -4.9101, -4.5282,\n",
      "         -4.5367, -4.9321, -4.6626, -4.3626, -4.4065, -4.3646, -4.6883, -4.7903,\n",
      "         -4.5274, -4.6949, -4.4256, -4.8308, -4.6879, -4.2371, -4.6267, -4.6363,\n",
      "         -4.6194, -4.7621, -4.5217, -4.4726, -4.8034, -4.4665, -4.5272, -4.1193,\n",
      "         -4.5155, -4.4857, -4.7456, -4.3015, -4.5643, -4.6203, -4.7522, -5.0446,\n",
      "         -4.9946, -4.2541, -4.7133, -4.9696, -4.5097, -4.7035, -4.6597, -4.6659,\n",
      "         -4.3352, -4.3106, -4.8689, -4.5789, -4.9333, -4.2009, -5.0828, -4.5494,\n",
      "         -4.6207, -4.2067, -4.3111, -4.7378, -4.7676, -4.2103, -4.5058, -4.5886,\n",
      "         -4.6697]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thou\n",
      "target index is: [22] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6482, -4.5760, -4.9491, -4.6656, -4.1906, -4.7716, -4.4991, -4.6965,\n",
      "         -4.6312, -4.5297, -4.6897, -4.2458, -4.8044, -4.6887, -4.7323, -4.2796,\n",
      "         -4.7158, -4.6511, -4.8099, -4.5054, -4.7672, -4.1741, -4.8554, -4.5926,\n",
      "         -4.2378, -4.6988, -4.7572, -4.3591, -4.2933, -4.3577, -4.7008, -4.5707,\n",
      "         -4.7697, -4.8151, -4.5892, -4.5219, -4.6200, -4.8292, -4.9515, -4.3318,\n",
      "         -4.8974, -4.1991, -4.6445, -4.5445, -4.4110, -4.4859, -4.5665, -4.8180,\n",
      "         -4.3702, -5.1522, -4.7143, -4.6796, -4.6494, -4.2264, -4.6055, -4.4142,\n",
      "         -4.2409, -4.4999, -4.6306, -4.4083, -4.6678, -4.5463, -4.3264, -4.5501,\n",
      "         -4.7384, -4.4828, -4.5883, -4.4299, -4.7690, -4.2596, -4.2843, -4.6186,\n",
      "         -4.8875, -4.8983, -4.7980, -4.9435, -4.5212, -4.6159, -4.7664, -4.6612,\n",
      "         -4.6299, -4.3925, -4.5451, -4.3805, -4.7072, -4.1743, -4.7209, -4.8641,\n",
      "         -4.8162, -4.4247, -4.8102, -4.6571, -4.5757, -4.5887, -4.6216, -4.6274,\n",
      "         -4.6802]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : feel'st\n",
      "target index is: [35] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5192, -4.2121, -4.7165, -4.8735, -4.1346, -4.7443, -4.7245, -4.1806,\n",
      "         -4.7930, -4.4808, -4.6960, -4.6146, -4.7539, -4.8587, -4.6877, -4.5433,\n",
      "         -4.6070, -4.3423, -4.5944, -4.4976, -4.5888, -4.4869, -4.5671, -4.8912,\n",
      "         -4.5807, -4.8137, -4.4260, -4.5200, -4.5462, -4.5240, -4.4867, -4.6575,\n",
      "         -4.8628, -4.6185, -4.3221, -4.9108, -4.5166, -4.8148, -4.7682, -4.7816,\n",
      "         -4.5847, -4.8648, -4.5820, -4.6691, -4.4420, -4.3863, -4.4767, -4.6030,\n",
      "         -4.6861, -4.5481, -4.5776, -4.6843, -4.6307, -4.6214, -4.6697, -4.6198,\n",
      "         -4.5607, -4.3886, -4.3839, -4.5058, -4.9271, -4.6252, -4.5426, -4.1676,\n",
      "         -4.5238, -4.5102, -4.5364, -4.5516, -4.5237, -4.6629, -4.6673, -4.5252,\n",
      "         -4.8674, -4.9692, -4.7292, -4.7279, -4.3573, -4.4594, -4.5731, -4.7348,\n",
      "         -4.5250, -4.4888, -4.7240, -4.8987, -4.7668, -4.4085, -4.3817, -4.5559,\n",
      "         -4.6235, -4.1063, -4.4310, -4.5435, -4.8733, -4.3836, -4.5452, -4.6421,\n",
      "         -4.4905]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : it\n",
      "target index is: [88] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5626, -4.3970, -4.7911, -4.6946, -4.1320, -4.8829, -4.6412, -4.2109,\n",
      "         -4.6322, -4.6324, -4.6745, -4.3398, -4.4937, -4.8421, -4.6826, -4.6131,\n",
      "         -4.5217, -5.0289, -4.5440, -4.6581, -4.6741, -4.3636, -5.0254, -4.6178,\n",
      "         -4.1702, -4.8112, -4.1265, -4.6313, -4.0818, -4.6918, -4.6438, -5.2762,\n",
      "         -5.0617, -4.7255, -4.8893, -5.1004, -4.4904, -4.7031, -4.7479, -4.7418,\n",
      "         -4.9522, -4.4097, -4.6329, -4.6056, -4.5231, -4.2942, -4.6734, -4.8656,\n",
      "         -4.4781, -4.7674, -4.6779, -4.1048, -4.9191, -4.3386, -4.8185, -4.4235,\n",
      "         -4.5385, -4.1555, -4.6542, -4.7053, -4.6264, -4.5895, -4.3004, -4.1162,\n",
      "         -4.7370, -4.8216, -4.7541, -4.6477, -4.5212, -4.2825, -4.1329, -4.3080,\n",
      "         -4.8754, -4.7541, -4.7031, -4.7208, -4.8096, -3.9686, -4.7856, -4.8478,\n",
      "         -4.5765, -4.5477, -4.8719, -4.8038, -4.5038, -4.7320, -4.3746, -4.6152,\n",
      "         -4.7808, -4.6316, -4.9074, -4.7438, -4.7422, -4.2927, -4.5369, -4.6498,\n",
      "         -4.2107]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : cold.\n",
      "target index is: [79] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3929, -4.0966, -4.7880, -4.8540, -4.1021, -5.0375, -4.5040, -4.4901,\n",
      "         -4.8269, -4.4728, -4.7779, -4.5524, -4.6836, -4.7639, -5.0643, -4.7263,\n",
      "         -4.5954, -4.1747, -4.8339, -4.4070, -4.7405, -4.3457, -4.6888, -4.8581,\n",
      "         -4.3740, -4.7600, -4.4489, -4.2436, -4.2281, -4.4688, -4.3618, -4.5924,\n",
      "         -4.6933, -4.7209, -4.5233, -4.5177, -4.6884, -4.7543, -4.7299, -4.6987,\n",
      "         -4.6864, -4.5277, -4.5151, -4.3761, -4.4303, -4.2838, -4.4622, -4.7262,\n",
      "         -4.7402, -5.0437, -4.5507, -4.5958, -4.6826, -4.5436, -4.3664, -4.7743,\n",
      "         -4.4281, -4.4800, -4.3118, -4.6781, -4.8708, -4.4325, -4.6030, -4.4748,\n",
      "         -4.5491, -4.9909, -4.6074, -4.2525, -4.5565, -4.4121, -4.6735, -4.6649,\n",
      "         -4.9136, -5.0429, -4.9314, -4.8405, -4.5080, -4.5748, -4.5907, -4.7380,\n",
      "         -4.2883, -4.4731, -4.6165, -4.6590, -4.8971, -4.2651, -4.7925, -4.5543,\n",
      "         -4.8047, -4.4473, -4.6086, -4.5181, -4.7525, -4.5083, -4.4342, -4.6634,\n",
      "         -4.5966]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : winters\n",
      "target index is: [3] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2737, -4.6693, -4.3930, -4.6579, -4.2003, -4.5907, -4.5315, -4.2506,\n",
      "         -4.7451, -4.9135, -4.9118, -4.7901, -4.5542, -4.2675, -4.5668, -4.3748,\n",
      "         -4.1131, -4.6706, -4.6381, -4.8413, -4.8346, -4.6381, -4.7084, -4.5864,\n",
      "         -4.3997, -4.8939, -4.4616, -4.4743, -4.3718, -4.5674, -4.2737, -5.0470,\n",
      "         -4.9008, -4.6236, -4.9263, -4.8890, -4.5717, -4.7043, -5.0279, -4.6736,\n",
      "         -4.9386, -4.3824, -4.8566, -4.3714, -5.1078, -4.3629, -5.1190, -5.1771,\n",
      "         -4.9060, -4.2594, -4.6330, -4.3899, -4.8294, -4.1330, -4.9552, -4.1512,\n",
      "         -4.2626, -4.1612, -4.8548, -4.4008, -4.2841, -4.6444, -4.4514, -4.1076,\n",
      "         -4.5580, -3.9672, -5.3830, -4.4950, -4.8517, -4.6509, -4.5725, -4.2595,\n",
      "         -4.9455, -4.8678, -4.5943, -5.1632, -4.8775, -4.1448, -4.6209, -4.8047,\n",
      "         -4.3467, -4.5684, -4.6955, -5.0682, -4.7420, -4.3912, -4.6871, -4.6414,\n",
      "         -5.0957, -4.3887, -4.4038, -4.6911, -4.6534, -4.6777, -4.4278, -4.7690,\n",
      "         -4.3713]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : shall\n",
      "target index is: [10] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5371, -4.3389, -5.0924, -4.8568, -4.2338, -4.7552, -4.4087, -4.6835,\n",
      "         -4.7607, -4.4440, -4.7194, -4.3964, -4.8114, -4.6852, -5.0486, -4.5158,\n",
      "         -4.7358, -4.5844, -4.6751, -4.4963, -4.5093, -3.9855, -4.6585, -4.5066,\n",
      "         -4.2087, -4.7811, -4.5922, -4.6013, -4.4350, -4.6126, -4.8635, -4.6702,\n",
      "         -4.6183, -4.8062, -4.6897, -4.4454, -4.9317, -4.5062, -5.0141, -4.3895,\n",
      "         -4.9279, -4.7097, -4.6856, -4.7272, -4.3939, -4.4653, -4.6369, -4.6305,\n",
      "         -4.4189, -5.0788, -4.4736, -4.7497, -4.5998, -4.3117, -4.5037, -4.5189,\n",
      "         -4.6596, -4.5439, -4.2280, -4.5667, -4.7925, -4.4240, -4.2481, -4.1245,\n",
      "         -4.4558, -4.7685, -4.6512, -4.5580, -4.6540, -4.1867, -4.3861, -4.7139,\n",
      "         -4.5424, -4.6724, -4.9229, -4.7731, -4.0704, -4.7573, -4.8065, -4.6905,\n",
      "         -4.4086, -4.5061, -4.9246, -4.6160, -4.5965, -4.4414, -4.8526, -4.9524,\n",
      "         -4.7776, -4.3081, -4.6721, -4.9118, -4.5987, -4.2231, -4.6162, -4.7885,\n",
      "         -4.3793]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : besiege\n",
      "target index is: [75] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3751, -4.5194, -4.3934, -4.7745, -4.0881, -4.7780, -4.5806, -4.2640,\n",
      "         -4.6858, -4.7050, -4.9449, -4.6882, -4.6552, -4.5514, -5.0341, -4.6803,\n",
      "         -4.5813, -4.4359, -4.8313, -4.6020, -4.5665, -4.8709, -4.5894, -4.5683,\n",
      "         -4.3851, -4.7262, -4.6744, -4.5879, -4.2690, -4.3625, -4.4876, -4.6066,\n",
      "         -4.7514, -4.6919, -4.8580, -4.7798, -4.6246, -4.6678, -4.6788, -4.4835,\n",
      "         -4.4752, -4.6802, -4.7616, -4.1514, -4.5078, -4.4771, -4.3509, -4.3945,\n",
      "         -4.5465, -4.5967, -4.5782, -4.3316, -4.7880, -4.3744, -4.7320, -4.5512,\n",
      "         -4.5267, -4.4831, -4.4635, -4.6846, -5.0592, -4.4645, -4.5857, -3.7886,\n",
      "         -4.6812, -4.4540, -4.8265, -4.6433, -4.5395, -4.7582, -4.5675, -4.5483,\n",
      "         -4.7895, -4.9376, -4.7672, -4.7348, -4.7371, -4.2455, -4.7346, -4.8737,\n",
      "         -4.6852, -4.5139, -4.6195, -4.9355, -4.7097, -4.2686, -4.3489, -4.7878,\n",
      "         -5.3079, -4.1732, -4.6994, -4.6737, -4.5139, -4.5891, -4.3286, -4.5798,\n",
      "         -4.8212]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2481, -4.5214, -4.7318, -4.9287, -4.0124, -4.6700, -4.8193, -4.3751,\n",
      "         -5.2624, -4.3252, -4.8709, -4.1395, -4.8459, -4.5847, -4.6959, -4.9957,\n",
      "         -4.9133, -4.6089, -4.5010, -4.4918, -4.4799, -4.5056, -4.7917, -4.5156,\n",
      "         -4.8803, -4.8505, -4.1031, -4.5881, -4.5804, -4.5670, -4.6512, -4.8935,\n",
      "         -4.8833, -4.5706, -4.5359, -5.1781, -4.5645, -4.9856, -4.8215, -4.6646,\n",
      "         -4.8500, -4.9564, -4.8012, -4.5678, -4.6509, -4.3172, -4.8533, -4.8065,\n",
      "         -4.7824, -4.6923, -4.3639, -5.0615, -4.3669, -4.4040, -5.0317, -4.2278,\n",
      "         -4.8002, -4.4716, -4.4661, -4.2290, -4.3071, -4.4331, -4.6455, -3.9033,\n",
      "         -4.3260, -4.6889, -5.0644, -4.5975, -4.6883, -4.7231, -4.3083, -4.7664,\n",
      "         -5.1983, -4.7063, -4.4558, -4.9293, -4.3447, -4.2611, -4.4131, -4.5381,\n",
      "         -4.6520, -4.2732, -4.9650, -4.9650, -4.6565, -4.4153, -4.4274, -4.5228,\n",
      "         -4.8323, -4.5722, -4.0699, -4.4043, -4.6024, -4.4539, -4.1480, -4.6590,\n",
      "         -4.5765]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : brow,\n",
      "target index is: [13] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4351, -4.3060, -4.6389, -4.6327, -4.2842, -4.8641, -4.7425, -4.4208,\n",
      "         -4.7070, -4.7612, -4.8580, -4.5105, -4.8110, -4.3958, -4.7575, -4.8872,\n",
      "         -4.6658, -4.7242, -4.4990, -4.4836, -4.7973, -4.9199, -4.7424, -4.3231,\n",
      "         -4.6066, -4.8125, -4.7212, -4.2619, -4.0968, -4.3645, -4.2403, -4.7439,\n",
      "         -4.8991, -4.5614, -4.9209, -5.0242, -4.5307, -4.8966, -4.3475, -4.3547,\n",
      "         -4.7269, -4.5981, -4.4690, -4.1377, -4.5973, -4.1455, -4.7271, -4.8206,\n",
      "         -4.5959, -4.8135, -4.8703, -4.4726, -4.8995, -4.1269, -4.6031, -4.4063,\n",
      "         -4.3941, -4.0800, -4.7309, -4.6290, -4.8757, -4.4288, -4.5468, -4.1268,\n",
      "         -4.7628, -4.5759, -5.0748, -4.5430, -4.6017, -4.4320, -4.3825, -4.5253,\n",
      "         -4.8330, -4.9239, -4.8143, -5.0310, -5.0771, -3.8835, -4.7978, -5.0024,\n",
      "         -4.9893, -4.5403, -4.7335, -5.0694, -5.0063, -4.3879, -4.3737, -4.5354,\n",
      "         -4.9223, -3.9911, -4.8679, -4.5857, -4.6750, -4.5637, -4.3003, -4.8364,\n",
      "         -4.3049]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : And\n",
      "target index is: [6] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4158, -4.3280, -4.6253, -4.7841, -4.1955, -4.8249, -4.7282, -4.4841,\n",
      "         -4.8400, -4.5792, -4.4666, -4.3390, -4.8979, -4.9718, -4.3749, -4.8574,\n",
      "         -4.8663, -4.9885, -4.4888, -4.4407, -4.4100, -4.3673, -4.7152, -4.6245,\n",
      "         -4.6443, -4.6989, -4.2990, -4.4156, -4.3411, -4.9379, -4.5542, -5.2257,\n",
      "         -4.7490, -4.6349, -4.4544, -4.8222, -4.6667, -4.8991, -4.7756, -4.6185,\n",
      "         -4.8085, -4.9610, -4.8500, -4.7176, -4.7042, -4.4821, -4.5205, -4.6002,\n",
      "         -4.4754, -4.9946, -4.5202, -4.6606, -4.4313, -4.7075, -5.1702, -4.5763,\n",
      "         -4.5562, -4.4771, -4.4683, -4.5877, -4.6130, -4.5858, -4.8810, -4.1925,\n",
      "         -4.9527, -4.6553, -4.9628, -4.5862, -4.6268, -4.6796, -4.0854, -4.8092,\n",
      "         -5.0690, -4.5834, -4.2507, -4.8062, -4.7223, -4.3382, -4.7280, -4.2141,\n",
      "         -4.5822, -4.0201, -4.9193, -4.6828, -4.3705, -4.4392, -4.5147, -4.5250,\n",
      "         -4.7826, -4.3093, -4.5846, -4.5269, -4.2709, -4.0952, -4.1280, -4.4105,\n",
      "         -4.5047]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : dig\n",
      "target index is: [42] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4106, -4.6198, -4.7066, -4.9327, -4.2272, -4.8256, -4.6912, -4.5206,\n",
      "         -4.5284, -4.6655, -4.8580, -4.9803, -4.7432, -4.8184, -4.5473, -4.7164,\n",
      "         -4.6707, -4.7450, -4.6961, -4.4160, -4.8552, -4.4941, -5.0800, -4.6884,\n",
      "         -4.4676, -4.9490, -4.4860, -4.4804, -4.1302, -4.7695, -4.5106, -4.8200,\n",
      "         -4.8827, -4.7990, -4.2428, -4.5049, -4.3794, -4.6799, -4.8236, -4.7007,\n",
      "         -4.8011, -4.4353, -4.7424, -4.6245, -4.6711, -4.2388, -4.8872, -4.4995,\n",
      "         -4.6496, -4.8539, -4.3627, -4.7399, -4.6394, -4.5101, -4.7174, -4.5865,\n",
      "         -4.2106, -4.2674, -4.6189, -4.4184, -4.5669, -4.6766, -4.6654, -4.6067,\n",
      "         -4.6587, -4.3779, -4.9913, -4.5590, -4.6234, -4.7910, -4.2232, -4.1663,\n",
      "         -5.0110, -4.8785, -4.7395, -4.7712, -4.6585, -4.1699, -4.7172, -4.4811,\n",
      "         -4.4134, -4.4810, -4.4928, -4.9819, -4.4934, -4.3554, -4.2983, -4.4378,\n",
      "         -4.6972, -4.1885, -4.4815, -4.4191, -4.7637, -4.4308, -4.5735, -4.4147,\n",
      "         -4.2660]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : deep\n",
      "target index is: [76] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5713, -4.8957, -4.6882, -4.6154, -4.2399, -4.8161, -4.3867, -4.1774,\n",
      "         -4.7159, -5.0091, -4.8067, -4.4326, -4.5668, -4.8754, -4.8180, -4.2924,\n",
      "         -4.2431, -4.8119, -4.4592, -4.9358, -4.4906, -4.2255, -4.6244, -4.7201,\n",
      "         -4.1499, -4.9052, -4.4577, -4.7237, -4.6523, -4.4721, -4.7219, -4.6604,\n",
      "         -4.9092, -4.9015, -4.4039, -4.6186, -4.9661, -4.5067, -5.0128, -4.7211,\n",
      "         -4.8254, -4.6597, -4.8790, -4.5452, -4.4069, -4.3347, -4.5356, -4.6255,\n",
      "         -4.4744, -4.3147, -4.5099, -4.1604, -4.7475, -4.4174, -4.6181, -4.4517,\n",
      "         -4.5213, -4.5605, -4.5065, -4.6415, -5.0359, -4.6782, -4.5353, -3.9315,\n",
      "         -4.6978, -4.4561, -4.8784, -4.4057, -4.6899, -4.5722, -4.3775, -4.6885,\n",
      "         -4.6067, -4.5132, -4.6192, -4.9296, -4.5027, -4.5758, -4.8636, -4.7212,\n",
      "         -4.1463, -4.7650, -4.6956, -4.6301, -4.3470, -4.5563, -4.6708, -5.0575,\n",
      "         -4.9433, -4.3732, -4.5162, -4.7192, -4.6858, -4.4138, -4.4582, -4.4567,\n",
      "         -4.5687]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : trenches\n",
      "target index is: [54] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4702, -4.5226, -4.9257, -5.4002, -4.0793, -4.6501, -4.4404, -4.3984,\n",
      "         -4.8236, -4.4033, -4.8905, -4.3991, -4.8000, -4.8105, -4.9638, -4.7191,\n",
      "         -4.4657, -4.6390, -4.6829, -4.6595, -4.5568, -4.2594, -4.8828, -4.5601,\n",
      "         -4.4517, -4.8812, -4.1668, -4.5645, -4.5879, -4.7083, -4.4858, -5.0426,\n",
      "         -4.9236, -4.9063, -4.5002, -4.5722, -4.3565, -4.7514, -5.0218, -4.6798,\n",
      "         -4.8548, -4.8029, -4.5843, -4.5253, -4.4293, -4.4452, -4.5309, -4.7389,\n",
      "         -4.4068, -5.1727, -4.1469, -4.7628, -4.6455, -4.3788, -4.4798, -4.6705,\n",
      "         -4.9132, -4.6358, -4.2907, -4.4711, -4.6835, -4.3998, -4.4979, -4.1065,\n",
      "         -4.5105, -4.6520, -4.7241, -4.4846, -4.4498, -4.3552, -4.6372, -4.7054,\n",
      "         -5.2008, -4.6298, -4.8425, -5.0719, -4.2775, -4.1998, -4.3652, -4.5476,\n",
      "         -4.5516, -4.5337, -4.6337, -4.5214, -4.6811, -4.4171, -4.5253, -4.6875,\n",
      "         -4.6821, -4.6318, -4.0921, -4.5563, -4.7262, -4.2642, -4.5746, -4.7164,\n",
      "         -4.4989]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : in\n",
      "target index is: [95] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7436, -4.4398, -4.5666, -4.5182, -4.1268, -4.6706, -4.7059, -4.1994,\n",
      "         -4.7479, -4.5741, -4.6529, -4.2531, -4.4513, -4.6966, -4.8343, -4.6545,\n",
      "         -4.5888, -4.7373, -4.2060, -4.5053, -4.5227, -4.5599, -4.5945, -4.6421,\n",
      "         -4.2477, -4.9543, -4.4319, -4.8110, -4.3709, -4.4697, -4.7221, -4.7019,\n",
      "         -4.9229, -4.6785, -4.6130, -5.0734, -4.4838, -4.6533, -4.3187, -4.7004,\n",
      "         -4.5035, -4.5857, -4.9482, -4.6941, -4.5156, -4.3926, -4.4772, -4.9092,\n",
      "         -4.8286, -4.5074, -4.6259, -4.1728, -4.6498, -4.2676, -4.7345, -4.4216,\n",
      "         -4.5298, -4.2755, -4.3370, -4.7196, -4.8102, -4.6612, -4.4972, -4.0775,\n",
      "         -4.7863, -4.4453, -4.7164, -4.5989, -4.7935, -4.8371, -4.4394, -4.5087,\n",
      "         -5.0070, -4.8060, -4.8457, -4.8299, -4.6672, -4.3380, -4.6233, -5.0182,\n",
      "         -4.7795, -4.2338, -4.6851, -4.6877, -4.7261, -4.4171, -4.6482, -4.6796,\n",
      "         -4.8505, -4.2699, -4.9074, -4.7373, -4.6257, -4.3270, -4.4880, -4.6073,\n",
      "         -4.5404]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2503, -4.5173, -5.1254, -4.8404, -4.2692, -4.7134, -4.7843, -4.3576,\n",
      "         -5.2635, -4.2371, -4.9050, -4.2066, -4.4750, -4.3543, -4.9938, -5.0926,\n",
      "         -4.6398, -4.6043, -4.6168, -4.4104, -4.5191, -4.5287, -4.5986, -4.5964,\n",
      "         -4.5623, -5.0597, -4.2743, -4.5188, -4.6000, -4.7525, -4.7369, -4.4951,\n",
      "         -4.9759, -4.7978, -4.8313, -5.3881, -4.6912, -4.5572, -4.6398, -4.3257,\n",
      "         -4.5468, -4.6607, -4.3718, -4.4280, -4.2067, -4.1459, -4.7047, -4.6932,\n",
      "         -4.9548, -4.7921, -4.6136, -4.6921, -4.4260, -4.3643, -4.5011, -4.5450,\n",
      "         -4.5862, -4.3382, -4.4283, -4.6325, -4.6833, -4.4357, -4.3313, -4.2174,\n",
      "         -4.0253, -4.8265, -4.8349, -4.5093, -4.6164, -4.2275, -4.3411, -4.6541,\n",
      "         -4.7677, -4.7432, -4.7967, -4.7254, -4.2743, -4.1840, -4.4406, -4.6971,\n",
      "         -4.7545, -4.7600, -4.8398, -5.0271, -5.0872, -4.4419, -4.6885, -4.5014,\n",
      "         -5.1521, -4.6112, -4.4338, -4.7704, -4.9234, -4.3930, -4.2528, -4.8530,\n",
      "         -4.4616]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty's\n",
      "target index is: [80] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2939, -4.4788, -4.7467, -4.5262, -4.2043, -4.9242, -4.5610, -4.3086,\n",
      "         -4.3886, -5.1201, -4.9704, -4.2115, -4.6784, -4.7233, -4.6058, -4.7418,\n",
      "         -4.8786, -5.1529, -4.5443, -4.4027, -4.9399, -4.7375, -4.6075, -4.4876,\n",
      "         -4.2059, -4.6486, -4.6573, -4.4250, -3.8501, -4.5691, -4.8069, -4.6016,\n",
      "         -4.7211, -4.5688, -4.6374, -5.1383, -4.8578, -4.6211, -4.6656, -4.5080,\n",
      "         -4.6763, -4.2354, -4.9877, -4.0541, -4.5064, -4.0907, -4.4372, -4.4805,\n",
      "         -4.5402, -4.8918, -4.7790, -4.4704, -4.7563, -4.3375, -4.6110, -4.4005,\n",
      "         -4.3077, -4.3164, -4.7300, -5.0457, -4.8310, -4.1816, -4.4670, -4.0943,\n",
      "         -5.0333, -4.8012, -5.0861, -4.6659, -4.8233, -4.6322, -4.2890, -4.7275,\n",
      "         -4.5107, -4.8581, -4.7994, -4.9018, -5.1802, -4.2235, -4.6183, -4.4610,\n",
      "         -4.7731, -4.3160, -5.2153, -4.8058, -4.8633, -4.1021, -4.6074, -5.0105,\n",
      "         -5.0300, -4.5887, -5.2159, -4.4866, -4.5945, -4.4891, -4.2752, -4.3069,\n",
      "         -4.5314]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : field,\n",
      "target index is: [77] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.0320, -4.1554, -4.7724, -5.6493, -4.0628, -5.0866, -4.5475, -4.4387,\n",
      "         -4.8801, -4.8020, -4.6841, -5.1385, -5.0685, -4.8568, -4.6663, -4.8113,\n",
      "         -4.9002, -4.7090, -4.8154, -4.5750, -4.7561, -4.3254, -5.0715, -4.6583,\n",
      "         -4.6165, -4.8609, -4.3106, -4.0456, -4.2134, -4.9105, -4.2801, -4.7812,\n",
      "         -4.7956, -4.6977, -4.4962, -4.9534, -4.7125, -5.0052, -4.9737, -4.8264,\n",
      "         -4.5651, -5.1521, -4.8641, -4.6364, -4.5717, -4.0494, -5.0907, -4.4216,\n",
      "         -4.6088, -5.0146, -3.8248, -5.2323, -4.3954, -4.8009, -4.7894, -4.4995,\n",
      "         -4.5406, -4.3682, -4.4708, -4.2609, -4.7548, -4.4585, -4.4185, -3.7657,\n",
      "         -4.4737, -4.5386, -4.9806, -4.6933, -4.4525, -4.4676, -4.6050, -4.4515,\n",
      "         -5.3901, -4.8379, -4.8052, -4.8864, -4.3838, -4.1506, -4.4617, -4.4955,\n",
      "         -4.5335, -4.3790, -5.2267, -5.2290, -4.5280, -4.4596, -4.2636, -4.8422,\n",
      "         -4.6271, -4.2292, -4.1299, -4.3283, -4.9412, -4.1719, -4.4686, -4.8839,\n",
      "         -4.4680]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Thy\n",
      "target index is: [73] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3046, -4.5941, -4.7242, -4.6594, -4.2247, -4.9355, -4.6450, -4.1482,\n",
      "         -4.7252, -4.9095, -4.6578, -4.2334, -4.3449, -4.7278, -4.6369, -4.3670,\n",
      "         -4.6776, -4.8350, -4.1371, -4.6953, -4.5281, -4.2516, -4.7978, -4.8049,\n",
      "         -4.1442, -4.8527, -4.5763, -4.7177, -4.0303, -4.4520, -4.7763, -4.7101,\n",
      "         -4.8819, -4.5855, -4.7089, -5.1144, -4.9113, -4.5580, -4.7923, -4.9450,\n",
      "         -4.7575, -4.4226, -4.9683, -4.6609, -4.4913, -4.4228, -4.6202, -5.0948,\n",
      "         -4.6988, -4.5064, -4.6177, -4.2948, -4.7737, -4.4915, -4.7956, -4.4854,\n",
      "         -4.2278, -4.1686, -4.5632, -4.4323, -4.8352, -4.4053, -4.4880, -3.9090,\n",
      "         -4.8233, -4.6393, -4.7977, -4.8872, -4.8856, -4.6676, -4.3393, -4.4134,\n",
      "         -4.8717, -4.6909, -4.7728, -4.9085, -4.5921, -4.3624, -4.7476, -4.7296,\n",
      "         -4.4701, -4.3039, -5.1134, -4.6902, -4.3464, -4.7500, -4.7081, -4.6615,\n",
      "         -4.6842, -4.6292, -4.7285, -4.6436, -4.7064, -4.1511, -4.4841, -4.5954,\n",
      "         -4.4813]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : youth's\n",
      "target index is: [89] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2220, -4.7431, -4.7398, -4.8619, -4.1393, -4.7352, -4.8757, -4.5455,\n",
      "         -4.8264, -5.0077, -4.8947, -4.4223, -4.7390, -4.3879, -5.0431, -4.8375,\n",
      "         -4.6797, -4.6708, -4.6514, -4.6476, -4.3795, -4.4859, -4.5416, -4.5381,\n",
      "         -4.3144, -4.7204, -4.6842, -4.7775, -4.4852, -4.3866, -5.0042, -4.3706,\n",
      "         -4.9464, -4.6420, -4.6711, -5.1968, -4.7750, -4.7542, -4.8173, -4.3052,\n",
      "         -4.6377, -4.6585, -4.9063, -4.3444, -4.3074, -4.4940, -4.4815, -4.4055,\n",
      "         -4.5450, -4.4485, -4.3442, -4.8458, -4.4730, -4.2245, -4.3956, -4.4223,\n",
      "         -4.4812, -4.5256, -4.5714, -4.4788, -4.7347, -4.3862, -4.4858, -3.6498,\n",
      "         -4.2884, -4.3417, -4.8772, -4.6232, -4.7471, -4.5901, -4.3486, -4.6611,\n",
      "         -4.9243, -4.8097, -4.8653, -4.6310, -4.4341, -4.3101, -4.7929, -4.2910,\n",
      "         -4.7184, -4.7439, -4.9774, -5.1961, -4.5709, -4.2966, -4.4924, -5.0334,\n",
      "         -5.2621, -4.1914, -4.4585, -4.7269, -4.6446, -4.4828, -4.4226, -4.7100,\n",
      "         -4.8705]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : proud\n",
      "target index is: [50] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5251, -4.3363, -4.9387, -5.0910, -4.3774, -4.6470, -4.3932, -4.5304,\n",
      "         -5.3595, -4.5059, -4.8853, -4.4375, -4.8902, -4.5637, -4.6086, -5.1365,\n",
      "         -4.9458, -4.6963, -4.5277, -4.0581, -4.3914, -4.3798, -4.8897, -4.4867,\n",
      "         -4.9148, -4.9233, -4.4564, -4.3770, -4.7201, -4.8717, -4.7422, -4.6151,\n",
      "         -4.8728, -4.8279, -4.3497, -5.1341, -4.6167, -5.0169, -4.6631, -4.1877,\n",
      "         -4.3745, -4.6269, -4.6430, -4.4387, -4.5964, -4.2273, -4.8587, -4.2910,\n",
      "         -4.4671, -5.3944, -4.2826, -5.1156, -4.2835, -4.4998, -4.5127, -4.5363,\n",
      "         -4.8280, -4.4383, -4.3911, -4.7607, -4.6541, -4.2756, -4.6359, -4.3457,\n",
      "         -4.3548, -4.8665, -4.8970, -4.2468, -4.6348, -4.2684, -4.4460, -4.8540,\n",
      "         -4.9448, -4.9461, -4.5987, -4.8138, -4.5365, -4.2721, -4.2430, -4.1335,\n",
      "         -4.8653, -4.8070, -5.1338, -4.8245, -5.0133, -4.3148, -4.5397, -4.5552,\n",
      "         -4.7190, -4.2977, -4.3780, -4.1629, -4.8823, -4.5113, -4.2262, -4.6230,\n",
      "         -4.2626]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : livery\n",
      "target index is: [28] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6556, -4.4205, -4.9990, -4.7424, -4.0794, -5.1248, -4.4395, -4.3523,\n",
      "         -4.5739, -4.4791, -4.8766, -4.5810, -4.7248, -4.8552, -4.3111, -4.5778,\n",
      "         -4.8037, -5.0213, -4.7642, -4.4136, -4.7918, -4.0888, -5.0566, -4.7885,\n",
      "         -4.2082, -4.9129, -4.1682, -4.4401, -4.1176, -4.8358, -4.9310, -5.1408,\n",
      "         -4.9136, -4.7732, -4.6584, -4.7878, -4.5847, -4.6991, -5.0521, -4.5072,\n",
      "         -4.9490, -4.5378, -4.7823, -4.7491, -4.7913, -4.2928, -4.6525, -4.8834,\n",
      "         -4.4031, -5.0412, -4.3889, -4.6489, -4.5304, -4.2835, -4.6774, -4.3429,\n",
      "         -4.3174, -4.1907, -4.7033, -4.8965, -4.5243, -4.4475, -4.2167, -4.4865,\n",
      "         -4.5853, -4.5697, -4.7373, -4.7335, -4.7092, -4.3390, -4.2441, -4.4351,\n",
      "         -4.8144, -4.9070, -4.6555, -4.9107, -4.6136, -4.1662, -4.6123, -4.5207,\n",
      "         -4.5522, -4.6243, -4.9106, -4.6824, -4.4922, -4.3705, -4.4531, -4.8315,\n",
      "         -4.4518, -4.5209, -4.9341, -4.5706, -4.7559, -4.3010, -4.5108, -4.5054,\n",
      "         -3.9907]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : so\n",
      "target index is: [69] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3995, -4.3062, -4.9252, -4.7977, -4.2618, -5.0274, -4.6314, -4.4016,\n",
      "         -4.5583, -4.6582, -4.7927, -4.8230, -4.4618, -5.0169, -4.8511, -4.6148,\n",
      "         -4.7236, -4.3870, -4.5548, -4.5773, -4.4119, -4.2716, -5.0581, -4.8139,\n",
      "         -4.3145, -4.9256, -4.3769, -4.4956, -4.2137, -4.6712, -4.8368, -4.7783,\n",
      "         -4.9672, -4.9836, -4.6069, -4.7786, -4.8745, -4.4273, -4.8428, -4.6943,\n",
      "         -4.6450, -4.6613, -4.6338, -4.5875, -4.3724, -4.2870, -4.4968, -4.5537,\n",
      "         -4.4977, -4.8942, -4.5829, -4.4730, -4.8302, -4.3610, -4.4737, -4.6922,\n",
      "         -4.2139, -4.3460, -4.3058, -4.6494, -4.8859, -4.5150, -4.1993, -4.1697,\n",
      "         -4.4219, -4.8527, -4.4870, -4.4542, -4.2982, -4.4474, -4.2984, -4.4882,\n",
      "         -4.8047, -4.8648, -4.9898, -4.8469, -4.2717, -4.5004, -5.0040, -4.8158,\n",
      "         -4.3532, -4.6289, -4.8631, -4.7525, -4.7150, -4.3967, -4.5613, -4.6483,\n",
      "         -4.7475, -4.2626, -4.7511, -4.8528, -4.7507, -4.1550, -4.6957, -4.6503,\n",
      "         -4.3140]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : gazed\n",
      "target index is: [17] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4639, -4.3355, -4.6872, -4.7838, -4.3121, -4.6387, -4.5313, -4.3470,\n",
      "         -4.5776, -4.7443, -4.6899, -4.5632, -4.5820, -4.7055, -4.7690, -4.6269,\n",
      "         -4.4410, -4.6671, -4.6477, -4.5122, -4.6779, -4.6138, -4.7236, -4.6080,\n",
      "         -4.3937, -4.8698, -4.4339, -4.5632, -4.3369, -4.6133, -4.4016, -4.8370,\n",
      "         -4.8809, -4.7438, -4.5838, -4.6722, -4.5871, -4.6138, -4.7016, -4.5960,\n",
      "         -4.6963, -4.5906, -4.4371, -4.4272, -4.5732, -4.2802, -4.6830, -4.5672,\n",
      "         -4.4433, -4.5993, -4.5508, -4.2917, -4.8660, -4.4951, -4.6600, -4.3810,\n",
      "         -4.5725, -4.3027, -4.5480, -4.7090, -4.7422, -4.6188, -4.6721, -4.3256,\n",
      "         -4.6392, -4.6177, -4.8173, -4.4643, -4.5702, -4.5175, -4.4681, -4.4566,\n",
      "         -4.5017, -4.8317, -4.7098, -4.8364, -4.6438, -4.1838, -4.8211, -4.8594,\n",
      "         -4.6090, -4.6219, -4.6909, -4.8248, -4.5083, -4.4907, -4.3114, -4.6731,\n",
      "         -4.6846, -4.3062, -4.6752, -4.5505, -4.8031, -4.4964, -4.5801, -4.5442,\n",
      "         -4.5072]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : on\n",
      "target index is: [87] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4800, -4.6591, -4.6070, -4.6206, -4.2337, -4.6132, -4.3855, -4.2676,\n",
      "         -4.6806, -4.7087, -4.6161, -4.7790, -4.7581, -4.5841, -4.6639, -4.4688,\n",
      "         -4.3071, -4.6346, -4.6739, -4.7381, -4.8090, -4.6582, -4.6861, -4.5132,\n",
      "         -4.4450, -4.7555, -4.6041, -4.5084, -4.6195, -4.4175, -4.4615, -4.6726,\n",
      "         -4.7411, -4.7230, -4.7477, -4.6337, -4.7143, -4.6639, -4.9501, -4.5933,\n",
      "         -4.7092, -4.5342, -4.8201, -4.2954, -4.6825, -4.3797, -4.6139, -4.5765,\n",
      "         -4.4494, -4.3486, -4.7515, -4.4204, -5.1041, -4.2753, -4.6372, -4.3041,\n",
      "         -4.2630, -4.3294, -4.6384, -4.5002, -4.7325, -4.7270, -4.4674, -4.0178,\n",
      "         -4.8129, -4.2828, -4.8161, -4.5251, -4.5866, -4.5585, -4.5068, -4.6418,\n",
      "         -4.6889, -4.4319, -4.5811, -4.8109, -4.6722, -4.5387, -4.9237, -4.7949,\n",
      "         -4.4169, -4.4638, -4.7688, -4.6869, -4.6468, -4.4726, -4.6196, -4.7587,\n",
      "         -4.9298, -4.2473, -4.5100, -4.3418, -4.7562, -4.6545, -4.5149, -4.6736,\n",
      "         -4.7886]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : now,\n",
      "target index is: [63] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4526, -4.6102, -4.8469, -4.9176, -3.8152, -4.5128, -4.5296, -4.5355,\n",
      "         -4.6666, -4.6498, -4.5807, -4.3889, -5.0537, -4.8259, -4.7784, -4.5107,\n",
      "         -4.5629, -4.8029, -4.6150, -4.4097, -4.5733, -4.0892, -4.8976, -4.9084,\n",
      "         -4.6379, -4.9755, -4.6819, -4.3387, -4.3358, -4.7713, -4.4313, -5.0092,\n",
      "         -4.7140, -4.6530, -4.2531, -4.8900, -4.4947, -4.8697, -5.0979, -4.7401,\n",
      "         -4.6719, -4.4856, -4.7331, -4.4802, -4.5910, -4.3930, -4.3974, -4.8873,\n",
      "         -4.5459, -5.1340, -4.7737, -4.5854, -4.4956, -4.4790, -4.5713, -4.4577,\n",
      "         -4.2365, -4.4471, -4.4265, -4.5471, -4.5047, -4.5686, -4.8128, -4.3193,\n",
      "         -4.4625, -4.4165, -4.6750, -4.5486, -4.6963, -4.4289, -4.4395, -4.5986,\n",
      "         -5.0219, -4.9094, -4.6262, -4.8467, -4.9774, -4.4355, -4.7237, -4.4519,\n",
      "         -4.6297, -4.0874, -4.9027, -4.8153, -4.3261, -4.3182, -4.5811, -4.5491,\n",
      "         -4.8546, -4.4218, -4.6679, -4.2079, -4.7095, -4.3453, -4.5836, -4.5648,\n",
      "         -4.6100]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Will\n",
      "target index is: [36] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4016, -4.7890, -4.8118, -4.8706, -4.1052, -4.6346, -4.6534, -4.2820,\n",
      "         -4.5403, -4.7409, -4.6192, -4.6574, -4.5939, -4.8607, -4.9240, -4.3011,\n",
      "         -4.4850, -4.5802, -4.3682, -4.5516, -4.8137, -4.1513, -4.9474, -5.0510,\n",
      "         -4.0951, -5.0241, -4.4213, -4.4275, -4.2139, -4.4391, -4.4767, -4.8977,\n",
      "         -5.0358, -4.8841, -4.3626, -4.6752, -4.6171, -4.6591, -5.0838, -4.7867,\n",
      "         -4.9796, -4.5720, -4.4426, -4.6299, -4.6713, -4.3761, -4.6887, -4.6833,\n",
      "         -4.5745, -4.8971, -4.4090, -4.5984, -4.9038, -4.5881, -4.6406, -4.4534,\n",
      "         -4.1131, -4.3040, -4.3144, -4.5285, -4.9755, -4.7241, -4.4755, -4.4652,\n",
      "         -4.5197, -4.4385, -4.6853, -4.5724, -4.7359, -4.6803, -4.2904, -4.3146,\n",
      "         -4.8084, -4.9104, -4.7276, -4.7625, -4.4170, -4.3171, -4.6650, -4.7879,\n",
      "         -4.4692, -4.6559, -4.6370, -4.7246, -4.4341, -4.4869, -4.5492, -4.7951,\n",
      "         -4.6549, -4.3319, -4.6574, -4.5299, -4.8087, -4.4930, -4.8399, -4.3795,\n",
      "         -4.3074]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : be\n",
      "target index is: [24] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3511, -4.6688, -4.7747, -4.7562, -4.1623, -4.9909, -4.5877, -4.3426,\n",
      "         -4.7556, -4.7884, -4.6379, -4.2936, -4.6802, -5.0081, -5.0868, -4.3668,\n",
      "         -4.3933, -4.7565, -4.6853, -4.9847, -4.3681, -3.9621, -4.4937, -4.6743,\n",
      "         -4.1040, -5.0870, -4.3238, -4.7890, -4.4092, -4.5732, -4.3784, -5.2407,\n",
      "         -4.8347, -4.7966, -4.6031, -4.5451, -4.6953, -4.5396, -4.9787, -4.8445,\n",
      "         -5.0287, -4.7324, -4.6342, -4.6784, -4.3731, -4.5074, -4.5250, -4.7580,\n",
      "         -4.6061, -4.6150, -4.7261, -4.0779, -5.0701, -4.4235, -4.6701, -4.6555,\n",
      "         -4.5156, -4.4778, -4.3349, -4.7078, -4.9023, -4.5379, -4.5774, -4.0491,\n",
      "         -4.6758, -4.5052, -4.8639, -4.4173, -4.3112, -4.4068, -4.1918, -4.6641,\n",
      "         -4.9433, -4.7537, -5.0790, -5.1774, -4.4961, -4.2881, -4.8476, -4.8914,\n",
      "         -4.1771, -4.5777, -4.6617, -4.4828, -4.3266, -4.4662, -4.3898, -4.8767,\n",
      "         -5.0057, -4.5298, -4.2042, -4.7618, -4.5491, -4.4234, -4.5472, -4.5898,\n",
      "         -4.5379]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : a\n",
      "target index is: [46] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3836, -4.5173, -4.6609, -5.3664, -4.1439, -4.6991, -4.2700, -4.0502,\n",
      "         -4.7709, -4.5573, -4.8329, -4.9097, -4.3972, -4.7519, -4.6898, -4.3057,\n",
      "         -4.2025, -4.6233, -4.6743, -4.5884, -5.0482, -4.3453, -4.8546, -4.9546,\n",
      "         -4.2991, -5.2787, -4.1922, -4.4253, -4.2945, -4.6509, -4.4733, -4.7521,\n",
      "         -4.8945, -5.0416, -4.4438, -4.6559, -4.5292, -4.3714, -4.9155, -4.5758,\n",
      "         -4.8521, -4.6023, -4.9690, -4.3207, -4.9325, -4.2092, -4.8645, -4.7576,\n",
      "         -4.7223, -4.7780, -4.1536, -4.6314, -4.5614, -4.5083, -4.6475, -4.5753,\n",
      "         -4.3247, -4.5309, -4.3938, -4.7366, -4.8510, -4.7091, -4.4651, -4.3366,\n",
      "         -4.6387, -4.3709, -5.0196, -4.3795, -4.7717, -4.8146, -4.7282, -4.4905,\n",
      "         -4.8867, -4.8431, -4.6670, -4.8821, -4.4332, -4.2843, -4.3241, -4.6980,\n",
      "         -4.3921, -4.6141, -4.7234, -4.7189, -4.8621, -4.3461, -4.6062, -4.7241,\n",
      "         -4.7311, -4.3442, -4.5700, -4.3807, -5.0718, -4.3415, -4.7845, -4.3123,\n",
      "         -4.3115]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : totter'd\n",
      "target index is: [20] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7220, -4.6591, -4.9488, -4.8748, -4.3867, -4.7975, -4.6593, -4.0600,\n",
      "         -4.8760, -4.5995, -4.8347, -4.2690, -4.3192, -4.6838, -4.9906, -4.6090,\n",
      "         -4.7019, -4.4307, -4.3081, -4.7229, -4.5960, -4.3759, -4.6895, -4.8039,\n",
      "         -4.0769, -5.1598, -4.5012, -4.7615, -4.1674, -4.3206, -4.5037, -4.7871,\n",
      "         -4.8191, -4.8857, -4.8725, -5.1894, -4.6464, -4.5089, -4.7798, -4.5435,\n",
      "         -4.7351, -4.7513, -4.6900, -4.6405, -4.6162, -4.4289, -4.8341, -4.8168,\n",
      "         -4.8073, -4.7030, -4.3764, -4.4917, -4.8320, -4.5336, -4.5456, -4.4244,\n",
      "         -4.3937, -4.2410, -4.2643, -4.4077, -4.7762, -4.4706, -4.5120, -3.9254,\n",
      "         -4.5405, -4.6384, -4.4372, -4.6804, -4.6293, -4.0341, -4.4048, -4.2870,\n",
      "         -5.0602, -4.8429, -5.0043, -5.0166, -4.3021, -4.3294, -4.3938, -4.9124,\n",
      "         -4.6790, -4.5884, -4.9787, -4.6201, -4.8365, -4.5587, -4.6355, -4.6923,\n",
      "         -4.8137, -4.4436, -4.5495, -4.7011, -4.8279, -4.1165, -4.6806, -4.6981,\n",
      "         -4.3020]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : weed\n",
      "target index is: [29] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6163, -4.7256, -4.5405, -4.6676, -4.1448, -4.7580, -4.5413, -4.3273,\n",
      "         -4.6827, -4.8063, -4.6527, -4.6480, -4.6846, -4.7983, -5.0435, -4.8081,\n",
      "         -4.4211, -4.4214, -4.4431, -4.5736, -4.5559, -4.6579, -4.7077, -4.4693,\n",
      "         -4.2061, -4.8311, -4.5491, -4.7162, -4.5562, -4.4690, -4.2995, -4.5945,\n",
      "         -4.5510, -4.7411, -4.6350, -4.7237, -4.3887, -4.5764, -4.3822, -4.6055,\n",
      "         -4.6257, -4.6855, -4.8050, -4.6134, -4.5194, -4.2722, -4.2384, -4.5276,\n",
      "         -4.6610, -4.4828, -4.7323, -4.3202, -4.8742, -4.3833, -4.4500, -4.5276,\n",
      "         -4.4475, -4.2953, -4.3168, -4.6600, -5.0209, -4.5222, -4.5234, -4.2142,\n",
      "         -4.8440, -4.6770, -4.6528, -4.6093, -4.4989, -4.4807, -4.5530, -4.6444,\n",
      "         -4.8304, -4.9239, -4.8301, -4.7828, -4.6132, -4.2418, -4.8745, -4.8857,\n",
      "         -4.7005, -4.5361, -4.6429, -4.5706, -4.7188, -4.5255, -4.4372, -4.7856,\n",
      "         -4.9802, -4.1602, -4.7008, -4.4938, -4.6627, -4.4883, -4.5400, -4.7835,\n",
      "         -4.6027]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : of\n",
      "target index is: [57] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5344, -4.4020, -4.3651, -4.6243, -3.9121, -4.7291, -5.0019, -4.4823,\n",
      "         -4.7177, -4.6062, -4.6319, -4.2424, -4.8615, -4.8075, -4.6314, -4.5620,\n",
      "         -4.5672, -4.9383, -4.4633, -4.7869, -4.4246, -4.1679, -4.5736, -4.4650,\n",
      "         -4.3943, -4.7350, -4.4420, -4.7021, -4.3875, -4.6134, -4.4560, -5.2687,\n",
      "         -4.7172, -4.2980, -4.6579, -5.0059, -4.5855, -4.8926, -4.5723, -4.8792,\n",
      "         -4.7113, -4.7989, -4.8138, -4.6644, -4.4806, -4.4180, -4.4574, -4.9473,\n",
      "         -4.8222, -4.4473, -4.6356, -4.4641, -4.8342, -4.3041, -4.9812, -4.5016,\n",
      "         -4.6501, -4.4205, -4.4872, -4.4438, -4.7470, -4.7958, -4.7110, -3.8038,\n",
      "         -4.7782, -4.6361, -5.0331, -4.6417, -4.6213, -4.7495, -4.3107, -4.5344,\n",
      "         -4.9749, -4.6876, -4.6459, -4.7678, -4.7320, -4.4408, -4.7730, -4.8962,\n",
      "         -4.6366, -4.0746, -4.8219, -4.7598, -4.4339, -4.5735, -4.4011, -4.5739,\n",
      "         -4.9112, -4.1715, -4.6148, -4.7432, -4.5517, -4.4572, -4.0739, -4.8048,\n",
      "         -4.4412]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : small\n",
      "target index is: [38] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3532, -4.2930, -4.6551, -4.8469, -4.3029, -4.7445, -4.5694, -4.5237,\n",
      "         -4.6885, -4.9235, -4.8672, -4.6279, -4.7748, -4.4905, -4.2980, -4.7561,\n",
      "         -4.8165, -5.0164, -4.6023, -4.2559, -4.8074, -4.5543, -4.6717, -4.4198,\n",
      "         -4.7282, -5.0912, -4.7314, -4.4238, -4.1008, -4.5982, -4.4666, -4.9959,\n",
      "         -4.7731, -4.6594, -4.4453, -4.8615, -4.7604, -4.8399, -4.9015, -4.4042,\n",
      "         -4.6272, -4.5810, -4.8892, -4.1346, -4.8718, -4.1510, -4.9948, -4.4106,\n",
      "         -4.4383, -4.8541, -4.9110, -4.6933, -4.7729, -4.4461, -4.6254, -4.6457,\n",
      "         -4.2646, -4.2483, -4.6366, -4.6526, -4.6039, -4.7084, -4.8245, -4.2732,\n",
      "         -4.9674, -4.4792, -5.1482, -4.2307, -4.6846, -4.7701, -4.2103, -4.6617,\n",
      "         -4.7776, -4.6731, -4.8369, -4.7033, -5.1074, -4.3221, -4.6431, -4.2047,\n",
      "         -4.6906, -4.4126, -4.7934, -4.9346, -4.6354, -4.0907, -4.3207, -4.4218,\n",
      "         -5.0252, -4.2127, -4.5502, -4.2571, -4.6573, -4.5939, -4.2403, -4.3873,\n",
      "         -4.3348]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : worth\n",
      "target index is: [83] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7031, -4.6270, -4.7579, -5.0453, -4.2416, -4.8371, -4.3540, -4.5108,\n",
      "         -4.6992, -4.7151, -5.0662, -4.8156, -4.9012, -4.8024, -4.4475, -4.5374,\n",
      "         -4.5282, -4.8509, -4.6053, -4.3534, -4.7812, -3.9420, -5.1702, -4.6927,\n",
      "         -4.1735, -5.1145, -4.2280, -4.0640, -4.5678, -4.5769, -4.9992, -4.9186,\n",
      "         -5.0559, -4.9124, -4.5448, -4.2974, -4.8072, -4.9104, -5.1890, -4.6685,\n",
      "         -4.9648, -5.1868, -4.7889, -4.6263, -4.7549, -4.4944, -4.7952, -4.9997,\n",
      "         -4.2800, -4.9091, -3.9276, -4.7720, -4.2079, -3.8842, -4.9827, -4.0479,\n",
      "         -4.8373, -4.4218, -4.5070, -4.5430, -4.7847, -4.7783, -4.5576, -4.1582,\n",
      "         -4.8480, -4.1865, -5.0703, -4.5451, -4.8515, -4.5966, -4.2063, -4.7321,\n",
      "         -4.8822, -4.2681, -4.4808, -5.0489, -4.4624, -4.4284, -4.8910, -4.7213,\n",
      "         -4.2410, -4.3443, -4.7894, -4.4725, -4.2718, -4.2900, -5.0506, -5.2521,\n",
      "         -4.5156, -4.2445, -4.5487, -4.7038, -4.5260, -4.3318, -4.4053, -4.8121,\n",
      "         -4.3092]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : held:\n",
      "target index is: [19] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3956, -4.3830, -5.0625, -5.0722, -4.0204, -4.9019, -4.3665, -4.5555,\n",
      "         -4.6536, -4.1602, -5.0436, -4.6158, -4.8723, -4.7423, -4.4211, -4.6563,\n",
      "         -4.6088, -4.6866, -4.9870, -4.4831, -4.3739, -4.3788, -4.9968, -4.7259,\n",
      "         -4.8182, -5.2084, -4.4411, -4.4395, -4.6052, -4.6566, -4.7504, -4.6382,\n",
      "         -4.7388, -5.1985, -4.5919, -4.6000, -4.4909, -4.6330, -4.9685, -4.2488,\n",
      "         -4.5869, -4.5944, -4.4798, -4.2482, -4.2728, -4.5795, -4.6781, -4.5433,\n",
      "         -4.2086, -5.3396, -4.3562, -4.9872, -4.7302, -4.3522, -4.7403, -4.5748,\n",
      "         -4.5947, -4.6295, -4.5093, -4.5813, -4.6457, -4.3763, -4.4251, -4.4573,\n",
      "         -4.4477, -4.6817, -4.6929, -4.2978, -4.5736, -4.3496, -4.5786, -4.9544,\n",
      "         -4.8524, -4.5655, -4.8732, -5.3257, -4.1982, -4.7738, -4.6608, -4.7508,\n",
      "         -4.6521, -4.2307, -4.8012, -4.5414, -5.3070, -3.9169, -5.0923, -4.5535,\n",
      "         -4.7149, -4.0187, -4.5719, -4.8284, -4.8108, -4.1375, -4.6221, -4.2982,\n",
      "         -4.2607]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Then\n",
      "target index is: [65] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3941, -4.5001, -4.8971, -4.7469, -3.9501, -4.8665, -4.6484, -4.7376,\n",
      "         -4.8132, -4.6352, -4.7201, -4.6116, -4.7824, -4.6864, -4.7596, -4.5842,\n",
      "         -4.5368, -4.6818, -5.1206, -4.7315, -4.5904, -4.2221, -4.9340, -4.3305,\n",
      "         -4.4185, -4.7360, -4.7829, -4.2825, -4.3199, -4.3967, -4.6745, -4.5547,\n",
      "         -4.8233, -4.8817, -4.5359, -4.2682, -4.6655, -5.0134, -4.9968, -4.4341,\n",
      "         -4.8883, -4.4035, -4.5214, -4.3554, -4.3014, -4.3470, -4.5101, -4.7136,\n",
      "         -4.3282, -4.9884, -4.6772, -4.5305, -4.9720, -4.0187, -4.5709, -4.3973,\n",
      "         -4.2842, -4.4480, -4.7090, -4.3395, -4.7612, -4.6154, -4.4932, -4.3872,\n",
      "         -4.6726, -4.5760, -4.7588, -4.2730, -4.6062, -4.4586, -4.4095, -4.7109,\n",
      "         -4.8188, -4.7764, -4.9266, -4.9790, -4.4588, -4.5163, -5.0684, -5.0010,\n",
      "         -4.4900, -4.2134, -4.4246, -4.5113, -4.8050, -4.0591, -4.8115, -5.0200,\n",
      "         -4.8542, -4.1038, -4.7202, -4.9188, -4.5393, -4.4093, -4.5052, -4.8728,\n",
      "         -4.6999]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : being\n",
      "target index is: [32] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3834, -4.2601, -4.6175, -5.0636, -4.1678, -4.3826, -4.5181, -4.1167,\n",
      "         -4.9734, -4.4482, -4.8327, -4.3400, -4.6617, -4.4162, -5.0165, -4.4090,\n",
      "         -4.4396, -4.4732, -4.6904, -4.0553, -4.8300, -4.7633, -4.5158, -4.5669,\n",
      "         -4.8971, -4.5753, -4.6346, -4.5298, -4.4143, -4.7770, -4.2636, -4.8261,\n",
      "         -4.9012, -4.5693, -4.5207, -4.7960, -4.4921, -4.9779, -4.9235, -4.8160,\n",
      "         -4.6947, -4.7244, -4.5136, -4.1847, -4.4625, -4.1284, -4.7238, -4.7297,\n",
      "         -4.7686, -4.6793, -4.7025, -4.3744, -4.5340, -4.5250, -4.9919, -4.6801,\n",
      "         -4.5613, -4.6242, -4.5142, -4.5616, -4.9029, -4.8407, -4.7710, -4.2229,\n",
      "         -4.5702, -4.5246, -4.9840, -4.4929, -4.6635, -4.8678, -4.5474, -4.6581,\n",
      "         -4.6800, -5.0917, -4.3810, -4.5416, -4.6340, -4.4048, -4.5814, -4.6838,\n",
      "         -4.6614, -4.4121, -4.4433, -4.8977, -4.8075, -4.4609, -4.3596, -4.2067,\n",
      "         -5.0865, -4.3750, -4.6716, -4.4061, -4.9975, -4.5010, -4.4216, -4.4004,\n",
      "         -4.6741]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : asked,\n",
      "target index is: [23] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2078, -4.6077, -4.5080, -4.6389, -4.1244, -4.8260, -4.6950, -4.3777,\n",
      "         -4.6626, -4.5903, -4.6543, -4.3277, -4.6500, -4.7043, -4.6757, -4.7859,\n",
      "         -4.7288, -5.0668, -4.4370, -4.8100, -4.5317, -4.4823, -4.7283, -4.5933,\n",
      "         -4.4143, -4.8493, -4.5342, -4.4941, -4.3189, -4.5487, -4.5900, -4.8107,\n",
      "         -4.6635, -4.5711, -4.7167, -5.0469, -4.5743, -4.4472, -4.5130, -4.6480,\n",
      "         -4.7506, -4.4060, -4.6550, -4.4898, -4.3994, -4.1926, -4.6470, -4.8669,\n",
      "         -4.7843, -4.5081, -4.5923, -4.3673, -4.8956, -4.4384, -4.8092, -4.3761,\n",
      "         -4.5818, -4.2835, -4.3669, -4.6306, -4.7090, -4.5102, -4.6161, -3.9558,\n",
      "         -4.7824, -4.6169, -4.9455, -4.6691, -4.8638, -4.6376, -4.5127, -4.5935,\n",
      "         -4.9164, -4.5130, -4.6463, -4.9552, -4.7609, -4.2751, -4.6324, -4.9371,\n",
      "         -4.5844, -4.1849, -4.9089, -4.6210, -4.4095, -4.5275, -4.6293, -4.5425,\n",
      "         -5.0194, -4.4425, -4.5328, -4.5092, -4.6403, -4.6249, -4.2706, -4.7008,\n",
      "         -4.4378]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : where\n",
      "target index is: [51] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3740, -4.2831, -4.6731, -4.9590, -4.2569, -4.9371, -4.7567, -4.6465,\n",
      "         -4.8765, -4.6455, -4.9535, -4.5944, -4.8334, -4.6296, -4.6383, -4.9508,\n",
      "         -4.6776, -4.5884, -4.9211, -4.5220, -4.6501, -4.5576, -4.8628, -4.5141,\n",
      "         -4.5884, -4.7478, -4.3662, -4.3863, -4.2891, -4.6375, -4.3248, -4.9276,\n",
      "         -4.7351, -4.6555, -4.5130, -4.9781, -4.4651, -4.6651, -4.7818, -4.5551,\n",
      "         -4.6105, -4.7004, -4.6290, -4.5682, -4.5562, -4.1301, -4.7888, -4.5654,\n",
      "         -4.7499, -4.7871, -4.2387, -4.8999, -4.7121, -4.4952, -4.4865, -4.6908,\n",
      "         -4.5375, -4.4031, -4.5650, -4.5379, -4.5477, -4.4428, -4.5134, -4.3618,\n",
      "         -4.4798, -4.7982, -5.0330, -4.2938, -4.3951, -4.3292, -4.6674, -4.4839,\n",
      "         -5.0733, -4.9847, -4.8442, -4.9424, -4.6155, -4.2145, -4.4484, -4.5043,\n",
      "         -4.4280, -4.3833, -4.7434, -4.8945, -4.8357, -4.2501, -4.3257, -4.4805,\n",
      "         -4.7679, -4.4026, -4.2230, -4.7023, -4.6969, -4.3534, -4.2569, -4.5801,\n",
      "         -4.2106]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : all\n",
      "target index is: [52] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4759, -4.2713, -4.6775, -4.7898, -4.4207, -4.8227, -4.4635, -4.4528,\n",
      "         -4.5416, -4.8751, -5.0048, -4.7081, -4.4974, -4.6073, -4.5927, -4.6389,\n",
      "         -4.6361, -4.7310, -4.5897, -4.2227, -4.8069, -4.7526, -4.7359, -4.4884,\n",
      "         -4.3844, -4.8630, -4.4860, -4.4930, -4.1964, -4.8237, -4.4783, -4.7719,\n",
      "         -4.8644, -4.8256, -4.4864, -4.5424, -4.6083, -4.4838, -4.6561, -4.6072,\n",
      "         -4.7246, -4.6032, -4.7410, -4.4862, -4.7916, -4.1861, -4.8230, -4.6364,\n",
      "         -4.5656, -4.8188, -4.4329, -4.4512, -4.6121, -4.3037, -4.7114, -4.5472,\n",
      "         -4.3763, -4.3847, -4.5885, -4.7443, -4.7726, -4.7189, -4.5666, -4.5517,\n",
      "         -4.7992, -4.5272, -5.0826, -4.3612, -4.6386, -4.6537, -4.4358, -4.4862,\n",
      "         -4.5518, -4.8968, -4.6288, -4.6542, -4.5934, -4.2195, -4.5408, -4.6628,\n",
      "         -4.5160, -4.5794, -4.6415, -4.8307, -4.6429, -4.3289, -4.4694, -4.5788,\n",
      "         -4.7098, -4.3133, -4.6654, -4.6415, -4.6534, -4.5190, -4.3333, -4.4545,\n",
      "         -4.2120]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4204, -4.3551, -4.9425, -4.7836, -4.2701, -4.7817, -4.8768, -4.3867,\n",
      "         -5.0855, -4.2658, -5.0062, -4.3736, -4.5181, -4.6594, -4.6558, -4.8035,\n",
      "         -4.5438, -4.4430, -4.4570, -4.4980, -4.6431, -4.3520, -4.5656, -4.7868,\n",
      "         -4.4384, -5.0753, -4.3458, -4.5242, -4.4850, -4.4987, -4.7071, -4.6636,\n",
      "         -4.8349, -4.6401, -4.8899, -5.0788, -4.6800, -4.6350, -4.8874, -4.6334,\n",
      "         -4.6382, -4.7580, -4.6705, -4.5962, -4.5188, -4.1116, -4.8083, -4.7076,\n",
      "         -4.8771, -4.6615, -4.7511, -4.7664, -4.5767, -4.2687, -4.4618, -4.7727,\n",
      "         -4.3102, -4.3924, -4.4510, -4.5458, -4.7049, -4.5591, -4.2769, -4.2830,\n",
      "         -4.2211, -4.7482, -4.7105, -4.2261, -4.6027, -4.3706, -4.4281, -4.5793,\n",
      "         -4.8021, -4.6080, -4.7783, -4.7383, -4.2269, -4.4513, -4.3973, -4.7048,\n",
      "         -4.4773, -4.5553, -4.7980, -5.0430, -4.8660, -4.4536, -4.7426, -4.6220,\n",
      "         -4.8936, -4.4665, -4.5143, -4.7818, -4.8220, -4.3233, -4.0523, -4.8336,\n",
      "         -4.3690]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty\n",
      "target index is: [0] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3958, -4.6694, -4.7989, -4.9168, -4.2163, -4.6823, -4.4269, -4.2135,\n",
      "         -5.1084, -4.4867, -4.8050, -4.4041, -4.3021, -4.6134, -4.8324, -5.0848,\n",
      "         -4.6799, -4.5609, -4.6687, -4.4988, -4.7689, -4.7244, -4.9033, -4.6359,\n",
      "         -4.4754, -5.1875, -4.3446, -4.4328, -4.2212, -4.6914, -4.5135, -4.3331,\n",
      "         -4.7147, -4.9049, -4.6729, -5.1486, -4.3221, -4.5370, -4.3805, -4.3845,\n",
      "         -4.5428, -4.3709, -4.6273, -4.3005, -4.5361, -4.0635, -4.8912, -4.5881,\n",
      "         -4.8700, -4.7928, -4.5024, -4.6757, -4.8347, -4.5219, -4.5613, -4.5665,\n",
      "         -4.4506, -4.4021, -4.4989, -4.4715, -4.7088, -4.4252, -4.3813, -4.3942,\n",
      "         -4.2997, -5.0124, -4.8112, -4.4115, -4.7752, -4.0287, -4.5661, -4.4626,\n",
      "         -5.0972, -4.9255, -4.7634, -4.7430, -4.5939, -3.9051, -4.3801, -4.7831,\n",
      "         -4.6916, -4.7714, -4.8408, -4.9264, -5.1281, -4.3099, -4.5557, -4.3841,\n",
      "         -5.3255, -4.8405, -4.7682, -4.5636, -4.8853, -4.3511, -4.5138, -4.7953,\n",
      "         -4.2575]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : lies,\n",
      "target index is: [59] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2919, -4.6511, -4.6592, -4.6660, -4.1903, -4.8815, -4.4463, -4.2404,\n",
      "         -4.6636, -5.1524, -4.7715, -4.4050, -4.5361, -4.7945, -4.7724, -4.6492,\n",
      "         -4.4602, -4.9517, -4.8305, -4.9106, -4.4334, -4.4999, -4.7057, -4.5054,\n",
      "         -4.1539, -4.8721, -4.5012, -4.4013, -4.3474, -4.5920, -4.6157, -4.6986,\n",
      "         -4.5304, -5.1066, -4.4947, -4.6449, -4.8953, -4.3134, -4.6790, -4.3745,\n",
      "         -5.0402, -4.2404, -4.7525, -4.4151, -4.4768, -4.1675, -4.4883, -4.5887,\n",
      "         -4.5497, -4.5437, -4.5959, -4.1684, -5.0350, -4.3694, -4.7112, -4.3136,\n",
      "         -4.5765, -4.4855, -4.7496, -4.7768, -4.6664, -4.2876, -4.5207, -4.3478,\n",
      "         -4.6790, -4.6624, -4.7059, -4.3642, -4.6701, -4.4313, -4.4244, -4.6510,\n",
      "         -4.4763, -4.9544, -4.8703, -4.9240, -4.6370, -4.1391, -4.7958, -5.0578,\n",
      "         -4.3993, -4.7196, -4.6856, -4.7898, -4.4235, -4.4511, -4.4601, -5.0383,\n",
      "         -4.9934, -4.5165, -4.7229, -4.6914, -4.4272, -4.6213, -4.7088, -4.5715,\n",
      "         -4.4371]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Where\n",
      "target index is: [18] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5581, -4.4170, -4.3740, -4.5908, -4.2220, -4.9763, -4.7733, -4.4999,\n",
      "         -4.6682, -4.7660, -4.6983, -4.4897, -4.7132, -4.7746, -4.5616, -4.5526,\n",
      "         -4.8544, -4.5963, -4.5602, -4.6151, -4.3778, -4.3079, -4.7707, -4.6378,\n",
      "         -4.3960, -4.7775, -4.6639, -4.4629, -4.3420, -4.5547, -4.7079, -4.6563,\n",
      "         -4.8433, -4.5700, -4.6537, -4.8979, -4.5686, -4.8939, -4.5009, -4.5116,\n",
      "         -4.6614, -4.6597, -4.8528, -4.5243, -4.6457, -4.4001, -4.5567, -4.6732,\n",
      "         -4.4848, -4.8326, -4.5023, -4.8255, -4.5813, -4.6066, -4.7213, -4.7489,\n",
      "         -4.2746, -4.4475, -4.3954, -4.4972, -4.8224, -4.7965, -4.5014, -4.1907,\n",
      "         -4.8980, -4.4334, -4.9217, -4.3600, -4.5775, -4.6999, -4.2975, -4.4503,\n",
      "         -4.8505, -4.9344, -4.8206, -4.7773, -4.2979, -4.3092, -4.8394, -4.5495,\n",
      "         -4.4741, -4.2830, -4.6237, -4.7484, -4.6252, -4.4511, -4.3875, -4.6952,\n",
      "         -4.7770, -4.2395, -4.5545, -4.7112, -4.5615, -4.4194, -4.2592, -4.5021,\n",
      "         -4.5410]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : all\n",
      "target index is: [52] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2930, -4.2332, -4.6161, -4.9250, -4.3209, -4.6025, -4.5728, -4.4589,\n",
      "         -4.7910, -4.9626, -4.8498, -4.4908, -4.7438, -4.6660, -4.4997, -4.7380,\n",
      "         -4.7440, -5.0369, -4.4012, -4.1873, -4.7667, -4.4026, -4.7210, -4.4810,\n",
      "         -4.6088, -4.7361, -4.3967, -4.4741, -4.2077, -4.9777, -4.4489, -4.9366,\n",
      "         -4.8474, -4.6472, -4.3079, -4.7096, -4.5676, -4.7909, -4.7931, -4.7135,\n",
      "         -4.6576, -4.6312, -4.8461, -4.5718, -4.8964, -4.2376, -5.0100, -4.6353,\n",
      "         -4.6184, -4.8662, -4.4222, -4.6401, -4.4182, -4.4997, -5.0030, -4.6056,\n",
      "         -4.6183, -4.4651, -4.6058, -4.7820, -4.5558, -4.6086, -4.6901, -4.3848,\n",
      "         -4.9707, -4.4454, -5.1278, -4.5933, -4.7609, -4.6858, -4.3192, -4.5312,\n",
      "         -4.5807, -4.8314, -4.3902, -4.6183, -4.6955, -4.1765, -4.4829, -4.4061,\n",
      "         -4.4990, -4.4346, -4.8057, -4.8837, -4.4319, -4.4370, -4.3468, -4.5464,\n",
      "         -4.7275, -4.2617, -4.5043, -4.4134, -4.7318, -4.5267, -4.1353, -4.4159,\n",
      "         -4.3473]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : the\n",
      "target index is: [82] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1711, -4.4003, -4.5582, -4.8773, -4.1778, -4.6920, -4.6741, -4.3333,\n",
      "         -4.6283, -4.7037, -4.8793, -4.7324, -4.6363, -4.8036, -4.7019, -4.6509,\n",
      "         -4.4273, -4.5090, -4.4390, -4.6518, -4.8791, -4.4986, -4.8369, -4.6014,\n",
      "         -4.2178, -4.4990, -4.5418, -4.4828, -4.4373, -4.4905, -4.5572, -4.7073,\n",
      "         -4.5603, -4.6464, -4.8769, -4.7714, -4.8381, -4.5464, -4.8664, -4.8021,\n",
      "         -4.6984, -4.5487, -4.7666, -4.3508, -4.6025, -4.1666, -4.6169, -4.5212,\n",
      "         -4.5611, -4.4587, -4.5023, -4.5928, -4.9640, -4.4244, -4.5139, -4.6665,\n",
      "         -4.4302, -4.5309, -4.4126, -4.5639, -5.1427, -4.7238, -4.3883, -4.0289,\n",
      "         -4.8565, -4.7299, -4.7345, -4.4920, -4.6618, -4.7187, -4.7097, -4.6081,\n",
      "         -4.4924, -4.5601, -4.5191, -4.5334, -4.4141, -4.4755, -4.6835, -4.7973,\n",
      "         -4.2537, -4.3350, -4.8691, -4.7738, -4.5765, -4.5716, -4.7628, -4.7990,\n",
      "         -4.9133, -4.3549, -4.6189, -4.5198, -4.6532, -4.5377, -4.3365, -4.6038,\n",
      "         -4.6018]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : treasure\n",
      "target index is: [31] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3856, -4.3549, -4.7257, -4.9659, -4.1145, -4.7614, -4.6736, -4.5760,\n",
      "         -4.7623, -4.5637, -4.6190, -4.2724, -4.8193, -4.8102, -4.8121, -4.8155,\n",
      "         -4.4607, -4.7438, -4.6851, -4.5493, -4.5232, -4.4608, -4.9033, -4.6117,\n",
      "         -4.7495, -4.9754, -4.2860, -4.4394, -4.2861, -4.8920, -4.2485, -5.0113,\n",
      "         -4.6641, -4.5688, -4.4977, -5.0344, -4.3922, -4.6879, -4.7264, -4.7713,\n",
      "         -4.5746, -4.7498, -4.5290, -4.3519, -4.5556, -4.2618, -4.6529, -4.6927,\n",
      "         -4.7491, -4.8996, -4.2942, -4.7662, -4.7592, -4.8232, -4.6847, -4.3851,\n",
      "         -4.5588, -4.2701, -4.4843, -4.6142, -4.5097, -4.3513, -4.7828, -4.2034,\n",
      "         -4.4752, -4.6303, -5.0806, -4.6775, -4.2606, -4.3152, -4.7211, -4.7049,\n",
      "         -4.8714, -4.8663, -4.7536, -5.0162, -4.7060, -4.2720, -4.6204, -4.5551,\n",
      "         -4.6559, -4.1798, -4.8110, -4.9810, -4.6586, -4.4473, -4.3187, -4.2824,\n",
      "         -4.7383, -4.5234, -4.3286, -4.4576, -4.8552, -4.4784, -4.5003, -4.4596,\n",
      "         -4.2812]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : of\n",
      "target index is: [57] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4917, -4.1616, -4.3070, -4.5634, -4.1577, -4.8562, -4.9370, -4.4278,\n",
      "         -4.8185, -4.7644, -5.0758, -4.5441, -4.5904, -4.5724, -4.7884, -4.7570,\n",
      "         -4.6653, -4.5648, -4.5545, -4.5516, -4.5915, -4.3532, -4.7169, -4.3820,\n",
      "         -4.0790, -4.6788, -4.4874, -4.5505, -4.2773, -4.4783, -4.6638, -5.0538,\n",
      "         -5.0303, -4.5528, -4.8653, -4.8959, -4.8003, -4.7427, -4.5480, -4.7074,\n",
      "         -4.8357, -4.4866, -4.6478, -4.4814, -4.5488, -4.3115, -4.7525, -4.9326,\n",
      "         -4.6082, -4.5207, -4.4257, -4.4112, -4.8950, -4.2213, -4.6506, -4.6469,\n",
      "         -4.4428, -4.4201, -4.4578, -4.6970, -4.9011, -4.7187, -4.3731, -4.1279,\n",
      "         -4.7032, -4.6969, -5.0045, -4.5101, -4.7700, -4.6942, -4.5596, -4.4423,\n",
      "         -4.6965, -4.8633, -4.6641, -4.7858, -4.6080, -4.1611, -4.7336, -4.9254,\n",
      "         -4.2569, -4.3501, -4.7569, -4.8149, -4.6050, -4.4791, -4.5804, -4.6910,\n",
      "         -4.7672, -4.2057, -4.6770, -4.8085, -4.5972, -4.3684, -4.2984, -4.6410,\n",
      "         -4.3098]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1752, -4.2767, -4.8936, -5.0301, -4.1887, -4.7479, -4.7603, -4.2513,\n",
      "         -5.2549, -4.3752, -5.1392, -4.1410, -4.5782, -4.3343, -4.7149, -4.9497,\n",
      "         -4.5581, -4.5848, -4.7455, -4.1910, -4.7867, -4.7694, -4.5252, -4.4810,\n",
      "         -4.7325, -4.8546, -4.3806, -4.3380, -4.4143, -4.6763, -4.6564, -4.7512,\n",
      "         -5.0046, -4.7750, -4.8049, -5.2225, -4.5814, -4.5725, -4.9130, -4.4351,\n",
      "         -4.8656, -4.6435, -4.4972, -4.3852, -4.6500, -3.9952, -4.8453, -4.6970,\n",
      "         -4.8420, -4.7246, -4.6133, -4.7391, -4.4487, -4.3098, -4.8000, -4.8038,\n",
      "         -4.4596, -4.4914, -4.6751, -4.6765, -4.6167, -4.6420, -4.2909, -4.4860,\n",
      "         -4.3277, -4.7812, -5.1388, -4.3115, -4.5892, -4.5909, -4.2593, -4.6667,\n",
      "         -4.6844, -5.0505, -4.5448, -4.6947, -4.3111, -4.1963, -4.3457, -4.5992,\n",
      "         -4.5247, -4.5613, -4.6611, -5.0119, -5.1436, -4.2440, -4.6093, -4.3060,\n",
      "         -5.0779, -4.5306, -4.4347, -4.7767, -4.8710, -4.4830, -4.1906, -4.4606,\n",
      "         -4.3447]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : lusty\n",
      "target index is: [30] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2205, -4.6066, -4.4247, -4.9563, -4.2066, -4.7008, -4.5635, -4.1659,\n",
      "         -4.6900, -4.9676, -4.9068, -4.4765, -4.4201, -4.6468, -4.9026, -4.8294,\n",
      "         -4.4290, -4.7350, -4.4152, -4.8062, -4.7102, -5.0423, -4.7377, -4.6726,\n",
      "         -4.4046, -4.7127, -4.5137, -4.4768, -4.1909, -4.5221, -4.2038, -4.6922,\n",
      "         -4.5866, -4.8761, -4.7509, -4.8830, -4.3901, -4.4499, -4.4826, -4.5201,\n",
      "         -4.8206, -4.2742, -4.7957, -4.3079, -4.6630, -4.1498, -4.5165, -4.5803,\n",
      "         -4.7248, -4.5601, -4.6243, -4.3062, -5.0747, -4.5143, -4.8556, -4.7180,\n",
      "         -4.3595, -4.3588, -4.5129, -4.6547, -4.8401, -4.3670, -4.6045, -4.1779,\n",
      "         -4.6886, -4.7796, -4.8381, -4.8103, -4.8025, -4.4124, -4.6331, -4.4038,\n",
      "         -5.0274, -4.9662, -4.6994, -4.6811, -4.9224, -3.8097, -4.5521, -5.0175,\n",
      "         -4.5134, -4.5596, -4.6503, -4.9119, -4.8322, -4.4725, -4.4008, -4.4288,\n",
      "         -5.2440, -4.3888, -4.8132, -4.5013, -4.5430, -4.5804, -4.3950, -4.7638,\n",
      "         -4.4032]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : days;\n",
      "target index is: [48] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5490, -4.7597, -4.4013, -4.4535, -3.7609, -4.7611, -4.5679, -4.4341,\n",
      "         -4.5032, -4.9503, -4.4783, -4.6019, -5.0935, -4.9751, -4.6496, -4.5847,\n",
      "         -4.9387, -5.0743, -4.6111, -4.7515, -4.6231, -4.0519, -4.7470, -4.5204,\n",
      "         -4.4219, -4.8274, -4.5242, -4.5032, -4.5812, -4.5340, -4.5945, -4.6518,\n",
      "         -4.7008, -4.7256, -4.4102, -4.9508, -4.7352, -4.8658, -4.5638, -4.5656,\n",
      "         -4.8148, -4.6542, -5.0535, -4.4402, -4.8636, -4.6994, -4.3609, -4.4292,\n",
      "         -4.2865, -4.3386, -4.4635, -4.6640, -4.7791, -4.4791, -4.7008, -3.8972,\n",
      "         -4.5863, -4.1692, -4.4812, -4.5643, -4.6497, -4.8152, -4.9734, -3.9684,\n",
      "         -5.0375, -4.3742, -4.9382, -4.5221, -4.7398, -5.0492, -4.2085, -4.5104,\n",
      "         -4.8460, -4.9786, -4.4703, -4.9976, -4.7494, -4.5774, -4.6986, -4.6369,\n",
      "         -4.7686, -4.0333, -5.0212, -4.6474, -4.4436, -4.6625, -4.5447, -5.0107,\n",
      "         -4.8469, -4.2501, -4.6812, -4.3886, -4.4817, -4.5414, -4.3965, -4.4559,\n",
      "         -4.5853]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : To\n",
      "target index is: [26] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2644, -4.6407, -5.0087, -4.9524, -4.0570, -4.7829, -4.4827, -4.6965,\n",
      "         -4.5829, -4.6277, -4.9420, -4.4691, -4.8619, -4.4965, -4.8498, -4.6434,\n",
      "         -4.2025, -4.7090, -4.8736, -4.6598, -4.3343, -4.1849, -4.9410, -4.6949,\n",
      "         -4.5272, -4.8543, -4.3803, -4.4267, -4.3740, -4.8351, -4.6262, -4.9260,\n",
      "         -4.9380, -4.9730, -4.5404, -4.5505, -4.5819, -4.5391, -5.1325, -4.6719,\n",
      "         -4.7040, -4.6936, -4.3646, -4.7154, -4.1497, -4.4143, -4.5627, -4.8266,\n",
      "         -4.4414, -5.0043, -4.2489, -4.5821, -4.6362, -4.2411, -4.8108, -4.7216,\n",
      "         -4.6663, -4.5879, -4.5060, -4.5887, -4.6281, -4.4095, -4.5661, -4.2790,\n",
      "         -4.3577, -4.8273, -4.9607, -4.4967, -4.5948, -4.2807, -4.3885, -4.5229,\n",
      "         -4.9174, -4.5117, -4.8657, -4.9982, -4.5730, -4.3577, -4.8426, -4.6658,\n",
      "         -4.1562, -4.3452, -4.5585, -4.7083, -4.4290, -4.3722, -4.6437, -4.7277,\n",
      "         -4.8590, -4.5844, -4.4774, -4.9798, -4.5231, -4.2165, -4.4035, -4.7335,\n",
      "         -4.3480]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : say,\n",
      "target index is: [96] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7898, -4.3257, -4.6522, -4.9226, -3.9661, -4.7212, -4.6217, -4.2788,\n",
      "         -4.7563, -4.4967, -4.7651, -4.6171, -4.6806, -4.7723, -4.5893, -4.8454,\n",
      "         -4.8214, -4.3588, -4.7373, -4.2326, -4.6864, -4.5879, -4.7477, -4.7205,\n",
      "         -4.4746, -4.8354, -4.4225, -4.5202, -4.2689, -4.5197, -4.6167, -4.6226,\n",
      "         -4.8536, -4.7600, -4.4925, -4.8497, -4.4919, -4.8388, -4.5426, -4.4619,\n",
      "         -4.5837, -4.6780, -4.6739, -4.4233, -4.6748, -4.4717, -4.4018, -4.5012,\n",
      "         -4.5361, -4.6906, -4.3529, -4.8239, -4.6607, -4.5533, -4.7461, -4.3882,\n",
      "         -4.6543, -4.4097, -4.4838, -4.6709, -4.6845, -4.6497, -4.5606, -4.2077,\n",
      "         -4.5718, -4.4590, -4.5249, -4.6105, -4.5640, -4.8428, -4.6475, -4.4719,\n",
      "         -4.8142, -5.1599, -4.6713, -4.7402, -4.3945, -4.5227, -4.5946, -4.8625,\n",
      "         -4.7917, -4.3873, -4.7052, -4.6732, -4.9474, -4.2149, -4.4035, -4.7245,\n",
      "         -4.6281, -4.1430, -4.7327, -4.5618, -4.6337, -4.2857, -4.6888, -4.4049,\n",
      "         -4.4799]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : within\n",
      "target index is: [34] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2264, -4.3312, -4.7274, -4.8909, -4.4952, -4.8556, -4.5228, -4.0757,\n",
      "         -5.1436, -4.5657, -4.9887, -4.3867, -4.2867, -4.6268, -5.1683, -5.0403,\n",
      "         -4.5523, -4.5769, -4.7288, -4.5904, -4.5310, -4.7240, -4.7701, -4.9242,\n",
      "         -4.4841, -4.9393, -4.2056, -4.3676, -4.1132, -4.5157, -4.5429, -4.6594,\n",
      "         -4.9494, -4.8428, -4.8221, -4.9944, -4.7636, -4.3498, -4.5593, -4.5329,\n",
      "         -4.6889, -4.6526, -4.4110, -4.3367, -4.3353, -4.0042, -4.7020, -4.7689,\n",
      "         -4.6356, -4.7607, -4.6477, -4.1927, -4.6791, -4.5997, -4.5335, -4.6398,\n",
      "         -4.6081, -4.2222, -4.4131, -4.9643, -4.8455, -4.5920, -4.5082, -4.3992,\n",
      "         -4.3565, -4.9454, -4.9619, -4.5259, -4.5179, -4.1610, -4.4266, -4.5829,\n",
      "         -4.7566, -4.7734, -4.6931, -4.8832, -4.5297, -4.0294, -4.4792, -5.0719,\n",
      "         -4.3559, -4.7305, -4.6164, -4.9371, -4.9007, -4.6606, -4.6826, -4.3820,\n",
      "         -5.1283, -4.6026, -4.5288, -4.4274, -4.8124, -4.5444, -4.4270, -4.5415,\n",
      "         -4.3947]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thine\n",
      "target index is: [56] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1455, -4.9178, -4.1321, -4.5846, -4.0840, -4.7126, -4.8654, -4.3184,\n",
      "         -4.7080, -4.8694, -4.7818, -4.7986, -4.7218, -4.7291, -4.7673, -4.6767,\n",
      "         -4.6147, -4.7454, -4.4941, -4.9833, -4.8294, -4.5946, -4.8349, -4.4549,\n",
      "         -4.3263, -4.7503, -4.6685, -4.5080, -4.2952, -4.3704, -4.3508, -4.5516,\n",
      "         -4.6370, -4.5193, -4.6834, -4.8799, -4.3751, -4.8479, -4.6622, -4.6965,\n",
      "         -4.9985, -4.2982, -4.9557, -4.2306, -4.8529, -4.2889, -4.6073, -4.4687,\n",
      "         -4.7876, -4.3161, -4.5530, -4.7044, -5.1930, -4.5656, -4.9042, -4.5940,\n",
      "         -4.1723, -4.3479, -4.4096, -4.2971, -4.7279, -4.5889, -4.6081, -4.0462,\n",
      "         -4.7671, -4.4608, -5.0845, -4.7521, -4.9330, -4.9887, -4.4718, -4.4228,\n",
      "         -5.2552, -5.0272, -4.5746, -4.7928, -4.6846, -4.0845, -4.6319, -4.8291,\n",
      "         -4.4970, -4.0679, -4.6684, -4.8234, -4.6654, -4.6241, -4.3964, -4.5459,\n",
      "         -5.2645, -4.3042, -4.4206, -4.3823, -4.5045, -4.7983, -4.2329, -4.7068,\n",
      "         -4.4643]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : own\n",
      "target index is: [92] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4119, -4.4202, -4.4671, -4.9383, -3.7350, -4.4330, -4.7247, -4.6185,\n",
      "         -4.9167, -5.0468, -4.8505, -4.6185, -5.1178, -4.8214, -4.7868, -4.7075,\n",
      "         -4.5868, -5.1429, -4.4947, -4.3463, -4.4670, -4.0464, -4.7735, -4.5882,\n",
      "         -4.7728, -4.7607, -4.5230, -4.5935, -4.5844, -5.0440, -4.1940, -4.8354,\n",
      "         -4.6471, -4.3928, -4.2039, -4.8760, -4.6229, -5.1318, -4.8515, -4.8385,\n",
      "         -4.4861, -4.7552, -5.0585, -4.2558, -4.9355, -4.3930, -4.6024, -4.5017,\n",
      "         -4.7445, -4.6987, -4.6191, -4.7866, -4.6635, -4.5887, -4.9452, -4.2032,\n",
      "         -4.8230, -4.4312, -4.4805, -4.5730, -4.4737, -4.7143, -5.0475, -3.8058,\n",
      "         -4.7694, -4.4824, -5.1578, -4.5788, -4.6306, -4.9596, -4.4679, -4.4987,\n",
      "         -4.5942, -5.1094, -4.4045, -4.6242, -4.8795, -4.5992, -4.6506, -4.4158,\n",
      "         -4.7497, -4.1927, -4.9220, -4.8687, -4.2242, -4.5426, -4.1545, -4.5954,\n",
      "         -4.8315, -4.3864, -4.3941, -4.3503, -4.7361, -4.6432, -3.9254, -4.6668,\n",
      "         -4.3137]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : deep\n",
      "target index is: [76] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3259, -4.6548, -4.6692, -4.7996, -4.2504, -4.5385, -4.3800, -4.2448,\n",
      "         -4.6929, -4.9173, -5.0521, -4.3697, -4.5061, -4.4774, -4.6704, -4.4208,\n",
      "         -4.0926, -4.7351, -4.6415, -4.6364, -4.5807, -4.5963, -4.6761, -4.6409,\n",
      "         -4.4727, -4.6384, -4.5751, -4.5078, -4.4601, -4.6098, -4.6420, -4.8782,\n",
      "         -4.8970, -4.8796, -4.7083, -4.8137, -4.7918, -4.4463, -5.1254, -4.7375,\n",
      "         -4.7172, -4.5013, -4.8868, -4.3976, -4.5334, -4.3513, -4.6295, -4.7856,\n",
      "         -4.5235, -4.4470, -4.5998, -4.3146, -4.7917, -4.3249, -4.9206, -4.6527,\n",
      "         -4.4140, -4.6432, -4.7447, -4.6105, -4.7961, -4.6304, -4.4436, -3.9757,\n",
      "         -4.6008, -4.4720, -4.9073, -4.4372, -4.5726, -4.6200, -4.4231, -4.6378,\n",
      "         -4.5391, -4.4105, -4.4781, -4.6127, -4.6976, -4.5805, -4.6828, -4.7130,\n",
      "         -4.0668, -4.5191, -4.6844, -4.7415, -4.4706, -4.4186, -4.7882, -4.7278,\n",
      "         -4.9998, -4.4762, -4.5355, -4.8300, -4.6677, -4.6551, -4.2284, -4.5757,\n",
      "         -4.6190]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : sunken\n",
      "target index is: [91] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4412, -4.5312, -4.6983, -4.8518, -4.1897, -4.8733, -4.6058, -4.7522,\n",
      "         -4.7272, -4.4357, -4.9334, -4.4830, -4.8182, -4.6703, -4.6707, -4.8348,\n",
      "         -4.8988, -4.7891, -4.7434, -4.3373, -4.4801, -4.2070, -4.9600, -4.5311,\n",
      "         -4.5678, -4.9007, -4.3735, -4.6576, -4.3306, -4.6455, -4.8823, -4.6444,\n",
      "         -4.6549, -4.7846, -4.7399, -5.0145, -4.7159, -4.6851, -4.7779, -4.2396,\n",
      "         -4.8032, -4.7391, -4.8503, -4.3665, -4.5034, -4.5827, -4.6939, -4.5597,\n",
      "         -4.3275, -4.9236, -3.9446, -5.2303, -4.3877, -4.4575, -4.7603, -4.2466,\n",
      "         -4.8022, -4.4767, -4.4422, -4.4936, -4.5245, -4.4185, -4.6377, -3.9688,\n",
      "         -4.5164, -4.6325, -4.9857, -4.5668, -4.6330, -4.5313, -4.4287, -4.6051,\n",
      "         -4.8383, -4.7885, -4.5617, -5.0314, -4.2086, -4.5870, -4.5830, -4.5365,\n",
      "         -4.6477, -4.1778, -4.9217, -4.5815, -4.7877, -4.2856, -4.7750, -4.8391,\n",
      "         -4.7666, -4.2927, -4.4159, -4.7069, -4.5279, -4.3494, -4.5125, -4.2708,\n",
      "         -4.3732]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : eyes,\n",
      "target index is: [58] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2921, -4.4885, -5.0845, -5.3259, -3.8627, -4.6397, -4.3681, -4.4970,\n",
      "         -4.7259, -4.6088, -5.1194, -4.6411, -4.8162, -4.5894, -4.6192, -4.6756,\n",
      "         -4.5729, -4.7145, -5.0015, -4.5390, -4.7376, -4.3183, -5.0595, -4.6207,\n",
      "         -4.5417, -4.8510, -4.4346, -4.3538, -4.3268, -4.7044, -4.7634, -4.5532,\n",
      "         -4.6553, -5.0721, -4.5921, -4.7142, -4.5084, -4.5337, -5.0980, -4.2976,\n",
      "         -4.5761, -4.3547, -4.7752, -4.4104, -4.6012, -4.3053, -4.8501, -4.4557,\n",
      "         -4.4836, -5.0496, -4.3096, -4.9697, -4.5177, -4.2641, -4.4730, -4.6694,\n",
      "         -4.5570, -4.7684, -4.6284, -4.4160, -4.5753, -4.3222, -4.1134, -4.4500,\n",
      "         -4.2555, -4.6955, -4.7031, -4.5469, -4.6259, -4.2669, -4.5044, -4.6008,\n",
      "         -4.8983, -4.8076, -4.7741, -4.7985, -4.4486, -4.4954, -4.6594, -4.7266,\n",
      "         -4.4298, -4.5001, -4.9264, -4.9046, -4.9045, -4.0280, -4.6339, -4.6479,\n",
      "         -4.6878, -4.4527, -4.8035, -4.6484, -4.8508, -4.1906, -4.6908, -4.6048,\n",
      "         -4.2414]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Were\n",
      "target index is: [37] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2571, -4.5015, -4.6982, -4.6513, -4.2176, -4.7020, -4.4254, -4.2829,\n",
      "         -4.7974, -4.9101, -4.5933, -4.4401, -4.5403, -4.8295, -4.9935, -4.6730,\n",
      "         -4.7118, -4.5532, -4.6692, -4.7015, -4.3298, -4.4428, -4.9009, -5.0240,\n",
      "         -4.2962, -4.9286, -4.5746, -4.4065, -4.1914, -4.4194, -4.6163, -4.6486,\n",
      "         -4.5711, -4.8756, -4.3569, -4.8287, -4.8553, -4.3759, -4.7575, -4.3726,\n",
      "         -4.7087, -4.5288, -4.6888, -4.6688, -4.5658, -4.2038, -4.2535, -4.7895,\n",
      "         -4.4819, -4.8731, -4.7198, -4.3170, -4.8153, -4.5021, -4.4681, -4.4625,\n",
      "         -4.3836, -4.3988, -4.4486, -4.8882, -4.6372, -4.1377, -4.5613, -4.3298,\n",
      "         -4.4955, -4.6912, -4.6031, -4.3589, -4.6977, -4.1622, -4.5258, -4.5731,\n",
      "         -4.6871, -5.1109, -4.9612, -4.9301, -4.6398, -4.2670, -4.7466, -4.8900,\n",
      "         -4.5697, -4.6985, -4.7588, -4.7972, -4.6202, -4.3405, -4.4535, -4.8154,\n",
      "         -4.8893, -4.4119, -4.7995, -4.4920, -4.6276, -4.5350, -4.8419, -4.6854,\n",
      "         -4.6094]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : an\n",
      "target index is: [74] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5114, -4.6889, -4.6774, -4.4980, -4.0961, -4.9847, -4.6600, -4.5379,\n",
      "         -4.7160, -4.4875, -4.9730, -4.7165, -4.8445, -4.9160, -4.7771, -4.8511,\n",
      "         -4.8131, -4.5788, -4.6658, -4.7306, -4.3800, -4.0688, -4.8467, -4.8744,\n",
      "         -4.4225, -5.2009, -4.3518, -4.2028, -4.6290, -4.3628, -4.8337, -4.5480,\n",
      "         -4.8597, -4.9269, -4.3887, -4.7101, -4.7503, -4.5833, -4.7681, -4.4685,\n",
      "         -4.9066, -4.7499, -4.5832, -4.5198, -4.4254, -4.4201, -4.5401, -4.5598,\n",
      "         -4.3491, -4.9981, -4.4205, -4.4538, -4.6566, -4.3877, -4.4378, -4.3359,\n",
      "         -4.4538, -4.3365, -4.2103, -4.8167, -4.5873, -4.5619, -4.5893, -4.3319,\n",
      "         -4.5998, -4.3744, -4.8423, -4.2869, -4.7156, -4.5631, -4.3812, -4.6472,\n",
      "         -4.8417, -4.8317, -5.0236, -5.1097, -4.3447, -4.2494, -4.5651, -4.8748,\n",
      "         -4.3685, -4.5840, -4.4571, -4.8034, -4.5170, -4.2769, -4.6583, -5.0373,\n",
      "         -4.8071, -4.5718, -4.3793, -4.4430, -4.5648, -4.5451, -4.6192, -4.4857,\n",
      "         -4.3577]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : all-eating\n",
      "target index is: [60] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4814, -4.5604, -4.8560, -4.7436, -3.9428, -4.7184, -4.7352, -4.4123,\n",
      "         -4.8265, -4.4266, -5.0291, -4.6692, -4.8955, -4.6089, -4.7125, -4.6932,\n",
      "         -4.4620, -4.4390, -4.8259, -4.5151, -4.7424, -4.5866, -4.9160, -4.8909,\n",
      "         -4.7003, -4.9167, -4.6916, -4.2593, -4.2472, -4.4093, -4.5363, -4.5441,\n",
      "         -4.8504, -4.9226, -4.3592, -4.7403, -4.2924, -4.9318, -4.8212, -4.6115,\n",
      "         -4.7626, -4.4983, -4.4709, -4.5477, -4.3757, -4.4392, -4.5354, -4.6367,\n",
      "         -4.6711, -4.8565, -4.5052, -4.8199, -4.8538, -4.2296, -4.6557, -4.7618,\n",
      "         -4.3135, -4.4196, -4.6421, -4.4768, -4.6681, -4.6251, -4.4682, -4.4553,\n",
      "         -4.4364, -4.4054, -4.5847, -4.2839, -4.7577, -4.5842, -4.3978, -4.2536,\n",
      "         -5.0657, -4.9097, -4.7568, -4.8101, -4.3663, -4.3391, -4.5662, -5.0238,\n",
      "         -4.4215, -4.3175, -4.3135, -4.9292, -4.9831, -4.0405, -4.7304, -4.5580,\n",
      "         -4.8724, -4.2227, -4.5222, -4.6614, -4.7446, -4.4753, -4.6023, -4.5515,\n",
      "         -4.5538]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : shame,\n",
      "target index is: [41] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6950, -4.7262, -4.8696, -4.5089, -4.1562, -4.5988, -4.6697, -4.4442,\n",
      "         -4.5923, -4.6335, -4.5811, -4.4953, -4.8642, -4.7360, -4.7785, -4.4876,\n",
      "         -4.4492, -4.9054, -4.5670, -4.5122, -4.5667, -4.2259, -4.7523, -4.6003,\n",
      "         -4.5416, -4.9675, -4.3743, -4.5094, -4.4922, -4.6002, -4.4209, -5.0095,\n",
      "         -5.1109, -4.7938, -4.5535, -4.7096, -4.5036, -5.0362, -4.8195, -4.7203,\n",
      "         -4.8067, -4.3758, -4.5001, -4.5751, -4.5384, -4.4817, -4.6259, -4.6530,\n",
      "         -4.4174, -4.6492, -4.8582, -4.2273, -4.8380, -4.3230, -4.8885, -4.1539,\n",
      "         -4.4691, -4.3022, -4.4259, -4.4880, -4.6420, -5.0152, -4.6995, -4.2074,\n",
      "         -4.7793, -4.2458, -5.0327, -4.5038, -4.6340, -4.6735, -3.9765, -4.4445,\n",
      "         -4.7543, -4.6046, -4.6083, -4.8651, -4.8926, -4.3211, -4.9734, -4.8487,\n",
      "         -4.6643, -4.4608, -4.4495, -4.5794, -4.3204, -4.5210, -4.3817, -4.7544,\n",
      "         -4.7652, -4.1807, -4.7079, -4.4084, -4.7369, -4.6482, -4.4892, -4.7300,\n",
      "         -4.4525]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : and\n",
      "target index is: [44] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7046, -4.4923, -4.5594, -4.6269, -4.1945, -4.7413, -4.5277, -4.3995,\n",
      "         -4.7108, -4.7991, -4.4670, -4.4659, -4.8419, -4.8524, -4.5164, -4.5073,\n",
      "         -4.6193, -4.9049, -4.6341, -4.5699, -4.3557, -4.3067, -4.5076, -4.4680,\n",
      "         -4.5295, -4.7063, -4.3726, -4.4411, -4.6251, -4.5482, -4.6433, -4.8350,\n",
      "         -4.8095, -4.7401, -4.4013, -4.4928, -4.7803, -4.9155, -4.6135, -4.5356,\n",
      "         -4.7852, -4.6795, -4.8364, -4.5604, -4.5679, -4.6079, -4.3794, -4.5865,\n",
      "         -4.2810, -4.5392, -4.6044, -4.5705, -4.6187, -4.3732, -4.9057, -4.4753,\n",
      "         -4.7426, -4.6566, -4.6203, -4.6695, -4.8138, -4.7476, -4.7900, -4.1801,\n",
      "         -4.9203, -4.4376, -4.8699, -4.3838, -4.6437, -4.8374, -4.2996, -4.7888,\n",
      "         -4.6139, -4.6346, -4.3988, -4.7414, -4.6003, -4.4703, -4.8201, -4.4216,\n",
      "         -4.4633, -4.3464, -4.6701, -4.6582, -4.5998, -4.3452, -4.6003, -4.8045,\n",
      "         -4.8706, -4.1388, -4.8109, -4.7546, -4.3167, -4.3465, -4.4324, -4.4122,\n",
      "         -4.5657]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thriftless\n",
      "target index is: [43] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3911, -4.4370, -4.5471, -4.7402, -4.0976, -4.5571, -4.6730, -4.4753,\n",
      "         -4.7328, -4.5176, -4.9411, -4.3934, -4.7831, -4.6282, -4.6356, -4.9084,\n",
      "         -4.8724, -4.5492, -4.8817, -4.1914, -4.6858, -4.8050, -4.6483, -4.6039,\n",
      "         -4.8480, -4.7497, -4.5506, -4.4618, -4.1727, -4.7250, -4.6678, -4.5107,\n",
      "         -4.7354, -4.5610, -4.6307, -5.0340, -4.6340, -4.9061, -4.5307, -4.4710,\n",
      "         -4.5473, -4.5855, -4.7336, -4.1921, -4.4689, -4.2834, -4.4745, -4.1490,\n",
      "         -4.5508, -4.6991, -4.8444, -4.9313, -4.6392, -4.6394, -4.9163, -4.7448,\n",
      "         -4.4012, -4.4657, -4.5310, -4.6895, -4.5688, -4.7175, -4.5723, -4.3794,\n",
      "         -4.6606, -4.8217, -4.8994, -4.4003, -4.4729, -4.7212, -4.2012, -4.6658,\n",
      "         -4.7762, -5.0868, -4.5784, -4.5708, -4.4763, -4.4864, -4.5506, -4.3677,\n",
      "         -4.7386, -4.3063, -4.5191, -4.7902, -5.0403, -4.2960, -4.4866, -4.5196,\n",
      "         -5.2543, -4.4417, -4.7394, -4.4470, -4.5243, -4.5417, -4.1789, -4.2738,\n",
      "         -4.5999]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : praise.\n",
      "target index is: [94] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-3.9387, -5.0459, -4.7114, -5.1224, -3.7683, -4.7172, -4.8460, -4.3944,\n",
      "         -4.6781, -5.0023, -4.6568, -4.2943, -4.5615, -4.5697, -4.8059, -4.5600,\n",
      "         -4.8794, -5.0642, -4.7004, -4.5281, -4.7800, -4.0513, -5.1712, -4.9617,\n",
      "         -4.4236, -4.8531, -4.4847, -4.0986, -3.9013, -4.8622, -4.5778, -4.8008,\n",
      "         -4.8596, -4.7841, -4.4378, -5.2882, -4.6951, -4.6423, -4.9857, -4.9246,\n",
      "         -4.6588, -4.3299, -4.9271, -4.5651, -4.7078, -4.4082, -4.8522, -4.6475,\n",
      "         -4.7238, -4.8354, -4.3121, -4.8013, -4.4591, -4.6257, -4.8600, -4.5203,\n",
      "         -3.9285, -4.4131, -4.5113, -4.7031, -4.4026, -4.4370, -4.3264, -4.2983,\n",
      "         -4.5700, -4.6392, -5.0558, -4.9797, -4.8757, -4.8368, -4.1807, -4.2699,\n",
      "         -4.8749, -5.1042, -4.5658, -4.5276, -4.7798, -4.0470, -4.5300, -4.4448,\n",
      "         -4.5790, -4.1970, -5.2050, -5.0465, -4.1041, -4.6352, -4.2871, -4.7681,\n",
      "         -5.2038, -4.9474, -5.0467, -4.2606, -4.7400, -4.3646, -4.5312, -4.4209,\n",
      "         -4.4700]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : How\n",
      "target index is: [12] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1933, -4.6823, -4.5005, -5.0455, -4.0126, -4.9913, -4.6481, -4.3686,\n",
      "         -5.1405, -4.9460, -5.0326, -5.0868, -4.7532, -4.5200, -5.3280, -5.0810,\n",
      "         -4.8446, -4.4164, -4.7829, -4.7161, -4.6323, -4.8542, -4.8457, -5.0157,\n",
      "         -4.4261, -5.1188, -4.5746, -4.1828, -4.2646, -4.5947, -4.3075, -3.9759,\n",
      "         -4.6364, -4.7175, -4.4418, -5.1814, -4.5437, -4.5060, -4.5177, -4.5197,\n",
      "         -4.3545, -4.8634, -4.8018, -4.1808, -4.6080, -3.9901, -4.4929, -4.1449,\n",
      "         -5.0406, -4.5374, -4.3952, -4.7766, -4.6853, -4.7462, -4.5226, -4.7946,\n",
      "         -4.4110, -4.4583, -4.2732, -4.6730, -4.6678, -4.3061, -4.2588, -4.1955,\n",
      "         -4.5276, -4.8943, -4.6675, -4.3406, -4.3751, -4.4299, -4.5495, -4.3145,\n",
      "         -5.2967, -5.3340, -4.9385, -4.7716, -4.5591, -4.0925, -4.5104, -4.5699,\n",
      "         -4.6398, -4.9584, -4.6872, -5.1551, -4.9893, -4.1146, -4.1486, -4.8234,\n",
      "         -5.5534, -4.4257, -4.4647, -4.1340, -4.8315, -4.8431, -4.3908, -4.7801,\n",
      "         -4.5488]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : much\n",
      "target index is: [68] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4646, -4.9988, -4.6365, -4.4414, -3.5229, -4.4828, -4.7598, -4.2673,\n",
      "         -4.9894, -4.5335, -4.4921, -4.4707, -4.8559, -4.7973, -4.9813, -4.7894,\n",
      "         -4.7960, -4.8641, -4.1039, -4.8620, -4.7475, -4.1057, -5.0401, -4.8154,\n",
      "         -4.5219, -5.1010, -4.5157, -4.3606, -4.5841, -4.6027, -4.2237, -4.9752,\n",
      "         -4.6771, -4.5104, -4.4408, -5.3165, -4.4643, -5.0617, -4.6908, -4.9803,\n",
      "         -4.8611, -4.5816, -4.9493, -4.6272, -4.8499, -4.3964, -4.6508, -5.1190,\n",
      "         -4.9782, -4.5976, -4.9074, -4.4223, -5.0539, -4.1256, -4.5936, -3.9862,\n",
      "         -4.2290, -3.9930, -4.2305, -4.1781, -4.5406, -4.8165, -4.5595, -3.8398,\n",
      "         -4.6272, -4.3752, -4.6722, -4.5016, -5.1158, -4.7359, -4.4452, -4.2910,\n",
      "         -5.4864, -5.0557, -4.5816, -5.0533, -4.9244, -4.1567, -4.5568, -5.1498,\n",
      "         -4.8787, -4.1205, -4.9613, -4.8643, -4.3345, -4.5808, -4.5743, -4.8506,\n",
      "         -5.3002, -4.4912, -4.8801, -4.1186, -4.6731, -4.6161, -4.3143, -5.1580,\n",
      "         -4.3766]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : more\n",
      "target index is: [4] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3315, -4.8139, -4.7114, -4.3908, -4.1548, -4.6130, -4.8726, -4.4350,\n",
      "         -4.8767, -4.4805, -4.8727, -4.3103, -4.7343, -4.3879, -4.8323, -4.7794,\n",
      "         -4.5925, -4.7797, -4.6889, -4.6521, -4.4423, -4.4613, -4.6817, -4.6240,\n",
      "         -4.5723, -4.8113, -4.5873, -4.4493, -4.3873, -4.5654, -4.7613, -4.6833,\n",
      "         -4.8781, -4.5625, -4.9108, -5.0021, -4.8979, -4.6832, -4.7555, -4.6463,\n",
      "         -4.6083, -4.5471, -4.5954, -4.5048, -4.0793, -4.3242, -4.5254, -4.7062,\n",
      "         -4.7030, -4.5377, -4.9259, -4.3076, -4.7681, -4.3496, -4.8077, -4.3973,\n",
      "         -4.4725, -4.2205, -4.4733, -4.6723, -4.6064, -4.6145, -4.5942, -3.8830,\n",
      "         -4.4974, -4.6154, -4.8420, -4.5979, -4.6441, -4.5999, -4.0253, -4.5655,\n",
      "         -4.6960, -4.4683, -4.4987, -4.8301, -4.6875, -4.4924, -4.7077, -4.8113,\n",
      "         -4.5120, -4.2549, -4.6652, -4.7779, -4.5326, -4.5689, -4.7663, -4.7302,\n",
      "         -5.2235, -4.4915, -4.7176, -4.6849, -4.6380, -4.5494, -4.1023, -4.9274,\n",
      "         -4.5213]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : praise\n",
      "target index is: [45] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4433, -4.4927, -4.7196, -5.1986, -4.0303, -4.5911, -4.4913, -4.2636,\n",
      "         -5.2230, -4.5974, -4.8341, -4.3331, -4.7845, -4.5565, -5.0914, -4.8175,\n",
      "         -4.6576, -4.4887, -4.7793, -4.2118, -4.7069, -4.6932, -4.9513, -4.7464,\n",
      "         -4.9179, -4.9145, -4.5143, -4.2426, -4.3077, -4.6244, -4.2918, -4.4301,\n",
      "         -4.8547, -4.8493, -4.4742, -5.1778, -4.3346, -5.0297, -4.5170, -4.5944,\n",
      "         -4.4859, -4.5870, -4.7240, -4.1690, -4.6441, -4.1124, -4.7452, -4.3989,\n",
      "         -4.8147, -5.1223, -4.2429, -5.0870, -4.4430, -4.7519, -4.5749, -4.6432,\n",
      "         -4.3642, -4.4892, -4.4376, -4.5270, -4.5448, -4.3144, -4.6099, -4.3840,\n",
      "         -4.3134, -4.6223, -5.1591, -4.5674, -4.5658, -4.3269, -4.6916, -4.6350,\n",
      "         -5.2141, -5.2819, -4.6803, -4.9051, -4.5474, -4.0937, -4.3495, -4.4433,\n",
      "         -4.8759, -4.6386, -4.7290, -5.0182, -4.9845, -4.2417, -4.1995, -4.2911,\n",
      "         -5.1151, -4.6819, -4.5783, -4.0325, -5.0507, -4.5141, -4.6518, -4.3788,\n",
      "         -4.3736]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : deserv'd\n",
      "target index is: [66] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4291, -4.7072, -4.5612, -4.3409, -4.0601, -4.7300, -4.6351, -4.3508,\n",
      "         -4.8512, -4.8313, -4.4583, -4.7344, -4.7878, -4.7447, -4.8927, -4.8149,\n",
      "         -4.8251, -4.8455, -4.4926, -4.9107, -4.4278, -4.4653, -4.8010, -4.6403,\n",
      "         -4.2728, -5.0955, -4.6854, -4.5037, -4.3213, -4.6528, -4.2181, -4.7069,\n",
      "         -4.8102, -4.7558, -4.5580, -5.2256, -4.5086, -4.6656, -4.5457, -4.6101,\n",
      "         -4.7960, -4.5991, -4.8389, -4.5330, -4.8153, -4.2676, -4.7458, -4.5619,\n",
      "         -4.7858, -4.4647, -4.8310, -4.3129, -5.1447, -4.4333, -4.5726, -4.4702,\n",
      "         -4.0625, -4.1560, -4.2553, -4.4357, -4.6461, -4.4751, -4.5974, -4.2159,\n",
      "         -4.6337, -4.4372, -4.6382, -4.2811, -4.5482, -4.3409, -4.5299, -4.4689,\n",
      "         -5.2546, -4.9351, -4.8678, -4.9575, -4.9686, -3.9843, -4.7822, -4.8902,\n",
      "         -4.6078, -4.4781, -4.8804, -4.8645, -4.6571, -4.2935, -4.1838, -4.6428,\n",
      "         -5.1979, -4.3116, -4.4543, -4.5003, -4.7547, -4.7002, -4.2583, -4.8276,\n",
      "         -4.3884]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3236, -4.2317, -4.9186, -4.6740, -4.2381, -4.7630, -4.8768, -4.2112,\n",
      "         -5.0404, -4.7817, -5.3297, -4.5041, -4.4132, -4.6767, -4.6012, -4.7553,\n",
      "         -4.4915, -4.5414, -4.3710, -4.4460, -4.6364, -4.2495, -4.7441, -4.7186,\n",
      "         -4.3600, -5.0120, -4.3109, -4.4660, -4.5555, -4.6414, -4.7591, -4.7977,\n",
      "         -5.2201, -4.6874, -4.6263, -5.0610, -4.7059, -4.7865, -5.0190, -4.8494,\n",
      "         -4.8576, -4.7075, -4.7987, -4.5873, -4.7544, -4.0127, -4.8406, -4.9075,\n",
      "         -4.8405, -4.5003, -4.8367, -4.3302, -4.5466, -4.1924, -4.4822, -4.7610,\n",
      "         -4.3073, -4.1970, -4.5677, -4.5921, -4.7537, -4.6887, -4.1218, -4.3878,\n",
      "         -4.4452, -4.7108, -4.8808, -4.2188, -4.8276, -4.7749, -4.3189, -4.4995,\n",
      "         -4.7837, -4.8376, -4.7082, -4.6420, -4.3427, -4.3127, -4.4237, -4.7388,\n",
      "         -4.0882, -4.6550, -4.7795, -5.0842, -4.6368, -4.4245, -4.7338, -4.8935,\n",
      "         -4.7731, -4.4130, -4.5982, -4.7507, -4.9543, -4.2946, -3.8428, -4.9353,\n",
      "         -4.1494]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty's\n",
      "target index is: [80] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2951, -4.4854, -4.7527, -4.5313, -4.2008, -4.9296, -4.5680, -4.3162,\n",
      "         -4.3941, -5.1249, -4.9751, -4.2190, -4.6631, -4.7290, -4.6116, -4.7490,\n",
      "         -4.8860, -5.1518, -4.5350, -4.4008, -4.9371, -4.7460, -4.6123, -4.4852,\n",
      "         -4.2079, -4.6531, -4.6526, -4.4327, -3.8476, -4.5682, -4.8033, -4.5939,\n",
      "         -4.7165, -4.5749, -4.6396, -5.1436, -4.8538, -4.6166, -4.6618, -4.5131,\n",
      "         -4.6829, -4.2353, -4.9921, -4.0529, -4.5066, -4.0870, -4.4391, -4.4870,\n",
      "         -4.5271, -4.8975, -4.7722, -4.4618, -4.7517, -4.3449, -4.6164, -4.4072,\n",
      "         -4.3050, -4.3067, -4.7283, -5.0378, -4.8297, -4.1884, -4.4733, -4.0935,\n",
      "         -5.0401, -4.7997, -5.0793, -4.6740, -4.8160, -4.6244, -4.2962, -4.7340,\n",
      "         -4.5159, -4.8530, -4.7953, -4.9064, -5.1732, -4.1909, -4.5889, -4.4668,\n",
      "         -4.7728, -4.3241, -5.2070, -4.7893, -4.8698, -4.1110, -4.6123, -5.0074,\n",
      "         -5.0330, -4.5833, -5.2208, -4.4814, -4.5844, -4.4946, -4.2703, -4.3130,\n",
      "         -4.5341]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : use,\n",
      "target index is: [11] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1720, -4.6062, -4.9948, -5.2793, -3.7457, -5.0879, -4.6930, -4.6366,\n",
      "         -4.7061, -4.5886, -4.9167, -4.7757, -5.2886, -4.8250, -4.6597, -4.8403,\n",
      "         -5.0148, -4.4839, -4.7329, -4.3657, -4.8260, -4.1267, -5.2164, -4.6574,\n",
      "         -4.3523, -4.8803, -4.2382, -4.1926, -4.0698, -5.0261, -4.7260, -4.5910,\n",
      "         -4.7965, -4.6523, -4.9601, -5.1875, -5.0925, -4.7676, -5.1068, -4.7037,\n",
      "         -4.6800, -5.3212, -4.9252, -4.6110, -4.7166, -4.4314, -4.7934, -4.3430,\n",
      "         -4.4231, -4.8584, -3.9626, -5.4968, -4.3002, -4.5126, -4.8616, -4.3322,\n",
      "         -4.5070, -4.3853, -4.3309, -4.2202, -4.6631, -4.4488, -4.3491, -3.6349,\n",
      "         -4.5653, -4.8482, -4.9101, -4.8849, -4.3682, -4.4926, -4.2200, -4.5934,\n",
      "         -5.1027, -4.6327, -4.6907, -4.8344, -4.1036, -4.6387, -4.6722, -4.4843,\n",
      "         -4.5975, -4.0330, -5.4891, -5.0722, -4.5938, -4.6146, -4.6353, -4.9922,\n",
      "         -4.7764, -4.3468, -4.3086, -4.4254, -4.6253, -4.0638, -4.2803, -4.6160,\n",
      "         -4.6113]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : If\n",
      "target index is: [61] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7298, -4.3087, -4.9055, -4.9630, -4.4574, -4.7747, -4.7833, -4.2825,\n",
      "         -4.6210, -4.7779, -4.8151, -4.1617, -4.7377, -4.4769, -4.8524, -4.8390,\n",
      "         -4.3918, -4.6292, -4.9073, -4.4723, -4.5030, -4.9058, -4.8564, -4.5897,\n",
      "         -4.5671, -4.8354, -4.5085, -4.2705, -4.3266, -4.4759, -4.4062, -4.7747,\n",
      "         -5.2107, -4.7077, -4.9569, -5.3572, -4.4051, -4.9265, -4.4681, -4.4776,\n",
      "         -4.2825, -4.8374, -4.2621, -4.4638, -4.2206, -4.3608, -4.5190, -4.7865,\n",
      "         -4.5614, -4.8196, -4.3113, -4.3788, -4.6113, -4.3657, -4.5295, -4.5124,\n",
      "         -4.5993, -4.3796, -4.8447, -4.6172, -4.6098, -4.2949, -4.4593, -3.7300,\n",
      "         -4.4076, -4.4123, -4.7502, -4.6455, -4.3163, -3.9892, -4.4993, -4.5475,\n",
      "         -4.8812, -4.8662, -5.0769, -5.0233, -4.8203, -4.0522, -4.7788, -4.7904,\n",
      "         -5.0325, -4.5606, -4.9097, -5.1382, -5.0034, -4.3249, -4.4144, -4.5683,\n",
      "         -5.0589, -4.1649, -4.6979, -4.8651, -4.9442, -4.2727, -4.6407, -4.8002,\n",
      "         -4.6330]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thou\n",
      "target index is: [22] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5519, -4.4336, -4.9606, -4.6258, -4.4044, -4.8803, -4.4677, -4.3790,\n",
      "         -4.4360, -4.7315, -4.6000, -4.4571, -4.7574, -4.8958, -4.5939, -4.5721,\n",
      "         -4.7436, -5.0921, -4.5225, -4.3899, -4.5608, -4.4481, -4.8498, -4.3399,\n",
      "         -4.2569, -4.5765, -4.4724, -4.6729, -4.5133, -4.7177, -4.8889, -4.9387,\n",
      "         -4.6898, -4.7435, -4.3562, -4.5151, -4.5397, -4.6664, -4.7101, -4.5067,\n",
      "         -5.0502, -4.1679, -4.8331, -4.7376, -4.4729, -4.3813, -4.3564, -4.5636,\n",
      "         -4.1483, -5.1460, -4.8589, -4.2712, -4.7380, -4.3639, -4.6890, -4.4377,\n",
      "         -4.5451, -4.4599, -4.4999, -4.7103, -4.7445, -4.4773, -4.2969, -4.4250,\n",
      "         -4.9326, -4.6403, -4.5572, -4.4676, -4.5992, -4.4542, -4.1781, -4.9290,\n",
      "         -4.5245, -4.7308, -4.6728, -4.8872, -4.5284, -4.3899, -4.7393, -4.4217,\n",
      "         -4.6246, -4.5784, -4.8573, -4.4629, -4.5324, -4.5955, -4.7017, -4.7129,\n",
      "         -4.7843, -4.3036, -5.0064, -4.4052, -4.5595, -4.5256, -4.6537, -4.5173,\n",
      "         -4.4735]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : couldst\n",
      "target index is: [47] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4844, -4.3484, -4.4883, -4.7838, -4.2147, -4.8064, -4.7825, -4.3834,\n",
      "         -4.6166, -4.7764, -4.6229, -4.5100, -4.6185, -4.8613, -4.6934, -4.3024,\n",
      "         -4.5639, -4.5374, -4.4499, -4.5810, -4.5221, -4.3148, -4.7149, -4.7734,\n",
      "         -4.2696, -4.5829, -4.4470, -4.6146, -4.2921, -4.6820, -4.5509, -4.8149,\n",
      "         -4.8138, -4.4979, -4.6427, -4.8241, -4.5851, -4.7965, -4.7589, -4.8401,\n",
      "         -4.5947, -4.7353, -4.7783, -4.6796, -4.6169, -4.5658, -4.6540, -4.7733,\n",
      "         -4.5874, -4.6071, -4.4942, -4.6375, -4.6185, -4.5178, -4.7457, -4.6493,\n",
      "         -4.4435, -4.4933, -4.4292, -4.4873, -4.7892, -4.6133, -4.4250, -4.1564,\n",
      "         -4.7502, -4.4696, -4.7958, -4.7069, -4.4996, -4.5996, -4.3737, -4.3978,\n",
      "         -4.7627, -4.8233, -4.7163, -4.7100, -4.3656, -4.3840, -4.7954, -4.6502,\n",
      "         -4.4756, -4.4082, -4.7906, -4.8122, -4.5001, -4.6176, -4.3781, -4.6723,\n",
      "         -4.6180, -4.3276, -4.5374, -4.7539, -4.6494, -4.2734, -4.4291, -4.5942,\n",
      "         -4.5817]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : answer\n",
      "target index is: [53] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3983, -4.7385, -4.7324, -4.7835, -4.2175, -4.5551, -4.6926, -4.2969,\n",
      "         -4.7983, -4.7942, -4.7306, -4.4174, -4.5309, -4.7099, -4.8257, -4.6751,\n",
      "         -4.2586, -4.6340, -4.3739, -4.6840, -4.5765, -4.3855, -4.6250, -4.5193,\n",
      "         -4.2869, -5.0268, -4.3304, -4.8012, -4.5645, -4.5106, -4.5479, -4.7407,\n",
      "         -4.7968, -4.7299, -4.3895, -4.8842, -4.5682, -4.3495, -4.7905, -4.7855,\n",
      "         -4.7862, -4.6336, -4.8008, -4.6500, -4.3831, -4.3247, -4.5429, -4.7150,\n",
      "         -4.7583, -4.3430, -4.7844, -4.4473, -4.8204, -4.3769, -4.5885, -4.5344,\n",
      "         -4.6122, -4.4303, -4.4195, -4.4489, -4.6109, -4.5741, -4.4528, -3.9963,\n",
      "         -4.5507, -4.6103, -4.8075, -4.6163, -4.6387, -4.5678, -4.4123, -4.5935,\n",
      "         -4.8016, -4.6629, -4.8343, -4.7610, -4.4001, -4.3050, -4.5903, -4.9168,\n",
      "         -4.3761, -4.6159, -4.6950, -4.8378, -4.6364, -4.7067, -4.4933, -4.5701,\n",
      "         -5.0941, -4.3296, -4.4375, -4.6796, -4.7569, -4.5158, -4.4995, -4.8148,\n",
      "         -4.3275]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : 'This\n",
      "target index is: [9] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4253, -4.7044, -4.8519, -4.6987, -3.7096, -4.6335, -4.3964, -4.3355,\n",
      "         -4.9068, -4.8387, -4.9071, -4.5879, -4.8753, -4.7638, -4.7724, -4.8109,\n",
      "         -4.4488, -4.8620, -4.7066, -4.5387, -4.4755, -4.3695, -4.8448, -4.3991,\n",
      "         -4.5516, -4.9770, -4.4512, -4.4496, -4.5512, -4.7621, -4.5338, -4.6831,\n",
      "         -4.5949, -4.9302, -4.3081, -4.6466, -4.5494, -4.7585, -4.8425, -4.3757,\n",
      "         -4.8163, -4.2196, -4.7275, -4.3924, -4.7133, -4.1630, -4.5153, -4.5520,\n",
      "         -4.6005, -4.8375, -4.9253, -4.4963, -4.9932, -4.0155, -4.4259, -4.2550,\n",
      "         -4.6103, -4.3589, -4.6570, -4.5672, -4.5039, -4.4427, -4.6504, -4.4575,\n",
      "         -4.4707, -4.6747, -4.4542, -4.2223, -4.6744, -4.7599, -4.3884, -4.5830,\n",
      "         -4.7849, -5.0632, -4.8906, -5.0180, -4.7378, -4.4037, -4.7052, -4.7868,\n",
      "         -4.7452, -4.4760, -4.7031, -4.8014, -4.6381, -4.2087, -4.4028, -4.8371,\n",
      "         -4.9354, -4.3890, -4.6966, -4.4787, -4.6045, -4.6720, -4.5232, -4.6989,\n",
      "         -4.3216]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : fair\n",
      "target index is: [21] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3929, -4.4411, -4.8793, -4.5945, -4.0953, -4.6096, -4.8313, -4.2932,\n",
      "         -4.6806, -4.4091, -4.8294, -4.4785, -4.6195, -4.6657, -4.7600, -4.5906,\n",
      "         -4.6295, -4.4804, -4.6019, -4.3706, -4.5656, -4.2580, -4.9116, -4.9011,\n",
      "         -4.4575, -4.7737, -4.4495, -4.3896, -4.2988, -4.6355, -4.6117, -4.7009,\n",
      "         -4.9823, -4.7946, -4.4860, -4.6627, -4.7844, -4.7897, -5.1406, -4.8337,\n",
      "         -4.7562, -4.5546, -4.4601, -4.6918, -4.4231, -4.2531, -4.5933, -4.8176,\n",
      "         -4.5532, -4.8657, -4.7106, -4.3037, -4.7062, -4.3878, -4.7038, -4.6917,\n",
      "         -4.2677, -4.3760, -4.5081, -4.5818, -4.6714, -4.5477, -4.5792, -4.4573,\n",
      "         -4.4548, -4.7207, -4.6849, -4.5451, -4.8024, -4.6398, -4.3511, -4.6039,\n",
      "         -4.6071, -4.8760, -4.5904, -4.6484, -4.5113, -4.5067, -4.6682, -4.7487,\n",
      "         -4.3695, -4.3287, -4.5285, -4.7101, -4.5784, -4.2659, -4.7803, -4.7452,\n",
      "         -4.7258, -4.3811, -4.8530, -4.8047, -4.7590, -4.1949, -4.3750, -4.6649,\n",
      "         -4.4026]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : child\n",
      "target index is: [5] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3792, -4.4326, -4.9904, -4.6457, -4.1136, -4.7680, -4.6074, -4.6833,\n",
      "         -4.7087, -4.4835, -4.9890, -4.5515, -4.8872, -4.7608, -4.7692, -4.8686,\n",
      "         -4.5718, -4.6799, -4.7962, -4.4727, -4.5498, -4.3711, -4.9085, -4.6302,\n",
      "         -4.7292, -5.2304, -4.5636, -4.4752, -4.1529, -4.7122, -4.4860, -4.7898,\n",
      "         -4.6986, -4.6992, -4.5539, -4.8030, -4.4629, -4.6629, -4.7064, -4.5169,\n",
      "         -4.6477, -4.4618, -4.5057, -4.3988, -4.5726, -4.2517, -4.7169, -4.5821,\n",
      "         -4.6007, -4.9001, -4.7533, -4.6082, -5.0375, -4.3648, -4.4005, -4.2356,\n",
      "         -4.3389, -4.2319, -4.5719, -4.7522, -4.5257, -4.4037, -4.7705, -4.4221,\n",
      "         -4.4410, -4.5750, -4.7709, -4.3082, -4.4571, -4.3997, -4.4092, -4.5394,\n",
      "         -4.8042, -4.9802, -5.0082, -5.2095, -4.8358, -4.2654, -4.6573, -4.7776,\n",
      "         -4.6215, -4.3770, -4.6590, -4.9964, -4.7151, -4.1564, -4.3892, -4.3011,\n",
      "         -4.8664, -4.4319, -4.4448, -4.3740, -4.6435, -4.5300, -4.6213, -4.5659,\n",
      "         -4.1749]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : of\n",
      "target index is: [57] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6147, -4.0588, -4.5636, -4.7175, -4.0957, -4.8243, -4.8345, -4.5297,\n",
      "         -4.7534, -4.8572, -5.0973, -4.4931, -4.5766, -4.5466, -4.6650, -4.5797,\n",
      "         -4.7564, -4.5596, -4.6669, -4.4096, -4.5009, -4.1922, -4.8134, -4.4436,\n",
      "         -4.2622, -4.5998, -4.4749, -4.4591, -4.2343, -4.7454, -4.7077, -4.9756,\n",
      "         -5.0758, -4.5510, -4.7100, -4.7207, -4.8522, -4.8760, -4.8474, -4.7489,\n",
      "         -4.6991, -4.4263, -4.5962, -4.5625, -4.5341, -4.2855, -4.8395, -4.9187,\n",
      "         -4.5088, -4.7533, -4.4891, -4.4654, -4.6181, -4.3016, -4.7752, -4.7237,\n",
      "         -4.3919, -4.4615, -4.4873, -4.5631, -4.8645, -4.8166, -4.4049, -4.2560,\n",
      "         -4.6221, -4.7219, -5.0454, -4.4451, -4.7742, -4.7055, -4.5207, -4.5171,\n",
      "         -4.6350, -4.9379, -4.6039, -4.7221, -4.5455, -4.3881, -4.7625, -4.8033,\n",
      "         -4.1583, -4.3723, -4.6222, -4.6557, -4.4555, -4.3535, -4.5981, -4.8241,\n",
      "         -4.5078, -4.2759, -4.8646, -4.8474, -4.6254, -4.2085, -4.1792, -4.7740,\n",
      "         -4.3341]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : mine\n",
      "target index is: [86] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1092, -4.3423, -4.6100, -5.0127, -4.1224, -4.6335, -4.8169, -4.4882,\n",
      "         -4.6950, -4.7829, -5.0267, -4.3107, -4.9269, -4.5441, -4.5900, -4.7761,\n",
      "         -4.6676, -4.8574, -4.5663, -4.1899, -4.9321, -4.7130, -4.5944, -4.1270,\n",
      "         -4.5200, -4.4784, -4.6734, -4.4617, -4.1988, -4.6156, -4.5907, -4.9996,\n",
      "         -4.7682, -4.4922, -4.6396, -4.6835, -4.6466, -4.7490, -4.8120, -4.7200,\n",
      "         -4.8785, -4.4615, -4.7906, -4.5261, -4.7963, -4.1656, -4.8601, -4.6159,\n",
      "         -4.5580, -4.5965, -4.6580, -4.8662, -4.6292, -4.3461, -4.8052, -4.6638,\n",
      "         -4.3231, -4.4451, -4.6791, -4.5604, -4.5910, -4.6162, -4.4150, -4.3484,\n",
      "         -4.7485, -4.6198, -5.1735, -4.8040, -4.6365, -4.7764, -4.2731, -4.5462,\n",
      "         -4.5847, -4.9264, -4.5970, -4.5967, -4.6137, -4.2276, -4.6589, -4.4806,\n",
      "         -4.6564, -4.3089, -4.7206, -4.8098, -4.6628, -4.4640, -4.4166, -4.4154,\n",
      "         -4.8943, -4.2469, -4.5404, -4.6069, -4.5220, -4.5183, -4.3203, -4.5918,\n",
      "         -4.3878]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Shall\n",
      "target index is: [81] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2641, -4.3717, -4.5808, -5.0836, -4.0382, -4.7187, -4.6902, -4.5452,\n",
      "         -4.7246, -4.9476, -4.7654, -4.2946, -4.6694, -4.7771, -4.7213, -4.6076,\n",
      "         -4.3255, -4.7058, -4.4981, -4.6284, -4.5863, -4.5109, -4.7197, -4.4130,\n",
      "         -4.3970, -4.5370, -4.3616, -4.4613, -4.4095, -4.8498, -4.1575, -5.0082,\n",
      "         -4.5600, -4.6249, -4.5637, -4.9823, -4.4550, -4.6448, -4.8670, -4.9608,\n",
      "         -4.6444, -4.7640, -4.7676, -4.6134, -4.6315, -4.1798, -4.5092, -4.7013,\n",
      "         -4.7659, -4.6506, -4.5619, -4.5966, -4.6954, -4.4334, -4.5698, -4.9800,\n",
      "         -4.5918, -4.6411, -4.5264, -4.5022, -4.6807, -4.5503, -4.6293, -4.1289,\n",
      "         -4.7771, -4.7384, -4.8139, -4.5470, -4.5182, -4.3700, -4.7549, -4.6206,\n",
      "         -4.8335, -4.8368, -4.7154, -4.5390, -4.6472, -4.1767, -4.5781, -4.5162,\n",
      "         -4.5218, -4.3663, -4.7807, -5.0744, -4.5375, -4.5627, -4.1755, -4.5745,\n",
      "         -4.9162, -4.3855, -4.5419, -4.7661, -4.7878, -4.3783, -4.1316, -4.6930,\n",
      "         -4.4565]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : sum\n",
      "target index is: [70] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3129, -4.3845, -4.6842, -4.8240, -4.1748, -4.8734, -4.5596, -4.3693,\n",
      "         -4.6486, -4.7715, -4.7052, -4.3228, -4.5653, -4.9627, -4.8128, -4.6796,\n",
      "         -4.5204, -5.1651, -4.7229, -4.6408, -4.6018, -4.3092, -4.7316, -4.5834,\n",
      "         -4.3038, -4.9695, -4.3035, -4.4889, -4.4599, -4.6260, -4.5706, -4.8855,\n",
      "         -4.8687, -4.9215, -4.3169, -4.4706, -4.7143, -4.4567, -4.6861, -4.5887,\n",
      "         -5.0516, -4.3938, -4.5964, -4.5162, -4.4175, -4.2178, -4.4183, -4.6250,\n",
      "         -4.3357, -4.7865, -4.6003, -4.1277, -4.9711, -4.4259, -4.6990, -4.5466,\n",
      "         -4.6253, -4.4603, -4.5837, -4.9406, -4.8150, -4.5794, -4.6707, -4.3055,\n",
      "         -4.9374, -4.5949, -4.8438, -4.3876, -4.5798, -4.6110, -4.3253, -4.7866,\n",
      "         -4.5477, -4.8245, -4.6612, -4.7989, -4.5747, -4.1681, -4.7221, -4.8368,\n",
      "         -4.3384, -4.6553, -4.5541, -4.6491, -4.2616, -4.6020, -4.4918, -4.6885,\n",
      "         -5.0186, -4.4304, -4.6870, -4.5484, -4.5528, -4.6854, -4.4806, -4.4222,\n",
      "         -4.4052]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : my\n",
      "target index is: [90] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4118, -4.3726, -4.6023, -5.1547, -4.2119, -5.1485, -4.4903, -4.4687,\n",
      "         -4.7350, -4.6195, -5.1335, -4.5733, -4.7527, -4.7834, -4.3668, -4.6202,\n",
      "         -4.6221, -4.6852, -4.9380, -4.3636, -4.8265, -4.2786, -4.8093, -4.5962,\n",
      "         -4.3995, -5.0074, -4.2179, -4.4669, -4.1281, -4.5947, -4.6758, -4.8632,\n",
      "         -4.7820, -4.8920, -4.7391, -4.5670, -4.6739, -4.4225, -4.8676, -4.5186,\n",
      "         -4.9321, -4.7741, -4.8808, -4.3772, -4.8540, -4.3139, -4.8132, -4.6435,\n",
      "         -4.5307, -5.1695, -4.1015, -5.0901, -4.4592, -4.5488, -4.7146, -4.4751,\n",
      "         -4.5273, -4.4588, -4.3182, -5.0230, -4.6106, -4.3876, -4.4809, -4.2553,\n",
      "         -4.6219, -4.3806, -5.0806, -4.5878, -4.4004, -4.5588, -4.5881, -4.5878,\n",
      "         -4.7446, -4.7520, -4.7293, -5.0185, -4.3981, -4.3220, -4.4629, -4.6506,\n",
      "         -4.4396, -4.4882, -4.8373, -4.4482, -4.6594, -4.1844, -4.5172, -4.8445,\n",
      "         -4.4862, -4.5948, -4.3999, -4.5554, -4.7081, -4.3186, -4.6297, -4.3086,\n",
      "         -4.1653]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : count,\n",
      "target index is: [55] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5978, -4.2375, -4.7308, -4.9474, -4.4770, -4.9452, -4.6690, -4.4355,\n",
      "         -4.6144, -4.8759, -4.9827, -4.6483, -4.6967, -4.7514, -4.7319, -4.6565,\n",
      "         -4.5661, -4.5995, -4.8566, -4.6551, -4.6193, -4.6744, -4.9575, -4.3808,\n",
      "         -4.4135, -4.7034, -4.4985, -4.2134, -4.2894, -4.6194, -4.2190, -4.8730,\n",
      "         -5.0260, -4.7774, -4.8416, -4.6427, -4.5583, -4.8143, -4.7199, -4.4977,\n",
      "         -4.6206, -4.6455, -4.3767, -4.5631, -4.5224, -4.2199, -4.9855, -4.6638,\n",
      "         -4.6448, -4.9519, -4.2686, -4.6496, -4.7886, -4.3196, -4.6200, -4.4420,\n",
      "         -4.2074, -4.2610, -4.6515, -4.4595, -4.5982, -4.5401, -4.3057, -4.1459,\n",
      "         -4.6023, -4.5085, -4.9719, -4.4055, -4.2188, -4.1807, -4.4495, -4.5179,\n",
      "         -4.7997, -4.8292, -5.0009, -5.1151, -4.3661, -4.2244, -4.8071, -4.9296,\n",
      "         -4.6982, -4.7280, -4.8512, -4.8597, -4.7572, -4.3133, -4.1929, -4.5537,\n",
      "         -4.7770, -4.3247, -4.3622, -4.9279, -4.7830, -4.2991, -4.5449, -4.7204,\n",
      "         -4.3882]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : and\n",
      "target index is: [44] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6768, -4.4652, -4.7036, -4.6750, -4.1845, -4.9009, -4.4328, -4.2643,\n",
      "         -4.7491, -4.9918, -4.6516, -4.4976, -4.6399, -4.8815, -4.7461, -4.4014,\n",
      "         -4.3159, -4.8255, -4.5533, -4.6931, -4.4876, -4.2834, -4.4832, -4.5372,\n",
      "         -4.1969, -4.8314, -4.4591, -4.5154, -4.7518, -4.4425, -4.6128, -4.8510,\n",
      "         -4.8191, -4.8301, -4.3562, -4.2730, -4.9145, -4.7951, -4.8318, -4.6593,\n",
      "         -4.9678, -4.6191, -4.8731, -4.5747, -4.4567, -4.5214, -4.3220, -4.8076,\n",
      "         -4.2449, -4.5743, -4.6503, -4.3203, -4.8224, -4.1831, -4.5708, -4.5910,\n",
      "         -4.5241, -4.6136, -4.6816, -4.7782, -4.9795, -4.6984, -4.3754, -4.1351,\n",
      "         -4.9426, -4.4690, -4.7099, -4.1389, -4.6630, -4.8300, -4.5410, -4.8592,\n",
      "         -4.3730, -4.6501, -4.7721, -4.8554, -4.3155, -4.4745, -4.8205, -4.4733,\n",
      "         -4.3280, -4.5266, -4.7777, -4.8067, -4.6409, -4.5097, -4.6984, -4.7899,\n",
      "         -4.9640, -4.1291, -4.8848, -4.9407, -4.3353, -4.4185, -4.4772, -4.4506,\n",
      "         -4.5561]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : make\n",
      "target index is: [14] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4703, -4.2518, -4.7328, -5.1244, -4.3304, -4.6367, -4.6003, -4.4018,\n",
      "         -4.6768, -4.6792, -4.7849, -4.5489, -4.8393, -4.6605, -4.4101, -4.5905,\n",
      "         -4.6130, -4.7354, -4.7400, -4.1840, -4.8679, -4.6705, -4.9336, -4.4079,\n",
      "         -4.7212, -4.6813, -4.4162, -4.3492, -4.2975, -4.6593, -4.5720, -4.7928,\n",
      "         -4.8862, -4.7536, -4.4439, -4.4393, -4.5250, -4.9789, -4.7934, -4.6048,\n",
      "         -4.7027, -4.6353, -4.6376, -4.4506, -4.7732, -4.3351, -5.0590, -4.5214,\n",
      "         -4.4061, -4.9865, -4.2202, -4.8686, -4.2626, -4.5531, -4.9862, -4.2658,\n",
      "         -4.5125, -4.3805, -4.8229, -4.4623, -4.5808, -4.6310, -4.3860, -4.4248,\n",
      "         -4.6242, -4.4595, -5.2362, -4.8718, -4.4406, -4.5580, -4.2101, -4.6584,\n",
      "         -4.5685, -4.8726, -4.4885, -4.7838, -4.5031, -4.2657, -4.7756, -4.7167,\n",
      "         -4.6754, -4.6181, -4.7006, -4.7574, -4.5941, -4.4667, -4.4630, -4.5570,\n",
      "         -4.5082, -4.1592, -4.5864, -4.3964, -4.7812, -4.4464, -4.6243, -4.5236,\n",
      "         -4.3657]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : my\n",
      "target index is: [90] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3584, -4.2354, -4.8763, -5.0441, -4.1915, -5.0065, -4.3565, -4.3981,\n",
      "         -4.8270, -4.6814, -4.6740, -4.3979, -4.6286, -4.9885, -4.7747, -4.4740,\n",
      "         -4.3787, -4.8124, -4.7642, -4.6261, -4.8069, -4.1370, -4.7608, -4.9087,\n",
      "         -4.2535, -5.0325, -4.1661, -4.5468, -4.1586, -4.6991, -4.3632, -4.8917,\n",
      "         -4.5930, -4.7039, -4.7341, -4.6585, -4.8489, -4.3535, -5.0238, -4.8377,\n",
      "         -4.7006, -4.8947, -4.6447, -4.5603, -4.5335, -4.2868, -4.5880, -4.8790,\n",
      "         -4.6311, -4.7814, -4.5176, -4.5949, -4.6885, -4.6212, -4.5147, -4.7277,\n",
      "         -4.7543, -4.5266, -4.5015, -4.8700, -4.8056, -4.1714, -4.5000, -4.0090,\n",
      "         -4.7206, -4.8717, -4.8237, -4.5193, -4.4775, -4.0587, -4.7011, -4.7236,\n",
      "         -4.6157, -4.5849, -4.7811, -4.9414, -4.4620, -4.4645, -4.4127, -4.5705,\n",
      "         -4.4869, -4.4731, -5.0043, -4.7454, -4.6410, -4.6379, -4.6538, -4.5695,\n",
      "         -4.6192, -4.2745, -4.5165, -4.7584, -4.8071, -4.2204, -4.3342, -4.4658,\n",
      "         -4.3029]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : old\n",
      "target index is: [84] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.0883, -4.3321, -4.4085, -5.0319, -4.2470, -5.2512, -4.4143, -4.4170,\n",
      "         -4.5132, -4.9257, -4.9719, -4.7965, -4.2773, -4.8021, -4.9263, -4.4208,\n",
      "         -4.5141, -4.5992, -4.8736, -4.7529, -4.7278, -4.2583, -5.0998, -4.7361,\n",
      "         -4.0467, -4.8598, -4.3318, -4.5108, -3.9264, -4.7182, -4.5988, -4.6862,\n",
      "         -4.6434, -4.9703, -4.8624, -4.5961, -4.7768, -4.3373, -4.7259, -4.5449,\n",
      "         -4.8472, -4.4902, -4.7809, -4.2689, -4.5284, -4.3938, -4.8323, -4.5605,\n",
      "         -4.6198, -4.9102, -4.0689, -4.7203, -4.9356, -4.6694, -4.7190, -4.5759,\n",
      "         -4.2461, -4.5650, -4.4067, -4.8332, -4.9502, -4.3823, -4.3824, -4.2741,\n",
      "         -4.7387, -4.7426, -4.8917, -4.5753, -4.4972, -4.3901, -4.5652, -4.4109,\n",
      "         -4.7612, -4.8895, -4.7469, -4.9625, -4.3349, -4.3519, -4.7765, -4.8894,\n",
      "         -4.1307, -4.5592, -4.8210, -4.7403, -4.5034, -4.5070, -4.6077, -4.7728,\n",
      "         -4.8610, -4.5500, -4.5691, -4.6109, -4.6114, -4.4351, -4.8260, -4.3707,\n",
      "         -4.4118]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : excuse,'\n",
      "target index is: [64] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4931, -4.4306, -4.5222, -4.7927, -4.1607, -4.9120, -4.6358, -4.3545,\n",
      "         -4.7587, -4.8057, -4.7466, -4.6523, -4.4940, -4.5105, -4.8309, -4.6177,\n",
      "         -4.7291, -4.2849, -4.6397, -4.6059, -4.4124, -4.6788, -4.5236, -4.7622,\n",
      "         -4.2715, -4.7736, -4.5907, -4.5563, -4.3657, -4.2481, -4.6427, -4.6806,\n",
      "         -4.8899, -4.7324, -4.6721, -5.2190, -4.7948, -4.6660, -4.6044, -4.5250,\n",
      "         -4.3731, -4.7939, -4.8026, -4.6289, -4.5798, -4.5889, -4.5473, -4.4495,\n",
      "         -4.5004, -4.4596, -4.3263, -4.5103, -4.5041, -4.4871, -4.5728, -4.4268,\n",
      "         -4.6110, -4.4598, -4.3816, -4.6105, -4.9453, -4.5345, -4.5291, -3.7466,\n",
      "         -4.6844, -4.4205, -4.6747, -4.3496, -4.5236, -4.6268, -4.6011, -4.5710,\n",
      "         -4.9445, -4.8674, -4.8472, -4.6445, -4.6316, -4.4959, -4.5592, -4.5691,\n",
      "         -4.7559, -4.6926, -4.9412, -4.9300, -4.6679, -4.2167, -4.4142, -4.9542,\n",
      "         -4.8959, -4.1624, -4.4989, -4.7023, -4.5909, -4.4943, -4.6594, -4.5518,\n",
      "         -4.8557]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Proving\n",
      "target index is: [25] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4919, -4.6015, -4.9643, -4.7213, -4.4728, -4.6871, -4.6591, -4.4580,\n",
      "         -4.6036, -4.5647, -4.9636, -4.4026, -4.4485, -4.5327, -4.5403, -4.8618,\n",
      "         -4.5802, -4.8623, -4.3852, -4.6117, -4.4959, -4.4670, -4.7921, -4.4880,\n",
      "         -4.4329, -4.7071, -4.2117, -4.5757, -4.4570, -4.4776, -5.0749, -4.8188,\n",
      "         -4.8244, -4.8041, -4.9711, -5.0132, -4.4551, -4.7226, -4.6175, -4.3603,\n",
      "         -4.7701, -4.5802, -4.6257, -4.6840, -4.3522, -4.3773, -4.7282, -4.8173,\n",
      "         -4.4529, -4.9925, -4.3045, -4.5259, -4.5299, -4.1327, -4.5476, -4.2607,\n",
      "         -4.6892, -4.3742, -4.5642, -4.3723, -4.4810, -4.3600, -4.3756, -4.0190,\n",
      "         -4.4214, -4.5967, -4.7121, -4.6932, -4.9398, -4.1848, -4.0232, -4.5389,\n",
      "         -5.0943, -4.3682, -4.8061, -4.9813, -4.3651, -4.4446, -4.5325, -4.6196,\n",
      "         -4.7261, -4.6149, -4.9188, -4.8896, -4.8774, -4.5753, -5.1077, -4.9865,\n",
      "         -4.8295, -4.4094, -4.6309, -4.6834, -4.7301, -4.2155, -4.6059, -4.8427,\n",
      "         -4.3604]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : his\n",
      "target index is: [49] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7140, -4.3147, -4.9206, -5.1081, -4.2559, -4.5920, -4.2465, -4.3648,\n",
      "         -4.9790, -4.4476, -4.7159, -4.3028, -4.7291, -4.6935, -4.9012, -4.5474,\n",
      "         -4.4945, -4.4706, -4.6832, -4.3463, -4.4732, -4.3838, -4.5659, -4.6486,\n",
      "         -4.6427, -4.7816, -4.4124, -4.5532, -4.7653, -4.5562, -4.7054, -4.5787,\n",
      "         -4.7691, -4.7645, -4.5071, -4.6890, -4.5031, -4.8333, -4.7272, -4.3386,\n",
      "         -4.4157, -4.5056, -4.4740, -4.3075, -4.4864, -4.6670, -4.4568, -4.3918,\n",
      "         -4.3532, -5.1900, -4.4485, -4.7566, -4.3867, -4.3420, -4.6051, -4.5450,\n",
      "         -4.9020, -4.7270, -4.2489, -4.7032, -4.9174, -4.4973, -4.5153, -4.3415,\n",
      "         -4.4568, -4.6758, -4.5515, -4.3663, -4.6705, -4.2974, -4.7602, -4.8732,\n",
      "         -4.7396, -4.8215, -4.6879, -4.9426, -4.4069, -4.5107, -4.4219, -4.4926,\n",
      "         -4.8197, -4.6653, -4.8408, -4.5710, -4.9986, -4.3583, -4.7161, -4.5925,\n",
      "         -4.8370, -4.2673, -4.6397, -4.2916, -4.9261, -4.5340, -4.6920, -4.6138,\n",
      "         -4.5169]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty\n",
      "target index is: [0] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5891, -4.4712, -4.8524, -4.6868, -4.4005, -4.7248, -4.7333, -4.0847,\n",
      "         -4.7866, -4.4652, -4.6252, -4.3225, -4.4095, -4.7616, -4.7656, -4.7130,\n",
      "         -4.6868, -4.4980, -4.3185, -4.4601, -4.5925, -4.4468, -4.7597, -4.9182,\n",
      "         -4.2902, -5.2789, -4.2905, -4.7476, -4.0217, -4.4633, -4.6238, -4.6114,\n",
      "         -4.9831, -4.6830, -4.5321, -5.0265, -4.4604, -4.5974, -4.6456, -4.8040,\n",
      "         -4.7228, -4.6379, -4.7308, -4.7172, -4.6007, -4.4330, -4.7707, -5.0133,\n",
      "         -4.8578, -4.8071, -4.6587, -4.4572, -4.8502, -4.5790, -4.6597, -4.5715,\n",
      "         -4.2509, -4.1365, -4.4197, -4.3883, -4.6636, -4.5488, -4.5040, -4.3786,\n",
      "         -4.4235, -4.6907, -4.6158, -4.7170, -4.6578, -4.3424, -4.4583, -4.4692,\n",
      "         -5.1473, -4.6169, -4.9209, -4.9013, -4.4305, -4.2306, -4.3998, -4.9044,\n",
      "         -4.4592, -4.4161, -4.6846, -4.8067, -4.7838, -4.5051, -4.6904, -4.2713,\n",
      "         -4.7633, -4.5761, -4.6060, -4.5679, -4.8583, -4.2980, -4.6193, -4.6194,\n",
      "         -4.2210]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : by\n",
      "target index is: [62] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.0328, -4.6669, -4.6892, -4.6697, -3.8834, -4.7177, -4.4595, -4.1471,\n",
      "         -4.8883, -4.9199, -4.7177, -4.4944, -4.4252, -4.6889, -4.7674, -4.7886,\n",
      "         -4.4100, -4.6790, -4.5646, -4.7925, -4.7302, -4.4206, -4.9372, -4.7175,\n",
      "         -4.1592, -4.7856, -4.4931, -4.3830, -4.5053, -4.7240, -4.5522, -4.4550,\n",
      "         -4.5555, -4.9353, -4.5777, -5.1274, -4.7947, -4.2409, -4.7053, -4.3827,\n",
      "         -4.6838, -4.4545, -4.8247, -4.3312, -4.5074, -3.9020, -4.5026, -4.7502,\n",
      "         -4.8878, -4.5146, -4.7443, -4.3767, -4.8890, -4.2660, -4.4002, -4.4623,\n",
      "         -4.3073, -4.4134, -4.6726, -4.7901, -4.8354, -4.2337, -4.3460, -4.3491,\n",
      "         -4.5539, -4.8196, -4.5800, -4.2044, -4.9843, -4.6392, -4.7094, -4.7349,\n",
      "         -4.5140, -5.0217, -4.7412, -4.8040, -4.6645, -4.3174, -4.6630, -5.0207,\n",
      "         -4.3699, -4.4937, -5.0123, -5.0108, -4.6733, -4.3084, -4.7521, -5.0966,\n",
      "         -5.1444, -4.6018, -4.8918, -4.7110, -4.5111, -4.4957, -4.6101, -4.7965,\n",
      "         -4.5075]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : succession\n",
      "target index is: [7] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6540, -4.3966, -4.6673, -4.6793, -4.1897, -4.6710, -4.7225, -4.4224,\n",
      "         -4.7035, -4.5569, -4.7141, -4.2483, -4.7788, -4.5080, -4.9621, -4.6673,\n",
      "         -4.6337, -4.4940, -4.8420, -4.5081, -4.3394, -4.5716, -4.8391, -4.8720,\n",
      "         -4.5368, -4.7137, -4.4855, -4.2582, -4.1835, -4.4483, -4.4676, -4.7612,\n",
      "         -4.9432, -4.5337, -4.8851, -5.2027, -4.5453, -4.9388, -4.5372, -4.5155,\n",
      "         -4.3228, -4.6846, -4.4349, -4.7110, -4.3027, -4.5334, -4.3249, -4.8140,\n",
      "         -4.4138, -4.8597, -4.5253, -4.5254, -4.5672, -4.3968, -4.6660, -4.5116,\n",
      "         -4.5800, -4.3709, -4.5965, -4.7219, -4.5009, -4.4237, -4.4131, -3.8822,\n",
      "         -4.3859, -4.5307, -4.6055, -4.5334, -4.4176, -4.1144, -4.3723, -4.4140,\n",
      "         -4.9837, -4.8238, -4.8042, -4.9216, -4.7773, -4.3332, -4.6690, -4.8825,\n",
      "         -4.9833, -4.5228, -4.7066, -4.8874, -4.7349, -4.4155, -4.4472, -4.5887,\n",
      "         -4.9881, -4.4681, -4.7620, -4.6444, -4.7957, -4.6972, -4.5799, -4.9937,\n",
      "         -4.7023]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thine!\n",
      "target index is: [40] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6404, -4.3506, -4.6902, -4.4627, -4.2196, -4.7520, -4.6090, -4.2795,\n",
      "         -4.7109, -4.6346, -4.6320, -4.4046, -4.7173, -4.7487, -4.4804, -4.8156,\n",
      "         -4.8856, -5.0403, -4.6249, -4.5902, -4.5401, -4.5594, -4.6656, -4.5291,\n",
      "         -4.5235, -4.5998, -4.2131, -4.3872, -4.4006, -4.6600, -4.8672, -4.8494,\n",
      "         -4.9139, -4.5451, -4.5102, -4.8699, -4.7697, -4.7643, -4.5774, -4.4289,\n",
      "         -4.7206, -4.6219, -4.6350, -4.5794, -4.6285, -4.4704, -4.5655, -4.5477,\n",
      "         -4.3186, -4.7309, -4.3814, -4.4536, -4.5139, -4.5075, -4.9718, -4.1469,\n",
      "         -4.7602, -4.3091, -4.6960, -4.7593, -4.5207, -4.5130, -4.6153, -4.1753,\n",
      "         -4.8651, -4.5328, -4.7227, -4.6060, -4.7820, -4.6529, -4.1719, -4.7781,\n",
      "         -4.7972, -4.5498, -4.3287, -4.9269, -4.7064, -4.4266, -4.5492, -4.4466,\n",
      "         -4.7074, -4.3460, -4.9357, -4.8317, -4.7256, -4.4350, -4.8727, -4.7982,\n",
      "         -4.7163, -4.3892, -4.7906, -4.3328, -4.5691, -4.2848, -4.5404, -4.2610,\n",
      "         -4.6645]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : This\n",
      "target index is: [1] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4785, -4.3418, -4.7531, -4.7701, -4.1951, -4.5646, -4.7757, -4.4568,\n",
      "         -4.5404, -4.5526, -4.7895, -4.6869, -4.8452, -4.6899, -4.4343, -4.7214,\n",
      "         -4.6033, -4.6174, -4.8270, -4.3967, -4.6853, -4.6156, -5.0896, -4.4983,\n",
      "         -4.5696, -4.6590, -4.5097, -4.4065, -4.2679, -4.7150, -4.5693, -4.7707,\n",
      "         -4.7817, -4.6823, -4.6175, -4.8630, -4.4484, -4.8629, -4.6877, -4.6339,\n",
      "         -4.6123, -4.4072, -4.6480, -4.6333, -4.6056, -4.2357, -4.7381, -4.5643,\n",
      "         -4.3078, -4.7511, -4.4646, -4.7124, -4.6665, -4.5436, -4.7833, -4.4388,\n",
      "         -4.2999, -4.2317, -4.7166, -4.3134, -4.6043, -4.7186, -4.3676, -4.2832,\n",
      "         -4.5561, -4.7626, -4.9209, -4.7529, -4.4708, -4.3621, -4.1633, -4.3225,\n",
      "         -4.9535, -4.9024, -4.6434, -4.8044, -4.4615, -4.3643, -4.7656, -4.6738,\n",
      "         -4.5677, -4.4337, -4.5960, -4.8202, -4.7491, -4.5552, -4.5402, -4.4924,\n",
      "         -4.7475, -4.2832, -4.5888, -4.5490, -4.8898, -4.4317, -4.4814, -4.7513,\n",
      "         -4.4910]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : were\n",
      "target index is: [93] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2705, -4.4745, -4.7698, -4.8903, -3.8258, -4.5559, -4.4169, -4.2810,\n",
      "         -4.6462, -4.8772, -4.6170, -4.4699, -4.6531, -4.9289, -4.7633, -4.5214,\n",
      "         -4.4856, -4.9798, -4.5844, -4.4269, -4.8614, -4.1510, -4.7509, -4.9521,\n",
      "         -4.3627, -4.6836, -4.4085, -4.3492, -4.2650, -4.8591, -4.3933, -4.9206,\n",
      "         -4.6551, -4.5980, -4.2969, -4.8312, -4.9227, -4.5579, -5.1175, -4.7791,\n",
      "         -4.6728, -4.6816, -4.7792, -4.5853, -4.8048, -4.2346, -4.2527, -4.7213,\n",
      "         -4.4703, -4.7492, -4.8311, -4.3317, -4.7713, -4.6131, -4.6067, -4.4358,\n",
      "         -4.3793, -4.4108, -4.4182, -4.7529, -4.6263, -4.4915, -4.8389, -4.0510,\n",
      "         -4.7387, -4.6835, -4.7454, -4.5837, -4.7794, -4.5175, -4.5802, -4.5989,\n",
      "         -4.3616, -4.8164, -4.6704, -4.5201, -4.7660, -4.7079, -4.6502, -4.4423,\n",
      "         -4.6991, -4.5130, -5.0521, -4.7932, -4.2356, -4.6252, -4.4456, -4.7593,\n",
      "         -4.7413, -4.4419, -4.7725, -4.5545, -4.8016, -4.4575, -4.4941, -4.5032,\n",
      "         -4.5288]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : to\n",
      "target index is: [72] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5729, -4.5401, -4.7201, -4.4738, -4.4776, -4.7705, -4.9890, -4.2532,\n",
      "         -4.7184, -4.6968, -4.6308, -4.6283, -4.5640, -4.7272, -4.7955, -4.5545,\n",
      "         -4.7583, -4.2351, -4.6140, -4.5870, -4.3681, -4.4863, -5.0892, -4.8367,\n",
      "         -4.3961, -4.9907, -4.5225, -4.2727, -4.1785, -4.7310, -4.6297, -4.2684,\n",
      "         -5.0980, -4.7648, -4.5728, -5.1662, -4.5245, -4.7106, -4.6192, -4.7361,\n",
      "         -4.4869, -4.5290, -4.5908, -4.5768, -4.5169, -4.3153, -4.7042, -4.7270,\n",
      "         -4.7616, -4.6767, -4.3763, -4.5797, -4.6867, -4.7951, -4.8342, -4.6710,\n",
      "         -3.9725, -4.1531, -4.4915, -4.3371, -4.5437, -4.4711, -4.2933, -4.1369,\n",
      "         -4.4475, -4.5318, -4.8739, -4.9377, -4.4802, -4.4239, -4.1579, -4.1673,\n",
      "         -5.1887, -5.0112, -4.8872, -4.9084, -4.3040, -4.2519, -4.7227, -4.6811,\n",
      "         -4.5023, -4.5625, -4.5590, -4.9811, -4.7714, -4.5701, -4.5318, -4.5157,\n",
      "         -5.0593, -4.5094, -4.6478, -4.6626, -5.1076, -4.2671, -4.5217, -4.8638,\n",
      "         -4.5959]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : be\n",
      "target index is: [24] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2024, -4.8317, -4.8020, -5.0669, -4.0199, -4.8076, -4.6333, -4.2221,\n",
      "         -4.8899, -5.0999, -4.9487, -4.3079, -4.6678, -4.9104, -4.9928, -4.5599,\n",
      "         -3.9658, -5.0221, -4.5940, -5.0364, -4.3690, -4.2096, -4.6598, -4.4746,\n",
      "         -4.2792, -5.0072, -4.0524, -4.6929, -4.5737, -4.7327, -4.1914, -5.3449,\n",
      "         -4.8484, -5.0879, -4.3235, -4.7038, -4.8200, -4.4477, -5.0576, -4.9694,\n",
      "         -5.0641, -4.4123, -4.6628, -4.4772, -4.2585, -4.0936, -4.4866, -4.6815,\n",
      "         -4.5885, -4.4628, -4.4627, -4.1043, -5.2553, -4.3652, -4.7276, -4.6715,\n",
      "         -4.8269, -4.4771, -4.5471, -4.8986, -4.9605, -4.5700, -4.6844, -3.9129,\n",
      "         -4.6380, -4.7341, -4.9756, -4.4442, -4.4021, -4.5164, -4.3339, -4.7291,\n",
      "         -4.6874, -4.8338, -4.6851, -4.8649, -4.7683, -4.0433, -4.7430, -5.0269,\n",
      "         -4.1416, -4.8115, -4.7063, -4.6655, -4.3324, -4.8472, -4.3062, -4.9223,\n",
      "         -4.9950, -4.4535, -4.3655, -4.6756, -4.7681, -4.5851, -4.3199, -4.6513,\n",
      "         -4.3105]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : new\n",
      "target index is: [27] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5568, -4.4793, -4.3549, -4.7162, -4.1683, -4.7249, -4.6618, -4.3832,\n",
      "         -4.6086, -4.6459, -4.8602, -4.5218, -4.6255, -4.7546, -4.5905, -4.6340,\n",
      "         -4.5419, -4.5571, -4.4702, -4.6119, -4.7787, -4.6068, -4.5692, -4.4792,\n",
      "         -4.3874, -4.6538, -4.4759, -4.6429, -4.4557, -4.4069, -4.5147, -4.6457,\n",
      "         -4.8419, -4.7000, -4.5646, -4.7027, -4.6363, -4.6787, -4.5772, -4.7006,\n",
      "         -4.6556, -4.5361, -4.9829, -4.6323, -4.7152, -4.5963, -4.6570, -4.5520,\n",
      "         -4.5383, -4.3609, -4.3183, -4.5359, -4.6862, -4.3301, -4.7252, -4.4773,\n",
      "         -4.5207, -4.6117, -4.5282, -4.6488, -4.7270, -4.6162, -4.5521, -4.0877,\n",
      "         -4.9816, -4.4536, -4.8727, -4.4310, -4.7021, -4.9897, -4.5706, -4.5848,\n",
      "         -4.7177, -4.7591, -4.6487, -4.6916, -4.4912, -4.4343, -4.5596, -4.8221,\n",
      "         -4.4489, -4.3433, -4.6076, -4.7737, -4.6842, -4.3191, -4.5693, -4.7625,\n",
      "         -4.7737, -4.1795, -4.6140, -4.8164, -4.3937, -4.5455, -4.3749, -4.4149,\n",
      "         -4.6836]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : made\n",
      "target index is: [16] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3669, -4.6246, -4.7572, -4.8469, -4.2371, -4.6723, -4.4328, -4.5223,\n",
      "         -4.6805, -4.4028, -4.8825, -4.4605, -4.6670, -4.5650, -4.6926, -4.8086,\n",
      "         -4.4480, -4.7028, -4.5980, -4.5991, -4.3446, -4.3821, -4.7479, -4.5582,\n",
      "         -4.6472, -5.1443, -4.1379, -4.6879, -4.6228, -4.7375, -4.5361, -4.8774,\n",
      "         -4.5560, -4.9205, -4.5110, -4.9638, -4.5313, -4.3651, -4.6360, -4.4024,\n",
      "         -4.6346, -4.5311, -4.5465, -4.4102, -4.4750, -4.4535, -4.6976, -4.5250,\n",
      "         -4.5834, -4.8576, -4.3720, -4.7931, -4.8330, -4.4771, -4.6087, -4.4229,\n",
      "         -4.7822, -4.5662, -4.4056, -4.6004, -4.5599, -4.5046, -4.5819, -4.2239,\n",
      "         -4.3291, -4.8734, -4.8118, -4.3597, -4.6077, -4.3873, -4.5631, -4.6578,\n",
      "         -4.8152, -4.7007, -4.7634, -4.8762, -4.5104, -4.3701, -4.3546, -4.5988,\n",
      "         -4.4696, -4.5835, -4.7416, -4.7522, -4.7817, -4.4149, -4.7312, -4.5174,\n",
      "         -4.9491, -4.6429, -4.3513, -4.5942, -4.6649, -4.5253, -4.5227, -4.4717,\n",
      "         -4.3290]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : when\n",
      "target index is: [85] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4663, -4.5571, -4.8486, -4.7623, -4.2389, -4.6454, -4.2949, -4.3768,\n",
      "         -4.8677, -4.5392, -4.9412, -4.4625, -4.7194, -4.6060, -4.4798, -4.5305,\n",
      "         -4.2523, -4.6593, -4.7319, -4.4625, -4.4707, -4.3512, -4.8230, -4.7412,\n",
      "         -4.6269, -5.0788, -4.5134, -4.2549, -4.7752, -4.7628, -4.6979, -4.5795,\n",
      "         -4.7274, -5.0232, -4.4663, -4.7597, -4.3664, -4.5797, -4.8606, -4.3687,\n",
      "         -4.5881, -4.6903, -4.6625, -4.3697, -4.5998, -4.1508, -4.7483, -4.8801,\n",
      "         -4.7223, -4.9524, -4.5769, -4.6588, -4.5283, -3.8091, -4.3881, -4.5797,\n",
      "         -4.5823, -4.5752, -4.5773, -4.6103, -4.5985, -4.4891, -4.4115, -4.5684,\n",
      "         -4.4489, -4.4492, -4.8943, -4.1691, -4.7565, -4.5145, -4.6006, -4.8707,\n",
      "         -4.8462, -4.7845, -4.8848, -5.0048, -4.4972, -4.4098, -4.4914, -4.8633,\n",
      "         -4.5053, -4.4358, -4.6379, -4.7373, -4.9138, -4.0817, -4.9573, -4.9243,\n",
      "         -4.8156, -4.3838, -4.4498, -4.6633, -4.7371, -4.4800, -4.4735, -4.7174,\n",
      "         -4.2675]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thou\n",
      "target index is: [22] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6427, -4.5806, -4.9554, -4.6627, -4.1905, -4.7685, -4.4979, -4.6998,\n",
      "         -4.6387, -4.5331, -4.6900, -4.2437, -4.8020, -4.6909, -4.7304, -4.2851,\n",
      "         -4.7181, -4.6506, -4.8109, -4.4999, -4.7673, -4.1737, -4.8456, -4.5952,\n",
      "         -4.2296, -4.7017, -4.7579, -4.3640, -4.2953, -4.3569, -4.7057, -4.5704,\n",
      "         -4.7590, -4.8212, -4.5904, -4.5098, -4.6141, -4.8251, -4.9524, -4.3397,\n",
      "         -4.8953, -4.1963, -4.6458, -4.5452, -4.4027, -4.4894, -4.5666, -4.8140,\n",
      "         -4.3705, -5.1501, -4.7170, -4.6826, -4.6462, -4.2301, -4.6063, -4.4162,\n",
      "         -4.2470, -4.4934, -4.6304, -4.4102, -4.6665, -4.5443, -4.3297, -4.5535,\n",
      "         -4.7368, -4.4771, -4.5860, -4.4375, -4.7719, -4.2571, -4.2896, -4.6256,\n",
      "         -4.8874, -4.8947, -4.7969, -4.9373, -4.5150, -4.6140, -4.7476, -4.6600,\n",
      "         -4.6302, -4.3966, -4.5465, -4.3807, -4.7079, -4.1806, -4.7227, -4.8668,\n",
      "         -4.8184, -4.4277, -4.8039, -4.6584, -4.5753, -4.5889, -4.6247, -4.6250,\n",
      "         -4.6806]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : art\n",
      "target index is: [15] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3640, -4.4619, -4.7547, -4.9212, -4.2419, -4.7798, -4.5849, -4.3785,\n",
      "         -4.6592, -4.8092, -4.6773, -4.4373, -4.4485, -4.7713, -4.7562, -4.2539,\n",
      "         -4.4929, -4.4882, -4.2675, -4.5755, -4.6022, -4.2367, -4.8503, -4.8774,\n",
      "         -4.2151, -4.7173, -4.4198, -4.5371, -4.1801, -4.5837, -4.5314, -4.8425,\n",
      "         -4.8697, -4.6018, -4.5726, -4.9293, -4.6324, -4.6157, -4.9366, -4.9237,\n",
      "         -4.8266, -4.8492, -4.7597, -4.7901, -4.6263, -4.4788, -4.6492, -4.9608,\n",
      "         -4.5969, -4.6643, -4.4436, -4.7696, -4.5094, -4.5211, -4.7621, -4.6676,\n",
      "         -4.3620, -4.4344, -4.4768, -4.4191, -4.6907, -4.3989, -4.3886, -4.1265,\n",
      "         -4.6293, -4.4582, -4.8292, -4.8201, -4.6277, -4.4542, -4.5086, -4.5105,\n",
      "         -4.9044, -4.7444, -4.6171, -4.8022, -4.3955, -4.4110, -4.7082, -4.6560,\n",
      "         -4.4433, -4.4502, -4.9454, -4.8536, -4.4441, -4.6744, -4.5539, -4.6493,\n",
      "         -4.5286, -4.3718, -4.5340, -4.7092, -4.5876, -4.1676, -4.6787, -4.5227,\n",
      "         -4.4814]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : old,\n",
      "target index is: [8] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4578, -4.5427, -4.9801, -4.6944, -4.3146, -4.7130, -4.5800, -4.3356,\n",
      "         -4.7112, -4.5970, -4.7781, -4.3738, -4.5752, -4.9563, -5.0432, -4.9493,\n",
      "         -4.6867, -4.7593, -4.5760, -4.6613, -4.3271, -4.2930, -4.7992, -4.5935,\n",
      "         -4.3781, -5.1311, -4.2915, -4.7122, -4.6450, -4.5971, -4.6874, -4.7708,\n",
      "         -4.6874, -4.8624, -4.4783, -4.8557, -4.7358, -4.3857, -4.5950, -4.3445,\n",
      "         -4.6377, -4.5710, -4.6341, -4.5625, -4.2702, -4.2978, -4.4638, -4.3872,\n",
      "         -4.4781, -4.9178, -4.7727, -4.2549, -4.8984, -4.3633, -4.3355, -4.3930,\n",
      "         -4.5867, -4.2508, -4.2713, -4.7521, -4.7593, -4.3967, -4.4545, -4.1875,\n",
      "         -4.5091, -4.7510, -4.6854, -4.3966, -4.3772, -4.1700, -4.3847, -4.7204,\n",
      "         -4.6472, -4.8649, -4.9407, -4.9557, -4.4548, -4.3355, -4.7460, -4.8226,\n",
      "         -4.6352, -4.7416, -4.8658, -4.7266, -4.5878, -4.5792, -4.5918, -4.8476,\n",
      "         -5.0283, -4.3248, -4.7684, -4.6916, -4.6768, -4.2804, -4.6552, -4.7035,\n",
      "         -4.2775]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : And\n",
      "target index is: [6] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4852, -4.3556, -4.5036, -4.5629, -4.3419, -5.0165, -4.5431, -4.4567,\n",
      "         -4.6412, -4.7989, -4.8428, -4.3823, -4.5475, -4.6312, -4.6554, -4.7100,\n",
      "         -4.6609, -4.6265, -4.9641, -4.5664, -4.4806, -4.5107, -4.6182, -4.5845,\n",
      "         -4.1997, -4.7058, -4.6124, -4.4260, -4.2809, -4.5280, -4.7156, -4.7776,\n",
      "         -4.6594, -4.7119, -4.6145, -4.5407, -4.7753, -4.5906, -4.5563, -4.4064,\n",
      "         -4.8564, -4.3787, -4.7091, -4.4191, -4.4914, -4.3769, -4.4407, -4.6205,\n",
      "         -4.5310, -4.7827, -4.5336, -4.4585, -4.9224, -4.3237, -4.5914, -4.5344,\n",
      "         -4.4325, -4.5837, -4.5662, -4.8035, -4.6964, -4.4828, -4.5221, -4.3911,\n",
      "         -4.7149, -4.6599, -4.7504, -4.2672, -4.7043, -4.6136, -4.6004, -4.6754,\n",
      "         -4.5319, -4.9566, -4.7936, -4.7969, -4.5762, -4.3033, -4.7430, -4.7691,\n",
      "         -4.2909, -4.4507, -4.5919, -4.7205, -4.5429, -4.3189, -4.6066, -4.7660,\n",
      "         -4.8650, -4.5012, -4.8040, -4.7675, -4.2888, -4.5319, -4.5366, -4.5298,\n",
      "         -4.5147]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : see\n",
      "target index is: [67] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4390, -4.5418, -4.7734, -4.9908, -4.4300, -4.7279, -4.5684, -4.4362,\n",
      "         -4.7899, -4.6129, -5.0446, -4.8620, -4.6626, -4.7271, -4.6837, -4.7228,\n",
      "         -4.5319, -4.5476, -4.7111, -4.3901, -4.7722, -4.7204, -4.9878, -4.7295,\n",
      "         -4.6516, -4.9156, -4.5618, -4.3199, -4.3572, -4.7607, -4.5192, -4.7123,\n",
      "         -5.0342, -4.9078, -4.2815, -4.5823, -4.2364, -4.5603, -4.7300, -4.7448,\n",
      "         -4.7611, -4.6170, -4.5694, -4.6083, -4.5115, -4.0878, -4.7918, -4.7112,\n",
      "         -4.7945, -4.8506, -4.2482, -4.5845, -4.6226, -4.3544, -4.7282, -4.7636,\n",
      "         -4.4077, -4.3298, -4.6340, -4.4482, -4.7598, -4.5816, -4.4466, -4.5905,\n",
      "         -4.5552, -4.4630, -5.0977, -4.4308, -4.5432, -4.6847, -4.2452, -4.1334,\n",
      "         -5.0258, -4.9527, -4.7770, -4.8715, -4.3701, -4.0926, -4.5014, -4.7519,\n",
      "         -4.2981, -4.7155, -4.3515, -4.9482, -4.7468, -4.3366, -4.4742, -4.5184,\n",
      "         -4.7283, -4.2988, -4.2754, -4.5367, -4.9452, -4.3791, -4.4321, -4.5617,\n",
      "         -4.1479]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6413, -4.4041, -4.9675, -4.5699, -4.1933, -4.6587, -4.6627, -4.2335,\n",
      "         -5.1314, -4.3878, -4.7463, -4.1869, -4.3108, -4.6184, -4.7703, -4.8459,\n",
      "         -4.3690, -4.5346, -4.3663, -4.5507, -4.6435, -4.3857, -4.3976, -4.7296,\n",
      "         -4.3880, -5.1712, -4.2729, -4.9270, -4.5640, -4.4877, -4.6532, -4.5727,\n",
      "         -4.8299, -4.6185, -4.6074, -5.1001, -4.5832, -4.5197, -4.6166, -4.7445,\n",
      "         -4.4589, -4.7798, -4.8497, -4.6156, -4.4003, -4.1458, -4.5826, -5.0419,\n",
      "         -5.0154, -4.4715, -4.8301, -4.4241, -4.4342, -4.3063, -4.4327, -4.4911,\n",
      "         -4.6476, -4.2832, -4.3128, -4.5454, -4.7323, -4.7217, -4.4468, -3.9992,\n",
      "         -4.4358, -4.6888, -4.7005, -4.4113, -4.8224, -4.5062, -4.6467, -4.6437,\n",
      "         -4.8727, -4.5461, -4.8408, -4.8668, -4.3457, -4.5113, -4.4867, -4.9133,\n",
      "         -4.5865, -4.4502, -4.7589, -4.8057, -4.8347, -4.5741, -4.7748, -4.7245,\n",
      "         -4.9861, -4.4704, -4.6427, -4.7749, -4.8761, -4.3175, -4.2615, -4.9026,\n",
      "         -4.4237]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : blood\n",
      "target index is: [39] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5673, -4.4776, -4.8726, -4.4969, -4.3690, -4.7618, -4.4124, -4.3696,\n",
      "         -4.8290, -4.7472, -4.9836, -4.3986, -4.7048, -4.4629, -4.5169, -4.8714,\n",
      "         -4.6434, -4.8014, -4.3546, -4.3985, -4.7898, -4.8303, -4.6930, -4.4461,\n",
      "         -4.6487, -5.1365, -4.7707, -4.4867, -4.1632, -4.7210, -4.4795, -4.5328,\n",
      "         -4.7195, -4.6737, -4.6969, -5.3041, -4.3731, -4.7137, -4.4417, -4.2611,\n",
      "         -4.4806, -4.4230, -4.6900, -4.1553, -4.8008, -4.1341, -5.0033, -4.6444,\n",
      "         -4.6869, -4.8714, -4.7795, -4.7434, -4.7175, -4.2638, -4.3672, -4.4989,\n",
      "         -4.2639, -4.1410, -4.7062, -4.6907, -4.6383, -4.2086, -4.5762, -4.3307,\n",
      "         -4.5535, -4.5917, -4.7164, -4.2247, -4.6965, -4.1312, -4.4876, -4.5949,\n",
      "         -5.0337, -5.0499, -4.8884, -5.2828, -5.0863, -3.9804, -4.4260, -4.5699,\n",
      "         -5.0797, -4.6074, -5.0093, -5.0838, -5.2617, -4.0499, -4.4361, -4.4905,\n",
      "         -5.2204, -4.3531, -4.8410, -4.5648, -4.7664, -4.4966, -4.4091, -4.5136,\n",
      "         -4.3125]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : warm\n",
      "target index is: [2] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5511, -4.3839, -4.6695, -4.8116, -4.5753, -4.6392, -4.4471, -4.4581,\n",
      "         -4.7548, -5.0468, -4.9662, -4.7951, -4.7303, -4.7913, -4.6161, -4.5063,\n",
      "         -4.6977, -4.9717, -4.5374, -4.2592, -4.8448, -4.2679, -5.1649, -4.4719,\n",
      "         -4.1505, -4.7063, -4.3892, -4.2781, -4.3525, -4.7102, -4.7216, -4.7810,\n",
      "         -4.9447, -4.8255, -4.5761, -4.4307, -4.8064, -4.9383, -4.8790, -4.7049,\n",
      "         -4.8154, -4.5711, -4.6823, -4.5441, -4.7285, -4.3022, -4.8362, -4.8395,\n",
      "         -4.2334, -4.8789, -4.4567, -4.3871, -4.4230, -4.1312, -4.7035, -4.1843,\n",
      "         -4.4703, -4.1309, -4.6805, -4.6635, -4.7851, -4.7670, -4.3374, -4.3894,\n",
      "         -4.8047, -4.4555, -5.1306, -4.5257, -4.6758, -4.3488, -4.0932, -4.6714,\n",
      "         -4.3854, -4.5492, -4.5511, -4.8042, -4.4736, -4.3249, -4.7267, -4.8181,\n",
      "         -4.4681, -4.8289, -4.7713, -4.5770, -4.3409, -4.6248, -4.7910, -5.0619,\n",
      "         -4.5540, -4.1032, -4.6850, -4.5614, -4.7217, -4.7567, -4.3226, -4.6956,\n",
      "         -4.2517]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : when\n",
      "target index is: [85] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5018, -4.3335, -4.7569, -4.9883, -4.2385, -4.7509, -4.3446, -4.4183,\n",
      "         -4.7113, -4.3613, -4.6550, -4.6605, -4.8251, -4.6415, -4.4568, -4.5014,\n",
      "         -4.2956, -4.6416, -4.7928, -4.6012, -4.5010, -4.4243, -4.7619, -4.6799,\n",
      "         -4.5299, -5.0693, -4.4028, -4.3426, -4.8358, -4.6144, -4.6604, -4.5789,\n",
      "         -4.7500, -4.9356, -4.5931, -4.7048, -4.5319, -4.4103, -4.9114, -4.5300,\n",
      "         -4.5419, -4.9303, -4.6620, -4.3625, -4.4033, -4.3700, -4.6884, -4.7910,\n",
      "         -4.5338, -4.6933, -4.4298, -4.8345, -4.6865, -4.2446, -4.6283, -4.6351,\n",
      "         -4.6255, -4.7552, -4.5204, -4.4782, -4.8037, -4.4596, -4.5297, -4.1198,\n",
      "         -4.5170, -4.4732, -4.7440, -4.3071, -4.5665, -4.6236, -4.7573, -5.0535,\n",
      "         -4.9938, -4.2454, -4.7158, -4.9665, -4.5043, -4.7104, -4.6378, -4.6705,\n",
      "         -4.3308, -4.3165, -4.8709, -4.5768, -4.9290, -4.1968, -5.0864, -4.5541,\n",
      "         -4.6197, -4.2109, -4.3090, -4.7351, -4.7694, -4.2150, -4.5097, -4.5856,\n",
      "         -4.6713]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thou\n",
      "target index is: [22] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6436, -4.5821, -4.9497, -4.6633, -4.1915, -4.7688, -4.4926, -4.7003,\n",
      "         -4.6333, -4.5339, -4.6900, -4.2442, -4.8030, -4.6911, -4.7308, -4.2673,\n",
      "         -4.7184, -4.6513, -4.8118, -4.5012, -4.7679, -4.1740, -4.8380, -4.5959,\n",
      "         -4.2305, -4.7022, -4.7593, -4.3651, -4.2962, -4.3575, -4.7065, -4.5715,\n",
      "         -4.7597, -4.8217, -4.5914, -4.5101, -4.6148, -4.8259, -4.9536, -4.3357,\n",
      "         -4.8962, -4.1961, -4.6463, -4.5457, -4.4037, -4.4906, -4.5678, -4.8148,\n",
      "         -4.3713, -5.1509, -4.7180, -4.6838, -4.6473, -4.2315, -4.6079, -4.4175,\n",
      "         -4.2474, -4.4950, -4.6314, -4.4110, -4.6676, -4.5452, -4.3305, -4.5545,\n",
      "         -4.7370, -4.4770, -4.5863, -4.4327, -4.7732, -4.2580, -4.2904, -4.6265,\n",
      "         -4.8880, -4.8960, -4.7976, -4.9384, -4.5158, -4.6151, -4.7438, -4.6603,\n",
      "         -4.6309, -4.3975, -4.5474, -4.3816, -4.7088, -4.1709, -4.7236, -4.8677,\n",
      "         -4.8201, -4.4287, -4.8053, -4.6590, -4.5761, -4.5903, -4.6258, -4.6254,\n",
      "         -4.6820]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : feel'st\n",
      "target index is: [35] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5102, -4.2142, -4.7191, -4.8709, -4.1355, -4.7424, -4.7232, -4.1852,\n",
      "         -4.7898, -4.4824, -4.6994, -4.6199, -4.7561, -4.8530, -4.6876, -4.5468,\n",
      "         -4.6091, -4.3404, -4.5989, -4.4969, -4.5868, -4.4913, -4.5523, -4.8882,\n",
      "         -4.5731, -4.8099, -4.4268, -4.5222, -4.5492, -4.5228, -4.4866, -4.6576,\n",
      "         -4.8631, -4.6254, -4.3190, -4.9131, -4.5165, -4.8148, -4.7666, -4.7806,\n",
      "         -4.5853, -4.8643, -4.5807, -4.6720, -4.4378, -4.3920, -4.4766, -4.6068,\n",
      "         -4.6914, -4.5508, -4.5799, -4.6878, -4.6246, -4.6218, -4.6721, -4.6207,\n",
      "         -4.5637, -4.3805, -4.3869, -4.5083, -4.9267, -4.6189, -4.5410, -4.1741,\n",
      "         -4.5282, -4.5092, -4.5331, -4.5578, -4.5204, -4.6652, -4.6685, -4.5337,\n",
      "         -4.8654, -4.9587, -4.7307, -4.7268, -4.3509, -4.4674, -4.5414, -4.7367,\n",
      "         -4.5145, -4.4926, -4.7237, -4.8998, -4.7651, -4.4098, -4.3837, -4.5573,\n",
      "         -4.6148, -4.1103, -4.4281, -4.5478, -4.8747, -4.3869, -4.5475, -4.6427,\n",
      "         -4.4958]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : it\n",
      "target index is: [88] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5591, -4.3978, -4.7894, -4.6982, -4.1305, -4.8824, -4.6273, -4.2144,\n",
      "         -4.6322, -4.6323, -4.6717, -4.3399, -4.4880, -4.8394, -4.6837, -4.6146,\n",
      "         -4.5263, -5.0286, -4.5439, -4.6569, -4.6755, -4.3670, -5.0158, -4.6220,\n",
      "         -4.1650, -4.8147, -4.1304, -4.6280, -4.0880, -4.6909, -4.6445, -5.2794,\n",
      "         -5.0625, -4.7332, -4.8926, -5.1025, -4.4933, -4.7042, -4.7438, -4.7411,\n",
      "         -4.9513, -4.4156, -4.6319, -4.6106, -4.5133, -4.2983, -4.6740, -4.8638,\n",
      "         -4.4751, -4.7655, -4.6843, -4.1050, -4.9133, -4.3429, -4.8189, -4.4274,\n",
      "         -4.5386, -4.1468, -4.6597, -4.6998, -4.6305, -4.5887, -4.3014, -4.1284,\n",
      "         -4.7362, -4.8272, -4.7538, -4.6519, -4.5247, -4.2740, -4.1377, -4.3183,\n",
      "         -4.8749, -4.7518, -4.7046, -4.7197, -4.8043, -3.9701, -4.7389, -4.8306,\n",
      "         -4.5638, -4.5529, -4.8710, -4.8061, -4.5039, -4.7275, -4.3748, -4.6163,\n",
      "         -4.7831, -4.6315, -4.8974, -4.7484, -4.7426, -4.2951, -4.5448, -4.6498,\n",
      "         -4.2135]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : cold.\n",
      "target index is: [79] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3841, -4.1026, -4.7883, -4.8422, -4.1053, -5.0338, -4.4990, -4.4918,\n",
      "         -4.8281, -4.4766, -4.7830, -4.5541, -4.6845, -4.7635, -5.0644, -4.7244,\n",
      "         -4.6000, -4.1713, -4.8360, -4.4086, -4.7390, -4.3488, -4.6768, -4.8567,\n",
      "         -4.3659, -4.7596, -4.4536, -4.2474, -4.2315, -4.4675, -4.3637, -4.5915,\n",
      "         -4.6909, -4.7272, -4.5248, -4.5159, -4.6873, -4.7526, -4.7291, -4.6974,\n",
      "         -4.6852, -4.5269, -4.5176, -4.3816, -4.4304, -4.2886, -4.4610, -4.7267,\n",
      "         -4.7415, -5.0472, -4.5559, -4.5976, -4.6782, -4.5472, -4.3695, -4.7760,\n",
      "         -4.4289, -4.4683, -4.3150, -4.6775, -4.8688, -4.4301, -4.6022, -4.4824,\n",
      "         -4.5485, -4.9894, -4.6022, -4.2547, -4.5519, -4.4135, -4.6755, -4.6723,\n",
      "         -4.9135, -5.0379, -4.9291, -4.8347, -4.5060, -4.5778, -4.5590, -4.7396,\n",
      "         -4.2794, -4.4784, -4.6196, -4.6609, -4.8937, -4.2660, -4.7936, -4.5575,\n",
      "         -4.8030, -4.4520, -4.6078, -4.5228, -4.7519, -4.5125, -4.4346, -4.6619,\n",
      "         -4.6001]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : winters\n",
      "target index is: [3] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2757, -4.6704, -4.3890, -4.6646, -4.1982, -4.5929, -4.5247, -4.2515,\n",
      "         -4.7460, -4.9132, -4.8889, -4.7906, -4.5493, -4.2641, -4.5691, -4.3773,\n",
      "         -4.1152, -4.6758, -4.6377, -4.8346, -4.8310, -4.6386, -4.6858, -4.5890,\n",
      "         -4.3940, -4.8952, -4.4626, -4.4764, -4.3775, -4.5688, -4.2729, -5.0487,\n",
      "         -4.9001, -4.6315, -4.9306, -4.8909, -4.5729, -4.7037, -5.0270, -4.6772,\n",
      "         -4.9429, -4.3832, -4.8580, -4.3758, -5.0980, -4.3668, -5.1235, -5.1833,\n",
      "         -4.9034, -4.2550, -4.6353, -4.3894, -4.8276, -4.1407, -4.9559, -4.1507,\n",
      "         -4.2689, -4.1537, -4.8580, -4.3990, -4.2867, -4.6458, -4.4552, -4.1094,\n",
      "         -4.5604, -3.9710, -5.3829, -4.5008, -4.8536, -4.6492, -4.5788, -4.2706,\n",
      "         -4.9451, -4.8637, -4.5991, -5.1677, -4.8672, -4.1472, -4.5754, -4.8024,\n",
      "         -4.3378, -4.5697, -4.6935, -5.0640, -4.7452, -4.3856, -4.6896, -4.6440,\n",
      "         -5.0989, -4.3898, -4.3971, -4.6877, -4.6480, -4.6827, -4.4377, -4.7735,\n",
      "         -4.3759]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : shall\n",
      "target index is: [10] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5261, -4.3438, -5.0964, -4.8539, -4.2403, -4.7526, -4.4019, -4.6878,\n",
      "         -4.7600, -4.4438, -4.7243, -4.4010, -4.8094, -4.6833, -5.0463, -4.5129,\n",
      "         -4.7398, -4.5805, -4.6778, -4.4920, -4.5126, -3.9897, -4.6451, -4.5122,\n",
      "         -4.2013, -4.7814, -4.5951, -4.6033, -4.4367, -4.6109, -4.8673, -4.6713,\n",
      "         -4.6137, -4.8146, -4.6922, -4.4417, -4.9328, -4.5024, -5.0138, -4.3883,\n",
      "         -4.9299, -4.7136, -4.6857, -4.7300, -4.3926, -4.4702, -4.6348, -4.6278,\n",
      "         -4.4244, -5.0766, -4.4731, -4.7546, -4.5942, -4.3146, -4.5032, -4.5215,\n",
      "         -4.6632, -4.5378, -4.2255, -4.5685, -4.7920, -4.4149, -4.2509, -4.1338,\n",
      "         -4.4545, -4.7646, -4.6519, -4.5619, -4.6575, -4.1870, -4.3906, -4.7238,\n",
      "         -4.5420, -4.6676, -4.9235, -4.7578, -4.0678, -4.7617, -4.7808, -4.6910,\n",
      "         -4.3983, -4.5118, -4.9275, -4.6214, -4.5934, -4.4366, -4.8522, -4.9572,\n",
      "         -4.7791, -4.3104, -4.6668, -4.9145, -4.6012, -4.2268, -4.6212, -4.7856,\n",
      "         -4.3792]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : besiege\n",
      "target index is: [75] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3742, -4.5227, -4.3930, -4.7743, -4.0950, -4.7786, -4.5709, -4.2639,\n",
      "         -4.6872, -4.7075, -4.9458, -4.6817, -4.6560, -4.5532, -5.0328, -4.6823,\n",
      "         -4.5794, -4.4355, -4.8306, -4.6042, -4.5666, -4.8739, -4.5763, -4.5667,\n",
      "         -4.3839, -4.7205, -4.6748, -4.5903, -4.2761, -4.3648, -4.4896, -4.6052,\n",
      "         -4.7486, -4.6995, -4.8574, -4.7818, -4.6272, -4.6679, -4.6790, -4.4873,\n",
      "         -4.4724, -4.6809, -4.7636, -4.1545, -4.5048, -4.4787, -4.3506, -4.3966,\n",
      "         -4.5428, -4.5988, -4.5736, -4.3331, -4.7814, -4.3781, -4.7310, -4.5538,\n",
      "         -4.5290, -4.4727, -4.4643, -4.6875, -5.0600, -4.4633, -4.5915, -3.7928,\n",
      "         -4.6814, -4.4578, -4.8257, -4.6457, -4.5307, -4.7655, -4.5712, -4.5572,\n",
      "         -4.7899, -4.9356, -4.7665, -4.7352, -4.7331, -4.2422, -4.6839, -4.8764,\n",
      "         -4.6838, -4.5154, -4.6214, -4.9313, -4.7126, -4.2703, -4.3513, -4.7882,\n",
      "         -5.3071, -4.1774, -4.6954, -4.6735, -4.5088, -4.5930, -4.3275, -4.5816,\n",
      "         -4.8247]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2310, -4.5160, -4.7354, -4.9349, -4.0080, -4.6718, -4.8181, -4.3842,\n",
      "         -5.2618, -4.3288, -4.8719, -4.1458, -4.8396, -4.5514, -4.7028, -5.0065,\n",
      "         -4.9143, -4.6155, -4.5115, -4.4842, -4.4840, -4.5175, -4.7759, -4.5124,\n",
      "         -4.8787, -4.8497, -4.0995, -4.5939, -4.5759, -4.5691, -4.6394, -4.8961,\n",
      "         -4.8892, -4.5837, -4.5370, -5.1840, -4.5660, -4.9871, -4.8139, -4.6619,\n",
      "         -4.8559, -4.9593, -4.7851, -4.5698, -4.6509, -4.3206, -4.8608, -4.8136,\n",
      "         -4.7909, -4.6895, -4.3625, -5.0591, -4.3542, -4.4122, -5.0389, -4.2290,\n",
      "         -4.8053, -4.4646, -4.4603, -4.2286, -4.3055, -4.4107, -4.6469, -3.9206,\n",
      "         -4.3359, -4.6919, -5.0594, -4.6103, -4.6889, -4.7267, -4.3148, -4.7816,\n",
      "         -5.2016, -4.6885, -4.4664, -4.9319, -4.3360, -4.2708, -4.3750, -4.5413,\n",
      "         -4.6251, -4.2760, -4.9624, -4.9684, -4.6592, -4.4099, -4.4321, -4.5293,\n",
      "         -4.8314, -4.5769, -4.0638, -4.4100, -4.5998, -4.4600, -4.1493, -4.6562,\n",
      "         -4.5817]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : brow,\n",
      "target index is: [13] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4344, -4.3083, -4.6285, -4.6361, -4.2863, -4.8673, -4.7183, -4.4221,\n",
      "         -4.7132, -4.7652, -4.8525, -4.5001, -4.8117, -4.3973, -4.7573, -4.8882,\n",
      "         -4.6718, -4.7277, -4.4976, -4.4834, -4.7990, -4.9189, -4.7213, -4.3246,\n",
      "         -4.6079, -4.8141, -4.7258, -4.2647, -4.0962, -4.3679, -4.2414, -4.7442,\n",
      "         -4.8939, -4.5705, -4.9248, -5.0251, -4.5335, -4.8980, -4.3464, -4.3596,\n",
      "         -4.7249, -4.5998, -4.4716, -4.1412, -4.5838, -4.1481, -4.7328, -4.8213,\n",
      "         -4.5886, -4.8102, -4.8703, -4.4737, -4.8944, -4.1360, -4.6072, -4.4114,\n",
      "         -4.3972, -4.0672, -4.7350, -4.6277, -4.8787, -4.4330, -4.5538, -4.1321,\n",
      "         -4.7663, -4.5807, -5.0721, -4.5462, -4.5989, -4.4328, -4.3866, -4.5357,\n",
      "         -4.8365, -4.9200, -4.8157, -5.0347, -5.0688, -3.8760, -4.7416, -4.9985,\n",
      "         -4.9834, -4.5416, -4.7327, -5.0579, -5.0119, -4.3822, -4.3741, -4.5348,\n",
      "         -4.9249, -3.9991, -4.8588, -4.5894, -4.6714, -4.5662, -4.3056, -4.8398,\n",
      "         -4.3110]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : And\n",
      "target index is: [6] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4093, -4.3237, -4.6299, -4.7897, -4.1965, -4.8258, -4.7265, -4.4951,\n",
      "         -4.8401, -4.5812, -4.4696, -4.3404, -4.8915, -4.9533, -4.3734, -4.8637,\n",
      "         -4.8692, -4.9917, -4.4966, -4.4278, -4.4138, -4.3760, -4.7032, -4.6230,\n",
      "         -4.6453, -4.7013, -4.2954, -4.4191, -4.3366, -4.9438, -4.5518, -5.2277,\n",
      "         -4.7517, -4.6457, -4.4581, -4.8254, -4.6624, -4.9012, -4.7691, -4.6222,\n",
      "         -4.8133, -4.9650, -4.8261, -4.7132, -4.6994, -4.4847, -4.5239, -4.5997,\n",
      "         -4.4813, -4.9949, -4.5214, -4.6640, -4.4201, -4.7110, -5.1742, -4.5781,\n",
      "         -4.5633, -4.4720, -4.4655, -4.5943, -4.6136, -4.5680, -4.8872, -4.2052,\n",
      "         -4.9577, -4.6581, -4.9607, -4.5949, -4.6334, -4.6788, -4.0886, -4.8208,\n",
      "         -5.0648, -4.5686, -4.2573, -4.8068, -4.7050, -4.3430, -4.6997, -4.2150,\n",
      "         -4.5739, -4.0221, -4.9110, -4.6780, -4.3718, -4.4320, -4.5163, -4.5301,\n",
      "         -4.7822, -4.3123, -4.5753, -4.5295, -4.2708, -4.1000, -4.1288, -4.4083,\n",
      "         -4.5044]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : dig\n",
      "target index is: [42] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4111, -4.6238, -4.7036, -4.9350, -4.2326, -4.8258, -4.6863, -4.5248,\n",
      "         -4.5273, -4.6682, -4.8539, -4.9817, -4.7372, -4.8188, -4.5491, -4.7172,\n",
      "         -4.6736, -4.7427, -4.6978, -4.4136, -4.8502, -4.4936, -5.0673, -4.6905,\n",
      "         -4.4561, -4.9523, -4.4893, -4.4847, -4.1304, -4.7731, -4.5129, -4.8216,\n",
      "         -4.8829, -4.8054, -4.2436, -4.5056, -4.3773, -4.6756, -4.8272, -4.7085,\n",
      "         -4.8038, -4.4349, -4.7412, -4.6294, -4.6608, -4.2482, -4.8922, -4.4991,\n",
      "         -4.6499, -4.8543, -4.3670, -4.7446, -4.6317, -4.5137, -4.7216, -4.5858,\n",
      "         -4.2164, -4.2556, -4.6217, -4.4179, -4.5678, -4.6728, -4.6684, -4.6133,\n",
      "         -4.6585, -4.3771, -4.9857, -4.5633, -4.6226, -4.7876, -4.2263, -4.1758,\n",
      "         -5.0111, -4.8683, -4.7422, -4.7736, -4.6378, -4.1745, -4.6785, -4.4807,\n",
      "         -4.4117, -4.4797, -4.4892, -4.9760, -4.4970, -4.3515, -4.3021, -4.4389,\n",
      "         -4.6969, -4.1947, -4.4698, -4.4240, -4.7622, -4.4293, -4.5764, -4.4154,\n",
      "         -4.2694]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : deep\n",
      "target index is: [76] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5697, -4.8980, -4.6918, -4.6177, -4.2446, -4.8159, -4.3819, -4.1779,\n",
      "         -4.7153, -5.0068, -4.8054, -4.4345, -4.5688, -4.8778, -4.8104, -4.2949,\n",
      "         -4.2432, -4.8109, -4.4567, -4.9305, -4.4906, -4.2289, -4.6118, -4.7218,\n",
      "         -4.1466, -4.9040, -4.4554, -4.7182, -4.6602, -4.4711, -4.7253, -4.6609,\n",
      "         -4.9061, -4.9088, -4.4071, -4.6195, -4.9688, -4.5101, -5.0118, -4.7216,\n",
      "         -4.8288, -4.6625, -4.8789, -4.5441, -4.4034, -4.3361, -4.5295, -4.6241,\n",
      "         -4.4749, -4.3146, -4.5078, -4.1637, -4.7441, -4.4203, -4.6073, -4.4555,\n",
      "         -4.5246, -4.5584, -4.5072, -4.6476, -5.0343, -4.6780, -4.5399, -3.9345,\n",
      "         -4.6952, -4.4582, -4.8820, -4.4084, -4.6904, -4.5753, -4.3826, -4.6978,\n",
      "         -4.6044, -4.5124, -4.6188, -4.9252, -4.5004, -4.5788, -4.8309, -4.7201,\n",
      "         -4.1405, -4.7711, -4.6966, -4.6318, -4.3469, -4.5503, -4.6702, -5.0599,\n",
      "         -4.9436, -4.3725, -4.5096, -4.7146, -4.6864, -4.4200, -4.4640, -4.4563,\n",
      "         -4.5686]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : trenches\n",
      "target index is: [54] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4584, -4.5268, -4.9283, -5.3998, -4.0836, -4.6535, -4.4362, -4.4073,\n",
      "         -4.8219, -4.4060, -4.8929, -4.4054, -4.8001, -4.8016, -4.9644, -4.7174,\n",
      "         -4.4688, -4.6403, -4.6867, -4.6526, -4.5539, -4.2632, -4.8604, -4.5613,\n",
      "         -4.4475, -4.8816, -4.1706, -4.5645, -4.5847, -4.7074, -4.4877, -5.0465,\n",
      "         -4.9225, -4.9143, -4.5004, -4.5724, -4.3568, -4.7465, -5.0227, -4.6830,\n",
      "         -4.8544, -4.8028, -4.5812, -4.5287, -4.4237, -4.4550, -4.5292, -4.7398,\n",
      "         -4.4097, -5.1703, -4.1490, -4.7674, -4.6358, -4.3828, -4.4824, -4.6702,\n",
      "         -4.9170, -4.6287, -4.2892, -4.4717, -4.6824, -4.3915, -4.4997, -4.1185,\n",
      "         -4.5111, -4.6477, -4.7170, -4.4922, -4.4515, -4.3563, -4.6387, -4.7164,\n",
      "         -5.2024, -4.6162, -4.8471, -5.0670, -4.2702, -4.2103, -4.3366, -4.5467,\n",
      "         -4.5474, -4.5388, -4.6353, -4.5253, -4.6791, -4.4115, -4.5314, -4.6927,\n",
      "         -4.6820, -4.6393, -4.0849, -4.5610, -4.7263, -4.2686, -4.5802, -4.7017,\n",
      "         -4.4973]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : in\n",
      "target index is: [95] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7383, -4.4383, -4.5666, -4.5194, -4.1236, -4.6701, -4.6978, -4.1970,\n",
      "         -4.7463, -4.5726, -4.6523, -4.2529, -4.4522, -4.6908, -4.8345, -4.6575,\n",
      "         -4.5864, -4.7371, -4.2087, -4.5116, -4.5224, -4.5638, -4.5836, -4.6435,\n",
      "         -4.2445, -4.9501, -4.4291, -4.8116, -4.3787, -4.4669, -4.7213, -4.7049,\n",
      "         -4.9230, -4.6865, -4.6087, -5.0771, -4.4883, -4.6575, -4.3139, -4.6928,\n",
      "         -4.5043, -4.5906, -4.9500, -4.6982, -4.5158, -4.3963, -4.4767, -4.9102,\n",
      "         -4.8292, -4.5078, -4.6271, -4.1693, -4.6448, -4.2708, -4.7343, -4.4254,\n",
      "         -4.5323, -4.2655, -4.3377, -4.7188, -4.8127, -4.6637, -4.4941, -4.0858,\n",
      "         -4.7893, -4.4483, -4.7167, -4.6022, -4.7926, -4.8401, -4.4460, -4.5186,\n",
      "         -5.0073, -4.8094, -4.8452, -4.8286, -4.6673, -4.3404, -4.5685, -5.0153,\n",
      "         -4.7659, -4.2382, -4.6867, -4.6928, -4.7287, -4.4208, -4.6496, -4.6820,\n",
      "         -4.8491, -4.2646, -4.9061, -4.7433, -4.6213, -4.3336, -4.4907, -4.6106,\n",
      "         -4.5493]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2349, -4.5178, -5.1214, -4.8412, -4.2719, -4.7137, -4.7722, -4.3567,\n",
      "         -5.2659, -4.2360, -4.9049, -4.2104, -4.4726, -4.3442, -4.9979, -5.1000,\n",
      "         -4.6434, -4.6030, -4.6214, -4.4155, -4.5235, -4.5336, -4.5836, -4.5984,\n",
      "         -4.5574, -5.0587, -4.2801, -4.5203, -4.5986, -4.7494, -4.7262, -4.4987,\n",
      "         -4.9799, -4.8077, -4.8331, -5.3927, -4.6969, -4.5568, -4.6393, -4.3198,\n",
      "         -4.5496, -4.6651, -4.3734, -4.4361, -4.2068, -4.1464, -4.7088, -4.6976,\n",
      "         -4.9573, -4.7864, -4.6109, -4.6905, -4.4218, -4.3736, -4.5054, -4.5496,\n",
      "         -4.5818, -4.3284, -4.4302, -4.6224, -4.6846, -4.4309, -4.3309, -4.2302,\n",
      "         -4.0314, -4.8280, -4.8303, -4.5138, -4.6116, -4.2306, -4.3464, -4.6642,\n",
      "         -4.7713, -4.7396, -4.7982, -4.7241, -4.2751, -4.1890, -4.4007, -4.6967,\n",
      "         -4.7194, -4.7627, -4.8407, -5.0308, -5.0864, -4.4383, -4.6908, -4.5051,\n",
      "         -5.1521, -4.6147, -4.4310, -4.7754, -4.9261, -4.3989, -4.2557, -4.8562,\n",
      "         -4.4673]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty's\n",
      "target index is: [80] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2937, -4.4786, -4.7372, -4.5298, -4.2092, -4.9269, -4.5453, -4.3041,\n",
      "         -4.3957, -5.1259, -4.9684, -4.1836, -4.6686, -4.7266, -4.6067, -4.7427,\n",
      "         -4.8831, -5.1573, -4.5412, -4.4070, -4.9419, -4.7404, -4.5945, -4.4914,\n",
      "         -4.2072, -4.6500, -4.6598, -4.4323, -3.8539, -4.5740, -4.8079, -4.5996,\n",
      "         -4.7208, -4.5793, -4.6451, -5.1395, -4.8589, -4.6222, -4.6663, -4.5136,\n",
      "         -4.6794, -4.2414, -4.9871, -4.0594, -4.5046, -4.0944, -4.4453, -4.4793,\n",
      "         -4.5344, -4.8915, -4.7781, -4.4686, -4.7560, -4.3492, -4.6136, -4.4030,\n",
      "         -4.3125, -4.3038, -4.7333, -5.0443, -4.8344, -4.1831, -4.4740, -4.1022,\n",
      "         -5.0337, -4.8048, -5.0836, -4.6693, -4.8213, -4.6295, -4.2966, -4.7394,\n",
      "         -4.5081, -4.8588, -4.7995, -4.9052, -5.1713, -4.1992, -4.5635, -4.4600,\n",
      "         -4.7684, -4.3155, -5.2135, -4.7928, -4.8655, -4.1004, -4.6086, -5.0106,\n",
      "         -5.0354, -4.5911, -5.2064, -4.4876, -4.5891, -4.4949, -4.2763, -4.3163,\n",
      "         -4.5414]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : field,\n",
      "target index is: [77] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.0198, -4.1587, -4.7759, -5.6527, -4.0701, -5.0910, -4.5444, -4.4511,\n",
      "         -4.8778, -4.8111, -4.6841, -5.1437, -5.0625, -4.8427, -4.6718, -4.8157,\n",
      "         -4.9066, -4.7108, -4.8253, -4.5607, -4.7532, -4.3376, -5.0432, -4.6614,\n",
      "         -4.6030, -4.8609, -4.3129, -4.0537, -4.2060, -4.9145, -4.2812, -4.7793,\n",
      "         -4.7979, -4.7123, -4.4984, -4.9541, -4.7101, -4.9991, -4.9740, -4.8371,\n",
      "         -4.5672, -5.1549, -4.8537, -4.6432, -4.5589, -4.0620, -5.0964, -4.4248,\n",
      "         -4.6177, -5.0114, -3.8265, -5.2370, -4.3822, -4.8050, -4.7968, -4.4978,\n",
      "         -4.5490, -4.3586, -4.4714, -4.2662, -4.7556, -4.4272, -4.4259, -3.7808,\n",
      "         -4.4762, -4.5359, -4.9714, -4.7083, -4.4494, -4.4658, -4.6080, -4.4689,\n",
      "         -5.3894, -4.7945, -4.8161, -4.8841, -4.3638, -4.1607, -4.4203, -4.4994,\n",
      "         -4.5234, -4.3822, -5.2212, -5.2275, -4.5246, -4.4507, -4.2711, -4.8477,\n",
      "         -4.6225, -4.2395, -4.1158, -4.3349, -4.9417, -4.1709, -4.4746, -4.8789,\n",
      "         -4.4720]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Thy\n",
      "target index is: [73] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3033, -4.5959, -4.7259, -4.6616, -4.2249, -4.9344, -4.6422, -4.1478,\n",
      "         -4.7215, -4.9064, -4.6541, -4.2314, -4.3358, -4.7241, -4.6374, -4.3698,\n",
      "         -4.6779, -4.8323, -4.1389, -4.6974, -4.5303, -4.2585, -4.7917, -4.8089,\n",
      "         -4.1341, -4.8531, -4.5759, -4.7195, -4.0408, -4.4472, -4.7774, -4.7089,\n",
      "         -4.8830, -4.5938, -4.7123, -5.1160, -4.9128, -4.5603, -4.7873, -4.9417,\n",
      "         -4.7600, -4.4293, -4.9666, -4.6644, -4.4923, -4.4245, -4.6198, -5.0956,\n",
      "         -4.6989, -4.5046, -4.6181, -4.2932, -4.7719, -4.4932, -4.7921, -4.4893,\n",
      "         -4.2318, -4.1604, -4.5647, -4.4326, -4.8409, -4.4006, -4.4851, -3.9171,\n",
      "         -4.8224, -4.6438, -4.8001, -4.8915, -4.8898, -4.6666, -4.3445, -4.4240,\n",
      "         -4.8667, -4.6914, -4.7724, -4.9063, -4.5870, -4.3615, -4.7081, -4.7253,\n",
      "         -4.4585, -4.3051, -5.1141, -4.6935, -4.3468, -4.7514, -4.7090, -4.6660,\n",
      "         -4.6846, -4.6150, -4.7273, -4.6434, -4.7021, -4.1542, -4.4890, -4.6002,\n",
      "         -4.4865]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : youth's\n",
      "target index is: [89] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2156, -4.7458, -4.7388, -4.8669, -4.1494, -4.7401, -4.8651, -4.5473,\n",
      "         -4.8259, -5.0061, -4.8938, -4.4207, -4.7354, -4.3822, -5.0401, -4.8437,\n",
      "         -4.6805, -4.6717, -4.6529, -4.6483, -4.3851, -4.4916, -4.5247, -4.5408,\n",
      "         -4.3102, -4.7135, -4.6819, -4.7793, -4.4852, -4.3878, -5.0029, -4.3718,\n",
      "         -4.9441, -4.6523, -4.6728, -5.2008, -4.7786, -4.7537, -4.8164, -4.3071,\n",
      "         -4.6375, -4.6620, -4.9052, -4.3465, -4.3052, -4.4936, -4.4824, -4.4083,\n",
      "         -4.5457, -4.4422, -4.3232, -4.8507, -4.4627, -4.2309, -4.3940, -4.4277,\n",
      "         -4.4860, -4.5209, -4.5656, -4.4822, -4.7375, -4.3783, -4.4941, -3.6584,\n",
      "         -4.2925, -4.3461, -4.8764, -4.6274, -4.7390, -4.5990, -4.3515, -4.6727,\n",
      "         -4.9257, -4.8015, -4.8668, -4.6292, -4.4274, -4.3104, -4.7521, -4.2957,\n",
      "         -4.7044, -4.7445, -4.9784, -5.1931, -4.5756, -4.2951, -4.4951, -5.0386,\n",
      "         -5.2605, -4.1949, -4.4547, -4.7261, -4.6418, -4.4879, -4.4251, -4.7102,\n",
      "         -4.8733]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : proud\n",
      "target index is: [50] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5086, -4.3363, -4.9337, -5.0934, -4.3825, -4.6518, -4.3838, -4.5387,\n",
      "         -5.3636, -4.5114, -4.8887, -4.4380, -4.8878, -4.5512, -4.6116, -5.1399,\n",
      "         -4.9533, -4.7008, -4.5343, -4.0525, -4.3949, -4.3824, -4.8656, -4.4859,\n",
      "         -4.9143, -4.9276, -4.4604, -4.3822, -4.6996, -4.8758, -4.7371, -4.6190,\n",
      "         -4.8748, -4.8388, -4.3522, -5.1355, -4.6152, -5.0124, -4.6653, -4.1925,\n",
      "         -4.3784, -4.6297, -4.6335, -4.4429, -4.5919, -4.2360, -4.8679, -4.2912,\n",
      "         -4.4721, -5.3897, -4.2836, -5.1200, -4.2734, -4.5102, -4.5209, -4.5386,\n",
      "         -4.8318, -4.4252, -4.3908, -4.7577, -4.6554, -4.2663, -4.6421, -4.3601,\n",
      "         -4.3630, -4.8640, -4.8855, -4.2562, -4.6363, -4.2683, -4.4473, -4.8659,\n",
      "         -4.9475, -4.9290, -4.6050, -4.8117, -4.5193, -4.2756, -4.2125, -4.1370,\n",
      "         -4.8499, -4.8089, -5.1250, -4.8184, -5.0143, -4.3026, -4.5448, -4.5602,\n",
      "         -4.7194, -4.3094, -4.3671, -4.1705, -4.8856, -4.5144, -4.2279, -4.6186,\n",
      "         -4.2669]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : livery\n",
      "target index is: [28] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6512, -4.4208, -4.9965, -4.7456, -4.0802, -5.1219, -4.4325, -4.3568,\n",
      "         -4.5735, -4.4836, -4.8722, -4.5806, -4.7163, -4.8520, -4.3141, -4.5774,\n",
      "         -4.8088, -5.0205, -4.7674, -4.4037, -4.7876, -4.0935, -5.0401, -4.7943,\n",
      "         -4.2010, -4.9173, -4.1733, -4.4447, -4.1203, -4.8377, -4.9306, -5.1447,\n",
      "         -4.9158, -4.7817, -4.6602, -4.7874, -4.5853, -4.6955, -5.0529, -4.5093,\n",
      "         -4.9508, -4.5417, -4.7788, -4.7545, -4.7834, -4.3019, -4.6579, -4.8824,\n",
      "         -4.4072, -5.0391, -4.3987, -4.6513, -4.5272, -4.2893, -4.6812, -4.3380,\n",
      "         -4.3227, -4.1821, -4.7062, -4.8934, -4.5257, -4.4413, -4.2192, -4.4986,\n",
      "         -4.5828, -4.5677, -4.7346, -4.7388, -4.7148, -4.3224, -4.2521, -4.4460,\n",
      "         -4.8128, -4.8991, -4.6590, -4.9093, -4.6040, -4.1686, -4.5717, -4.5115,\n",
      "         -4.5394, -4.6295, -4.9053, -4.6817, -4.4898, -4.3622, -4.4535, -4.8343,\n",
      "         -4.4535, -4.5225, -4.9214, -4.5762, -4.7607, -4.3059, -4.5200, -4.5072,\n",
      "         -3.9950]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : so\n",
      "target index is: [69] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3938, -4.3131, -4.9258, -4.7944, -4.2701, -5.0239, -4.6220, -4.4031,\n",
      "         -4.5565, -4.6577, -4.7964, -4.8285, -4.4625, -5.0191, -4.8502, -4.6155,\n",
      "         -4.7286, -4.3733, -4.5565, -4.5789, -4.4122, -4.2748, -5.0441, -4.8188,\n",
      "         -4.3009, -4.9251, -4.3832, -4.4980, -4.2198, -4.6695, -4.8375, -4.7783,\n",
      "         -4.9641, -4.9917, -4.6070, -4.7803, -4.8781, -4.4240, -4.8445, -4.6958,\n",
      "         -4.6457, -4.6640, -4.6375, -4.5938, -4.3670, -4.2930, -4.4954, -4.5516,\n",
      "         -4.5017, -4.8936, -4.5848, -4.4792, -4.8244, -4.3628, -4.4730, -4.6938,\n",
      "         -4.2146, -4.3348, -4.3094, -4.6487, -4.8853, -4.5093, -4.1996, -4.1777,\n",
      "         -4.4170, -4.8506, -4.4852, -4.4555, -4.2943, -4.4463, -4.3044, -4.4977,\n",
      "         -4.8056, -4.8612, -4.9868, -4.8408, -4.2678, -4.5070, -4.9612, -4.8140,\n",
      "         -4.3405, -4.6323, -4.8669, -4.7554, -4.7148, -4.3954, -4.5613, -4.6500,\n",
      "         -4.7456, -4.2651, -4.7467, -4.8574, -4.7529, -4.1569, -4.6987, -4.6528,\n",
      "         -4.3172]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : gazed\n",
      "target index is: [17] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4637, -4.3378, -4.6854, -4.7848, -4.3150, -4.6384, -4.5217, -4.3482,\n",
      "         -4.5778, -4.7449, -4.6893, -4.5624, -4.5834, -4.7083, -4.7685, -4.6279,\n",
      "         -4.4439, -4.6658, -4.6462, -4.5128, -4.6771, -4.6133, -4.7131, -4.6078,\n",
      "         -4.3891, -4.8703, -4.4358, -4.5600, -4.3407, -4.6138, -4.4034, -4.8381,\n",
      "         -4.8788, -4.7491, -4.5844, -4.6738, -4.5879, -4.6139, -4.7013, -4.5974,\n",
      "         -4.6965, -4.5932, -4.4390, -4.4305, -4.5641, -4.2848, -4.6821, -4.5681,\n",
      "         -4.4426, -4.6012, -4.5532, -4.2946, -4.8634, -4.4981, -4.6602, -4.3829,\n",
      "         -4.5729, -4.2916, -4.5537, -4.7100, -4.7432, -4.6222, -4.6748, -4.3304,\n",
      "         -4.6398, -4.6197, -4.8164, -4.4667, -4.5690, -4.5168, -4.4704, -4.4633,\n",
      "         -4.5006, -4.8300, -4.7086, -4.8375, -4.6367, -4.1852, -4.7856, -4.8553,\n",
      "         -4.6051, -4.6240, -4.6895, -4.8230, -4.5093, -4.4880, -4.3114, -4.6686,\n",
      "         -4.6838, -4.3095, -4.6672, -4.5530, -4.8047, -4.4995, -4.5850, -4.5464,\n",
      "         -4.5098]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : on\n",
      "target index is: [87] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4799, -4.6597, -4.6075, -4.6229, -4.2340, -4.6137, -4.3794, -4.2681,\n",
      "         -4.6828, -4.7101, -4.6094, -4.7788, -4.7607, -4.5852, -4.6618, -4.4690,\n",
      "         -4.3078, -4.6350, -4.6758, -4.7335, -4.8075, -4.6597, -4.6659, -4.5133,\n",
      "         -4.4427, -4.7564, -4.6019, -4.5113, -4.6248, -4.4207, -4.4637, -4.6695,\n",
      "         -4.7354, -4.7294, -4.7515, -4.6318, -4.7133, -4.6644, -4.9503, -4.5976,\n",
      "         -4.7123, -4.5337, -4.8198, -4.2958, -4.6749, -4.3808, -4.6145, -4.5766,\n",
      "         -4.4492, -4.3473, -4.7532, -4.4222, -5.1042, -4.2810, -4.6359, -4.3079,\n",
      "         -4.2692, -4.3219, -4.6412, -4.5061, -4.7341, -4.7231, -4.4726, -4.0131,\n",
      "         -4.8141, -4.2820, -4.8172, -4.5302, -4.5859, -4.5629, -4.5124, -4.6502,\n",
      "         -4.6858, -4.4270, -4.5837, -4.8120, -4.6645, -4.5392, -4.8931, -4.7968,\n",
      "         -4.4157, -4.4659, -4.7704, -4.6819, -4.6501, -4.4691, -4.6232, -4.7605,\n",
      "         -4.9303, -4.2501, -4.5061, -4.3389, -4.7527, -4.6544, -4.5185, -4.6764,\n",
      "         -4.7921]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : now,\n",
      "target index is: [63] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4484, -4.6135, -4.8469, -4.9169, -3.8109, -4.5103, -4.5276, -4.5391,\n",
      "         -4.6653, -4.6530, -4.5803, -4.3897, -5.0435, -4.8209, -4.7809, -4.5056,\n",
      "         -4.5679, -4.8056, -4.6204, -4.4058, -4.5741, -4.0907, -4.8778, -4.9087,\n",
      "         -4.6280, -4.9787, -4.6802, -4.3462, -4.3353, -4.7745, -4.4369, -5.0111,\n",
      "         -4.7119, -4.6607, -4.2552, -4.8835, -4.4775, -4.8668, -5.0980, -4.7443,\n",
      "         -4.6714, -4.4836, -4.7249, -4.4821, -4.5853, -4.3981, -4.4012, -4.8868,\n",
      "         -4.5485, -5.1365, -4.7775, -4.5881, -4.4934, -4.4848, -4.5775, -4.4616,\n",
      "         -4.2440, -4.4324, -4.4295, -4.5517, -4.5058, -4.5605, -4.8151, -4.3262,\n",
      "         -4.4667, -4.4135, -4.6676, -4.5564, -4.6990, -4.4287, -4.4420, -4.6085,\n",
      "         -5.0138, -4.8991, -4.6256, -4.8454, -4.9580, -4.4382, -4.7042, -4.4537,\n",
      "         -4.6313, -4.0925, -4.9021, -4.8130, -4.3269, -4.3160, -4.5870, -4.5531,\n",
      "         -4.8545, -4.4250, -4.6653, -4.2109, -4.7097, -4.3467, -4.5862, -4.5625,\n",
      "         -4.6117]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Will\n",
      "target index is: [36] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3998, -4.7947, -4.8138, -4.8703, -4.1052, -4.6308, -4.6502, -4.2846,\n",
      "         -4.5378, -4.7433, -4.6174, -4.6611, -4.5880, -4.8638, -4.9252, -4.2974,\n",
      "         -4.4899, -4.5772, -4.3707, -4.5471, -4.8087, -4.1536, -4.9354, -5.0522,\n",
      "         -4.0758, -5.0256, -4.4227, -4.4277, -4.2197, -4.4363, -4.4829, -4.8985,\n",
      "         -5.0349, -4.8914, -4.3639, -4.6725, -4.6130, -4.6594, -5.0859, -4.7908,\n",
      "         -4.9801, -4.5721, -4.4442, -4.6341, -4.6631, -4.3845, -4.6876, -4.6825,\n",
      "         -4.5764, -4.8986, -4.4144, -4.6028, -4.9026, -4.5912, -4.6401, -4.4551,\n",
      "         -4.1173, -4.2962, -4.3203, -4.5308, -4.9748, -4.7207, -4.4754, -4.4719,\n",
      "         -4.5177, -4.4395, -4.6824, -4.5791, -4.7361, -4.6767, -4.2954, -4.3243,\n",
      "         -4.8039, -4.9027, -4.7268, -4.7595, -4.4069, -4.3235, -4.6332, -4.7850,\n",
      "         -4.4655, -4.6620, -4.6382, -4.7274, -4.4344, -4.4828, -4.5526, -4.7961,\n",
      "         -4.6541, -4.3342, -4.6514, -4.5335, -4.8100, -4.4958, -4.8474, -4.3785,\n",
      "         -4.3105]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : be\n",
      "target index is: [24] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3497, -4.6735, -4.7799, -4.7541, -4.1657, -4.9912, -4.5793, -4.3476,\n",
      "         -4.7538, -4.7850, -4.6388, -4.2983, -4.6838, -5.0082, -5.0831, -4.3672,\n",
      "         -4.3960, -4.7531, -4.6833, -4.9838, -4.3694, -3.9654, -4.4830, -4.6781,\n",
      "         -4.0989, -5.0845, -4.3234, -4.7785, -4.4182, -4.5689, -4.3835, -5.2445,\n",
      "         -4.8317, -4.8032, -4.6047, -4.5460, -4.6972, -4.5449, -4.9725, -4.8429,\n",
      "         -5.0283, -4.7379, -4.6336, -4.6799, -4.3651, -4.5115, -4.5084, -4.7590,\n",
      "         -4.6090, -4.6181, -4.7280, -4.0794, -5.0605, -4.4226, -4.6637, -4.6574,\n",
      "         -4.5172, -4.4666, -4.3365, -4.7121, -4.8998, -4.5387, -4.5780, -4.0568,\n",
      "         -4.6730, -4.5075, -4.8671, -4.4195, -4.3120, -4.4096, -4.1945, -4.6735,\n",
      "         -4.9420, -4.7526, -5.0770, -5.1709, -4.4942, -4.2960, -4.8096, -4.8877,\n",
      "         -4.1718, -4.5852, -4.6642, -4.4876, -4.3224, -4.4646, -4.3904, -4.8777,\n",
      "         -5.0048, -4.5290, -4.1997, -4.7642, -4.5485, -4.4302, -4.5546, -4.5858,\n",
      "         -4.5376]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : a\n",
      "target index is: [46] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3772, -4.5191, -4.6606, -5.3659, -4.1473, -4.6991, -4.2690, -4.0508,\n",
      "         -4.7672, -4.5591, -4.8263, -4.9121, -4.3939, -4.7505, -4.6911, -4.3080,\n",
      "         -4.2036, -4.6244, -4.6765, -4.5837, -5.0303, -4.3498, -4.8313, -4.9536,\n",
      "         -4.2907, -5.2763, -4.1956, -4.4280, -4.3002, -4.6503, -4.4737, -4.7544,\n",
      "         -4.8979, -5.0506, -4.4427, -4.6575, -4.5303, -4.3664, -4.9204, -4.5774,\n",
      "         -4.8574, -4.6030, -4.9698, -4.3281, -4.9286, -4.2211, -4.8662, -4.7610,\n",
      "         -4.7218, -4.7808, -4.1606, -4.6341, -4.5614, -4.5146, -4.6501, -4.5696,\n",
      "         -4.3286, -4.5232, -4.3975, -4.7362, -4.8508, -4.7070, -4.4652, -4.3433,\n",
      "         -4.6354, -4.3676, -5.0121, -4.3870, -4.7696, -4.8113, -4.7335, -4.5017,\n",
      "         -4.8837, -4.8329, -4.6681, -4.8831, -4.4250, -4.2917, -4.2797, -4.6987,\n",
      "         -4.3846, -4.6183, -4.7215, -4.7184, -4.8588, -4.3425, -4.6109, -4.7263,\n",
      "         -4.7290, -4.3484, -4.5605, -4.3843, -5.0724, -4.3493, -4.7918, -4.3109,\n",
      "         -4.3192]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : totter'd\n",
      "target index is: [20] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7126, -4.6656, -4.9478, -4.8739, -4.3869, -4.7980, -4.6504, -4.0621,\n",
      "         -4.8738, -4.5992, -4.8326, -4.2735, -4.3190, -4.6833, -4.9941, -4.6083,\n",
      "         -4.7069, -4.4272, -4.3082, -4.7253, -4.5946, -4.3804, -4.6719, -4.8094,\n",
      "         -4.0633, -5.1573, -4.5059, -4.7614, -4.1730, -4.3055, -4.5080, -4.7905,\n",
      "         -4.8196, -4.8932, -4.8717, -5.1904, -4.6496, -4.5093, -4.7795, -4.5392,\n",
      "         -4.7338, -4.7560, -4.6958, -4.6495, -4.6115, -4.4356, -4.8295, -4.8201,\n",
      "         -4.8072, -4.6991, -4.3784, -4.4920, -4.8286, -4.5362, -4.5440, -4.4262,\n",
      "         -4.3948, -4.2284, -4.2663, -4.4040, -4.7796, -4.4711, -4.5055, -3.9354,\n",
      "         -4.5391, -4.6382, -4.4348, -4.6863, -4.6284, -4.0338, -4.4093, -4.2979,\n",
      "         -5.0616, -4.8409, -5.0025, -5.0115, -4.3042, -4.3362, -4.3549, -4.9083,\n",
      "         -4.6678, -4.5965, -4.9842, -4.6264, -4.8335, -4.5590, -4.6400, -4.6967,\n",
      "         -4.8126, -4.4401, -4.5503, -4.7053, -4.8287, -4.1225, -4.6894, -4.6966,\n",
      "         -4.3069]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : weed\n",
      "target index is: [29] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6129, -4.7302, -4.5397, -4.6658, -4.1459, -4.7595, -4.5302, -4.3259,\n",
      "         -4.6837, -4.8058, -4.6542, -4.6472, -4.6878, -4.8012, -5.0419, -4.8085,\n",
      "         -4.4227, -4.4192, -4.4418, -4.5784, -4.5552, -4.6577, -4.6971, -4.4695,\n",
      "         -4.2003, -4.8304, -4.5491, -4.7158, -4.5606, -4.4658, -4.3034, -4.5944,\n",
      "         -4.5490, -4.7478, -4.6349, -4.7239, -4.3904, -4.5792, -4.3816, -4.6046,\n",
      "         -4.6264, -4.6900, -4.8093, -4.6177, -4.5159, -4.2773, -4.2356, -4.5263,\n",
      "         -4.6584, -4.4845, -4.7337, -4.3211, -4.8713, -4.3866, -4.4487, -4.5312,\n",
      "         -4.4494, -4.2789, -4.3206, -4.6596, -5.0225, -4.5256, -4.5241, -4.2187,\n",
      "         -4.8442, -4.6800, -4.6516, -4.6121, -4.4928, -4.4843, -4.5554, -4.6527,\n",
      "         -4.8317, -4.9239, -4.8281, -4.7812, -4.6097, -4.2435, -4.8311, -4.8856,\n",
      "         -4.6951, -4.5401, -4.6458, -4.5723, -4.7194, -4.5257, -4.4401, -4.7867,\n",
      "         -4.9791, -4.1608, -4.6972, -4.4990, -4.6585, -4.4917, -4.5427, -4.7859,\n",
      "         -4.6087]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : of\n",
      "target index is: [57] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5305, -4.4009, -4.3677, -4.6264, -3.9093, -4.7287, -4.9935, -4.4876,\n",
      "         -4.7178, -4.6049, -4.6318, -4.2443, -4.8598, -4.7962, -4.6306, -4.5667,\n",
      "         -4.5679, -4.9401, -4.4682, -4.7847, -4.4292, -4.1743, -4.5656, -4.4652,\n",
      "         -4.3938, -4.7355, -4.4372, -4.6984, -4.3925, -4.6143, -4.4555, -5.2692,\n",
      "         -4.7167, -4.3065, -4.6588, -5.0088, -4.5858, -4.8977, -4.5561, -4.8752,\n",
      "         -4.7116, -4.8058, -4.8057, -4.6636, -4.4740, -4.4176, -4.4535, -4.9509,\n",
      "         -4.8262, -4.4493, -4.6364, -4.4618, -4.8231, -4.3067, -4.9823, -4.5057,\n",
      "         -4.6562, -4.4113, -4.4877, -4.4476, -4.7495, -4.7887, -4.7125, -3.8130,\n",
      "         -4.7833, -4.6413, -5.0362, -4.6470, -4.6244, -4.7506, -4.3127, -4.5437,\n",
      "         -4.9729, -4.6830, -4.6499, -4.7679, -4.7224, -4.4445, -4.7289, -4.8925,\n",
      "         -4.6237, -4.0781, -4.8199, -4.7614, -4.4341, -4.5729, -4.3985, -4.5765,\n",
      "         -4.9093, -4.1684, -4.6107, -4.7468, -4.5482, -4.4635, -4.0791, -4.8071,\n",
      "         -4.4459]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : small\n",
      "target index is: [38] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3537, -4.2931, -4.6482, -4.8517, -4.3102, -4.7468, -4.5585, -4.5261,\n",
      "         -4.6927, -4.9268, -4.8631, -4.6175, -4.7734, -4.4902, -4.2959, -4.7603,\n",
      "         -4.8211, -5.0199, -4.6040, -4.2525, -4.8081, -4.5550, -4.6518, -4.4181,\n",
      "         -4.7293, -5.0930, -4.7346, -4.4284, -4.0980, -4.6055, -4.4662, -4.9968,\n",
      "         -4.7727, -4.6673, -4.4505, -4.8637, -4.7580, -4.8386, -4.9033, -4.4125,\n",
      "         -4.6316, -4.5849, -4.8820, -4.1359, -4.8626, -4.1545, -5.0008, -4.4121,\n",
      "         -4.4378, -4.8558, -4.9108, -4.6968, -4.7665, -4.4551, -4.6293, -4.6481,\n",
      "         -4.2713, -4.2350, -4.6405, -4.6557, -4.6073, -4.7078, -4.8327, -4.2762,\n",
      "         -4.9732, -4.4803, -5.1453, -4.2357, -4.6842, -4.7715, -4.2137, -4.6715,\n",
      "         -4.7753, -4.6679, -4.8401, -4.7091, -5.0877, -4.3148, -4.6021, -4.2077,\n",
      "         -4.6889, -4.4095, -4.7857, -4.9120, -4.6395, -4.0846, -4.3235, -4.4228,\n",
      "         -5.0262, -4.2192, -4.5397, -4.2568, -4.6554, -4.5964, -4.2400, -4.3931,\n",
      "         -4.3396]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : worth\n",
      "target index is: [83] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6965, -4.6250, -4.7644, -5.0508, -4.2465, -4.8379, -4.3515, -4.5194,\n",
      "         -4.7006, -4.7222, -5.0600, -4.8223, -4.8990, -4.7912, -4.4456, -4.5388,\n",
      "         -4.5321, -4.8551, -4.6129, -4.3159, -4.7785, -3.9538, -5.1344, -4.6971,\n",
      "         -4.1715, -5.1178, -4.2289, -4.0698, -4.5655, -4.5821, -5.0001, -4.9178,\n",
      "         -5.0518, -4.9244, -4.5494, -4.2959, -4.8054, -4.9097, -5.1893, -4.6760,\n",
      "         -4.9720, -5.1865, -4.7773, -4.6234, -4.7414, -4.5002, -4.7987, -4.9999,\n",
      "         -4.2876, -4.9017, -3.9328, -4.7777, -4.2040, -3.8932, -4.9809, -4.0445,\n",
      "         -4.8472, -4.4242, -4.5042, -4.5526, -4.7809, -4.7584, -4.5696, -4.1662,\n",
      "         -4.8491, -4.1817, -5.0720, -4.5564, -4.8602, -4.5903, -4.2157, -4.7470,\n",
      "         -4.8818, -4.2476, -4.4913, -5.0457, -4.4500, -4.4369, -4.8524, -4.7220,\n",
      "         -4.2312, -4.3511, -4.7821, -4.4704, -4.2723, -4.2699, -5.0492, -5.2572,\n",
      "         -4.5188, -4.2515, -4.5318, -4.6999, -4.5302, -4.3387, -4.4165, -4.8082,\n",
      "         -4.3052]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : held:\n",
      "target index is: [19] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3842, -4.3856, -5.0619, -5.0707, -4.0289, -4.9013, -4.3606, -4.5598,\n",
      "         -4.6573, -4.1653, -5.0458, -4.6200, -4.8739, -4.7373, -4.4213, -4.6533,\n",
      "         -4.6117, -4.6849, -4.9926, -4.4750, -4.3717, -4.3818, -4.9591, -4.7297,\n",
      "         -4.8153, -5.2096, -4.4443, -4.4483, -4.6045, -4.6566, -4.7505, -4.6398,\n",
      "         -4.7308, -5.2064, -4.5919, -4.5953, -4.4895, -4.6241, -4.9735, -4.2519,\n",
      "         -4.5900, -4.5907, -4.4814, -4.2494, -4.2681, -4.5858, -4.6815, -4.5422,\n",
      "         -4.2158, -5.3359, -4.3596, -4.9941, -4.7245, -4.3608, -4.7435, -4.5720,\n",
      "         -4.6001, -4.6198, -4.5048, -4.5838, -4.6428, -4.3677, -4.4275, -4.4621,\n",
      "         -4.4484, -4.6606, -4.6881, -4.3033, -4.5762, -4.3506, -4.5881, -4.9653,\n",
      "         -4.8544, -4.5564, -4.8756, -5.3202, -4.1924, -4.7797, -4.6351, -4.7557,\n",
      "         -4.6481, -4.2350, -4.8048, -4.5420, -5.3046, -3.9113, -5.0979, -4.5590,\n",
      "         -4.7161, -4.0270, -4.5666, -4.8294, -4.8144, -4.1420, -4.6244, -4.2941,\n",
      "         -4.2616]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Then\n",
      "target index is: [65] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3910, -4.5047, -4.8987, -4.7455, -3.9518, -4.8636, -4.6366, -4.7422,\n",
      "         -4.8165, -4.6377, -4.7212, -4.6131, -4.7874, -4.6877, -4.7558, -4.5766,\n",
      "         -4.5399, -4.6804, -5.1209, -4.7260, -4.5925, -4.2194, -4.9106, -4.3339,\n",
      "         -4.4167, -4.7380, -4.7831, -4.2868, -4.3233, -4.4004, -4.6797, -4.5553,\n",
      "         -4.8043, -4.8896, -4.5368, -4.2611, -4.6634, -5.0104, -4.9956, -4.4375,\n",
      "         -4.8878, -4.4001, -4.5239, -4.3548, -4.2902, -4.3490, -4.5084, -4.7106,\n",
      "         -4.3298, -4.9857, -4.6775, -4.5345, -4.9657, -4.0244, -4.5710, -4.4016,\n",
      "         -4.2914, -4.4394, -4.7078, -4.3453, -4.7604, -4.6161, -4.5006, -4.3890,\n",
      "         -4.6739, -4.5708, -4.7604, -4.2745, -4.6104, -4.4619, -4.4172, -4.7211,\n",
      "         -4.8204, -4.7754, -4.9268, -4.9735, -4.4514, -4.5191, -5.0332, -5.0001,\n",
      "         -4.4881, -4.2174, -4.4279, -4.5112, -4.8091, -4.0540, -4.8102, -5.0223,\n",
      "         -4.8570, -4.1092, -4.7142, -4.9204, -4.5371, -4.4114, -4.5094, -4.8716,\n",
      "         -4.6983]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : being\n",
      "target index is: [32] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3746, -4.2626, -4.6195, -5.0612, -4.1697, -4.3793, -4.5158, -4.1225,\n",
      "         -4.9719, -4.4509, -4.8348, -4.3400, -4.6620, -4.4089, -5.0164, -4.4129,\n",
      "         -4.4405, -4.4761, -4.6964, -4.0559, -4.8286, -4.7679, -4.5005, -4.5503,\n",
      "         -4.8931, -4.5750, -4.6383, -4.5310, -4.4165, -4.7810, -4.2590, -4.8259,\n",
      "         -4.9030, -4.5774, -4.5208, -4.7982, -4.4898, -4.9781, -4.9230, -4.8174,\n",
      "         -4.6970, -4.7245, -4.5091, -4.1878, -4.4590, -4.1306, -4.7272, -4.7330,\n",
      "         -4.7691, -4.6837, -4.7058, -4.3789, -4.5306, -4.5290, -4.9957, -4.6846,\n",
      "         -4.5618, -4.6157, -4.5203, -4.5626, -4.9049, -4.8386, -4.7733, -4.2292,\n",
      "         -4.5774, -4.5270, -4.9753, -4.4997, -4.6610, -4.8730, -4.5467, -4.6670,\n",
      "         -4.6764, -5.0845, -4.3841, -4.5437, -4.6220, -4.4088, -4.5432, -4.6866,\n",
      "         -4.6516, -4.4107, -4.4386, -4.8930, -4.8088, -4.4609, -4.3613, -4.2090,\n",
      "         -5.0828, -4.3815, -4.6653, -4.4082, -4.9966, -4.5059, -4.4187, -4.4019,\n",
      "         -4.6800]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : asked,\n",
      "target index is: [23] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2053, -4.6059, -4.5060, -4.6415, -4.1185, -4.8275, -4.6864, -4.3774,\n",
      "         -4.6664, -4.5910, -4.6502, -4.3215, -4.6452, -4.6980, -4.6807, -4.7902,\n",
      "         -4.7314, -5.0715, -4.4378, -4.8124, -4.5342, -4.4862, -4.7207, -4.5957,\n",
      "         -4.4138, -4.8514, -4.5324, -4.4935, -4.3245, -4.5482, -4.5884, -4.8113,\n",
      "         -4.6654, -4.5785, -4.7199, -5.0492, -4.5768, -4.4506, -4.5065, -4.6461,\n",
      "         -4.7538, -4.4111, -4.6531, -4.4941, -4.3974, -4.1934, -4.6485, -4.8688,\n",
      "         -4.7826, -4.5086, -4.5956, -4.3585, -4.8939, -4.4457, -4.8114, -4.3784,\n",
      "         -4.5836, -4.2738, -4.3685, -4.6272, -4.7093, -4.5100, -4.6158, -3.9627,\n",
      "         -4.7841, -4.6203, -4.9465, -4.6738, -4.8646, -4.6374, -4.5184, -4.6021,\n",
      "         -4.9170, -4.5124, -4.6487, -4.9574, -4.7574, -4.2711, -4.5914, -4.9342,\n",
      "         -4.5736, -4.1876, -4.9087, -4.6212, -4.4106, -4.5264, -4.6317, -4.5439,\n",
      "         -5.0223, -4.4398, -4.5286, -4.5122, -4.6331, -4.6302, -4.2756, -4.7046,\n",
      "         -4.4439]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : where\n",
      "target index is: [51] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3701, -4.2868, -4.6720, -4.9591, -4.2631, -4.9389, -4.7502, -4.6524,\n",
      "         -4.8773, -4.6472, -4.9533, -4.5986, -4.8335, -4.6221, -4.6406, -4.9540,\n",
      "         -4.6816, -4.5884, -4.9241, -4.5203, -4.6520, -4.5611, -4.8491, -4.5166,\n",
      "         -4.5867, -4.7482, -4.3704, -4.3874, -4.2859, -4.6400, -4.3229, -4.9304,\n",
      "         -4.7356, -4.6626, -4.5135, -4.9809, -4.4673, -4.6629, -4.7806, -4.5581,\n",
      "         -4.6111, -4.7019, -4.6259, -4.5726, -4.5482, -4.1357, -4.7911, -4.5701,\n",
      "         -4.7529, -4.7873, -4.2397, -4.9020, -4.6965, -4.4977, -4.4916, -4.6899,\n",
      "         -4.5402, -4.3923, -4.5641, -4.5360, -4.5483, -4.4379, -4.5162, -4.3717,\n",
      "         -4.4815, -4.7987, -5.0286, -4.2970, -4.3953, -4.3295, -4.6667, -4.4917,\n",
      "         -5.0754, -4.9741, -4.8480, -4.9426, -4.6050, -4.2203, -4.4161, -4.5040,\n",
      "         -4.4197, -4.3848, -4.7407, -4.8918, -4.8357, -4.2463, -4.3256, -4.4836,\n",
      "         -4.7667, -4.4090, -4.2177, -4.7064, -4.6972, -4.3559, -4.2593, -4.5783,\n",
      "         -4.2113]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : all\n",
      "target index is: [52] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4750, -4.2727, -4.6746, -4.7906, -4.4269, -4.8226, -4.4565, -4.4539,\n",
      "         -4.5429, -4.8778, -5.0018, -4.7047, -4.4978, -4.6091, -4.5913, -4.6418,\n",
      "         -4.6375, -4.7316, -4.5893, -4.2204, -4.8018, -4.7541, -4.7220, -4.4875,\n",
      "         -4.3823, -4.8641, -4.4908, -4.4939, -4.1980, -4.8286, -4.4769, -4.7730,\n",
      "         -4.8652, -4.8323, -4.4876, -4.5453, -4.6118, -4.4832, -4.6587, -4.6093,\n",
      "         -4.7282, -4.6063, -4.7415, -4.4900, -4.7841, -4.1941, -4.8275, -4.6373,\n",
      "         -4.5656, -4.8212, -4.4371, -4.4546, -4.6081, -4.3094, -4.7137, -4.5458,\n",
      "         -4.3787, -4.3781, -4.5932, -4.7434, -4.7733, -4.7220, -4.5712, -4.5579,\n",
      "         -4.8001, -4.5285, -5.0804, -4.3625, -4.6387, -4.6507, -4.4389, -4.4939,\n",
      "         -4.5528, -4.8931, -4.6310, -4.6569, -4.5828, -4.2190, -4.4935, -4.6624,\n",
      "         -4.5071, -4.5779, -4.6344, -4.8242, -4.6444, -4.3227, -4.4673, -4.5769,\n",
      "         -4.7101, -4.3190, -4.6516, -4.6433, -4.6543, -4.5240, -4.3367, -4.4594,\n",
      "         -4.2179]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4032, -4.3571, -4.9422, -4.7819, -4.2717, -4.7800, -4.8710, -4.3883,\n",
      "         -5.0854, -4.2663, -5.0068, -4.3791, -4.5176, -4.6477, -4.6582, -4.8094,\n",
      "         -4.5464, -4.4402, -4.4635, -4.4986, -4.6449, -4.3608, -4.5529, -4.7891,\n",
      "         -4.4319, -5.0744, -4.3512, -4.5269, -4.4877, -4.4958, -4.6979, -4.6637,\n",
      "         -4.8375, -4.6499, -4.8911, -5.0831, -4.6856, -4.6351, -4.8847, -4.6264,\n",
      "         -4.6419, -4.7621, -4.6703, -4.6015, -4.5200, -4.1141, -4.8106, -4.7109,\n",
      "         -4.8826, -4.6576, -4.7512, -4.7664, -4.5707, -4.2745, -4.4642, -4.7744,\n",
      "         -4.3090, -4.3870, -4.4521, -4.5413, -4.7044, -4.5502, -4.2741, -4.2939,\n",
      "         -4.2252, -4.7489, -4.7100, -4.2308, -4.5996, -4.3718, -4.4339, -4.5893,\n",
      "         -4.8041, -4.6023, -4.7812, -4.7348, -4.2293, -4.4587, -4.3603, -4.7055,\n",
      "         -4.4461, -4.5588, -4.7997, -5.0471, -4.8636, -4.4511, -4.7419, -4.6264,\n",
      "         -4.8927, -4.4677, -4.5128, -4.7858, -4.8234, -4.3292, -4.0549, -4.8355,\n",
      "         -4.3752]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty\n",
      "target index is: [0] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3847, -4.6756, -4.7867, -4.9169, -4.2171, -4.6843, -4.4134, -4.2110,\n",
      "         -5.1110, -4.4872, -4.8008, -4.4055, -4.2944, -4.6082, -4.8384, -5.0892,\n",
      "         -4.6869, -4.5602, -4.6687, -4.5078, -4.7684, -4.7260, -4.8883, -4.6391,\n",
      "         -4.4673, -5.1894, -4.3537, -4.4370, -4.2208, -4.6872, -4.5075, -4.3375,\n",
      "         -4.7196, -4.9142, -4.6754, -5.1523, -4.3272, -4.5326, -4.3837, -4.3813,\n",
      "         -4.5456, -4.3746, -4.6321, -4.3123, -4.5361, -4.0726, -4.8982, -4.5909,\n",
      "         -4.8638, -4.7891, -4.5066, -4.6734, -4.8320, -4.5313, -4.5681, -4.5705,\n",
      "         -4.4474, -4.3865, -4.5042, -4.4507, -4.7118, -4.4277, -4.3784, -4.4077,\n",
      "         -4.3004, -5.0135, -4.7991, -4.4164, -4.7702, -4.0279, -4.5703, -4.4735,\n",
      "         -5.1020, -4.9233, -4.7625, -4.7423, -4.5920, -3.9074, -4.3336, -4.7787,\n",
      "         -4.6679, -4.7751, -4.8436, -4.9278, -5.1282, -4.3076, -4.5611, -4.3890,\n",
      "         -5.3282, -4.8446, -4.7646, -4.5718, -4.8824, -4.3555, -4.5183, -4.7965,\n",
      "         -4.2643]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : lies,\n",
      "target index is: [59] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2943, -4.6561, -4.6567, -4.6679, -4.1938, -4.8851, -4.4313, -4.2359,\n",
      "         -4.6670, -5.1512, -4.7681, -4.3990, -4.5360, -4.7996, -4.7683, -4.6494,\n",
      "         -4.4636, -4.9514, -4.8182, -4.9110, -4.4335, -4.4954, -4.6947, -4.5102,\n",
      "         -4.1525, -4.8740, -4.5025, -4.3957, -4.3540, -4.5922, -4.6185, -4.7007,\n",
      "         -4.5280, -5.1137, -4.4989, -4.6470, -4.8987, -4.3137, -4.6810, -4.3783,\n",
      "         -5.0424, -4.2443, -4.7562, -4.4183, -4.4717, -4.1720, -4.4866, -4.5871,\n",
      "         -4.5453, -4.5437, -4.5965, -4.1690, -5.0322, -4.3765, -4.7065, -4.3171,\n",
      "         -4.5779, -4.4762, -4.7535, -4.7752, -4.6654, -4.2939, -4.5252, -4.3535,\n",
      "         -4.6746, -4.6659, -4.7076, -4.3627, -4.6686, -4.4312, -4.4290, -4.6602,\n",
      "         -4.4767, -4.9564, -4.8655, -4.9244, -4.6341, -4.1363, -4.7573, -5.0534,\n",
      "         -4.3973, -4.7238, -4.6878, -4.7879, -4.4256, -4.4452, -4.4619, -5.0378,\n",
      "         -4.9963, -4.5192, -4.7133, -4.6909, -4.4274, -4.6262, -4.7146, -4.5735,\n",
      "         -4.4392]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Where\n",
      "target index is: [18] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5547, -4.4200, -4.3764, -4.5916, -4.2266, -4.9765, -4.7683, -4.5056,\n",
      "         -4.6669, -4.7676, -4.7000, -4.4931, -4.7134, -4.7692, -4.5592, -4.5530,\n",
      "         -4.8534, -4.5953, -4.5626, -4.6140, -4.3812, -4.3121, -4.7627, -4.6402,\n",
      "         -4.3912, -4.7751, -4.6611, -4.4654, -4.3434, -4.5574, -4.7099, -4.6575,\n",
      "         -4.8409, -4.5768, -4.6514, -4.8986, -4.5698, -4.8962, -4.4978, -4.5139,\n",
      "         -4.6602, -4.6616, -4.8488, -4.5232, -4.6393, -4.4035, -4.5552, -4.6744,\n",
      "         -4.4887, -4.8329, -4.4989, -4.8281, -4.5645, -4.6053, -4.7212, -4.7508,\n",
      "         -4.2796, -4.4427, -4.3915, -4.5010, -4.8206, -4.7900, -4.5049, -4.1982,\n",
      "         -4.8987, -4.4349, -4.9220, -4.3614, -4.5771, -4.7045, -4.2998, -4.4585,\n",
      "         -4.8527, -4.9285, -4.8227, -4.7750, -4.2891, -4.3139, -4.8038, -4.5506,\n",
      "         -4.4699, -4.2853, -4.6233, -4.7485, -4.6283, -4.4506, -4.3857, -4.6999,\n",
      "         -4.7761, -4.2421, -4.5492, -4.7146, -4.5584, -4.4220, -4.2589, -4.5011,\n",
      "         -4.5440]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : all\n",
      "target index is: [52] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2901, -4.2326, -4.6146, -4.9303, -4.3267, -4.6048, -4.5684, -4.4645,\n",
      "         -4.7922, -4.9657, -4.8465, -4.4881, -4.7385, -4.6604, -4.5007, -4.7456,\n",
      "         -4.7466, -5.0418, -4.4054, -4.1812, -4.7667, -4.4074, -4.7091, -4.4780,\n",
      "         -4.6084, -4.7392, -4.3989, -4.4741, -4.2026, -4.9831, -4.4461, -4.9375,\n",
      "         -4.8519, -4.6566, -4.3106, -4.7139, -4.5681, -4.7904, -4.7928, -4.7182,\n",
      "         -4.6641, -4.6364, -4.8373, -4.5742, -4.8885, -4.2450, -5.0152, -4.6364,\n",
      "         -4.6205, -4.8678, -4.4241, -4.6426, -4.4112, -4.5056, -5.0070, -4.6051,\n",
      "         -4.6237, -4.4582, -4.6087, -4.7832, -4.5595, -4.6041, -4.6969, -4.3942,\n",
      "         -4.9762, -4.4501, -5.1240, -4.6003, -4.7626, -4.6833, -4.3189, -4.5413,\n",
      "         -4.5796, -4.8201, -4.3962, -4.6213, -4.6758, -4.1760, -4.4419, -4.4074,\n",
      "         -4.4899, -4.4321, -4.7922, -4.8742, -4.4335, -4.4281, -4.3468, -4.5474,\n",
      "         -4.7280, -4.2673, -4.4892, -4.4162, -4.7326, -4.5312, -4.1392, -4.4190,\n",
      "         -4.3521]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : the\n",
      "target index is: [82] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1665, -4.4017, -4.5609, -4.8769, -4.1794, -4.6918, -4.6713, -4.3328,\n",
      "         -4.6297, -4.7071, -4.8785, -4.7292, -4.6346, -4.8026, -4.7007, -4.6532,\n",
      "         -4.4279, -4.5085, -4.4423, -4.6481, -4.8790, -4.5044, -4.8280, -4.6015,\n",
      "         -4.2133, -4.4995, -4.5421, -4.4865, -4.4424, -4.4929, -4.5573, -4.6980,\n",
      "         -4.5592, -4.6542, -4.8798, -4.7716, -4.8399, -4.5464, -4.8660, -4.8052,\n",
      "         -4.7025, -4.5497, -4.7665, -4.3530, -4.6023, -4.1680, -4.6204, -4.5210,\n",
      "         -4.5607, -4.4583, -4.5030, -4.5934, -4.9630, -4.4290, -4.5134, -4.6688,\n",
      "         -4.4336, -4.5277, -4.4151, -4.5670, -5.1435, -4.7136, -4.3934, -4.0314,\n",
      "         -4.8549, -4.7319, -4.7353, -4.4966, -4.6592, -4.7214, -4.7139, -4.6162,\n",
      "         -4.4905, -4.5526, -4.5228, -4.5328, -4.4086, -4.4734, -4.6507, -4.7996,\n",
      "         -4.2456, -4.3349, -4.8701, -4.7730, -4.5776, -4.5690, -4.7644, -4.8022,\n",
      "         -4.9133, -4.3560, -4.6148, -4.5185, -4.6495, -4.5381, -4.3368, -4.6062,\n",
      "         -4.6070]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : treasure\n",
      "target index is: [31] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3809, -4.3575, -4.7240, -4.9664, -4.1152, -4.7623, -4.6684, -4.5813,\n",
      "         -4.7617, -4.5659, -4.6186, -4.2741, -4.8131, -4.8022, -4.8169, -4.8185,\n",
      "         -4.4654, -4.7455, -4.6882, -4.5511, -4.5238, -4.4649, -4.8903, -4.6111,\n",
      "         -4.7426, -4.9769, -4.2874, -4.4410, -4.2847, -4.8929, -4.2487, -5.0154,\n",
      "         -4.6664, -4.5766, -4.4980, -5.0354, -4.3879, -4.6875, -4.7233, -4.7733,\n",
      "         -4.5748, -4.7533, -4.5237, -4.3579, -4.5504, -4.2682, -4.6534, -4.6975,\n",
      "         -4.7516, -4.9026, -4.2983, -4.7655, -4.7514, -4.8269, -4.6905, -4.3853,\n",
      "         -4.5609, -4.2487, -4.4863, -4.6127, -4.5104, -4.3465, -4.7821, -4.2133,\n",
      "         -4.4786, -4.6302, -5.0712, -4.6843, -4.2614, -4.3152, -4.7214, -4.7132,\n",
      "         -4.8680, -4.8569, -4.7549, -5.0160, -4.6932, -4.2761, -4.5943, -4.5545,\n",
      "         -4.6499, -4.1827, -4.8091, -4.9791, -4.6561, -4.4470, -4.3232, -4.2841,\n",
      "         -4.7366, -4.5267, -4.3239, -4.4636, -4.8546, -4.4802, -4.5043, -4.4584,\n",
      "         -4.2844]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : of\n",
      "target index is: [57] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4891, -4.1641, -4.3083, -4.5631, -4.1602, -4.8559, -4.9255, -4.4284,\n",
      "         -4.8192, -4.7644, -5.0748, -4.5445, -4.5932, -4.5690, -4.7867, -4.7606,\n",
      "         -4.6659, -4.5631, -4.5560, -4.5508, -4.5936, -4.3584, -4.7090, -4.3851,\n",
      "         -4.0763, -4.6792, -4.4899, -4.5480, -4.2833, -4.4811, -4.6617, -5.0525,\n",
      "         -5.0289, -4.5612, -4.8650, -4.8999, -4.8055, -4.7463, -4.5416, -4.7055,\n",
      "         -4.8362, -4.4929, -4.6488, -4.4846, -4.5422, -4.3135, -4.7514, -4.9342,\n",
      "         -4.6103, -4.5213, -4.4254, -4.4116, -4.8843, -4.2247, -4.6505, -4.6478,\n",
      "         -4.4449, -4.4143, -4.4600, -4.6978, -4.9014, -4.7183, -4.3759, -4.1375,\n",
      "         -4.7033, -4.7027, -5.0073, -4.5094, -4.7700, -4.6943, -4.5631, -4.4503,\n",
      "         -4.6993, -4.8624, -4.6665, -4.7855, -4.6045, -4.1622, -4.6758, -4.9218,\n",
      "         -4.2409, -4.3510, -4.7557, -4.8163, -4.6070, -4.4764, -4.5734, -4.6916,\n",
      "         -4.7675, -4.2058, -4.6692, -4.8107, -4.5954, -4.3746, -4.3023, -4.6455,\n",
      "         -4.3146]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1618, -4.2767, -4.8910, -5.0325, -4.1950, -4.7473, -4.7555, -4.2529,\n",
      "         -5.2560, -4.3769, -5.1370, -4.1436, -4.5752, -4.3207, -4.7177, -4.9593,\n",
      "         -4.5593, -4.5864, -4.7518, -4.1915, -4.7876, -4.7769, -4.5096, -4.4772,\n",
      "         -4.7316, -4.8544, -4.3866, -4.3416, -4.4133, -4.6799, -4.6394, -4.7539,\n",
      "         -5.0095, -4.7863, -4.8068, -5.2290, -4.5866, -4.5700, -4.9147, -4.4348,\n",
      "         -4.8727, -4.6460, -4.4930, -4.3908, -4.6498, -3.9981, -4.8522, -4.7030,\n",
      "         -4.8456, -4.7222, -4.6146, -4.7398, -4.4425, -4.3188, -4.8065, -4.8055,\n",
      "         -4.4578, -4.4857, -4.6769, -4.6693, -4.6181, -4.6351, -4.2942, -4.4982,\n",
      "         -4.3348, -4.7821, -5.1335, -4.3172, -4.5870, -4.5938, -4.2638, -4.6779,\n",
      "         -4.6868, -5.0442, -4.5494, -4.6972, -4.3068, -4.2012, -4.3026, -4.6021,\n",
      "         -4.4951, -4.5588, -4.6567, -5.0097, -5.1447, -4.2407, -4.6101, -4.3095,\n",
      "         -5.0787, -4.5370, -4.4270, -4.7797, -4.8728, -4.4897, -4.1899, -4.4638,\n",
      "         -4.3504]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : lusty\n",
      "target index is: [30] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2198, -4.6123, -4.4166, -4.9584, -4.2094, -4.7042, -4.5499, -4.1647,\n",
      "         -4.6914, -4.9683, -4.9013, -4.4704, -4.4120, -4.6496, -4.9039, -4.8327,\n",
      "         -4.4332, -4.7367, -4.4111, -4.8113, -4.7089, -5.0434, -4.7284, -4.6737,\n",
      "         -4.3995, -4.7138, -4.5192, -4.4774, -4.1954, -4.5206, -4.2052, -4.6926,\n",
      "         -4.5891, -4.8838, -4.7555, -4.8860, -4.3923, -4.4505, -4.4847, -4.5241,\n",
      "         -4.8213, -4.2764, -4.7996, -4.3149, -4.6606, -4.1553, -4.5207, -4.5815,\n",
      "         -4.7096, -4.5579, -4.6243, -4.3052, -5.0737, -4.5223, -4.8572, -4.7237,\n",
      "         -4.3585, -4.3468, -4.5194, -4.6477, -4.8448, -4.3712, -4.6079, -4.1850,\n",
      "         -4.6875, -4.7861, -4.8313, -4.8142, -4.7955, -4.4153, -4.6351, -4.4151,\n",
      "         -5.0286, -4.9656, -4.6971, -4.6841, -4.9174, -3.8056, -4.5036, -5.0131,\n",
      "         -4.5065, -4.5611, -4.6529, -4.9079, -4.8358, -4.4712, -4.4054, -4.4308,\n",
      "         -5.2471, -4.3912, -4.8074, -4.5024, -4.5363, -4.5833, -4.3988, -4.7651,\n",
      "         -4.4090]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : days;\n",
      "target index is: [48] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5472, -4.7543, -4.4054, -4.4584, -3.7549, -4.7626, -4.5636, -4.4374,\n",
      "         -4.5027, -4.9522, -4.4782, -4.6012, -5.0879, -4.9656, -4.6486, -4.5884,\n",
      "         -4.9372, -5.0784, -4.6138, -4.7467, -4.6249, -4.0543, -4.7384, -4.5228,\n",
      "         -4.4204, -4.8270, -4.5058, -4.5062, -4.5830, -4.5381, -4.5961, -4.6531,\n",
      "         -4.6991, -4.7362, -4.4084, -4.9519, -4.7320, -4.8700, -4.5571, -4.5684,\n",
      "         -4.8191, -4.6557, -5.0441, -4.4374, -4.8587, -4.7027, -4.3614, -4.4296,\n",
      "         -4.2914, -4.3405, -4.4622, -4.6632, -4.7713, -4.4835, -4.7014, -3.8999,\n",
      "         -4.5963, -4.1591, -4.4770, -4.5724, -4.6470, -4.8025, -4.9806, -3.9736,\n",
      "         -5.0408, -4.3768, -4.9392, -4.5299, -4.7408, -5.0524, -4.2147, -4.5226,\n",
      "         -4.8411, -4.9701, -4.4746, -4.9983, -4.7336, -4.5802, -4.6604, -4.6387,\n",
      "         -4.7655, -4.0385, -5.0200, -4.6467, -4.4484, -4.6595, -4.5493, -5.0138,\n",
      "         -4.8461, -4.2508, -4.6753, -4.3947, -4.4752, -4.5454, -4.3987, -4.4574,\n",
      "         -4.5916]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : To\n",
      "target index is: [26] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2618, -4.6455, -5.0125, -4.9538, -4.0649, -4.7820, -4.4780, -4.7026,\n",
      "         -4.5818, -4.6287, -4.9419, -4.4742, -4.8597, -4.4935, -4.8495, -4.6429,\n",
      "         -4.2083, -4.7085, -4.8748, -4.6503, -4.3375, -4.1876, -4.9224, -4.6986,\n",
      "         -4.5229, -4.8572, -4.3853, -4.4241, -4.3736, -4.8366, -4.6286, -4.9283,\n",
      "         -4.9336, -4.9802, -4.5462, -4.5503, -4.5802, -4.5356, -5.1331, -4.6772,\n",
      "         -4.7041, -4.6932, -4.3602, -4.7167, -4.1420, -4.4171, -4.5612, -4.8276,\n",
      "         -4.4435, -5.0010, -4.2501, -4.5877, -4.6284, -4.2447, -4.8091, -4.7237,\n",
      "         -4.6688, -4.5802, -4.5054, -4.5916, -4.6266, -4.4019, -4.5706, -4.2870,\n",
      "         -4.3567, -4.8248, -4.9600, -4.5012, -4.5992, -4.2813, -4.3915, -4.5321,\n",
      "         -4.9163, -4.5044, -4.8676, -4.9931, -4.5644, -4.3644, -4.8218, -4.6648,\n",
      "         -4.1539, -4.3491, -4.5596, -4.7100, -4.4291, -4.3647, -4.6449, -4.7300,\n",
      "         -4.8616, -4.5882, -4.4721, -4.9775, -4.5257, -4.2180, -4.4084, -4.7277,\n",
      "         -4.3364]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : say,\n",
      "target index is: [96] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7831, -4.3244, -4.6528, -4.9216, -3.9661, -4.7198, -4.6179, -4.2815,\n",
      "         -4.7540, -4.4997, -4.7677, -4.6214, -4.6807, -4.7655, -4.5914, -4.8469,\n",
      "         -4.8200, -4.3583, -4.7424, -4.2335, -4.6831, -4.5900, -4.7316, -4.7199,\n",
      "         -4.4702, -4.8300, -4.4198, -4.5255, -4.2721, -4.5201, -4.6159, -4.6260,\n",
      "         -4.8524, -4.7680, -4.4824, -4.8508, -4.4921, -4.8375, -4.5424, -4.4614,\n",
      "         -4.5841, -4.6750, -4.6738, -4.4267, -4.6719, -4.4798, -4.4054, -4.5044,\n",
      "         -4.5403, -4.6927, -4.3541, -4.8268, -4.6523, -4.5560, -4.7504, -4.3865,\n",
      "         -4.6590, -4.4016, -4.4827, -4.6725, -4.6829, -4.6446, -4.5611, -4.2156,\n",
      "         -4.5745, -4.4567, -4.5192, -4.6141, -4.5614, -4.8445, -4.6528, -4.4814,\n",
      "         -4.8134, -5.1549, -4.6730, -4.7389, -4.3865, -4.5298, -4.5535, -4.8638,\n",
      "         -4.7838, -4.3915, -4.7053, -4.6755, -4.9506, -4.2163, -4.4054, -4.7264,\n",
      "         -4.6239, -4.1482, -4.7282, -4.5694, -4.6333, -4.2911, -4.6890, -4.4042,\n",
      "         -4.4872]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : within\n",
      "target index is: [34] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2183, -4.3332, -4.7249, -4.8892, -4.5002, -4.8546, -4.5115, -4.0755,\n",
      "         -5.1460, -4.5673, -4.9902, -4.3876, -4.2854, -4.6257, -5.1713, -5.0463,\n",
      "         -4.5569, -4.5749, -4.7278, -4.5943, -4.5307, -4.7297, -4.7611, -4.9234,\n",
      "         -4.4789, -4.9387, -4.2140, -4.3661, -4.1167, -4.5153, -4.5376, -4.6612,\n",
      "         -4.9533, -4.8505, -4.8257, -4.9989, -4.7685, -4.3531, -4.5615, -4.5312,\n",
      "         -4.6889, -4.6555, -4.4142, -4.3439, -4.3344, -4.0056, -4.7027, -4.7708,\n",
      "         -4.6320, -4.7599, -4.6506, -4.1928, -4.6784, -4.6072, -4.5347, -4.6447,\n",
      "         -4.5963, -4.2119, -4.4194, -4.9572, -4.8445, -4.5929, -4.5077, -4.4093,\n",
      "         -4.3566, -4.9487, -4.9570, -4.5287, -4.5112, -4.1637, -4.4313, -4.5914,\n",
      "         -4.7593, -4.7729, -4.6905, -4.8840, -4.5317, -4.0313, -4.4389, -5.0682,\n",
      "         -4.3352, -4.7341, -4.6181, -4.9379, -4.9006, -4.6573, -4.6844, -4.3821,\n",
      "         -5.1293, -4.6066, -4.5222, -4.4303, -4.8139, -4.5489, -4.4270, -4.5448,\n",
      "         -4.3978]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thine\n",
      "target index is: [56] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1454, -4.9214, -4.1311, -4.5878, -4.0807, -4.7149, -4.8586, -4.3202,\n",
      "         -4.7091, -4.8702, -4.7756, -4.7940, -4.7145, -4.7231, -4.7703, -4.6786,\n",
      "         -4.6134, -4.7481, -4.4957, -4.9869, -4.8306, -4.5975, -4.8279, -4.4552,\n",
      "         -4.3186, -4.7517, -4.6643, -4.5112, -4.3006, -4.3733, -4.3528, -4.5495,\n",
      "         -4.6354, -4.5284, -4.6850, -4.8815, -4.3766, -4.8509, -4.6584, -4.6999,\n",
      "         -5.0022, -4.3008, -4.9555, -4.2359, -4.8503, -4.2925, -4.6097, -4.4705,\n",
      "         -4.7824, -4.3160, -4.5523, -4.7013, -5.1848, -4.5696, -4.9060, -4.5983,\n",
      "         -4.1786, -4.3363, -4.4105, -4.2968, -4.7295, -4.5853, -4.6114, -4.0519,\n",
      "         -4.7686, -4.4674, -5.0818, -4.7570, -4.9288, -4.9945, -4.4756, -4.4356,\n",
      "         -5.2559, -5.0238, -4.5793, -4.7955, -4.6721, -4.0839, -4.5793, -4.8302,\n",
      "         -4.4919, -4.0665, -4.6709, -4.8215, -4.6721, -4.6246, -4.4008, -4.5517,\n",
      "         -5.2672, -4.3033, -4.4162, -4.3852, -4.4849, -4.7998, -4.2334, -4.7086,\n",
      "         -4.4724]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : own\n",
      "target index is: [92] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4098, -4.4215, -4.4689, -4.9424, -3.7351, -4.4336, -4.7202, -4.6235,\n",
      "         -4.9178, -5.0480, -4.8489, -4.6179, -5.1091, -4.8125, -4.7882, -4.7128,\n",
      "         -4.5908, -5.1487, -4.5002, -4.3423, -4.4711, -4.0475, -4.7606, -4.5846,\n",
      "         -4.7702, -4.7636, -4.5162, -4.5924, -4.5799, -5.0502, -4.1957, -4.8350,\n",
      "         -4.6480, -4.4046, -4.2060, -4.8780, -4.6154, -5.1331, -4.8443, -4.8427,\n",
      "         -4.4910, -4.7593, -5.0474, -4.2567, -4.9273, -4.3964, -4.6049, -4.5043,\n",
      "         -4.7497, -4.7037, -4.6181, -4.7881, -4.6532, -4.5946, -4.9487, -4.2082,\n",
      "         -4.8325, -4.4151, -4.4820, -4.5793, -4.4762, -4.7049, -5.0565, -3.8144,\n",
      "         -4.7764, -4.4878, -5.1526, -4.5877, -4.6316, -4.9639, -4.4662, -4.5096,\n",
      "         -4.5853, -5.0975, -4.4092, -4.6239, -4.8458, -4.6004, -4.6144, -4.4196,\n",
      "         -4.7438, -4.1932, -4.9128, -4.8617, -4.2262, -4.5354, -4.1557, -4.5976,\n",
      "         -4.8309, -4.3904, -4.3858, -4.3535, -4.7326, -4.6465, -3.9277, -4.6681,\n",
      "         -4.3177]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : deep\n",
      "target index is: [76] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3245, -4.6570, -4.6715, -4.8026, -4.2564, -4.5392, -4.3776, -4.2455,\n",
      "         -4.6940, -4.9174, -5.0462, -4.3676, -4.5044, -4.4768, -4.6663, -4.4240,\n",
      "         -4.0939, -4.7376, -4.6414, -4.6288, -4.5810, -4.6007, -4.6602, -4.6402,\n",
      "         -4.4720, -4.6385, -4.5780, -4.5070, -4.4649, -4.6119, -4.6410, -4.8757,\n",
      "         -4.8951, -4.8867, -4.7138, -4.8147, -4.7914, -4.4461, -5.1259, -4.7414,\n",
      "         -4.7205, -4.5026, -4.8845, -4.3976, -4.5309, -4.3499, -4.6307, -4.7866,\n",
      "         -4.5222, -4.4455, -4.5971, -4.3167, -4.7906, -4.3314, -4.9154, -4.6556,\n",
      "         -4.4172, -4.6423, -4.7461, -4.6145, -4.7984, -4.6268, -4.4499, -3.9776,\n",
      "         -4.6009, -4.4736, -4.9089, -4.4408, -4.5747, -4.6235, -4.4265, -4.6456,\n",
      "         -4.5369, -4.4079, -4.4800, -4.6131, -4.6928, -4.5786, -4.6548, -4.7146,\n",
      "         -4.0614, -4.5199, -4.6828, -4.7374, -4.4715, -4.4131, -4.7888, -4.7308,\n",
      "         -5.0022, -4.4767, -4.5307, -4.8195, -4.6675, -4.6590, -4.2308, -4.5770,\n",
      "         -4.6167]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : sunken\n",
      "target index is: [91] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4334, -4.5304, -4.7023, -4.8549, -4.1956, -4.8762, -4.6023, -4.7587,\n",
      "         -4.7275, -4.4380, -4.9353, -4.4863, -4.8144, -4.6570, -4.6726, -4.8364,\n",
      "         -4.8991, -4.7908, -4.7479, -4.3295, -4.4823, -4.2136, -4.9424, -4.5365,\n",
      "         -4.5676, -4.8983, -4.3704, -4.6628, -4.3289, -4.6453, -4.8815, -4.6470,\n",
      "         -4.6527, -4.7939, -4.7390, -5.0144, -4.7172, -4.6834, -4.7768, -4.2413,\n",
      "         -4.8064, -4.7405, -4.8445, -4.3660, -4.5015, -4.5865, -4.6956, -4.5617,\n",
      "         -4.3347, -4.9188, -3.9395, -5.2334, -4.3763, -4.4618, -4.7619, -4.2443,\n",
      "         -4.8085, -4.4724, -4.4296, -4.4980, -4.5225, -4.4037, -4.6431, -3.9796,\n",
      "         -4.5169, -4.6269, -4.9842, -4.5719, -4.6367, -4.5339, -4.4359, -4.6174,\n",
      "         -4.8409, -4.7790, -4.5670, -5.0275, -4.2024, -4.5920, -4.5565, -4.5402,\n",
      "         -4.6404, -4.1818, -4.9222, -4.5837, -4.7884, -4.2804, -4.7773, -4.8457,\n",
      "         -4.7689, -4.2960, -4.4100, -4.7090, -4.5269, -4.3548, -4.5146, -4.2673,\n",
      "         -4.3742]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : eyes,\n",
      "target index is: [58] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2841, -4.4945, -5.0807, -5.3265, -3.8707, -4.6400, -4.3618, -4.4987,\n",
      "         -4.7253, -4.6118, -5.1173, -4.6431, -4.8092, -4.5887, -4.6214, -4.6730,\n",
      "         -4.5786, -4.7115, -5.0034, -4.5366, -4.7340, -4.3177, -5.0356, -4.6251,\n",
      "         -4.5348, -4.8531, -4.4399, -4.3613, -4.3252, -4.7058, -4.7631, -4.5548,\n",
      "         -4.6522, -5.0804, -4.5938, -4.7123, -4.5073, -4.5184, -5.1029, -4.3029,\n",
      "         -4.5776, -4.3535, -4.7779, -4.4173, -4.5966, -4.3150, -4.8562, -4.4562,\n",
      "         -4.4851, -5.0459, -4.3126, -4.9752, -4.5138, -4.2706, -4.4782, -4.6688,\n",
      "         -4.5622, -4.7588, -4.6290, -4.4120, -4.5779, -4.3140, -4.1166, -4.4582,\n",
      "         -4.2536, -4.6874, -4.6945, -4.5521, -4.6265, -4.2635, -4.5086, -4.6109,\n",
      "         -4.8987, -4.7975, -4.7750, -4.7935, -4.4377, -4.4998, -4.6315, -4.7268,\n",
      "         -4.4237, -4.5028, -4.9284, -4.9042, -4.9038, -4.0245, -4.6393, -4.6530,\n",
      "         -4.6900, -4.4591, -4.7977, -4.6517, -4.8523, -4.1918, -4.6945, -4.6018,\n",
      "         -4.2424]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Were\n",
      "target index is: [37] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2562, -4.5076, -4.6959, -4.6491, -4.2212, -4.7005, -4.4155, -4.2796,\n",
      "         -4.7969, -4.9095, -4.5943, -4.4396, -4.5379, -4.8337, -4.9929, -4.6724,\n",
      "         -4.7168, -4.5492, -4.6637, -4.7058, -4.3283, -4.4418, -4.8898, -5.0267,\n",
      "         -4.2896, -4.9278, -4.5773, -4.4061, -4.1982, -4.4160, -4.6195, -4.6513,\n",
      "         -4.5704, -4.8814, -4.3582, -4.8287, -4.8540, -4.3759, -4.7593, -4.3740,\n",
      "         -4.7070, -4.5306, -4.6921, -4.6736, -4.5645, -4.2092, -4.2509, -4.7897,\n",
      "         -4.4790, -4.8754, -4.7212, -4.3206, -4.8133, -4.5062, -4.4676, -4.4655,\n",
      "         -4.3834, -4.3835, -4.4538, -4.8860, -4.6356, -4.1413, -4.5601, -4.3360,\n",
      "         -4.4933, -4.6913, -4.6006, -4.3606, -4.6918, -4.1645, -4.5283, -4.5807,\n",
      "         -4.6843, -5.1130, -4.9498, -4.9281, -4.6378, -4.2679, -4.7147, -4.8888,\n",
      "         -4.5670, -4.7051, -4.7620, -4.7978, -4.6191, -4.3419, -4.4565, -4.8151,\n",
      "         -4.8887, -4.4134, -4.7984, -4.4944, -4.6292, -4.5393, -4.8458, -4.6880,\n",
      "         -4.6119]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : an\n",
      "target index is: [74] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5070, -4.6904, -4.6795, -4.4972, -4.0975, -4.9837, -4.6533, -4.5407,\n",
      "         -4.7195, -4.4915, -4.9756, -4.7181, -4.8442, -4.9111, -4.7792, -4.8522,\n",
      "         -4.8160, -4.5785, -4.6656, -4.7234, -4.3805, -4.0723, -4.8305, -4.8786,\n",
      "         -4.4167, -5.2013, -4.3508, -4.2047, -4.6322, -4.3651, -4.8346, -4.5503,\n",
      "         -4.8575, -4.9346, -4.3896, -4.7103, -4.7515, -4.5860, -4.7700, -4.4711,\n",
      "         -4.9080, -4.7478, -4.5819, -4.5220, -4.4218, -4.4233, -4.5394, -4.5617,\n",
      "         -4.3538, -4.9985, -4.4218, -4.4571, -4.6492, -4.3940, -4.4378, -4.3342,\n",
      "         -4.4560, -4.3281, -4.2088, -4.8199, -4.5747, -4.5560, -4.5920, -4.3398,\n",
      "         -4.5983, -4.3715, -4.8419, -4.2892, -4.7124, -4.5634, -4.3897, -4.6562,\n",
      "         -4.8434, -4.8276, -5.0239, -5.1081, -4.3401, -4.2534, -4.5305, -4.8766,\n",
      "         -4.3617, -4.5908, -4.4600, -4.8049, -4.5198, -4.2711, -4.6595, -5.0403,\n",
      "         -4.8086, -4.5778, -4.3724, -4.4464, -4.5640, -4.5514, -4.6207, -4.4846,\n",
      "         -4.3589]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : all-eating\n",
      "target index is: [60] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4788, -4.5631, -4.8554, -4.7434, -3.9424, -4.7159, -4.7302, -4.4152,\n",
      "         -4.8279, -4.4322, -5.0263, -4.6722, -4.8955, -4.6073, -4.7145, -4.6901,\n",
      "         -4.4644, -4.4384, -4.8298, -4.5098, -4.7401, -4.5854, -4.8934, -4.8909,\n",
      "         -4.6935, -4.9169, -4.6925, -4.2648, -4.2497, -4.4132, -4.5364, -4.5448,\n",
      "         -4.8443, -4.9304, -4.3578, -4.7368, -4.2905, -4.9281, -4.8252, -4.6163,\n",
      "         -4.7607, -4.4863, -4.4721, -4.5506, -4.3689, -4.4434, -4.5397, -4.6398,\n",
      "         -4.6712, -4.8558, -4.5082, -4.8250, -4.8482, -4.2361, -4.6602, -4.7631,\n",
      "         -4.3181, -4.4124, -4.6432, -4.4782, -4.6652, -4.6208, -4.4719, -4.4596,\n",
      "         -4.4376, -4.4007, -4.5797, -4.2880, -4.7541, -4.5858, -4.4040, -4.2638,\n",
      "         -5.0656, -4.9030, -4.7586, -4.8113, -4.3573, -4.3449, -4.5318, -5.0260,\n",
      "         -4.4189, -4.3216, -4.3151, -4.9270, -4.9889, -4.0381, -4.7334, -4.5608,\n",
      "         -4.8704, -4.2310, -4.5193, -4.6644, -4.7427, -4.4765, -4.6033, -4.5504,\n",
      "         -4.5553]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : shame,\n",
      "target index is: [41] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6951, -4.7278, -4.8718, -4.5133, -4.1529, -4.5979, -4.6605, -4.4504,\n",
      "         -4.5930, -4.6348, -4.5771, -4.4980, -4.8657, -4.7346, -4.7785, -4.4860,\n",
      "         -4.4528, -4.9071, -4.5684, -4.5058, -4.5693, -4.2240, -4.7368, -4.6012,\n",
      "         -4.5367, -4.9694, -4.3715, -4.5070, -4.4939, -4.6034, -4.4250, -5.0136,\n",
      "         -5.1049, -4.8006, -4.5541, -4.7078, -4.4997, -5.0386, -4.8160, -4.7238,\n",
      "         -4.8054, -4.3765, -4.4965, -4.5738, -4.5193, -4.4836, -4.6234, -4.6525,\n",
      "         -4.4192, -4.6472, -4.8606, -4.2296, -4.8318, -4.3256, -4.8872, -4.1589,\n",
      "         -4.4747, -4.2940, -4.4286, -4.4930, -4.6423, -5.0159, -4.7044, -4.2115,\n",
      "         -4.7835, -4.2482, -5.0328, -4.5089, -4.6382, -4.6745, -3.9818, -4.4532,\n",
      "         -4.7530, -4.6015, -4.6118, -4.8661, -4.8788, -4.3257, -4.9394, -4.8446,\n",
      "         -4.6623, -4.4643, -4.4477, -4.5775, -4.3256, -4.5137, -4.3812, -4.7543,\n",
      "         -4.7668, -4.1852, -4.6997, -4.4105, -4.7355, -4.6495, -4.4961, -4.7294,\n",
      "         -4.4522]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : and\n",
      "target index is: [44] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7000, -4.4895, -4.5629, -4.6307, -4.1971, -4.7419, -4.5237, -4.4051,\n",
      "         -4.7112, -4.8006, -4.4676, -4.4678, -4.8425, -4.8459, -4.5077, -4.5104,\n",
      "         -4.6193, -4.9072, -4.6370, -4.5599, -4.3575, -4.3110, -4.4934, -4.4677,\n",
      "         -4.5329, -4.7060, -4.3676, -4.4420, -4.6262, -4.5536, -4.6438, -4.8363,\n",
      "         -4.8067, -4.7482, -4.4013, -4.4942, -4.7793, -4.9172, -4.6099, -4.5381,\n",
      "         -4.7882, -4.6805, -4.8256, -4.5521, -4.5619, -4.6094, -4.3789, -4.5844,\n",
      "         -4.2842, -4.5383, -4.6028, -4.5744, -4.6107, -4.3773, -4.9042, -4.4778,\n",
      "         -4.7496, -4.6552, -4.6189, -4.6765, -4.8133, -4.7409, -4.7975, -4.1861,\n",
      "         -4.9229, -4.4372, -4.8714, -4.3876, -4.6478, -4.8399, -4.3043, -4.7982,\n",
      "         -4.6130, -4.6296, -4.4017, -4.7407, -4.5914, -4.4734, -4.7912, -4.4221,\n",
      "         -4.4597, -4.3493, -4.6663, -4.6552, -4.6029, -4.3400, -4.6003, -4.8077,\n",
      "         -4.8699, -4.1421, -4.8037, -4.7546, -4.3175, -4.3522, -4.4350, -4.4108,\n",
      "         -4.5668]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thriftless\n",
      "target index is: [43] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3840, -4.4359, -4.5475, -4.7397, -4.1027, -4.5566, -4.6702, -4.4787,\n",
      "         -4.7350, -4.5209, -4.9460, -4.3895, -4.7771, -4.6204, -4.6364, -4.9123,\n",
      "         -4.8725, -4.5503, -4.8862, -4.1942, -4.6882, -4.8091, -4.6397, -4.5991,\n",
      "         -4.8457, -4.7501, -4.5495, -4.4701, -4.1718, -4.7318, -4.6631, -4.5099,\n",
      "         -4.7358, -4.5694, -4.6310, -5.0366, -4.6334, -4.9056, -4.5320, -4.4743,\n",
      "         -4.5500, -4.5843, -4.7268, -4.1939, -4.4717, -4.2841, -4.4803, -4.1500,\n",
      "         -4.5518, -4.7013, -4.8439, -4.9349, -4.6315, -4.6453, -4.9219, -4.7498,\n",
      "         -4.4024, -4.4570, -4.5300, -4.6900, -4.5677, -4.7077, -4.5772, -4.3864,\n",
      "         -4.6651, -4.8219, -4.8918, -4.4051, -4.4674, -4.7272, -4.2056, -4.6750,\n",
      "         -4.7760, -5.0799, -4.5805, -4.5717, -4.4662, -4.4857, -4.5195, -4.3728,\n",
      "         -4.7303, -4.3037, -4.5184, -4.7843, -5.0446, -4.2966, -4.4905, -4.5242,\n",
      "         -5.2543, -4.4475, -4.7350, -4.4511, -4.5182, -4.5418, -4.1667, -4.2761,\n",
      "         -4.6051]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : praise.\n",
      "target index is: [94] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-3.9370, -5.0482, -4.7093, -5.1277, -3.7662, -4.7166, -4.8438, -4.3974,\n",
      "         -4.6760, -5.0048, -4.6519, -4.2879, -4.5280, -4.5620, -4.8137, -4.5646,\n",
      "         -4.8849, -5.0682, -4.7021, -4.5291, -4.7785, -4.0589, -5.1697, -4.9642,\n",
      "         -4.4080, -4.8570, -4.4848, -4.1056, -3.9053, -4.8649, -4.5766, -4.8030,\n",
      "         -4.8668, -4.7950, -4.4423, -5.2890, -4.6890, -4.6393, -4.9853, -4.9305,\n",
      "         -4.6618, -4.3354, -4.9193, -4.5736, -4.7089, -4.4148, -4.8605, -4.6514,\n",
      "         -4.7215, -4.8381, -4.3139, -4.7995, -4.4574, -4.6333, -4.8677, -4.5208,\n",
      "         -3.9334, -4.4005, -4.5132, -4.6975, -4.4047, -4.4229, -4.3288, -4.3134,\n",
      "         -4.5697, -4.6464, -5.0459, -4.9883, -4.8749, -4.8307, -4.1849, -4.2820,\n",
      "         -4.8676, -5.0946, -4.5674, -4.5290, -4.7617, -4.0431, -4.4910, -4.4414,\n",
      "         -4.5673, -4.1978, -5.2018, -5.0443, -4.1061, -4.6352, -4.2929, -4.7727,\n",
      "         -5.2071, -4.9448, -5.0383, -4.2647, -4.7337, -4.3664, -4.5348, -4.4248,\n",
      "         -4.4751]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : How\n",
      "target index is: [12] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1868, -4.6903, -4.4941, -5.0409, -4.0182, -4.9941, -4.6385, -4.3651,\n",
      "         -5.1418, -4.9512, -5.0349, -5.0845, -4.7492, -4.5196, -5.3311, -5.0881,\n",
      "         -4.8464, -4.4131, -4.7815, -4.7224, -4.6310, -4.8585, -4.8317, -5.0151,\n",
      "         -4.4132, -5.1119, -4.5774, -4.1857, -4.2698, -4.5925, -4.3067, -3.9748,\n",
      "         -4.6417, -4.7269, -4.4437, -5.1854, -4.5495, -4.5061, -4.5220, -4.5237,\n",
      "         -4.3534, -4.8615, -4.8067, -4.1900, -4.6096, -3.9964, -4.4952, -4.1509,\n",
      "         -5.0345, -4.5390, -4.3895, -4.7785, -4.6790, -4.7537, -4.5258, -4.7994,\n",
      "         -4.4099, -4.4405, -4.2782, -4.6690, -4.6647, -4.2991, -4.2619, -4.2044,\n",
      "         -4.5269, -4.9002, -4.6569, -4.3469, -4.3443, -4.4379, -4.5519, -4.3271,\n",
      "         -5.2966, -5.3218, -4.9354, -4.7739, -4.5529, -4.0949, -4.4532, -4.5738,\n",
      "         -4.6234, -4.9632, -4.6909, -5.1523, -4.9920, -4.1179, -4.1587, -4.8257,\n",
      "         -5.5491, -4.4356, -4.4649, -4.1407, -4.8263, -4.8483, -4.3888, -4.7831,\n",
      "         -4.5573]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : much\n",
      "target index is: [68] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4568, -4.9974, -4.6336, -4.4452, -3.4945, -4.4804, -4.7515, -4.2686,\n",
      "         -4.9911, -4.5389, -4.4863, -4.4711, -4.8457, -4.7823, -4.9880, -4.7918,\n",
      "         -4.8013, -4.8716, -4.1095, -4.8581, -4.7492, -4.1068, -5.0254, -4.8159,\n",
      "         -4.5096, -5.1067, -4.5084, -4.3661, -4.5886, -4.6025, -4.2256, -4.9765,\n",
      "         -4.6792, -4.5237, -4.4416, -5.3163, -4.4586, -5.0673, -4.6823, -4.9776,\n",
      "         -4.8617, -4.5803, -4.9436, -4.6322, -4.8440, -4.4008, -4.6577, -5.1243,\n",
      "         -4.9785, -4.5970, -4.9144, -4.4170, -5.0505, -4.1362, -4.6004, -3.9931,\n",
      "         -4.2376, -3.9781, -4.2365, -4.1753, -4.5395, -4.8095, -4.5590, -3.8516,\n",
      "         -4.6361, -4.3831, -4.6687, -4.5145, -5.1149, -4.7354, -4.4525, -4.3059,\n",
      "         -5.4833, -5.0485, -4.5870, -5.0566, -4.9114, -4.1605, -4.4992, -5.1454,\n",
      "         -4.8614, -4.1290, -4.9627, -4.8678, -4.3424, -4.5773, -4.5800, -4.8553,\n",
      "         -5.3013, -4.4925, -4.8795, -4.1283, -4.6661, -4.6219, -4.3226, -5.1590,\n",
      "         -4.3870]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : more\n",
      "target index is: [4] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3264, -4.8121, -4.7129, -4.3946, -4.1541, -4.6105, -4.8650, -4.4361,\n",
      "         -4.8800, -4.4805, -4.8706, -4.3075, -4.7298, -4.3824, -4.8328, -4.7845,\n",
      "         -4.5955, -4.7819, -4.6920, -4.6505, -4.4485, -4.4667, -4.6734, -4.6253,\n",
      "         -4.5692, -4.8127, -4.5861, -4.4509, -4.3926, -4.5668, -4.7591, -4.6835,\n",
      "         -4.8764, -4.5704, -4.9161, -5.0044, -4.8977, -4.6865, -4.7514, -4.6456,\n",
      "         -4.6091, -4.5485, -4.5907, -4.5064, -4.0769, -4.3138, -4.5261, -4.7093,\n",
      "         -4.7036, -4.5339, -4.9226, -4.3067, -4.7660, -4.3576, -4.8068, -4.4049,\n",
      "         -4.4734, -4.2137, -4.4743, -4.6749, -4.6062, -4.6072, -4.5977, -3.8878,\n",
      "         -4.5011, -4.6196, -4.8448, -4.6023, -4.6440, -4.6048, -4.0323, -4.5745,\n",
      "         -4.6951, -4.4666, -4.5008, -4.8312, -4.6831, -4.4905, -4.6755, -4.8109,\n",
      "         -4.4959, -4.2562, -4.6670, -4.7762, -4.5363, -4.5662, -4.7662, -4.7335,\n",
      "         -5.2255, -4.4904, -4.7158, -4.6830, -4.6360, -4.5525, -4.1015, -4.9320,\n",
      "         -4.5219]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : praise\n",
      "target index is: [45] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4313, -4.4983, -4.7129, -5.1978, -4.0318, -4.5930, -4.4861, -4.2687,\n",
      "         -5.2216, -4.6033, -4.8333, -4.3325, -4.7739, -4.5479, -5.0978, -4.8201,\n",
      "         -4.6634, -4.4915, -4.7829, -4.2166, -4.7026, -4.6963, -4.9326, -4.7406,\n",
      "         -4.9055, -4.9145, -4.5191, -4.2491, -4.3015, -4.6256, -4.2884, -4.4346,\n",
      "         -4.8602, -4.8594, -4.4733, -5.1782, -4.3313, -5.0236, -4.5214, -4.5987,\n",
      "         -4.4859, -4.5865, -4.7203, -4.1793, -4.6406, -4.1237, -4.7523, -4.4037,\n",
      "         -4.8123, -5.1234, -4.2448, -5.0899, -4.4368, -4.7594, -4.5842, -4.6434,\n",
      "         -4.3650, -4.4694, -4.4411, -4.5185, -4.5441, -4.3088, -4.6100, -4.3974,\n",
      "         -4.3175, -4.6216, -5.1364, -4.5760, -4.5576, -4.3273, -4.6924, -4.6465,\n",
      "         -5.2135, -5.2670, -4.6814, -4.9061, -4.5332, -4.0975, -4.3115, -4.4455,\n",
      "         -4.8647, -4.6403, -4.7272, -5.0141, -4.9850, -4.2415, -4.2091, -4.2954,\n",
      "         -5.1130, -4.6916, -4.5714, -4.0414, -5.0479, -4.5162, -4.6515, -4.3764,\n",
      "         -4.3808]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : deserv'd\n",
      "target index is: [66] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4275, -4.7114, -4.5527, -4.3403, -4.0552, -4.7316, -4.6194, -4.3499,\n",
      "         -4.8539, -4.8330, -4.4545, -4.7315, -4.7860, -4.7447, -4.8946, -4.8182,\n",
      "         -4.8315, -4.8455, -4.4899, -4.9171, -4.4276, -4.4641, -4.7878, -4.6437,\n",
      "         -4.2629, -5.0968, -4.6869, -4.5028, -4.3259, -4.6508, -4.2211, -4.7092,\n",
      "         -4.8101, -4.7641, -4.5590, -5.2282, -4.5084, -4.6695, -4.5438, -4.6104,\n",
      "         -4.7957, -4.6044, -4.8432, -4.5411, -4.8069, -4.2746, -4.7447, -4.5648,\n",
      "         -4.7821, -4.4682, -4.8352, -4.3110, -5.1387, -4.4396, -4.5747, -4.4750,\n",
      "         -4.0652, -4.1361, -4.2627, -4.4298, -4.6453, -4.4799, -4.5962, -4.2243,\n",
      "         -4.6355, -4.4426, -4.6348, -4.2845, -4.5419, -4.3411, -4.5337, -4.4792,\n",
      "         -5.2566, -4.9327, -4.8661, -4.9601, -4.9610, -3.9852, -4.7226, -4.8852,\n",
      "         -4.5984, -4.4845, -4.8810, -4.8622, -4.6591, -4.2938, -4.1877, -4.6432,\n",
      "         -5.1971, -4.3143, -4.4507, -4.5076, -4.7503, -4.7062, -4.2642, -4.8327,\n",
      "         -4.3981]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3098, -4.2338, -4.9213, -4.6745, -4.2365, -4.7590, -4.8724, -4.2118,\n",
      "         -5.0406, -4.7832, -5.3271, -4.5105, -4.4120, -4.6660, -4.6023, -4.7646,\n",
      "         -4.4938, -4.5406, -4.3787, -4.4418, -4.6377, -4.2586, -4.7329, -4.7187,\n",
      "         -4.3515, -5.0136, -4.3165, -4.4661, -4.5603, -4.6429, -4.7499, -4.7966,\n",
      "         -5.2255, -4.6995, -4.6282, -5.0674, -4.7123, -4.7888, -5.0174, -4.8422,\n",
      "         -4.8640, -4.7113, -4.7986, -4.5925, -4.7535, -4.0153, -4.8449, -4.9125,\n",
      "         -4.8468, -4.4983, -4.8387, -4.3314, -4.5407, -4.2001, -4.4826, -4.7637,\n",
      "         -4.3073, -4.1942, -4.5735, -4.5889, -4.7533, -4.6825, -4.1217, -4.4011,\n",
      "         -4.4505, -4.7168, -4.8824, -4.2238, -4.8255, -4.7741, -4.3251, -4.5107,\n",
      "         -4.7860, -4.8327, -4.7140, -4.6408, -4.3403, -4.3202, -4.3707, -4.7379,\n",
      "         -4.0493, -4.6579, -4.7763, -5.0882, -4.6374, -4.4176, -4.7275, -4.8960,\n",
      "         -4.7725, -4.4153, -4.5913, -4.7531, -4.9571, -4.3034, -3.8469, -4.9404,\n",
      "         -4.1572]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty's\n",
      "target index is: [80] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2950, -4.4853, -4.7433, -4.5349, -4.2057, -4.9323, -4.5523, -4.3118,\n",
      "         -4.4013, -5.1307, -4.9732, -4.1911, -4.6533, -4.7324, -4.6125, -4.7499,\n",
      "         -4.8906, -5.1563, -4.5320, -4.4051, -4.9392, -4.7490, -4.5994, -4.4889,\n",
      "         -4.2092, -4.6547, -4.6551, -4.4401, -3.8514, -4.5731, -4.8043, -4.5920,\n",
      "         -4.7162, -4.5854, -4.6473, -5.1449, -4.8549, -4.6178, -4.6625, -4.5187,\n",
      "         -4.6861, -4.2413, -4.9915, -4.0583, -4.5049, -4.0907, -4.4472, -4.4859,\n",
      "         -4.5214, -4.8973, -4.7714, -4.4600, -4.7515, -4.3566, -4.6190, -4.4097,\n",
      "         -4.3098, -4.2942, -4.7317, -5.0364, -4.8332, -4.1900, -4.4803, -4.1014,\n",
      "         -5.0405, -4.8034, -5.0770, -4.6774, -4.8141, -4.6218, -4.3037, -4.7459,\n",
      "         -4.5135, -4.8538, -4.7954, -4.9098, -5.1645, -4.1666, -4.5344, -4.4658,\n",
      "         -4.7681, -4.3236, -5.2053, -4.7764, -4.8720, -4.1093, -4.6135, -5.0076,\n",
      "         -5.0384, -4.5858, -5.2113, -4.4824, -4.5790, -4.5004, -4.2714, -4.3224,\n",
      "         -4.5442]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : use,\n",
      "target index is: [11] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1590, -4.6051, -5.0033, -5.2838, -3.7510, -5.0893, -4.6948, -4.6472,\n",
      "         -4.7023, -4.5958, -4.9203, -4.7810, -5.2754, -4.8025, -4.6657, -4.8465,\n",
      "         -5.0169, -4.4854, -4.7457, -4.3501, -4.8295, -4.1432, -5.1981, -4.6627,\n",
      "         -4.3411, -4.8804, -4.2341, -4.2045, -4.0681, -5.0298, -4.7226, -4.5862,\n",
      "         -4.7996, -4.6677, -4.9627, -5.1889, -5.0891, -4.7618, -5.1039, -4.7130,\n",
      "         -4.6845, -5.3257, -4.9084, -4.6143, -4.7147, -4.4363, -4.8003, -4.3460,\n",
      "         -4.4352, -4.8531, -3.9591, -5.5013, -4.2880, -4.5172, -4.8676, -4.3318,\n",
      "         -4.5164, -4.3810, -4.3246, -4.2274, -4.6609, -4.4020, -4.3577, -3.6506,\n",
      "         -4.5666, -4.8464, -4.9069, -4.8992, -4.3669, -4.4926, -4.2275, -4.6110,\n",
      "         -5.0992, -4.5979, -4.7013, -4.8296, -4.0874, -4.6475, -4.6392, -4.4900,\n",
      "         -4.5810, -4.0352, -5.4885, -5.0768, -4.5929, -4.6086, -4.6417, -5.0018,\n",
      "         -4.7757, -4.3513, -4.3000, -4.4294, -4.6253, -4.0639, -4.2805, -4.6133,\n",
      "         -4.6128]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : If\n",
      "target index is: [61] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7242, -4.3117, -4.8985, -4.9672, -4.4647, -4.7782, -4.7683, -4.2871,\n",
      "         -4.6212, -4.7802, -4.8112, -4.1630, -4.7381, -4.4747, -4.8537, -4.8398,\n",
      "         -4.3963, -4.6290, -4.9087, -4.4720, -4.5058, -4.9105, -4.8233, -4.5916,\n",
      "         -4.5625, -4.8294, -4.5155, -4.2735, -4.3267, -4.4715, -4.4068, -4.7789,\n",
      "         -5.2073, -4.7147, -4.9560, -5.3579, -4.4073, -4.9251, -4.4678, -4.4801,\n",
      "         -4.2761, -4.8392, -4.2656, -4.4685, -4.2070, -4.3647, -4.5201, -4.7902,\n",
      "         -4.5605, -4.8117, -4.3055, -4.3817, -4.6047, -4.3701, -4.5322, -4.5145,\n",
      "         -4.6007, -4.3683, -4.8455, -4.6160, -4.6135, -4.2942, -4.4622, -3.7378,\n",
      "         -4.4112, -4.4120, -4.7440, -4.6497, -4.3137, -3.9921, -4.5013, -4.5563,\n",
      "         -4.8831, -4.8581, -5.0774, -5.0241, -4.8175, -4.0548, -4.7419, -4.7871,\n",
      "         -5.0241, -4.5653, -4.9119, -5.1372, -5.0031, -4.3238, -4.4172, -4.5699,\n",
      "         -5.0575, -4.1702, -4.6946, -4.8668, -4.9466, -4.2760, -4.6477, -4.7989,\n",
      "         -4.6343]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thou\n",
      "target index is: [22] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5476, -4.4336, -4.9600, -4.6269, -4.4088, -4.8826, -4.4571, -4.3812,\n",
      "         -4.4384, -4.7318, -4.6014, -4.4525, -4.7550, -4.8966, -4.5886, -4.5698,\n",
      "         -4.7464, -5.0898, -4.5221, -4.3884, -4.5625, -4.4484, -4.8400, -4.3441,\n",
      "         -4.2550, -4.5809, -4.4722, -4.6752, -4.5138, -4.7204, -4.8915, -4.9385,\n",
      "         -4.6868, -4.7510, -4.3600, -4.5124, -4.5406, -4.6654, -4.7120, -4.5110,\n",
      "         -5.0543, -4.1726, -4.8296, -4.7375, -4.4678, -4.3869, -4.3583, -4.5507,\n",
      "         -4.1487, -5.1423, -4.8610, -4.2748, -4.7354, -4.3700, -4.6892, -4.4418,\n",
      "         -4.5502, -4.4545, -4.5005, -4.7106, -4.7457, -4.4740, -4.3018, -4.4309,\n",
      "         -4.9306, -4.6390, -4.5573, -4.4700, -4.6029, -4.4510, -4.1843, -4.9380,\n",
      "         -4.5257, -4.7267, -4.6736, -4.8831, -4.5199, -4.3874, -4.7078, -4.4186,\n",
      "         -4.6214, -4.5799, -4.8555, -4.4609, -4.5346, -4.5876, -4.7050, -4.7163,\n",
      "         -4.7877, -4.3062, -4.9941, -4.4089, -4.5589, -4.5265, -4.6562, -4.5169,\n",
      "         -4.4780]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : couldst\n",
      "target index is: [47] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4819, -4.3518, -4.4922, -4.7847, -4.2186, -4.8052, -4.7809, -4.3894,\n",
      "         -4.6114, -4.7763, -4.6242, -4.5137, -4.6166, -4.8580, -4.6926, -4.3035,\n",
      "         -4.5641, -4.5341, -4.4531, -4.5798, -4.5222, -4.3192, -4.7086, -4.7744,\n",
      "         -4.2606, -4.5805, -4.4469, -4.6148, -4.2963, -4.6820, -4.5540, -4.8154,\n",
      "         -4.8142, -4.5044, -4.6417, -4.8259, -4.5853, -4.7975, -4.7554, -4.8418,\n",
      "         -4.5939, -4.7384, -4.7751, -4.6815, -4.6098, -4.5713, -4.6511, -4.7756,\n",
      "         -4.5909, -4.6089, -4.4949, -4.6412, -4.6077, -4.5127, -4.7452, -4.6509,\n",
      "         -4.4482, -4.4876, -4.4298, -4.4907, -4.7911, -4.6055, -4.4265, -4.1637,\n",
      "         -4.7498, -4.4727, -4.7955, -4.7111, -4.5008, -4.6005, -4.3736, -4.4065,\n",
      "         -4.7602, -4.8150, -4.7182, -4.7070, -4.3563, -4.3904, -4.7646, -4.6495,\n",
      "         -4.4709, -4.4099, -4.7897, -4.8148, -4.4997, -4.6180, -4.3781, -4.6744,\n",
      "         -4.6148, -4.3274, -4.5338, -4.7574, -4.6478, -4.2739, -4.4328, -4.5939,\n",
      "         -4.5836]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : answer\n",
      "target index is: [53] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3935, -4.7429, -4.7335, -4.7853, -4.2204, -4.5556, -4.6853, -4.2974,\n",
      "         -4.7959, -4.7856, -4.7290, -4.4218, -4.5286, -4.7051, -4.8239, -4.6803,\n",
      "         -4.2604, -4.6321, -4.3733, -4.6888, -4.5774, -4.3874, -4.6176, -4.5217,\n",
      "         -4.2816, -5.0269, -4.3319, -4.7962, -4.5693, -4.5081, -4.5473, -4.7433,\n",
      "         -4.7992, -4.7375, -4.3921, -4.8888, -4.5711, -4.3499, -4.7879, -4.7811,\n",
      "         -4.7896, -4.6391, -4.8009, -4.6539, -4.3820, -4.3270, -4.5400, -4.7159,\n",
      "         -4.7572, -4.3425, -4.7824, -4.4486, -4.8155, -4.3793, -4.5873, -4.5396,\n",
      "         -4.6135, -4.4216, -4.4211, -4.4464, -4.6131, -4.5739, -4.4518, -4.0041,\n",
      "         -4.5520, -4.6142, -4.8077, -4.6191, -4.6386, -4.5718, -4.4127, -4.6022,\n",
      "         -4.8015, -4.6617, -4.8331, -4.7586, -4.3952, -4.3110, -4.5572, -4.9148,\n",
      "         -4.3625, -4.6177, -4.6958, -4.8403, -4.6378, -4.7050, -4.4959, -4.5726,\n",
      "         -5.0932, -4.3274, -4.4342, -4.6819, -4.7549, -4.5197, -4.5031, -4.8150,\n",
      "         -4.3300]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : 'This\n",
      "target index is: [9] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4241, -4.7082, -4.8459, -4.6994, -3.7077, -4.6335, -4.3818, -4.3327,\n",
      "         -4.9108, -4.8386, -4.9044, -4.5874, -4.8768, -4.7650, -4.7693, -4.8096,\n",
      "         -4.4551, -4.8633, -4.7024, -4.5411, -4.4754, -4.3564, -4.8266, -4.4008,\n",
      "         -4.5502, -4.9806, -4.4504, -4.4494, -4.5512, -4.7667, -4.5371, -4.6860,\n",
      "         -4.5889, -4.9389, -4.3090, -4.6457, -4.5471, -4.7552, -4.8446, -4.3779,\n",
      "         -4.8184, -4.2182, -4.7299, -4.3955, -4.7062, -4.1701, -4.5181, -4.5504,\n",
      "         -4.5988, -4.8395, -4.9285, -4.5002, -4.9886, -4.0240, -4.4284, -4.2607,\n",
      "         -4.6169, -4.3427, -4.6611, -4.5666, -4.5049, -4.4487, -4.6567, -4.4623,\n",
      "         -4.4734, -4.6742, -4.4508, -4.2250, -4.6752, -4.7624, -4.3915, -4.5929,\n",
      "         -4.7839, -5.0634, -4.8875, -5.0186, -4.7222, -4.4057, -4.6651, -4.7858,\n",
      "         -4.7437, -4.4804, -4.7028, -4.7965, -4.6426, -4.2037, -4.4060, -4.8379,\n",
      "         -4.9364, -4.3966, -4.6908, -4.4835, -4.6035, -4.6767, -4.5276, -4.6998,\n",
      "         -4.3250]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : fair\n",
      "target index is: [21] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3868, -4.4439, -4.8824, -4.5921, -4.0938, -4.5990, -4.8297, -4.2949,\n",
      "         -4.6792, -4.4109, -4.8306, -4.4822, -4.6153, -4.6624, -4.7609, -4.5901,\n",
      "         -4.6329, -4.4783, -4.6073, -4.3684, -4.5659, -4.2614, -4.9011, -4.8992,\n",
      "         -4.4467, -4.7755, -4.4527, -4.3931, -4.3049, -4.6361, -4.6115, -4.7018,\n",
      "         -4.9801, -4.8019, -4.4860, -4.6617, -4.7815, -4.7899, -5.1398, -4.8320,\n",
      "         -4.7573, -4.5531, -4.4590, -4.6953, -4.4215, -4.2541, -4.5947, -4.8199,\n",
      "         -4.5572, -4.8674, -4.7158, -4.3067, -4.7048, -4.3912, -4.7055, -4.6941,\n",
      "         -4.2694, -4.3690, -4.5124, -4.5834, -4.6698, -4.5435, -4.5786, -4.4649,\n",
      "         -4.4572, -4.7198, -4.6833, -4.5492, -4.8046, -4.6389, -4.3560, -4.6123,\n",
      "         -4.6023, -4.8739, -4.5905, -4.6449, -4.5053, -4.5117, -4.6388, -4.7482,\n",
      "         -4.3553, -4.3327, -4.5292, -4.7128, -4.5782, -4.2648, -4.7776, -4.7476,\n",
      "         -4.7245, -4.3824, -4.8505, -4.8066, -4.7615, -4.1992, -4.3768, -4.6671,\n",
      "         -4.4047]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : child\n",
      "target index is: [5] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3785, -4.4371, -4.9834, -4.6452, -4.1161, -4.7672, -4.5956, -4.6835,\n",
      "         -4.7119, -4.4854, -4.9859, -4.5515, -4.8854, -4.7608, -4.7725, -4.8691,\n",
      "         -4.5777, -4.6779, -4.7954, -4.4768, -4.5502, -4.3680, -4.8929, -4.6317,\n",
      "         -4.7231, -5.2331, -4.5670, -4.4782, -4.1541, -4.7133, -4.4875, -4.7927,\n",
      "         -4.6966, -4.7058, -4.5559, -4.8034, -4.4607, -4.6601, -4.7077, -4.5197,\n",
      "         -4.6484, -4.4620, -4.5079, -4.4049, -4.5652, -4.2557, -4.7186, -4.5841,\n",
      "         -4.6009, -4.9012, -4.7579, -4.6094, -5.0331, -4.3701, -4.4051, -4.2374,\n",
      "         -4.3413, -4.2085, -4.5761, -4.7480, -4.5252, -4.4063, -4.7717, -4.4278,\n",
      "         -4.4412, -4.5729, -4.7656, -4.3111, -4.4552, -4.3999, -4.4130, -4.5472,\n",
      "         -4.8041, -4.9787, -5.0057, -5.2107, -4.8244, -4.2661, -4.6233, -4.7776,\n",
      "         -4.6174, -4.3793, -4.6596, -4.9915, -4.7164, -4.1552, -4.3923, -4.3016,\n",
      "         -4.8674, -4.4368, -4.4401, -4.3793, -4.6427, -4.5316, -4.6239, -4.5696,\n",
      "         -4.1773]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : of\n",
      "target index is: [57] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6117, -4.0625, -4.5665, -4.7167, -4.0998, -4.8202, -4.8267, -4.5337,\n",
      "         -4.7533, -4.8588, -5.0983, -4.4949, -4.5780, -4.5435, -4.6626, -4.5808,\n",
      "         -4.7587, -4.5582, -4.6700, -4.4045, -4.5033, -4.1976, -4.8034, -4.4437,\n",
      "         -4.2587, -4.6013, -4.4784, -4.4585, -4.2382, -4.7492, -4.7077, -4.9755,\n",
      "         -5.0717, -4.5591, -4.7094, -4.7214, -4.8551, -4.8773, -4.8417, -4.7485,\n",
      "         -4.6993, -4.4299, -4.5955, -4.5648, -4.5253, -4.2869, -4.8397, -4.9215,\n",
      "         -4.5132, -4.7546, -4.4902, -4.4691, -4.6065, -4.3036, -4.7753, -4.7248,\n",
      "         -4.3968, -4.4581, -4.4893, -4.5665, -4.8638, -4.8146, -4.4094, -4.2657,\n",
      "         -4.6235, -4.7261, -5.0476, -4.4459, -4.7775, -4.7049, -4.5238, -4.5265,\n",
      "         -4.6351, -4.9348, -4.6074, -4.7202, -4.5382, -4.3905, -4.7141, -4.8009,\n",
      "         -4.1437, -4.3734, -4.6188, -4.6560, -4.4574, -4.3483, -4.5868, -4.8256,\n",
      "         -4.5076, -4.2775, -4.8563, -4.8478, -4.6263, -4.2138, -4.1832, -4.7769,\n",
      "         -4.3354]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : mine\n",
      "target index is: [86] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1068, -4.3433, -4.6092, -5.0160, -4.1290, -4.6348, -4.8121, -4.4920,\n",
      "         -4.6949, -4.7824, -5.0230, -4.3072, -4.9204, -4.5395, -4.5910, -4.7819,\n",
      "         -4.6676, -4.8591, -4.5693, -4.1901, -4.9326, -4.7173, -4.5877, -4.1250,\n",
      "         -4.5174, -4.4814, -4.6755, -4.4656, -4.1994, -4.6216, -4.5857, -4.9984,\n",
      "         -4.7695, -4.5018, -4.6430, -4.6879, -4.6470, -4.7464, -4.8113, -4.7249,\n",
      "         -4.8854, -4.4668, -4.7859, -4.5305, -4.7916, -4.1678, -4.8660, -4.6170,\n",
      "         -4.5580, -4.5972, -4.6573, -4.8682, -4.6234, -4.3504, -4.8087, -4.6658,\n",
      "         -4.3277, -4.4369, -4.6799, -4.5606, -4.5955, -4.6094, -4.4220, -4.3549,\n",
      "         -4.7524, -4.6236, -5.1707, -4.8073, -4.6379, -4.7781, -4.2749, -4.5558,\n",
      "         -4.5849, -4.9182, -4.6025, -4.5990, -4.5985, -4.2261, -4.6196, -4.4832,\n",
      "         -4.6467, -4.2991, -4.7152, -4.8028, -4.6668, -4.4610, -4.4162, -4.4175,\n",
      "         -4.8959, -4.2491, -4.5280, -4.6085, -4.5171, -4.5184, -4.3191, -4.5952,\n",
      "         -4.3915]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Shall\n",
      "target index is: [81] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2594, -4.3773, -4.5792, -5.0839, -4.0433, -4.7199, -4.6853, -4.5492,\n",
      "         -4.7213, -4.9468, -4.7649, -4.2966, -4.6650, -4.7735, -4.7200, -4.6112,\n",
      "         -4.3291, -4.7068, -4.5002, -4.6301, -4.5877, -4.5138, -4.7097, -4.4114,\n",
      "         -4.3932, -4.5367, -4.3656, -4.4591, -4.4092, -4.8509, -4.1573, -5.0085,\n",
      "         -4.5628, -4.6324, -4.5659, -4.9852, -4.4544, -4.6430, -4.8638, -4.9622,\n",
      "         -4.6452, -4.7683, -4.7648, -4.6173, -4.6267, -4.1860, -4.5106, -4.7035,\n",
      "         -4.7642, -4.6522, -4.5613, -4.6001, -4.6850, -4.4347, -4.5726, -4.9840,\n",
      "         -4.5950, -4.6320, -4.5301, -4.5007, -4.6862, -4.5462, -4.6320, -4.1386,\n",
      "         -4.7801, -4.7434, -4.8096, -4.5522, -4.5169, -4.3718, -4.7468, -4.6283,\n",
      "         -4.8308, -4.8285, -4.7169, -4.5373, -4.6341, -4.1799, -4.5456, -4.5144,\n",
      "         -4.5135, -4.3664, -4.7765, -5.0729, -4.5359, -4.5614, -4.1772, -4.5775,\n",
      "         -4.9138, -4.3884, -4.5377, -4.7691, -4.7870, -4.3801, -4.1356, -4.6911,\n",
      "         -4.4586]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : sum\n",
      "target index is: [70] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3113, -4.3855, -4.6860, -4.8253, -4.1799, -4.8744, -4.5489, -4.3693,\n",
      "         -4.6511, -4.7705, -4.7062, -4.3204, -4.5661, -4.9641, -4.8089, -4.6825,\n",
      "         -4.5220, -5.1656, -4.7180, -4.6395, -4.6008, -4.3099, -4.7241, -4.5846,\n",
      "         -4.3045, -4.9709, -4.3047, -4.4811, -4.4639, -4.6291, -4.5713, -4.8876,\n",
      "         -4.8688, -4.9288, -4.3197, -4.4735, -4.7172, -4.4594, -4.6859, -4.5901,\n",
      "         -5.0552, -4.3991, -4.5951, -4.5175, -4.4134, -4.2223, -4.4141, -4.6230,\n",
      "         -4.3348, -4.7896, -4.6027, -4.1279, -4.9663, -4.4318, -4.6964, -4.5483,\n",
      "         -4.6247, -4.4526, -4.5876, -4.9410, -4.8125, -4.5832, -4.6754, -4.3135,\n",
      "         -4.9356, -4.5978, -4.8452, -4.3881, -4.5798, -4.6107, -4.3294, -4.7949,\n",
      "         -4.5488, -4.8258, -4.6605, -4.7983, -4.5693, -4.1685, -4.6816, -4.8326,\n",
      "         -4.3318, -4.6585, -4.5519, -4.6481, -4.2620, -4.5956, -4.4917, -4.6875,\n",
      "         -5.0206, -4.4340, -4.6713, -4.5500, -4.5535, -4.6917, -4.4844, -4.4227,\n",
      "         -4.4081]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : my\n",
      "target index is: [90] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4073, -4.3743, -4.6027, -5.1554, -4.2192, -5.1491, -4.4885, -4.4741,\n",
      "         -4.7345, -4.6244, -5.1309, -4.5751, -4.7471, -4.7768, -4.3718, -4.6223,\n",
      "         -4.6239, -4.6848, -4.9420, -4.3542, -4.8187, -4.2869, -4.7910, -4.5999,\n",
      "         -4.3956, -5.0054, -4.2217, -4.4708, -4.1312, -4.5963, -4.6740, -4.8666,\n",
      "         -4.7838, -4.9002, -4.7383, -4.5675, -4.6761, -4.4188, -4.8698, -4.5217,\n",
      "         -4.9360, -4.7768, -4.8780, -4.3824, -4.8491, -4.3244, -4.8140, -4.6476,\n",
      "         -4.5357, -5.1713, -4.1076, -5.0920, -4.4529, -4.5524, -4.7184, -4.4618,\n",
      "         -4.5317, -4.4501, -4.3160, -5.0233, -4.6073, -4.3791, -4.4832, -4.2660,\n",
      "         -4.6172, -4.3757, -5.0749, -4.5919, -4.4025, -4.5512, -4.5943, -4.5971,\n",
      "         -4.7444, -4.7419, -4.7328, -5.0172, -4.3911, -4.3262, -4.4276, -4.6510,\n",
      "         -4.4331, -4.4929, -4.8343, -4.4473, -4.6545, -4.1806, -4.5183, -4.8476,\n",
      "         -4.4865, -4.5999, -4.3890, -4.5586, -4.7101, -4.3264, -4.6353, -4.3086,\n",
      "         -4.1688]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : count,\n",
      "target index is: [55] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5947, -4.2431, -4.7271, -4.9497, -4.4853, -4.9476, -4.6561, -4.4421,\n",
      "         -4.6159, -4.8780, -4.9780, -4.6515, -4.6974, -4.7532, -4.7320, -4.6554,\n",
      "         -4.5706, -4.5958, -4.8573, -4.6515, -4.6173, -4.6760, -4.9323, -4.3870,\n",
      "         -4.4073, -4.7031, -4.5065, -4.2148, -4.2903, -4.6185, -4.2211, -4.8753,\n",
      "         -5.0215, -4.7838, -4.8437, -4.6428, -4.5624, -4.8123, -4.7219, -4.5031,\n",
      "         -4.6194, -4.6485, -4.3803, -4.5687, -4.5021, -4.2268, -4.9855, -4.6652,\n",
      "         -4.6458, -4.9480, -4.2702, -4.6547, -4.7795, -4.3216, -4.6213, -4.4419,\n",
      "         -4.2118, -4.2514, -4.6520, -4.4588, -4.6002, -4.5376, -4.3109, -4.1515,\n",
      "         -4.5987, -4.5062, -4.9682, -4.4071, -4.2193, -4.1786, -4.4547, -4.5275,\n",
      "         -4.8043, -4.8188, -5.0035, -5.1153, -4.3586, -4.2289, -4.7647, -4.9249,\n",
      "         -4.6940, -4.7293, -4.8507, -4.8572, -4.7575, -4.3075, -4.1937, -4.5553,\n",
      "         -4.7771, -4.3308, -4.3516, -4.9304, -4.7846, -4.3000, -4.5525, -4.7218,\n",
      "         -4.3910]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : and\n",
      "target index is: [44] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6721, -4.4672, -4.7060, -4.6760, -4.1910, -4.9013, -4.4252, -4.2656,\n",
      "         -4.7489, -4.9917, -4.6520, -4.4974, -4.6440, -4.8829, -4.7295, -4.4026,\n",
      "         -4.3159, -4.8239, -4.5521, -4.6861, -4.4885, -4.2857, -4.4663, -4.5392,\n",
      "         -4.1986, -4.8317, -4.4591, -4.5134, -4.7568, -4.4467, -4.6148, -4.8492,\n",
      "         -4.8144, -4.8382, -4.3582, -4.2736, -4.9177, -4.7961, -4.8302, -4.6612,\n",
      "         -4.9714, -4.6221, -4.8692, -4.5686, -4.4518, -4.5259, -4.3194, -4.8018,\n",
      "         -4.2468, -4.5734, -4.6488, -4.3258, -4.8160, -4.1880, -4.5653, -4.5943,\n",
      "         -4.5306, -4.6123, -4.6833, -4.7849, -4.9790, -4.6976, -4.3826, -4.1399,\n",
      "         -4.9428, -4.4681, -4.7133, -4.1390, -4.6666, -4.8321, -4.5455, -4.8685,\n",
      "         -4.3721, -4.6488, -4.7729, -4.8515, -4.3111, -4.4754, -4.7820, -4.4722,\n",
      "         -4.3223, -4.5299, -4.7765, -4.8043, -4.6413, -4.5043, -4.6969, -4.7925,\n",
      "         -4.9645, -4.1327, -4.8766, -4.9385, -4.3376, -4.4257, -4.4815, -4.4512,\n",
      "         -4.5581]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : make\n",
      "target index is: [14] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4641, -4.2524, -4.7338, -5.1293, -4.3369, -4.6383, -4.5958, -4.4097,\n",
      "         -4.6764, -4.6834, -4.7814, -4.5520, -4.8354, -4.6556, -4.4132, -4.5908,\n",
      "         -4.6141, -4.7371, -4.7453, -4.1763, -4.8648, -4.6752, -4.9147, -4.4088,\n",
      "         -4.7141, -4.6843, -4.4192, -4.3546, -4.2932, -4.6634, -4.5715, -4.7936,\n",
      "         -4.8856, -4.7625, -4.4442, -4.4382, -4.5238, -4.9738, -4.7962, -4.6118,\n",
      "         -4.7063, -4.6383, -4.6329, -4.4538, -4.7613, -4.3430, -5.0643, -4.5211,\n",
      "         -4.4098, -4.9830, -4.2237, -4.8734, -4.2564, -4.5570, -4.9896, -4.2644,\n",
      "         -4.5180, -4.3733, -4.8222, -4.4650, -4.5832, -4.6200, -4.3914, -4.4321,\n",
      "         -4.6262, -4.4560, -5.2296, -4.8781, -4.4445, -4.5552, -4.2156, -4.6686,\n",
      "         -4.5707, -4.8556, -4.4965, -4.7834, -4.4872, -4.2704, -4.7458, -4.7180,\n",
      "         -4.6709, -4.6156, -4.6952, -4.7553, -4.5961, -4.4579, -4.4651, -4.5589,\n",
      "         -4.5092, -4.1660, -4.5674, -4.4001, -4.7820, -4.4442, -4.6274, -4.5228,\n",
      "         -4.3686]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : my\n",
      "target index is: [90] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3498, -4.2374, -4.8769, -5.0413, -4.1983, -5.0049, -4.3519, -4.4022,\n",
      "         -4.8244, -4.6813, -4.6752, -4.3994, -4.6262, -4.9861, -4.7741, -4.4766,\n",
      "         -4.3836, -4.8106, -4.7669, -4.6228, -4.8035, -4.1435, -4.7451, -4.9116,\n",
      "         -4.2510, -5.0311, -4.1713, -4.5458, -4.1624, -4.6970, -4.3638, -4.8931,\n",
      "         -4.5949, -4.7115, -4.7368, -4.6596, -4.8495, -4.3521, -5.0213, -4.8357,\n",
      "         -4.7036, -4.9015, -4.6427, -4.5653, -4.5323, -4.2944, -4.5838, -4.8802,\n",
      "         -4.6355, -4.7838, -4.5235, -4.5972, -4.6849, -4.6242, -4.5154, -4.7243,\n",
      "         -4.7552, -4.5165, -4.5033, -4.8702, -4.8077, -4.1660, -4.5004, -4.0183,\n",
      "         -4.7191, -4.8689, -4.8219, -4.5253, -4.4799, -4.0546, -4.7019, -4.7325,\n",
      "         -4.6106, -4.5788, -4.7800, -4.9346, -4.4579, -4.4684, -4.3854, -4.5675,\n",
      "         -4.4754, -4.4793, -5.0020, -4.7463, -4.6281, -4.6356, -4.6543, -4.5717,\n",
      "         -4.6172, -4.2743, -4.5109, -4.7600, -4.8114, -4.2278, -4.3410, -4.4659,\n",
      "         -4.3059]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : old\n",
      "target index is: [84] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.0878, -4.3386, -4.4093, -5.0308, -4.2571, -5.2511, -4.4077, -4.4172,\n",
      "         -4.5126, -4.9263, -4.9709, -4.7970, -4.2719, -4.8052, -4.9271, -4.4204,\n",
      "         -4.5167, -4.5918, -4.8709, -4.7515, -4.7230, -4.2627, -5.0898, -4.7417,\n",
      "         -4.0373, -4.8600, -4.3365, -4.5115, -3.9347, -4.7177, -4.6011, -4.6855,\n",
      "         -4.6431, -4.9767, -4.8658, -4.5968, -4.7810, -4.3336, -4.7288, -4.5497,\n",
      "         -4.8488, -4.4940, -4.7836, -4.2751, -4.5243, -4.4014, -4.8308, -4.5604,\n",
      "         -4.6187, -4.9107, -4.0715, -4.7236, -4.9297, -4.6715, -4.7173, -4.5730,\n",
      "         -4.2482, -4.5564, -4.4076, -4.8314, -4.9500, -4.3759, -4.3852, -4.2812,\n",
      "         -4.7241, -4.7424, -4.8895, -4.5761, -4.4939, -4.3874, -4.5707, -4.4193,\n",
      "         -4.7629, -4.8852, -4.7447, -4.9592, -4.3310, -4.3535, -4.7368, -4.8863,\n",
      "         -4.1272, -4.5626, -4.8242, -4.7433, -4.5020, -4.5048, -4.6095, -4.7750,\n",
      "         -4.8628, -4.5509, -4.5604, -4.6127, -4.6103, -4.4364, -4.8308, -4.3718,\n",
      "         -4.4151]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : excuse,'\n",
      "target index is: [64] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4894, -4.4308, -4.5221, -4.7932, -4.1660, -4.9141, -4.6303, -4.3554,\n",
      "         -4.7565, -4.8077, -4.7452, -4.6524, -4.4943, -4.5068, -4.8303, -4.6212,\n",
      "         -4.7266, -4.2840, -4.6414, -4.6067, -4.4105, -4.6849, -4.5072, -4.7637,\n",
      "         -4.2688, -4.7613, -4.5896, -4.5584, -4.3710, -4.2457, -4.6432, -4.6820,\n",
      "         -4.8903, -4.7402, -4.6683, -5.2222, -4.8004, -4.6680, -4.6039, -4.5253,\n",
      "         -4.3710, -4.7946, -4.8044, -4.6318, -4.5765, -4.5942, -4.5469, -4.4552,\n",
      "         -4.5013, -4.4597, -4.3191, -4.5118, -4.4972, -4.4887, -4.5723, -4.4264,\n",
      "         -4.6141, -4.4548, -4.3809, -4.6129, -4.9440, -4.5305, -4.5319, -3.7523,\n",
      "         -4.6850, -4.4218, -4.6739, -4.3531, -4.5159, -4.6323, -4.6049, -4.5805,\n",
      "         -4.9441, -4.8625, -4.8468, -4.6454, -4.6317, -4.4988, -4.5182, -4.5716,\n",
      "         -4.7489, -4.6975, -4.9432, -4.9303, -4.6695, -4.2195, -4.4176, -4.9559,\n",
      "         -4.8919, -4.1644, -4.4984, -4.7041, -4.5906, -4.5009, -4.6628, -4.5532,\n",
      "         -4.8615]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Proving\n",
      "target index is: [25] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4812, -4.6011, -4.9628, -4.7271, -4.4747, -4.6892, -4.6484, -4.4630,\n",
      "         -4.6046, -4.5656, -4.9579, -4.4047, -4.4477, -4.5248, -4.5411, -4.8627,\n",
      "         -4.5842, -4.8634, -4.3881, -4.6030, -4.5004, -4.4723, -4.7682, -4.4953,\n",
      "         -4.4293, -4.7091, -4.2163, -4.5810, -4.4545, -4.4736, -5.0728, -4.8187,\n",
      "         -4.8224, -4.8126, -4.9757, -5.0132, -4.4598, -4.7209, -4.6184, -4.3617,\n",
      "         -4.7715, -4.5817, -4.6251, -4.6852, -4.3446, -4.3780, -4.7336, -4.8163,\n",
      "         -4.4526, -4.9720, -4.2992, -4.5288, -4.5276, -4.1390, -4.5476, -4.2640,\n",
      "         -4.6930, -4.3736, -4.5592, -4.3710, -4.4837, -4.3519, -4.3793, -4.0255,\n",
      "         -4.4249, -4.5946, -4.7123, -4.6992, -4.9444, -4.1868, -4.0324, -4.5501,\n",
      "         -5.0984, -4.3581, -4.8110, -4.9796, -4.3651, -4.4485, -4.5048, -4.6168,\n",
      "         -4.7102, -4.6171, -4.9211, -4.8903, -4.8810, -4.5661, -5.1108, -4.9928,\n",
      "         -4.8339, -4.4115, -4.6264, -4.6839, -4.7296, -4.2164, -4.6127, -4.8401,\n",
      "         -4.3609]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : his\n",
      "target index is: [49] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6958, -4.3160, -4.9191, -5.1054, -4.2592, -4.5936, -4.2398, -4.3703,\n",
      "         -4.9812, -4.4519, -4.7198, -4.3045, -4.7305, -4.6897, -4.9008, -4.5444,\n",
      "         -4.4986, -4.4726, -4.6885, -4.3428, -4.4709, -4.3858, -4.5411, -4.6461,\n",
      "         -4.6401, -4.7821, -4.4155, -4.5585, -4.7577, -4.5558, -4.7064, -4.5805,\n",
      "         -4.7663, -4.7720, -4.5073, -4.6850, -4.5004, -4.8284, -4.7308, -4.3401,\n",
      "         -4.4161, -4.5058, -4.4741, -4.3099, -4.4837, -4.6750, -4.4605, -4.3891,\n",
      "         -4.3551, -5.1873, -4.4506, -4.7626, -4.3847, -4.3494, -4.6096, -4.5466,\n",
      "         -4.9047, -4.7190, -4.2505, -4.7030, -4.9177, -4.4943, -4.5170, -4.3492,\n",
      "         -4.4603, -4.6689, -4.5429, -4.3733, -4.6711, -4.2993, -4.7628, -4.8820,\n",
      "         -4.7403, -4.8116, -4.6892, -4.9371, -4.4005, -4.5147, -4.3994, -4.4940,\n",
      "         -4.8150, -4.6703, -4.8414, -4.5719, -4.9968, -4.3531, -4.7216, -4.5962,\n",
      "         -4.8362, -4.2758, -4.6333, -4.2964, -4.9283, -4.5383, -4.6946, -4.6064,\n",
      "         -4.5208]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty\n",
      "target index is: [0] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5799, -4.4749, -4.8506, -4.6848, -4.3988, -4.7229, -4.7282, -4.0864,\n",
      "         -4.7835, -4.4642, -4.6238, -4.3280, -4.4065, -4.7550, -4.7695, -4.7148,\n",
      "         -4.6913, -4.4946, -4.3218, -4.4654, -4.5912, -4.4522, -4.7486, -4.9207,\n",
      "         -4.2769, -5.2792, -4.2958, -4.7508, -4.0278, -4.4552, -4.6233, -4.6157,\n",
      "         -4.9864, -4.6898, -4.5312, -5.0280, -4.4618, -4.5982, -4.6448, -4.7976,\n",
      "         -4.7242, -4.6416, -4.7324, -4.7247, -4.6013, -4.4392, -4.7705, -5.0159,\n",
      "         -4.8591, -4.8064, -4.6640, -4.4562, -4.8466, -4.5821, -4.6617, -4.5728,\n",
      "         -4.2509, -4.1241, -4.4229, -4.3812, -4.6651, -4.5482, -4.4923, -4.3881,\n",
      "         -4.4248, -4.6909, -4.6119, -4.7215, -4.6582, -4.3422, -4.4637, -4.4779,\n",
      "         -5.1480, -4.6161, -4.9198, -4.8983, -4.4308, -4.2371, -4.3640, -4.9010,\n",
      "         -4.4427, -4.4226, -4.6878, -4.8117, -4.7823, -4.5064, -4.6943, -4.2759,\n",
      "         -4.7614, -4.5721, -4.6063, -4.5733, -4.8569, -4.3021, -4.6242, -4.6197,\n",
      "         -4.2266]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : by\n",
      "target index is: [62] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.0304, -4.6707, -4.6833, -4.6709, -3.8826, -4.7165, -4.4487, -4.1328,\n",
      "         -4.8917, -4.9210, -4.7138, -4.4880, -4.4209, -4.6903, -4.7668, -4.7917,\n",
      "         -4.4126, -4.6789, -4.5594, -4.7971, -4.7298, -4.4174, -4.9218, -4.7222,\n",
      "         -4.1546, -4.7861, -4.4937, -4.3857, -4.5127, -4.7238, -4.5511, -4.4543,\n",
      "         -4.5553, -4.9450, -4.5797, -5.1305, -4.7986, -4.2400, -4.7092, -4.3810,\n",
      "         -4.6874, -4.4555, -4.8313, -4.3374, -4.5110, -3.9068, -4.5079, -4.7522,\n",
      "         -4.8850, -4.5152, -4.7455, -4.3757, -4.8902, -4.2768, -4.4004, -4.4664,\n",
      "         -4.3096, -4.4020, -4.6775, -4.7857, -4.8370, -4.2366, -4.3491, -4.3556,\n",
      "         -4.5525, -4.8225, -4.5793, -4.2055, -4.9793, -4.6413, -4.7154, -4.7460,\n",
      "         -4.5107, -5.0244, -4.7371, -4.8052, -4.6619, -4.3131, -4.6158, -5.0202,\n",
      "         -4.3558, -4.4980, -5.0160, -5.0106, -4.6757, -4.3071, -4.7551, -5.0993,\n",
      "         -5.1471, -4.6031, -4.8901, -4.7124, -4.5105, -4.5033, -4.6137, -4.8024,\n",
      "         -4.5149]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : succession\n",
      "target index is: [7] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6494, -4.4001, -4.6642, -4.6797, -4.1901, -4.6708, -4.7138, -4.4263,\n",
      "         -4.7037, -4.5614, -4.7144, -4.2482, -4.7765, -4.5068, -4.9641, -4.6667,\n",
      "         -4.6372, -4.4948, -4.8444, -4.5090, -4.3425, -4.5754, -4.8229, -4.8733,\n",
      "         -4.5300, -4.7098, -4.4889, -4.2613, -4.1863, -4.4471, -4.4705, -4.7640,\n",
      "         -4.9410, -4.5401, -4.8842, -5.2012, -4.5444, -4.9386, -4.5352, -4.5171,\n",
      "         -4.3118, -4.6831, -4.4365, -4.7157, -4.2949, -4.5348, -4.3256, -4.8176,\n",
      "         -4.4129, -4.8570, -4.5233, -4.5277, -4.5604, -4.3995, -4.6688, -4.5164,\n",
      "         -4.5804, -4.3612, -4.5986, -4.7210, -4.5016, -4.4200, -4.4142, -3.8910,\n",
      "         -4.3883, -4.5328, -4.6004, -4.5373, -4.4138, -4.1154, -4.3749, -4.4219,\n",
      "         -4.9841, -4.8179, -4.8029, -4.9205, -4.7742, -4.3348, -4.6385, -4.8791,\n",
      "         -4.9782, -4.5282, -4.7091, -4.8879, -4.7364, -4.4161, -4.4495, -4.5915,\n",
      "         -4.9870, -4.4725, -4.7617, -4.6489, -4.7968, -4.6979, -4.5826, -4.9920,\n",
      "         -4.7032]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thine!\n",
      "target index is: [40] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6331, -4.3392, -4.6897, -4.4676, -4.2180, -4.7524, -4.6043, -4.2824,\n",
      "         -4.7125, -4.6393, -4.6321, -4.4015, -4.7129, -4.7378, -4.4814, -4.8216,\n",
      "         -4.8859, -5.0452, -4.6295, -4.5832, -4.5419, -4.5660, -4.6527, -4.5300,\n",
      "         -4.5255, -4.5996, -4.2078, -4.3927, -4.4001, -4.6635, -4.8636, -4.8506,\n",
      "         -4.9162, -4.5537, -4.5108, -4.8732, -4.7709, -4.7663, -4.5747, -4.4306,\n",
      "         -4.7240, -4.6236, -4.6258, -4.5776, -4.6254, -4.4719, -4.5714, -4.5481,\n",
      "         -4.3228, -4.7272, -4.3828, -4.4525, -4.5112, -4.5148, -4.9752, -4.1483,\n",
      "         -4.7644, -4.3058, -4.6947, -4.7610, -4.5195, -4.5023, -4.6195, -4.1825,\n",
      "         -4.8698, -4.5330, -4.7230, -4.6129, -4.7846, -4.6514, -4.1797, -4.7878,\n",
      "         -4.7955, -4.5420, -4.3336, -4.9292, -4.7003, -4.4258, -4.5164, -4.4454,\n",
      "         -4.6966, -4.3489, -4.9324, -4.8294, -4.7285, -4.4308, -4.8755, -4.8006,\n",
      "         -4.7164, -4.3910, -4.7817, -4.3369, -4.5698, -4.2895, -4.5413, -4.2635,\n",
      "         -4.6701]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : This\n",
      "target index is: [1] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4751, -4.3449, -4.7531, -4.7733, -4.1978, -4.5646, -4.7702, -4.4629,\n",
      "         -4.5402, -4.5554, -4.7878, -4.6894, -4.8392, -4.6878, -4.4382, -4.7205,\n",
      "         -4.6067, -4.6153, -4.8306, -4.3959, -4.6869, -4.6180, -5.0782, -4.5012,\n",
      "         -4.5571, -4.6640, -4.5121, -4.4123, -4.2665, -4.7186, -4.5706, -4.7688,\n",
      "         -4.7783, -4.6904, -4.6199, -4.8616, -4.4467, -4.8590, -4.6889, -4.6408,\n",
      "         -4.6122, -4.4077, -4.6458, -4.6375, -4.5957, -4.2389, -4.7433, -4.5642,\n",
      "         -4.3090, -4.7468, -4.4660, -4.7166, -4.6602, -4.5459, -4.7871, -4.4433,\n",
      "         -4.3041, -4.2214, -4.7179, -4.3133, -4.6066, -4.7065, -4.3708, -4.2883,\n",
      "         -4.5567, -4.7618, -4.9158, -4.7583, -4.4718, -4.3613, -4.1684, -4.3319,\n",
      "         -4.9541, -4.8895, -4.6476, -4.8032, -4.4477, -4.3673, -4.7377, -4.6728,\n",
      "         -4.5625, -4.4316, -4.5973, -4.8191, -4.7533, -4.5516, -4.5445, -4.4961,\n",
      "         -4.7481, -4.2869, -4.5795, -4.5539, -4.8868, -4.4224, -4.4827, -4.7518,\n",
      "         -4.4934]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : were\n",
      "target index is: [93] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2687, -4.4743, -4.7708, -4.8918, -3.8262, -4.5519, -4.4154, -4.2808,\n",
      "         -4.6438, -4.8776, -4.6164, -4.4660, -4.6431, -4.9281, -4.7627, -4.5253,\n",
      "         -4.4890, -4.9812, -4.5865, -4.4265, -4.8600, -4.1533, -4.7425, -4.9498,\n",
      "         -4.3577, -4.6835, -4.4057, -4.3504, -4.2705, -4.8612, -4.3944, -4.9207,\n",
      "         -4.6570, -4.6066, -4.2993, -4.8318, -4.9166, -4.5580, -5.1155, -4.7811,\n",
      "         -4.6758, -4.6846, -4.7733, -4.5876, -4.8038, -4.2395, -4.2538, -4.7228,\n",
      "         -4.4718, -4.7544, -4.8347, -4.3339, -4.7721, -4.6170, -4.6088, -4.4387,\n",
      "         -4.3843, -4.4007, -4.4244, -4.7565, -4.6287, -4.4858, -4.8416, -4.0572,\n",
      "         -4.7411, -4.6870, -4.7429, -4.5902, -4.7797, -4.5158, -4.5816, -4.6086,\n",
      "         -4.3455, -4.8118, -4.6672, -4.5196, -4.7513, -4.7068, -4.6237, -4.4417,\n",
      "         -4.6933, -4.5165, -5.0485, -4.7887, -4.2324, -4.6250, -4.4485, -4.7597,\n",
      "         -4.7391, -4.4410, -4.7698, -4.5556, -4.8027, -4.4629, -4.4979, -4.5075,\n",
      "         -4.5330]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : to\n",
      "target index is: [72] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5680, -4.5476, -4.7190, -4.4740, -4.4797, -4.7688, -4.9849, -4.2559,\n",
      "         -4.7156, -4.6982, -4.6287, -4.6333, -4.5557, -4.7256, -4.8003, -4.5568,\n",
      "         -4.7639, -4.2285, -4.6163, -4.5922, -4.3696, -4.4923, -5.0802, -4.8405,\n",
      "         -4.3711, -4.9907, -4.5285, -4.2791, -4.1832, -4.7275, -4.6322, -4.2691,\n",
      "         -5.0996, -4.7733, -4.5728, -5.1680, -4.5258, -4.7107, -4.6204, -4.7373,\n",
      "         -4.4852, -4.5314, -4.5935, -4.5850, -4.5118, -4.3194, -4.7064, -4.7320,\n",
      "         -4.7620, -4.6749, -4.3754, -4.5816, -4.6791, -4.7949, -4.8360, -4.6741,\n",
      "         -3.9734, -4.1388, -4.4948, -4.3324, -4.5444, -4.4629, -4.2899, -4.1469,\n",
      "         -4.4474, -4.5348, -4.8677, -4.9417, -4.4742, -4.4258, -4.1628, -4.1772,\n",
      "         -5.1917, -5.0040, -4.8873, -4.9067, -4.2974, -4.2580, -4.6819, -4.6808,\n",
      "         -4.4884, -4.5653, -4.5642, -4.9842, -4.7745, -4.5728, -4.5352, -4.5207,\n",
      "         -5.0569, -4.5084, -4.6461, -4.6680, -5.1037, -4.2636, -4.5238, -4.8677,\n",
      "         -4.6014]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : be\n",
      "target index is: [24] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2019, -4.8365, -4.8057, -5.0686, -4.0243, -4.8097, -4.6200, -4.2255,\n",
      "         -4.8905, -5.0950, -4.9469, -4.3112, -4.6695, -4.9106, -4.9888, -4.5641,\n",
      "         -3.9703, -5.0231, -4.5883, -5.0343, -4.3696, -4.2095, -4.6496, -4.4756,\n",
      "         -4.2766, -5.0085, -4.0548, -4.6736, -4.5786, -4.7315, -4.1942, -5.3471,\n",
      "         -4.8488, -5.0965, -4.3281, -4.7083, -4.8233, -4.4518, -5.0524, -4.9696,\n",
      "         -5.0662, -4.4189, -4.6627, -4.4803, -4.2481, -4.0976, -4.4766, -4.6833,\n",
      "         -4.5864, -4.4660, -4.4645, -4.1055, -5.2470, -4.3693, -4.7215, -4.6772,\n",
      "         -4.8257, -4.4659, -4.5526, -4.8996, -4.9609, -4.5741, -4.6895, -3.9233,\n",
      "         -4.6374, -4.7415, -4.9779, -4.4464, -4.4015, -4.5179, -4.3331, -4.7393,\n",
      "         -4.6877, -4.8324, -4.6853, -4.8637, -4.7598, -4.0504, -4.6962, -5.0193,\n",
      "         -4.1323, -4.8168, -4.7043, -4.6666, -4.3310, -4.8385, -4.3060, -4.9211,\n",
      "         -4.9956, -4.4556, -4.3528, -4.6756, -4.7688, -4.5923, -4.3281, -4.6485,\n",
      "         -4.3095]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : new\n",
      "target index is: [27] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5540, -4.4787, -4.3568, -4.7184, -4.1712, -4.7257, -4.6593, -4.3843,\n",
      "         -4.6077, -4.6465, -4.8583, -4.5215, -4.6253, -4.7479, -4.5887, -4.6368,\n",
      "         -4.5341, -4.5585, -4.4729, -4.6109, -4.7756, -4.6121, -4.5597, -4.4792,\n",
      "         -4.3888, -4.6498, -4.4724, -4.6449, -4.4614, -4.4100, -4.5123, -4.6460,\n",
      "         -4.8421, -4.7075, -4.5617, -4.7055, -4.6410, -4.6801, -4.5751, -4.7014,\n",
      "         -4.6579, -4.5383, -4.9807, -4.6327, -4.7138, -4.6004, -4.6580, -4.5542,\n",
      "         -4.5392, -4.3627, -4.3173, -4.5369, -4.6785, -4.3319, -4.7255, -4.4774,\n",
      "         -4.5262, -4.6096, -4.5266, -4.6525, -4.7272, -4.6116, -4.5557, -4.0924,\n",
      "         -4.9819, -4.4556, -4.8735, -4.4327, -4.7009, -4.9929, -4.5751, -4.5937,\n",
      "         -4.7179, -4.7559, -4.6517, -4.6924, -4.4869, -4.4364, -4.5174, -4.8237,\n",
      "         -4.4430, -4.3438, -4.6065, -4.7742, -4.6875, -4.3197, -4.5698, -4.7658,\n",
      "         -4.7738, -4.1797, -4.6082, -4.8184, -4.3897, -4.5505, -4.3756, -4.4147,\n",
      "         -4.6899]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : made\n",
      "target index is: [16] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3613, -4.6268, -4.7554, -4.8490, -4.2397, -4.6753, -4.4260, -4.5240,\n",
      "         -4.6822, -4.4017, -4.8812, -4.4629, -4.6668, -4.5593, -4.6932, -4.8112,\n",
      "         -4.4522, -4.7041, -4.5976, -4.5990, -4.3456, -4.3815, -4.7323, -4.5604,\n",
      "         -4.6472, -5.1455, -4.1409, -4.6874, -4.6194, -4.7372, -4.5345, -4.8808,\n",
      "         -4.5571, -4.9263, -4.5134, -4.9657, -4.5317, -4.3629, -4.6371, -4.4034,\n",
      "         -4.6376, -4.5321, -4.5444, -4.4129, -4.4730, -4.4573, -4.6986, -4.5264,\n",
      "         -4.5844, -4.8547, -4.3720, -4.7947, -4.8276, -4.4832, -4.6107, -4.4243,\n",
      "         -4.7828, -4.5574, -4.4042, -4.5971, -4.5595, -4.5037, -4.5828, -4.2311,\n",
      "         -4.3311, -4.8706, -4.8076, -4.3629, -4.6088, -4.3899, -4.5650, -4.6648,\n",
      "         -4.8173, -4.6981, -4.7641, -4.8752, -4.5055, -4.3743, -4.3373, -4.5999,\n",
      "         -4.4623, -4.5862, -4.7421, -4.7509, -4.7821, -4.4083, -4.7348, -4.5201,\n",
      "         -4.9505, -4.6472, -4.3481, -4.5949, -4.6645, -4.5290, -4.5252, -4.4683,\n",
      "         -4.3280]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : when\n",
      "target index is: [85] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4603, -4.5608, -4.8439, -4.7614, -4.2400, -4.6457, -4.2862, -4.3752,\n",
      "         -4.8729, -4.5425, -4.9349, -4.4653, -4.7229, -4.6055, -4.4798, -4.5285,\n",
      "         -4.2563, -4.6613, -4.7329, -4.4532, -4.4669, -4.3481, -4.7839, -4.7431,\n",
      "         -4.6259, -5.0808, -4.5177, -4.2592, -4.7730, -4.7657, -4.6976, -4.5825,\n",
      "         -4.7216, -5.0304, -4.4688, -4.7575, -4.3661, -4.5768, -4.8656, -4.3691,\n",
      "         -4.5920, -4.6870, -4.6660, -4.3723, -4.5935, -4.1586, -4.7514, -4.8825,\n",
      "         -4.7250, -4.9492, -4.5820, -4.6637, -4.5269, -3.8194, -4.3899, -4.5787,\n",
      "         -4.5877, -4.5665, -4.5784, -4.6111, -4.5957, -4.4928, -4.4163, -4.5705,\n",
      "         -4.4520, -4.4404, -4.8908, -4.1730, -4.7594, -4.5149, -4.6066, -4.8794,\n",
      "         -4.8473, -4.7819, -4.8859, -5.0043, -4.4891, -4.4152, -4.4570, -4.8660,\n",
      "         -4.4992, -4.4411, -4.6377, -4.7343, -4.9154, -4.0727, -4.9585, -4.9276,\n",
      "         -4.8181, -4.3921, -4.4428, -4.6625, -4.7390, -4.4872, -4.4796, -4.7161,\n",
      "         -4.2696]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thou\n",
      "target index is: [22] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6382, -4.5867, -4.9560, -4.6604, -4.1914, -4.7657, -4.4914, -4.7036,\n",
      "         -4.6408, -4.5373, -4.6903, -4.2421, -4.8006, -4.6934, -4.7290, -4.2728,\n",
      "         -4.7208, -4.6509, -4.8128, -4.4957, -4.7681, -4.1736, -4.8283, -4.5985,\n",
      "         -4.2223, -4.7052, -4.7601, -4.3700, -4.2982, -4.3567, -4.7115, -4.5713,\n",
      "         -4.7490, -4.8277, -4.5926, -4.4980, -4.6089, -4.8218, -4.9545, -4.3435,\n",
      "         -4.8941, -4.1934, -4.6476, -4.5464, -4.3954, -4.4941, -4.5679, -4.8108,\n",
      "         -4.3716, -5.1489, -4.7207, -4.6868, -4.6442, -4.2351, -4.6087, -4.4195,\n",
      "         -4.2535, -4.4886, -4.6313, -4.4129, -4.6664, -4.5433, -4.3338, -4.5578,\n",
      "         -4.7355, -4.4713, -4.5840, -4.4403, -4.7761, -4.2554, -4.2956, -4.6335,\n",
      "         -4.8878, -4.8925, -4.7966, -4.9323, -4.5097, -4.6132, -4.7253, -4.6592,\n",
      "         -4.6312, -4.4017, -4.5489, -4.3818, -4.7095, -4.1773, -4.7254, -4.8705,\n",
      "         -4.8223, -4.4316, -4.7991, -4.6604, -4.5757, -4.5905, -4.6290, -4.6230,\n",
      "         -4.6824]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : art\n",
      "target index is: [15] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3611, -4.4654, -4.7588, -4.9232, -4.2462, -4.7787, -4.5851, -4.3832,\n",
      "         -4.6499, -4.8084, -4.6754, -4.4427, -4.4420, -4.7672, -4.7560, -4.2548,\n",
      "         -4.4937, -4.4857, -4.2713, -4.5715, -4.5996, -4.2435, -4.8392, -4.8795,\n",
      "         -4.2038, -4.7152, -4.4214, -4.5389, -4.1855, -4.5819, -4.5339, -4.8442,\n",
      "         -4.8720, -4.6091, -4.5735, -4.9306, -4.6306, -4.6137, -4.9353, -4.9253,\n",
      "         -4.8271, -4.8517, -4.7562, -4.7928, -4.6213, -4.4856, -4.6482, -4.9624,\n",
      "         -4.5994, -4.6639, -4.4446, -4.7737, -4.5041, -4.5191, -4.7616, -4.6676,\n",
      "         -4.3666, -4.4302, -4.4775, -4.4217, -4.6936, -4.3893, -4.3879, -4.1344,\n",
      "         -4.6283, -4.4595, -4.8278, -4.8258, -4.6292, -4.4530, -4.5097, -4.5198,\n",
      "         -4.9013, -4.7361, -4.6183, -4.7990, -4.3887, -4.4184, -4.6819, -4.6546,\n",
      "         -4.4374, -4.4533, -4.9453, -4.8573, -4.4434, -4.6738, -4.5561, -4.6527,\n",
      "         -4.5261, -4.3692, -4.5305, -4.7107, -4.5892, -4.1700, -4.6846, -4.5220,\n",
      "         -4.4820]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : old,\n",
      "target index is: [8] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4504, -4.5467, -4.9792, -4.6926, -4.3197, -4.7135, -4.5626, -4.3360,\n",
      "         -4.7133, -4.5941, -4.7822, -4.3774, -4.5771, -4.9566, -5.0418, -4.9513,\n",
      "         -4.6920, -4.7537, -4.5735, -4.6648, -4.3293, -4.2933, -4.7864, -4.5989,\n",
      "         -4.3735, -5.1313, -4.2946, -4.7091, -4.6462, -4.5940, -4.6890, -4.7752,\n",
      "         -4.6859, -4.8698, -4.4802, -4.8578, -4.7389, -4.3860, -4.5946, -4.3412,\n",
      "         -4.6386, -4.5770, -4.6368, -4.5667, -4.2669, -4.3025, -4.4595, -4.3849,\n",
      "         -4.4793, -4.9169, -4.7726, -4.2578, -4.8925, -4.3693, -4.3345, -4.3969,\n",
      "         -4.5850, -4.2358, -4.2730, -4.7482, -4.7582, -4.3983, -4.4544, -4.1970,\n",
      "         -4.5089, -4.7497, -4.6844, -4.3977, -4.3756, -4.1709, -4.3886, -4.7286,\n",
      "         -4.6491, -4.8659, -4.9361, -4.9493, -4.4534, -4.3405, -4.7090, -4.8189,\n",
      "         -4.6219, -4.7482, -4.8684, -4.7294, -4.5874, -4.5754, -4.5941, -4.8490,\n",
      "         -5.0280, -4.3282, -4.7620, -4.6968, -4.6803, -4.2852, -4.6599, -4.7033,\n",
      "         -4.2804]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : And\n",
      "target index is: [6] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4857, -4.3583, -4.5026, -4.5619, -4.3476, -5.0159, -4.5334, -4.4553,\n",
      "         -4.6433, -4.7997, -4.8429, -4.3786, -4.5497, -4.6318, -4.6509, -4.7098,\n",
      "         -4.6620, -4.6258, -4.9597, -4.5664, -4.4818, -4.5111, -4.6094, -4.5874,\n",
      "         -4.2012, -4.7053, -4.6149, -4.4257, -4.2865, -4.5308, -4.7159, -4.7794,\n",
      "         -4.6565, -4.7176, -4.6154, -4.5411, -4.7783, -4.5907, -4.5556, -4.4074,\n",
      "         -4.8569, -4.3808, -4.7107, -4.4211, -4.4891, -4.3796, -4.4407, -4.6194,\n",
      "         -4.5304, -4.7838, -4.5335, -4.4595, -4.9157, -4.3282, -4.5905, -4.5344,\n",
      "         -4.4342, -4.5779, -4.5666, -4.8039, -4.6935, -4.4865, -4.5249, -4.3973,\n",
      "         -4.7126, -4.6608, -4.7517, -4.2621, -4.7043, -4.6145, -4.6034, -4.6813,\n",
      "         -4.5342, -4.9592, -4.7913, -4.7959, -4.5749, -4.3015, -4.7079, -4.7681,\n",
      "         -4.2868, -4.4528, -4.5925, -4.7190, -4.5450, -4.3166, -4.6047, -4.7663,\n",
      "         -4.8668, -4.5033, -4.7980, -4.7687, -4.2882, -4.5376, -4.5378, -4.5327,\n",
      "         -4.5163]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : see\n",
      "target index is: [67] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4352, -4.5460, -4.7730, -4.9927, -4.4345, -4.7293, -4.5637, -4.4415,\n",
      "         -4.7901, -4.6157, -5.0411, -4.8672, -4.6627, -4.7250, -4.6859, -4.7258,\n",
      "         -4.5343, -4.5467, -4.7137, -4.3856, -4.7679, -4.7223, -4.9712, -4.7288,\n",
      "         -4.6427, -4.9180, -4.5669, -4.3210, -4.3565, -4.7639, -4.5174, -4.7139,\n",
      "         -5.0350, -4.9147, -4.2826, -4.5846, -4.2388, -4.5577, -4.7339, -4.7500,\n",
      "         -4.7643, -4.6155, -4.5698, -4.6128, -4.5019, -4.0955, -4.7955, -4.7134,\n",
      "         -4.7948, -4.8502, -4.2516, -4.5892, -4.6142, -4.3589, -4.7303, -4.7630,\n",
      "         -4.4100, -4.3228, -4.6371, -4.4464, -4.7585, -4.5792, -4.4492, -4.5978,\n",
      "         -4.5562, -4.4626, -5.0921, -4.4354, -4.5401, -4.6842, -4.2490, -4.1423,\n",
      "         -5.0301, -4.9430, -4.7818, -4.8742, -4.3581, -4.1003, -4.4592, -4.7522,\n",
      "         -4.2895, -4.7149, -4.3491, -4.9464, -4.7508, -4.3301, -4.4760, -4.5200,\n",
      "         -4.7275, -4.3075, -4.2642, -4.5391, -4.9444, -4.3801, -4.4355, -4.5598,\n",
      "         -4.1498]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6280, -4.4048, -4.9660, -4.5683, -4.1891, -4.6564, -4.6550, -4.2308,\n",
      "         -5.1307, -4.3856, -4.7459, -4.1913, -4.3130, -4.6100, -4.7714, -4.8493,\n",
      "         -4.3699, -4.5339, -4.3707, -4.5564, -4.6438, -4.3897, -4.3835, -4.7314,\n",
      "         -4.3832, -5.1684, -4.2748, -4.9268, -4.5691, -4.4826, -4.6492, -4.5757,\n",
      "         -4.8315, -4.6264, -4.6049, -5.1032, -4.5877, -4.5233, -4.6129, -4.7307,\n",
      "         -4.4602, -4.7845, -4.8532, -4.6213, -4.4025, -4.1491, -4.5831, -5.0445,\n",
      "         -5.0190, -4.4698, -4.8316, -4.4215, -4.4309, -4.3115, -4.4334, -4.4947,\n",
      "         -4.6465, -4.2745, -4.3145, -4.5404, -4.7334, -4.7233, -4.4414, -4.0092,\n",
      "         -4.4409, -4.6901, -4.7005, -4.4146, -4.8218, -4.5091, -4.6524, -4.6536,\n",
      "         -4.8732, -4.5483, -4.8414, -4.8629, -4.3490, -4.5172, -4.4441, -4.9118,\n",
      "         -4.5605, -4.4567, -4.7615, -4.8121, -4.8332, -4.5742, -4.7747, -4.7276,\n",
      "         -4.9845, -4.4678, -4.6424, -4.7796, -4.8771, -4.3254, -4.2661, -4.9046,\n",
      "         -4.4322]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : blood\n",
      "target index is: [39] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5635, -4.4812, -4.8512, -4.4997, -4.3710, -4.7648, -4.3928, -4.3670,\n",
      "         -4.8340, -4.7516, -4.9773, -4.3896, -4.6995, -4.4633, -4.5193, -4.8736,\n",
      "         -4.6499, -4.8029, -4.3526, -4.4045, -4.7898, -4.8276, -4.6690, -4.4485,\n",
      "         -4.6456, -5.1378, -4.7779, -4.4939, -4.1604, -4.7212, -4.4777, -4.5365,\n",
      "         -4.7209, -4.6825, -4.6998, -5.3062, -4.3743, -4.7109, -4.4457, -4.2649,\n",
      "         -4.4812, -4.4257, -4.6934, -4.1639, -4.7949, -4.1425, -5.0122, -4.6474,\n",
      "         -4.6814, -4.8687, -4.7810, -4.7441, -4.7146, -4.2741, -4.3754, -4.5027,\n",
      "         -4.2666, -4.1227, -4.7116, -4.6793, -4.6412, -4.2151, -4.5793, -4.3394,\n",
      "         -4.5569, -4.5928, -4.7073, -4.2293, -4.6921, -4.1295, -4.4913, -4.6048,\n",
      "         -5.0351, -5.0467, -4.8874, -5.2867, -5.0773, -3.9737, -4.3765, -4.5684,\n",
      "         -5.0685, -4.6101, -5.0076, -5.0737, -5.2635, -4.0482, -4.4410, -4.4925,\n",
      "         -5.2234, -4.3603, -4.8361, -4.5722, -4.7655, -4.5020, -4.4139, -4.5184,\n",
      "         -4.3207]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : warm\n",
      "target index is: [2] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5480, -4.3849, -4.6709, -4.8154, -4.5796, -4.6405, -4.4377, -4.4635,\n",
      "         -4.7597, -5.0517, -4.9624, -4.7932, -4.7293, -4.7923, -4.6137, -4.5062,\n",
      "         -4.7014, -4.9735, -4.5392, -4.2422, -4.8452, -4.2726, -5.1446, -4.4751,\n",
      "         -4.1458, -4.7115, -4.3922, -4.2790, -4.3519, -4.7141, -4.7244, -4.7790,\n",
      "         -4.9414, -4.8352, -4.5816, -4.4290, -4.8076, -4.9397, -4.8810, -4.7114,\n",
      "         -4.8211, -4.5742, -4.6796, -4.5455, -4.7153, -4.3073, -4.8408, -4.8355,\n",
      "         -4.2367, -4.8751, -4.4594, -4.3915, -4.4199, -4.1394, -4.7018, -4.1864,\n",
      "         -4.4753, -4.1303, -4.6829, -4.6693, -4.7844, -4.7600, -4.3473, -4.3951,\n",
      "         -4.8045, -4.4563, -5.1328, -4.5313, -4.6797, -4.3435, -4.1005, -4.6819,\n",
      "         -4.3864, -4.5374, -4.5576, -4.8023, -4.4607, -4.3252, -4.6842, -4.8156,\n",
      "         -4.4584, -4.8313, -4.7638, -4.5732, -4.3433, -4.6042, -4.7881, -5.0640,\n",
      "         -4.5572, -4.1091, -4.6670, -4.5603, -4.7246, -4.7589, -4.3306, -4.6969,\n",
      "         -4.2534]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : when\n",
      "target index is: [85] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4929, -4.3346, -4.7570, -4.9864, -4.2442, -4.7515, -4.3419, -4.4202,\n",
      "         -4.7133, -4.3645, -4.6535, -4.6655, -4.8285, -4.6360, -4.4539, -4.5014,\n",
      "         -4.2982, -4.6413, -4.7979, -4.5914, -4.4963, -4.4295, -4.7230, -4.6810,\n",
      "         -4.5296, -5.0680, -4.4066, -4.3500, -4.8360, -4.6153, -4.6606, -4.5783,\n",
      "         -4.7457, -4.9422, -4.5943, -4.7026, -4.5301, -4.4067, -4.9128, -4.5319,\n",
      "         -4.5471, -4.9286, -4.6614, -4.3624, -4.4001, -4.3754, -4.6885, -4.7919,\n",
      "         -4.5401, -4.6918, -4.4340, -4.8382, -4.6852, -4.2520, -4.6299, -4.6340,\n",
      "         -4.6317, -4.7484, -4.5191, -4.4838, -4.8041, -4.4528, -4.5322, -4.1203,\n",
      "         -4.5186, -4.4609, -4.7424, -4.3126, -4.5687, -4.6269, -4.7623, -5.0624,\n",
      "         -4.9932, -4.2368, -4.7185, -4.9636, -4.4989, -4.7172, -4.6162, -4.6752,\n",
      "         -4.3264, -4.3223, -4.8729, -4.5747, -4.9249, -4.1927, -5.0902, -4.5588,\n",
      "         -4.6187, -4.2151, -4.3070, -4.7324, -4.7713, -4.2197, -4.5136, -4.5827,\n",
      "         -4.6729]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thou\n",
      "target index is: [22] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6390, -4.5882, -4.9504, -4.6610, -4.1924, -4.7661, -4.4862, -4.7041,\n",
      "         -4.6355, -4.5381, -4.6903, -4.2426, -4.8016, -4.6936, -4.7294, -4.2550,\n",
      "         -4.7211, -4.6516, -4.8137, -4.4970, -4.7688, -4.1739, -4.8207, -4.5992,\n",
      "         -4.2233, -4.7057, -4.7615, -4.3711, -4.2991, -4.3573, -4.7123, -4.5723,\n",
      "         -4.7497, -4.8283, -4.5935, -4.4983, -4.6096, -4.8226, -4.9557, -4.3395,\n",
      "         -4.8950, -4.1932, -4.6482, -4.5469, -4.3965, -4.4952, -4.5691, -4.8115,\n",
      "         -4.3724, -5.1497, -4.7217, -4.6880, -4.6452, -4.2364, -4.6103, -4.4208,\n",
      "         -4.2538, -4.4902, -4.6323, -4.4137, -4.6675, -4.5442, -4.3345, -4.5588,\n",
      "         -4.7357, -4.4713, -4.5843, -4.4355, -4.7773, -4.2563, -4.2965, -4.6344,\n",
      "         -4.8884, -4.8939, -4.7974, -4.9334, -4.5105, -4.6143, -4.7215, -4.6595,\n",
      "         -4.6320, -4.4026, -4.5498, -4.3828, -4.7105, -4.1675, -4.7263, -4.8714,\n",
      "         -4.8241, -4.4327, -4.8005, -4.6610, -4.5766, -4.5918, -4.6300, -4.6234,\n",
      "         -4.6837]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : feel'st\n",
      "target index is: [35] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5013, -4.2163, -4.7217, -4.8684, -4.1364, -4.7404, -4.7219, -4.1898,\n",
      "         -4.7867, -4.4840, -4.7029, -4.6253, -4.7584, -4.8473, -4.6876, -4.5503,\n",
      "         -4.6113, -4.3384, -4.6034, -4.4962, -4.5848, -4.4957, -4.5377, -4.8854,\n",
      "         -4.5656, -4.8061, -4.4276, -4.5243, -4.5523, -4.5216, -4.4865, -4.6577,\n",
      "         -4.8636, -4.6323, -4.3158, -4.9154, -4.5164, -4.8149, -4.7649, -4.7797,\n",
      "         -4.5860, -4.8638, -4.5794, -4.6748, -4.4337, -4.3976, -4.4764, -4.6106,\n",
      "         -4.6966, -4.5536, -4.5821, -4.6914, -4.6185, -4.6221, -4.6745, -4.6216,\n",
      "         -4.5667, -4.3725, -4.3899, -4.5109, -4.9264, -4.6127, -4.5395, -4.1805,\n",
      "         -4.5326, -4.5082, -4.5299, -4.5639, -4.5172, -4.6676, -4.6697, -4.5422,\n",
      "         -4.8635, -4.9483, -4.7323, -4.7258, -4.3445, -4.4753, -4.5101, -4.7388,\n",
      "         -4.5042, -4.4965, -4.7234, -4.9010, -4.7635, -4.4112, -4.3857, -4.5587,\n",
      "         -4.6062, -4.1143, -4.4253, -4.5521, -4.8762, -4.3902, -4.5498, -4.6433,\n",
      "         -4.5012]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : it\n",
      "target index is: [88] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5559, -4.3987, -4.7878, -4.7021, -4.1292, -4.8817, -4.6135, -4.2176,\n",
      "         -4.6325, -4.6323, -4.6693, -4.3399, -4.4819, -4.8368, -4.6849, -4.6166,\n",
      "         -4.5306, -5.0283, -4.5438, -4.6555, -4.6773, -4.3706, -5.0060, -4.6262,\n",
      "         -4.1599, -4.8186, -4.1344, -4.6250, -4.0938, -4.6901, -4.6450, -5.2824,\n",
      "         -5.0635, -4.7410, -4.8962, -5.1045, -4.4962, -4.7056, -4.7395, -4.7407,\n",
      "         -4.9503, -4.4215, -4.6309, -4.6153, -4.5040, -4.3024, -4.6745, -4.8620,\n",
      "         -4.4725, -4.7637, -4.6905, -4.1054, -4.9077, -4.3473, -4.8191, -4.4311,\n",
      "         -4.5388, -4.1380, -4.6649, -4.6943, -4.6349, -4.5881, -4.3025, -4.1402,\n",
      "         -4.7354, -4.8329, -4.7538, -4.6561, -4.5279, -4.2653, -4.1428, -4.3282,\n",
      "         -4.8744, -4.7498, -4.7065, -4.7190, -4.7987, -3.9714, -4.6928, -4.8138,\n",
      "         -4.5515, -4.5578, -4.8701, -4.8086, -4.5043, -4.7228, -4.3750, -4.6173,\n",
      "         -4.7856, -4.6314, -4.8878, -4.7530, -4.7433, -4.2974, -4.5528, -4.6499,\n",
      "         -4.2159]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : cold.\n",
      "target index is: [79] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3754, -4.1085, -4.7887, -4.8305, -4.1084, -5.0301, -4.4940, -4.4935,\n",
      "         -4.8293, -4.4805, -4.7881, -4.5558, -4.6855, -4.7631, -5.0647, -4.7225,\n",
      "         -4.6048, -4.1679, -4.8380, -4.4103, -4.7375, -4.3519, -4.6649, -4.8554,\n",
      "         -4.3579, -4.7593, -4.4583, -4.2512, -4.2349, -4.4663, -4.3656, -4.5906,\n",
      "         -4.6886, -4.7335, -4.5262, -4.5141, -4.6863, -4.7510, -4.7283, -4.6961,\n",
      "         -4.6841, -4.5262, -4.5201, -4.3871, -4.4305, -4.2934, -4.4598, -4.7274,\n",
      "         -4.7428, -5.0507, -4.5610, -4.5994, -4.6738, -4.5508, -4.3727, -4.7777,\n",
      "         -4.4296, -4.4567, -4.3183, -4.6769, -4.8667, -4.4277, -4.6013, -4.4899,\n",
      "         -4.5479, -4.9880, -4.5972, -4.2567, -4.5473, -4.4149, -4.6774, -4.6797,\n",
      "         -4.9135, -5.0329, -4.9268, -4.8290, -4.5042, -4.5808, -4.5276, -4.7413,\n",
      "         -4.2706, -4.4837, -4.6228, -4.6627, -4.8905, -4.2670, -4.7948, -4.5607,\n",
      "         -4.8013, -4.4566, -4.6071, -4.5275, -4.7513, -4.5167, -4.4349, -4.6605,\n",
      "         -4.6036]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : winters\n",
      "target index is: [3] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2778, -4.6715, -4.3851, -4.6714, -4.1960, -4.5950, -4.5181, -4.2524,\n",
      "         -4.7471, -4.9129, -4.8661, -4.7913, -4.5446, -4.2607, -4.5714, -4.3799,\n",
      "         -4.1175, -4.6811, -4.6374, -4.8280, -4.8273, -4.6391, -4.6633, -4.5917,\n",
      "         -4.3883, -4.8967, -4.4636, -4.4786, -4.3832, -4.5702, -4.2722, -5.0505,\n",
      "         -4.8995, -4.6394, -4.9350, -4.8929, -4.5742, -4.7033, -5.0260, -4.6807,\n",
      "         -4.9472, -4.3841, -4.8595, -4.3803, -5.0885, -4.3707, -5.1281, -5.1894,\n",
      "         -4.9008, -4.2506, -4.6375, -4.3889, -4.8259, -4.1483, -4.9567, -4.1503,\n",
      "         -4.2752, -4.1465, -4.8613, -4.3972, -4.2893, -4.6473, -4.4589, -4.1110,\n",
      "         -4.5628, -3.9747, -5.3828, -4.5067, -4.8555, -4.6476, -4.5850, -4.2816,\n",
      "         -4.9448, -4.8597, -4.6039, -5.1723, -4.8571, -4.1497, -4.5305, -4.8001,\n",
      "         -4.3290, -4.5710, -4.6916, -5.0599, -4.7484, -4.3801, -4.6921, -4.6466,\n",
      "         -5.1022, -4.3908, -4.3904, -4.6845, -4.6426, -4.6877, -4.4475, -4.7780,\n",
      "         -4.3804]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : shall\n",
      "target index is: [10] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5153, -4.3487, -5.1004, -4.8510, -4.2468, -4.7502, -4.3952, -4.6922,\n",
      "         -4.7593, -4.4437, -4.7291, -4.4057, -4.8075, -4.6816, -5.0442, -4.5101,\n",
      "         -4.7438, -4.5766, -4.6806, -4.4878, -4.5159, -3.9938, -4.6319, -4.5179,\n",
      "         -4.1940, -4.7818, -4.5980, -4.6054, -4.4384, -4.6092, -4.8712, -4.6725,\n",
      "         -4.6091, -4.8230, -4.6947, -4.4381, -4.9340, -4.4986, -5.0137, -4.3870,\n",
      "         -4.9320, -4.7176, -4.6859, -4.7327, -4.3913, -4.4751, -4.6326, -4.6251,\n",
      "         -4.4300, -5.0744, -4.4727, -4.7596, -4.5887, -4.3174, -4.5026, -4.5241,\n",
      "         -4.6667, -4.5319, -4.2229, -4.5703, -4.7916, -4.4060, -4.2537, -4.1429,\n",
      "         -4.4532, -4.7608, -4.6525, -4.5658, -4.6611, -4.1873, -4.3952, -4.7337,\n",
      "         -4.5418, -4.6628, -4.9240, -4.7426, -4.0653, -4.7662, -4.7555, -4.6915,\n",
      "         -4.3882, -4.5175, -4.9305, -4.6269, -4.5903, -4.4320, -4.8519, -4.9620,\n",
      "         -4.7805, -4.3126, -4.6617, -4.9173, -4.6037, -4.2303, -4.6261, -4.7828,\n",
      "         -4.3791]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : besiege\n",
      "target index is: [75] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3734, -4.5259, -4.3926, -4.7741, -4.1018, -4.7793, -4.5613, -4.2638,\n",
      "         -4.6886, -4.7101, -4.9468, -4.6754, -4.6570, -4.5551, -5.0316, -4.6842,\n",
      "         -4.5776, -4.4351, -4.8299, -4.6065, -4.5668, -4.8770, -4.5634, -4.5650,\n",
      "         -4.3828, -4.7148, -4.6752, -4.5928, -4.2831, -4.3672, -4.4917, -4.6038,\n",
      "         -4.7460, -4.7071, -4.8568, -4.7840, -4.6297, -4.6680, -4.6792, -4.4912,\n",
      "         -4.4697, -4.6817, -4.7656, -4.1576, -4.5018, -4.4803, -4.3504, -4.3987,\n",
      "         -4.5391, -4.6010, -4.5691, -4.3346, -4.7750, -4.3818, -4.7302, -4.5564,\n",
      "         -4.5313, -4.4625, -4.4652, -4.6904, -5.0609, -4.4622, -4.5974, -3.7969,\n",
      "         -4.6816, -4.4617, -4.8249, -4.6482, -4.5218, -4.7728, -4.5748, -4.5661,\n",
      "         -4.7903, -4.9339, -4.7658, -4.7356, -4.7292, -4.2388, -4.6337, -4.8793,\n",
      "         -4.6826, -4.5169, -4.6234, -4.9273, -4.7155, -4.2722, -4.3536, -4.7887,\n",
      "         -5.3065, -4.1816, -4.6916, -4.6734, -4.5038, -4.5968, -4.3263, -4.5834,\n",
      "         -4.8281]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2142, -4.5106, -4.7392, -4.9411, -4.0037, -4.6736, -4.8171, -4.3933,\n",
      "         -5.2614, -4.3325, -4.8730, -4.1522, -4.8335, -4.5182, -4.7098, -5.0174,\n",
      "         -4.9155, -4.6223, -4.5220, -4.4767, -4.4881, -4.5294, -4.7604, -4.5093,\n",
      "         -4.8774, -4.8491, -4.0960, -4.5998, -4.5715, -4.5714, -4.6278, -4.8988,\n",
      "         -4.8954, -4.5968, -4.5381, -5.1902, -4.5675, -4.9887, -4.8065, -4.6593,\n",
      "         -4.8619, -4.9623, -4.7692, -4.5720, -4.6511, -4.3240, -4.8684, -4.8209,\n",
      "         -4.7994, -4.6868, -4.3613, -5.0567, -4.3415, -4.4204, -5.0463, -4.2304,\n",
      "         -4.8104, -4.4577, -4.4547, -4.2282, -4.3039, -4.3886, -4.6483, -3.9378,\n",
      "         -4.3458, -4.6949, -5.0546, -4.6232, -4.6896, -4.7305, -4.3213, -4.7968,\n",
      "         -5.2052, -4.6709, -4.4771, -4.9345, -4.3276, -4.2805, -4.3374, -4.5447,\n",
      "         -4.5985, -4.2789, -4.9600, -4.9718, -4.6620, -4.4047, -4.4369, -4.5357,\n",
      "         -4.8306, -4.5817, -4.0579, -4.4157, -4.5973, -4.4660, -4.1507, -4.6536,\n",
      "         -4.5868]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : brow,\n",
      "target index is: [13] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4336, -4.3107, -4.6182, -4.6397, -4.2884, -4.8706, -4.6943, -4.4234,\n",
      "         -4.7195, -4.7694, -4.8471, -4.4898, -4.8124, -4.3988, -4.7573, -4.8893,\n",
      "         -4.6778, -4.7313, -4.4964, -4.4833, -4.8008, -4.9180, -4.7005, -4.3261,\n",
      "         -4.6094, -4.8159, -4.7306, -4.2676, -4.0956, -4.3714, -4.2424, -4.7445,\n",
      "         -4.8887, -4.5797, -4.9288, -5.0263, -4.5363, -4.8994, -4.3453, -4.3647,\n",
      "         -4.7231, -4.6016, -4.4744, -4.1446, -4.5705, -4.1507, -4.7386, -4.8220,\n",
      "         -4.5815, -4.8070, -4.8704, -4.4749, -4.8894, -4.1452, -4.6114, -4.4165,\n",
      "         -4.4002, -4.0545, -4.7391, -4.6263, -4.8820, -4.4373, -4.5609, -4.1371,\n",
      "         -4.7700, -4.5855, -5.0696, -4.5495, -4.5962, -4.4337, -4.3907, -4.5461,\n",
      "         -4.8402, -4.9163, -4.8172, -5.0386, -5.0607, -3.8686, -4.6860, -4.9947,\n",
      "         -4.9778, -4.5428, -4.7320, -5.0464, -5.0177, -4.3765, -4.3745, -4.5342,\n",
      "         -4.9276, -4.0070, -4.8499, -4.5931, -4.6678, -4.5686, -4.3109, -4.8432,\n",
      "         -4.3171]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : And\n",
      "target index is: [6] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4029, -4.3195, -4.6345, -4.7955, -4.1974, -4.8268, -4.7248, -4.5061,\n",
      "         -4.8403, -4.5833, -4.4726, -4.3419, -4.8852, -4.9348, -4.3721, -4.8700,\n",
      "         -4.8721, -4.9949, -4.5045, -4.4151, -4.4176, -4.3847, -4.6913, -4.6216,\n",
      "         -4.6465, -4.7037, -4.2920, -4.4227, -4.3322, -4.9498, -4.5494, -5.2297,\n",
      "         -4.7544, -4.6564, -4.4618, -4.8286, -4.6582, -4.9034, -4.7628, -4.6259,\n",
      "         -4.8181, -4.9692, -4.8024, -4.7089, -4.6947, -4.4872, -4.5273, -4.5993,\n",
      "         -4.4872, -4.9952, -4.5226, -4.6674, -4.4090, -4.7145, -5.1783, -4.5800,\n",
      "         -4.5703, -4.4671, -4.4627, -4.6010, -4.6142, -4.5504, -4.8933, -4.2177,\n",
      "         -4.9627, -4.6610, -4.9587, -4.6036, -4.6400, -4.6781, -4.0918, -4.8323,\n",
      "         -5.0606, -4.5540, -4.2639, -4.8074, -4.6879, -4.3478, -4.6718, -4.2159,\n",
      "         -4.5658, -4.0241, -4.9028, -4.6732, -4.3731, -4.4250, -4.5178, -4.5353,\n",
      "         -4.7820, -4.3154, -4.5662, -4.5320, -4.2708, -4.1048, -4.1296, -4.4062,\n",
      "         -4.5040]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : dig\n",
      "target index is: [42] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4117, -4.6277, -4.7007, -4.9373, -4.2379, -4.8260, -4.6816, -4.5291,\n",
      "         -4.5263, -4.6709, -4.8500, -4.9833, -4.7315, -4.8193, -4.5509, -4.7180,\n",
      "         -4.6765, -4.7404, -4.6996, -4.4111, -4.8453, -4.4932, -5.0547, -4.6925,\n",
      "         -4.4447, -4.9555, -4.4926, -4.4891, -4.1307, -4.7767, -4.5153, -4.8232,\n",
      "         -4.8831, -4.8118, -4.2444, -4.5063, -4.3753, -4.6714, -4.8310, -4.7163,\n",
      "         -4.8065, -4.4344, -4.7400, -4.6344, -4.6505, -4.2574, -4.8972, -4.4987,\n",
      "         -4.6503, -4.8549, -4.3713, -4.7494, -4.6242, -4.5172, -4.7257, -4.5851,\n",
      "         -4.2222, -4.2440, -4.6245, -4.4175, -4.5688, -4.6692, -4.6714, -4.6197,\n",
      "         -4.6582, -4.3763, -4.9801, -4.5676, -4.6217, -4.7844, -4.2294, -4.1852,\n",
      "         -5.0113, -4.8582, -4.7450, -4.7759, -4.6172, -4.1792, -4.6403, -4.4804,\n",
      "         -4.4101, -4.4785, -4.4858, -4.9703, -4.5006, -4.3476, -4.3058, -4.4400,\n",
      "         -4.6967, -4.2008, -4.4583, -4.4289, -4.7608, -4.4278, -4.5792, -4.4162,\n",
      "         -4.2728]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : deep\n",
      "target index is: [76] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5681, -4.9004, -4.6954, -4.6202, -4.2493, -4.8157, -4.3772, -4.1783,\n",
      "         -4.7147, -5.0045, -4.8041, -4.4364, -4.5709, -4.8803, -4.8028, -4.2975,\n",
      "         -4.2432, -4.8099, -4.4542, -4.9252, -4.4907, -4.2323, -4.5993, -4.7236,\n",
      "         -4.1434, -4.9029, -4.4531, -4.7127, -4.6681, -4.4700, -4.7286, -4.6615,\n",
      "         -4.9031, -4.9160, -4.4103, -4.6205, -4.9716, -4.5135, -5.0109, -4.7221,\n",
      "         -4.8322, -4.6653, -4.8788, -4.5431, -4.3999, -4.3375, -4.5235, -4.6228,\n",
      "         -4.4755, -4.3145, -4.5056, -4.1670, -4.7409, -4.4233, -4.5964, -4.4594,\n",
      "         -4.5279, -4.5565, -4.5080, -4.6538, -5.0327, -4.6778, -4.5445, -3.9374,\n",
      "         -4.6927, -4.4602, -4.8858, -4.4112, -4.6909, -4.5784, -4.3876, -4.7070,\n",
      "         -4.6022, -4.5118, -4.6185, -4.9209, -4.4981, -4.5817, -4.7984, -4.7191,\n",
      "         -4.1349, -4.7773, -4.6977, -4.6336, -4.3469, -4.5444, -4.6697, -5.0624,\n",
      "         -4.9440, -4.3718, -4.5030, -4.7101, -4.6870, -4.4261, -4.4697, -4.4560,\n",
      "         -4.5686]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : trenches\n",
      "target index is: [54] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4468, -4.5310, -4.9310, -5.3994, -4.0878, -4.6569, -4.4321, -4.4161,\n",
      "         -4.8202, -4.4087, -4.8953, -4.4117, -4.8004, -4.7928, -4.9652, -4.7158,\n",
      "         -4.4720, -4.6416, -4.6905, -4.6457, -4.5511, -4.2669, -4.8383, -4.5626,\n",
      "         -4.4434, -4.8821, -4.1745, -4.5646, -4.5816, -4.7066, -4.4897, -5.0503,\n",
      "         -4.9216, -4.9224, -4.5007, -4.5727, -4.3570, -4.7417, -5.0237, -4.6861,\n",
      "         -4.8540, -4.8027, -4.5782, -4.5322, -4.4181, -4.4648, -4.5276, -4.7407,\n",
      "         -4.4126, -5.1680, -4.1512, -4.7721, -4.6262, -4.3867, -4.4850, -4.6700,\n",
      "         -4.9209, -4.6219, -4.2878, -4.4724, -4.6814, -4.3834, -4.5014, -4.1305,\n",
      "         -4.5118, -4.6435, -4.7099, -4.4997, -4.4531, -4.3574, -4.6403, -4.7271,\n",
      "         -5.2041, -4.6028, -4.8518, -5.0621, -4.2630, -4.2208, -4.3085, -4.5458,\n",
      "         -4.5435, -4.5437, -4.6370, -4.5293, -4.6770, -4.4059, -4.5375, -4.6979,\n",
      "         -4.6820, -4.6468, -4.0778, -4.5656, -4.7264, -4.2730, -4.5857, -4.6871,\n",
      "         -4.4958]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : in\n",
      "target index is: [95] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7331, -4.4367, -4.5667, -4.5205, -4.1203, -4.6695, -4.6897, -4.1946,\n",
      "         -4.7448, -4.5712, -4.6517, -4.2527, -4.4531, -4.6851, -4.8348, -4.6606,\n",
      "         -4.5839, -4.7368, -4.2114, -4.5180, -4.5222, -4.5678, -4.5729, -4.6450,\n",
      "         -4.2413, -4.9459, -4.4263, -4.8124, -4.3865, -4.4642, -4.7206, -4.7080,\n",
      "         -4.9233, -4.6944, -4.6045, -5.0809, -4.4929, -4.6617, -4.3092, -4.6852,\n",
      "         -4.5052, -4.5956, -4.9519, -4.7022, -4.5160, -4.4000, -4.4763, -4.9114,\n",
      "         -4.8298, -4.5082, -4.6283, -4.1658, -4.6400, -4.2740, -4.7343, -4.4292,\n",
      "         -4.5347, -4.2557, -4.3384, -4.7181, -4.8154, -4.6663, -4.4911, -4.0939,\n",
      "         -4.7924, -4.4513, -4.7171, -4.6054, -4.7919, -4.8432, -4.4526, -4.5285,\n",
      "         -5.0076, -4.8129, -4.8449, -4.8274, -4.6674, -4.3429, -4.5143, -5.0125,\n",
      "         -4.7524, -4.2426, -4.6885, -4.6979, -4.7315, -4.4246, -4.6511, -4.6846,\n",
      "         -4.8479, -4.2594, -4.9049, -4.7493, -4.6170, -4.3401, -4.4934, -4.6139,\n",
      "         -4.5582]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2195, -4.5184, -5.1175, -4.8421, -4.2747, -4.7140, -4.7602, -4.3558,\n",
      "         -5.2684, -4.2350, -4.9048, -4.2142, -4.4702, -4.3342, -5.0022, -5.1074,\n",
      "         -4.6470, -4.6019, -4.6260, -4.4207, -4.5280, -4.5385, -4.5689, -4.6003,\n",
      "         -4.5526, -5.0578, -4.2859, -4.5218, -4.5972, -4.7463, -4.7157, -4.5023,\n",
      "         -4.9840, -4.8176, -4.8349, -5.3975, -4.7028, -4.5564, -4.6389, -4.3140,\n",
      "         -4.5525, -4.6694, -4.3751, -4.4443, -4.2069, -4.1468, -4.7129, -4.7022,\n",
      "         -4.9599, -4.7808, -4.6083, -4.6890, -4.4178, -4.3829, -4.5098, -4.5543,\n",
      "         -4.5773, -4.3186, -4.4323, -4.6123, -4.6858, -4.4262, -4.3305, -4.2429,\n",
      "         -4.0375, -4.8296, -4.8257, -4.5184, -4.6068, -4.2337, -4.3517, -4.6743,\n",
      "         -4.7751, -4.7360, -4.7998, -4.7228, -4.2761, -4.1940, -4.3611, -4.6964,\n",
      "         -4.6845, -4.7653, -4.8416, -5.0346, -5.0858, -4.4348, -4.6932, -4.5089,\n",
      "         -5.1521, -4.6184, -4.4285, -4.7804, -4.9289, -4.4047, -4.2586, -4.8595,\n",
      "         -4.4729]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty's\n",
      "target index is: [80] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2936, -4.4786, -4.7278, -4.5335, -4.2142, -4.9297, -4.5298, -4.2997,\n",
      "         -4.4029, -5.1318, -4.9666, -4.1557, -4.6588, -4.7301, -4.6078, -4.7437,\n",
      "         -4.8878, -5.1618, -4.5383, -4.4114, -4.9441, -4.7434, -4.5817, -4.4951,\n",
      "         -4.2085, -4.6517, -4.6624, -4.4397, -3.8577, -4.5789, -4.8089, -4.5977,\n",
      "         -4.7205, -4.5898, -4.6528, -5.1409, -4.8600, -4.6234, -4.6670, -4.5192,\n",
      "         -4.6826, -4.2475, -4.9867, -4.0647, -4.5029, -4.0981, -4.4535, -4.4783,\n",
      "         -4.5288, -4.8913, -4.7772, -4.4669, -4.7558, -4.3610, -4.6162, -4.4055,\n",
      "         -4.3173, -4.2914, -4.7368, -5.0430, -4.8380, -4.1847, -4.4809, -4.1101,\n",
      "         -5.0342, -4.8086, -5.0813, -4.6728, -4.8194, -4.6269, -4.3042, -4.7512,\n",
      "         -4.5057, -4.8597, -4.7996, -4.9087, -5.1626, -4.1748, -4.5092, -4.4591,\n",
      "         -4.7639, -4.3149, -5.2119, -4.7801, -4.8679, -4.0986, -4.6098, -5.0108,\n",
      "         -5.0409, -4.5936, -5.1971, -4.4886, -4.5837, -4.5007, -4.2774, -4.3257,\n",
      "         -4.5514]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : field,\n",
      "target index is: [77] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.0078, -4.1622, -4.7795, -5.6563, -4.0775, -5.0955, -4.5416, -4.4636,\n",
      "         -4.8757, -4.8202, -4.6843, -5.1490, -5.0567, -4.8288, -4.6774, -4.8203,\n",
      "         -4.9132, -4.7126, -4.8353, -4.5467, -4.7504, -4.3497, -5.0152, -4.6647,\n",
      "         -4.5897, -4.8610, -4.3154, -4.0618, -4.1988, -4.9185, -4.2824, -4.7777,\n",
      "         -4.8004, -4.7269, -4.5008, -4.9550, -4.7079, -4.9932, -4.9744, -4.8479,\n",
      "         -4.5694, -5.1579, -4.8435, -4.6501, -4.5463, -4.0745, -5.1023, -4.4281,\n",
      "         -4.6268, -5.0083, -3.8282, -5.2418, -4.3693, -4.8091, -4.8042, -4.4961,\n",
      "         -4.5575, -4.3493, -4.4720, -4.2716, -4.7564, -4.3960, -4.4332, -3.7956,\n",
      "         -4.4787, -4.5333, -4.9626, -4.7233, -4.4465, -4.4641, -4.6110, -4.4861,\n",
      "         -5.3889, -4.7515, -4.8270, -4.8819, -4.3440, -4.1708, -4.3797, -4.5033,\n",
      "         -4.5135, -4.3854, -5.2159, -5.2262, -4.5213, -4.4419, -4.2787, -4.8534,\n",
      "         -4.6180, -4.2499, -4.1020, -4.3414, -4.9424, -4.1698, -4.4806, -4.8739,\n",
      "         -4.4761]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Thy\n",
      "target index is: [73] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3020, -4.5977, -4.7275, -4.6638, -4.2251, -4.9333, -4.6393, -4.1473,\n",
      "         -4.7178, -4.9034, -4.6504, -4.2295, -4.3267, -4.7204, -4.6380, -4.3725,\n",
      "         -4.6783, -4.8297, -4.1407, -4.6996, -4.5324, -4.2653, -4.7856, -4.8130,\n",
      "         -4.1240, -4.8535, -4.5756, -4.7214, -4.0513, -4.4425, -4.7785, -4.7077,\n",
      "         -4.8841, -4.6022, -4.7156, -5.1176, -4.9143, -4.5625, -4.7824, -4.9385,\n",
      "         -4.7626, -4.4361, -4.9650, -4.6680, -4.4934, -4.4262, -4.6196, -5.0965,\n",
      "         -4.6989, -4.5029, -4.6185, -4.2915, -4.7701, -4.4948, -4.7887, -4.4931,\n",
      "         -4.2358, -4.1524, -4.5662, -4.4330, -4.8466, -4.3961, -4.4823, -3.9252,\n",
      "         -4.8216, -4.6483, -4.8024, -4.8958, -4.8941, -4.6658, -4.3498, -4.4344,\n",
      "         -4.8619, -4.6920, -4.7720, -4.9042, -4.5820, -4.3606, -4.6689, -4.7210,\n",
      "         -4.4470, -4.3062, -5.1150, -4.6968, -4.3473, -4.7528, -4.7101, -4.6705,\n",
      "         -4.6851, -4.6007, -4.7262, -4.6432, -4.6979, -4.1573, -4.4940, -4.6051,\n",
      "         -4.4917]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : youth's\n",
      "target index is: [89] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2093, -4.7486, -4.7378, -4.8719, -4.1594, -4.7451, -4.8546, -4.5491,\n",
      "         -4.8255, -5.0045, -4.8929, -4.4191, -4.7320, -4.3764, -5.0372, -4.8500,\n",
      "         -4.6813, -4.6727, -4.6544, -4.6491, -4.3906, -4.4974, -4.5079, -4.5435,\n",
      "         -4.3060, -4.7067, -4.6798, -4.7811, -4.4853, -4.3891, -5.0016, -4.3731,\n",
      "         -4.9419, -4.6626, -4.6745, -5.2048, -4.7822, -4.7532, -4.8155, -4.3090,\n",
      "         -4.6375, -4.6656, -4.9043, -4.3487, -4.3030, -4.4933, -4.4833, -4.4111,\n",
      "         -4.5465, -4.4359, -4.3022, -4.8556, -4.4525, -4.2373, -4.3924, -4.4331,\n",
      "         -4.4908, -4.5163, -4.5598, -4.4855, -4.7404, -4.3705, -4.5023, -3.6668,\n",
      "         -4.2966, -4.3506, -4.8755, -4.6316, -4.7309, -4.6079, -4.3545, -4.6843,\n",
      "         -4.9272, -4.7935, -4.8684, -4.6273, -4.4210, -4.3106, -4.7117, -4.3005,\n",
      "         -4.6907, -4.7451, -4.9796, -5.1903, -4.5804, -4.2936, -4.4976, -5.0438,\n",
      "         -5.2590, -4.1983, -4.4509, -4.7256, -4.6391, -4.4931, -4.4275, -4.7104,\n",
      "         -4.8760]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : proud\n",
      "target index is: [50] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4923, -4.3364, -4.9289, -5.0960, -4.3875, -4.6567, -4.3745, -4.5470,\n",
      "         -5.3677, -4.5170, -4.8922, -4.4385, -4.8855, -4.5388, -4.6148, -5.1434,\n",
      "         -4.9609, -4.7054, -4.5409, -4.0470, -4.3984, -4.3849, -4.8418, -4.4851,\n",
      "         -4.9140, -4.9320, -4.4645, -4.3874, -4.6792, -4.8800, -4.7321, -4.6231,\n",
      "         -4.8769, -4.8496, -4.3549, -5.1371, -4.6138, -5.0081, -4.6676, -4.1974,\n",
      "         -4.3824, -4.6325, -4.6241, -4.4470, -4.5874, -4.2447, -4.8772, -4.2914,\n",
      "         -4.4771, -5.3852, -4.2846, -5.1245, -4.2635, -4.5205, -4.5292, -4.5409,\n",
      "         -4.8356, -4.4124, -4.3906, -4.7548, -4.6567, -4.2571, -4.6481, -4.3743,\n",
      "         -4.3712, -4.8616, -4.8742, -4.2655, -4.6379, -4.2682, -4.4487, -4.8777,\n",
      "         -4.9503, -4.9121, -4.6114, -4.8096, -4.5023, -4.2791, -4.1823, -4.1405,\n",
      "         -4.8349, -4.8110, -5.1163, -4.8125, -5.0153, -4.2906, -4.5499, -4.5653,\n",
      "         -4.7198, -4.3212, -4.3563, -4.1781, -4.8890, -4.5175, -4.2297, -4.6144,\n",
      "         -4.2712]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : livery\n",
      "target index is: [28] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6469, -4.4212, -4.9939, -4.7489, -4.0811, -5.1190, -4.4256, -4.3614,\n",
      "         -4.5733, -4.4882, -4.8680, -4.5804, -4.7078, -4.8489, -4.3172, -4.5769,\n",
      "         -4.8139, -5.0197, -4.7706, -4.3938, -4.7835, -4.0982, -5.0236, -4.8002,\n",
      "         -4.1938, -4.9220, -4.1784, -4.4495, -4.1230, -4.8397, -4.9302, -5.1485,\n",
      "         -4.9182, -4.7903, -4.6621, -4.7870, -4.5859, -4.6921, -5.0538, -4.5117,\n",
      "         -4.9526, -4.5456, -4.7754, -4.7599, -4.7758, -4.3110, -4.6633, -4.8814,\n",
      "         -4.4113, -5.0371, -4.4084, -4.6538, -4.5242, -4.2950, -4.6851, -4.3331,\n",
      "         -4.3281, -4.1736, -4.7092, -4.8903, -4.5271, -4.4353, -4.2218, -4.5106,\n",
      "         -4.5804, -4.5657, -4.7319, -4.7441, -4.7205, -4.3059, -4.2600, -4.4568,\n",
      "         -4.8113, -4.8914, -4.6626, -4.9083, -4.5944, -4.1709, -4.5315, -4.5025,\n",
      "         -4.5268, -4.6347, -4.9003, -4.6813, -4.4875, -4.3539, -4.4540, -4.8371,\n",
      "         -4.4552, -4.5242, -4.9088, -4.5817, -4.7657, -4.3108, -4.5291, -4.5090,\n",
      "         -3.9991]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : so\n",
      "target index is: [69] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3883, -4.3201, -4.9265, -4.7912, -4.2785, -5.0204, -4.6128, -4.4046,\n",
      "         -4.5548, -4.6572, -4.8001, -4.8340, -4.4633, -5.0215, -4.8493, -4.6162,\n",
      "         -4.7335, -4.3595, -4.5582, -4.5806, -4.4127, -4.2782, -5.0302, -4.8237,\n",
      "         -4.2874, -4.9246, -4.3896, -4.5006, -4.2258, -4.6678, -4.8382, -4.7782,\n",
      "         -4.9612, -4.9999, -4.6071, -4.7821, -4.8818, -4.4208, -4.8462, -4.6974,\n",
      "         -4.6463, -4.6667, -4.6412, -4.6001, -4.3617, -4.2990, -4.4941, -4.5497,\n",
      "         -4.5057, -4.8931, -4.5866, -4.4854, -4.8187, -4.3645, -4.4723, -4.6954,\n",
      "         -4.2155, -4.3238, -4.3130, -4.6481, -4.8848, -4.5037, -4.2000, -4.1856,\n",
      "         -4.4121, -4.8485, -4.4834, -4.4567, -4.2904, -4.4453, -4.3104, -4.5071,\n",
      "         -4.8065, -4.8577, -4.9838, -4.8347, -4.2640, -4.5137, -4.9189, -4.8122,\n",
      "         -4.3280, -4.6357, -4.8708, -4.7585, -4.7147, -4.3942, -4.5614, -4.6517,\n",
      "         -4.7437, -4.2676, -4.7425, -4.8621, -4.7552, -4.1588, -4.7017, -4.6554,\n",
      "         -4.3203]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : gazed\n",
      "target index is: [17] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4637, -4.3401, -4.6836, -4.7859, -4.3180, -4.6382, -4.5122, -4.3493,\n",
      "         -4.5781, -4.7456, -4.6888, -4.5616, -4.5848, -4.7112, -4.7681, -4.6290,\n",
      "         -4.4466, -4.6644, -4.6447, -4.5133, -4.6763, -4.6129, -4.7028, -4.6076,\n",
      "         -4.3846, -4.8708, -4.4376, -4.5570, -4.3445, -4.6143, -4.4053, -4.8393,\n",
      "         -4.8768, -4.7544, -4.5850, -4.6754, -4.5888, -4.6141, -4.7010, -4.5987,\n",
      "         -4.6966, -4.5958, -4.4409, -4.4338, -4.5552, -4.2894, -4.6813, -4.5691,\n",
      "         -4.4418, -4.6031, -4.5555, -4.2975, -4.8609, -4.5010, -4.6603, -4.3847,\n",
      "         -4.5733, -4.2806, -4.5595, -4.7109, -4.7443, -4.6257, -4.6776, -4.3351,\n",
      "         -4.6405, -4.6217, -4.8157, -4.4693, -4.5678, -4.5161, -4.4727, -4.4699,\n",
      "         -4.4994, -4.8285, -4.7074, -4.8387, -4.6297, -4.1867, -4.7504, -4.8513,\n",
      "         -4.6013, -4.6260, -4.6881, -4.8212, -4.5103, -4.4855, -4.3113, -4.6641,\n",
      "         -4.6830, -4.3128, -4.6593, -4.5555, -4.8064, -4.5026, -4.5899, -4.5485,\n",
      "         -4.5124]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : on\n",
      "target index is: [87] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4798, -4.6604, -4.6081, -4.6251, -4.2342, -4.6142, -4.3734, -4.2686,\n",
      "         -4.6850, -4.7114, -4.6028, -4.7786, -4.7634, -4.5864, -4.6597, -4.4691,\n",
      "         -4.3085, -4.6355, -4.6777, -4.7290, -4.8060, -4.6613, -4.6459, -4.5134,\n",
      "         -4.4404, -4.7573, -4.5998, -4.5142, -4.6302, -4.4239, -4.4658, -4.6663,\n",
      "         -4.7298, -4.7358, -4.7552, -4.6301, -4.7123, -4.6649, -4.9505, -4.6019,\n",
      "         -4.7153, -4.5331, -4.8195, -4.2961, -4.6674, -4.3818, -4.6150, -4.5767,\n",
      "         -4.4490, -4.3461, -4.7551, -4.4240, -5.1043, -4.2865, -4.6346, -4.3118,\n",
      "         -4.2753, -4.3144, -4.6441, -4.5121, -4.7356, -4.7193, -4.4777, -4.0083,\n",
      "         -4.8153, -4.2811, -4.8184, -4.5353, -4.5853, -4.5672, -4.5179, -4.6586,\n",
      "         -4.6827, -4.4221, -4.5863, -4.8130, -4.6570, -4.5398, -4.8629, -4.7988,\n",
      "         -4.4146, -4.4680, -4.7721, -4.6769, -4.6535, -4.4656, -4.6268, -4.7623,\n",
      "         -4.9308, -4.2528, -4.5022, -4.3360, -4.7491, -4.6543, -4.5222, -4.6792,\n",
      "         -4.7955]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : now,\n",
      "target index is: [63] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4444, -4.6167, -4.8469, -4.9163, -3.8066, -4.5078, -4.5258, -4.5427,\n",
      "         -4.6641, -4.6563, -4.5798, -4.3906, -5.0334, -4.8159, -4.7834, -4.5005,\n",
      "         -4.5730, -4.8082, -4.6258, -4.4020, -4.5749, -4.0921, -4.8582, -4.9090,\n",
      "         -4.6183, -4.9820, -4.6787, -4.3536, -4.3349, -4.7777, -4.4425, -5.0131,\n",
      "         -4.7098, -4.6684, -4.2573, -4.8771, -4.4604, -4.8640, -5.0983, -4.7486,\n",
      "         -4.6710, -4.4816, -4.7168, -4.4839, -4.5795, -4.4031, -4.4050, -4.8864,\n",
      "         -4.5512, -5.1391, -4.7814, -4.5909, -4.4914, -4.4906, -4.5838, -4.4654,\n",
      "         -4.2514, -4.4179, -4.4325, -4.5564, -4.5070, -4.5525, -4.8173, -4.3330,\n",
      "         -4.4708, -4.4105, -4.6602, -4.5642, -4.7017, -4.4285, -4.4444, -4.6184,\n",
      "         -5.0057, -4.8889, -4.6250, -4.8442, -4.9387, -4.4409, -4.6851, -4.4555,\n",
      "         -4.6330, -4.0975, -4.9016, -4.8108, -4.3277, -4.3138, -4.5930, -4.5572,\n",
      "         -4.8545, -4.4280, -4.6628, -4.2139, -4.7100, -4.3480, -4.5888, -4.5604,\n",
      "         -4.6133]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Will\n",
      "target index is: [36] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3981, -4.8006, -4.8159, -4.8700, -4.1052, -4.6268, -4.6472, -4.2871,\n",
      "         -4.5353, -4.7456, -4.6157, -4.6648, -4.5823, -4.8671, -4.9264, -4.2937,\n",
      "         -4.4948, -4.5742, -4.3732, -4.5427, -4.8038, -4.1559, -4.9236, -5.0536,\n",
      "         -4.0567, -5.0271, -4.4242, -4.4279, -4.2255, -4.4335, -4.4891, -4.8993,\n",
      "         -5.0342, -4.8985, -4.3653, -4.6698, -4.6089, -4.6597, -5.0883, -4.7949,\n",
      "         -4.9805, -4.5722, -4.4458, -4.6382, -4.6550, -4.3928, -4.6865, -4.6818,\n",
      "         -4.5782, -4.9002, -4.4198, -4.6073, -4.9014, -4.5943, -4.6396, -4.4569,\n",
      "         -4.1213, -4.2886, -4.3262, -4.5332, -4.9742, -4.7173, -4.4753, -4.4784,\n",
      "         -4.5157, -4.4403, -4.6796, -4.5858, -4.7363, -4.6731, -4.3003, -4.3338,\n",
      "         -4.7994, -4.8951, -4.7259, -4.7567, -4.3969, -4.3299, -4.6017, -4.7822,\n",
      "         -4.4619, -4.6680, -4.6393, -4.7304, -4.4348, -4.4788, -4.5560, -4.7971,\n",
      "         -4.6534, -4.3364, -4.6456, -4.5373, -4.8115, -4.4985, -4.8549, -4.3775,\n",
      "         -4.3137]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : be\n",
      "target index is: [24] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3484, -4.6783, -4.7850, -4.7521, -4.1691, -4.9915, -4.5710, -4.3526,\n",
      "         -4.7521, -4.7816, -4.6398, -4.3030, -4.6875, -5.0083, -5.0795, -4.3675,\n",
      "         -4.3986, -4.7497, -4.6813, -4.9829, -4.3708, -3.9686, -4.4723, -4.6818,\n",
      "         -4.0938, -5.0821, -4.3230, -4.7682, -4.4273, -4.5646, -4.3886, -5.2483,\n",
      "         -4.8287, -4.8097, -4.6063, -4.5468, -4.6992, -4.5501, -4.9664, -4.8415,\n",
      "         -5.0278, -4.7434, -4.6330, -4.6813, -4.3572, -4.5156, -4.4919, -4.7601,\n",
      "         -4.6118, -4.6213, -4.7298, -4.0808, -5.0510, -4.4217, -4.6573, -4.6592,\n",
      "         -4.5189, -4.4556, -4.3381, -4.7165, -4.8973, -4.5397, -4.5786, -4.0644,\n",
      "         -4.6704, -4.5098, -4.8704, -4.4217, -4.3129, -4.4124, -4.1973, -4.6827,\n",
      "         -4.9409, -4.7517, -5.0750, -5.1645, -4.4924, -4.3038, -4.7720, -4.8842,\n",
      "         -4.1665, -4.5927, -4.6669, -4.4924, -4.3184, -4.4630, -4.3912, -4.8788,\n",
      "         -5.0040, -4.5283, -4.1953, -4.7667, -4.5479, -4.4371, -4.5621, -4.5819,\n",
      "         -4.5373]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : a\n",
      "target index is: [46] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3708, -4.5210, -4.6604, -5.3655, -4.1507, -4.6993, -4.2682, -4.0515,\n",
      "         -4.7634, -4.5608, -4.8198, -4.9145, -4.3906, -4.7493, -4.6924, -4.3102,\n",
      "         -4.2046, -4.6256, -4.6786, -4.5792, -5.0126, -4.3542, -4.8082, -4.9526,\n",
      "         -4.2823, -5.2741, -4.1990, -4.4307, -4.3059, -4.6495, -4.4741, -4.7569,\n",
      "         -4.9014, -5.0596, -4.4418, -4.6592, -4.5314, -4.3615, -4.9254, -4.5791,\n",
      "         -4.8629, -4.6036, -4.9706, -4.3355, -4.9250, -4.2331, -4.8679, -4.7645,\n",
      "         -4.7213, -4.7836, -4.1676, -4.6368, -4.5615, -4.5208, -4.6528, -4.5640,\n",
      "         -4.3325, -4.5156, -4.4014, -4.7359, -4.8507, -4.7052, -4.4654, -4.3500,\n",
      "         -4.6322, -4.3643, -5.0047, -4.3944, -4.7677, -4.8082, -4.7388, -4.5129,\n",
      "         -4.8809, -4.8229, -4.6693, -4.8843, -4.4170, -4.2991, -4.2358, -4.6994,\n",
      "         -4.3770, -4.6225, -4.7198, -4.7181, -4.8557, -4.3389, -4.6157, -4.7286,\n",
      "         -4.7271, -4.3526, -4.5512, -4.3879, -5.0730, -4.3571, -4.7991, -4.3094,\n",
      "         -4.3268]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : totter'd\n",
      "target index is: [20] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7033, -4.6723, -4.9469, -4.8731, -4.3872, -4.7986, -4.6415, -4.0641,\n",
      "         -4.8716, -4.5988, -4.8305, -4.2780, -4.3188, -4.6827, -4.9977, -4.6077,\n",
      "         -4.7119, -4.4237, -4.3083, -4.7278, -4.5932, -4.3850, -4.6543, -4.8148,\n",
      "         -4.0496, -5.1551, -4.5106, -4.7615, -4.1785, -4.2904, -4.5125, -4.7938,\n",
      "         -4.8203, -4.9008, -4.8711, -5.1914, -4.6528, -4.5098, -4.7793, -4.5350,\n",
      "         -4.7326, -4.7607, -4.7017, -4.6585, -4.6071, -4.4425, -4.8250, -4.8234,\n",
      "         -4.8072, -4.6954, -4.3803, -4.4923, -4.8253, -4.5389, -4.5426, -4.4280,\n",
      "         -4.3960, -4.2159, -4.2684, -4.4001, -4.7830, -4.4717, -4.4990, -3.9452,\n",
      "         -4.5377, -4.6381, -4.4326, -4.6923, -4.6276, -4.0334, -4.4138, -4.3087,\n",
      "         -5.0632, -4.8389, -5.0008, -5.0066, -4.3063, -4.3430, -4.3164, -4.9044,\n",
      "         -4.6566, -4.6046, -4.9900, -4.6328, -4.8308, -4.5592, -4.6448, -4.7010,\n",
      "         -4.8117, -4.4366, -4.5513, -4.7096, -4.8297, -4.1285, -4.6982, -4.6950,\n",
      "         -4.3119]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : weed\n",
      "target index is: [29] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6095, -4.7349, -4.5390, -4.6639, -4.1469, -4.7611, -4.5193, -4.3245,\n",
      "         -4.6847, -4.8054, -4.6557, -4.6465, -4.6909, -4.8042, -5.0404, -4.8090,\n",
      "         -4.4243, -4.4169, -4.4406, -4.5832, -4.5546, -4.6575, -4.6867, -4.4699,\n",
      "         -4.1945, -4.8297, -4.5492, -4.7154, -4.5651, -4.4627, -4.3072, -4.5944,\n",
      "         -4.5471, -4.7544, -4.6349, -4.7242, -4.3920, -4.5822, -4.3810, -4.6038,\n",
      "         -4.6271, -4.6945, -4.8137, -4.6221, -4.5125, -4.2825, -4.2329, -4.5249,\n",
      "         -4.6558, -4.4863, -4.7351, -4.3220, -4.8686, -4.3898, -4.4473, -4.5348,\n",
      "         -4.4513, -4.2625, -4.3244, -4.6592, -5.0241, -4.5290, -4.5247, -4.2230,\n",
      "         -4.8445, -4.6829, -4.6504, -4.6149, -4.4868, -4.4880, -4.5578, -4.6609,\n",
      "         -4.8331, -4.9240, -4.8261, -4.7795, -4.6063, -4.2451, -4.7881, -4.8855,\n",
      "         -4.6898, -4.5440, -4.6488, -4.5742, -4.7200, -4.5260, -4.4431, -4.7877,\n",
      "         -4.9780, -4.1613, -4.6937, -4.5042, -4.6544, -4.4951, -4.5453, -4.7883,\n",
      "         -4.6146]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : of\n",
      "target index is: [57] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5266, -4.3998, -4.3705, -4.6287, -3.9065, -4.7283, -4.9854, -4.4929,\n",
      "         -4.7178, -4.6036, -4.6318, -4.2462, -4.8583, -4.7850, -4.6300, -4.5716,\n",
      "         -4.5686, -4.9420, -4.4731, -4.7826, -4.4339, -4.1807, -4.5577, -4.4655,\n",
      "         -4.3933, -4.7359, -4.4324, -4.6947, -4.3975, -4.6153, -4.4550, -5.2699,\n",
      "         -4.7163, -4.3148, -4.6597, -5.0119, -4.5863, -4.9029, -4.5402, -4.8714,\n",
      "         -4.7120, -4.8128, -4.7978, -4.6628, -4.4674, -4.4173, -4.4496, -4.9546,\n",
      "         -4.8304, -4.4513, -4.6372, -4.4595, -4.8122, -4.3092, -4.9836, -4.5098,\n",
      "         -4.6623, -4.4023, -4.4882, -4.4515, -4.7521, -4.7817, -4.7140, -3.8220,\n",
      "         -4.7885, -4.6464, -5.0395, -4.6522, -4.6275, -4.7519, -4.3146, -4.5529,\n",
      "         -4.9710, -4.6786, -4.6540, -4.7680, -4.7129, -4.4483, -4.6852, -4.8888,\n",
      "         -4.6110, -4.0814, -4.8180, -4.7631, -4.4345, -4.5725, -4.3959, -4.5791,\n",
      "         -4.9077, -4.1654, -4.6067, -4.7505, -4.5446, -4.4698, -4.0843, -4.8095,\n",
      "         -4.4507]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : small\n",
      "target index is: [38] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3542, -4.2933, -4.6413, -4.8566, -4.3175, -4.7490, -4.5476, -4.5286,\n",
      "         -4.6969, -4.9300, -4.8593, -4.6072, -4.7721, -4.4900, -4.2938, -4.7645,\n",
      "         -4.8256, -5.0235, -4.6058, -4.2492, -4.8090, -4.5558, -4.6321, -4.4164,\n",
      "         -4.7306, -5.0949, -4.7379, -4.4331, -4.0952, -4.6128, -4.4659, -4.9978,\n",
      "         -4.7724, -4.6752, -4.4557, -4.8659, -4.7556, -4.8374, -4.9053, -4.4208,\n",
      "         -4.6360, -4.5887, -4.8748, -4.1371, -4.8534, -4.1580, -5.0067, -4.4136,\n",
      "         -4.4375, -4.8576, -4.9108, -4.7004, -4.7603, -4.4639, -4.6333, -4.6505,\n",
      "         -4.2779, -4.2219, -4.6445, -4.6589, -4.6108, -4.7074, -4.8410, -4.2791,\n",
      "         -4.9791, -4.4814, -5.1425, -4.2406, -4.6839, -4.7730, -4.2171, -4.6812,\n",
      "         -4.7732, -4.6628, -4.8433, -4.7149, -5.0682, -4.3074, -4.5614, -4.2108,\n",
      "         -4.6872, -4.4064, -4.7781, -4.8895, -4.6437, -4.0786, -4.3263, -4.4239,\n",
      "         -5.0272, -4.2257, -4.5294, -4.2565, -4.6536, -4.5988, -4.2397, -4.3989,\n",
      "         -4.3445]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : worth\n",
      "target index is: [83] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6902, -4.6232, -4.7710, -5.0565, -4.2514, -4.8388, -4.3492, -4.5281,\n",
      "         -4.7021, -4.7294, -5.0538, -4.8290, -4.8970, -4.7801, -4.4437, -4.5403,\n",
      "         -4.5361, -4.8595, -4.6205, -4.2785, -4.7760, -3.9656, -5.0990, -4.7016,\n",
      "         -4.1696, -5.1212, -4.2300, -4.0755, -4.5633, -4.5875, -5.0011, -4.9171,\n",
      "         -5.0479, -4.9366, -4.5541, -4.2944, -4.8038, -4.9092, -5.1896, -4.6836,\n",
      "         -4.9792, -5.1864, -4.7659, -4.6205, -4.7280, -4.5060, -4.8023, -5.0002,\n",
      "         -4.2954, -4.8944, -3.9379, -4.7834, -4.2001, -3.9023, -4.9791, -4.0411,\n",
      "         -4.8572, -4.4268, -4.5015, -4.5623, -4.7772, -4.7387, -4.5816, -4.1741,\n",
      "         -4.8503, -4.1771, -5.0738, -4.5676, -4.8690, -4.5843, -4.2252, -4.7619,\n",
      "         -4.8815, -4.2272, -4.5019, -5.0427, -4.4378, -4.4454, -4.8144, -4.7227,\n",
      "         -4.2216, -4.3579, -4.7750, -4.4684, -4.2728, -4.2501, -5.0478, -5.2623,\n",
      "         -4.5221, -4.2585, -4.5150, -4.6959, -4.5346, -4.3457, -4.4276, -4.8044,\n",
      "         -4.3012]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : held:\n",
      "target index is: [19] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3729, -4.3883, -5.0615, -5.0692, -4.0373, -4.9008, -4.3548, -4.5641,\n",
      "         -4.6610, -4.1703, -5.0480, -4.6242, -4.8757, -4.7324, -4.4216, -4.6502,\n",
      "         -4.6146, -4.6833, -4.9982, -4.4670, -4.3695, -4.3846, -4.9216, -4.7335,\n",
      "         -4.8125, -5.2109, -4.4475, -4.4571, -4.6040, -4.6567, -4.7508, -4.6415,\n",
      "         -4.7230, -5.2143, -4.5920, -4.5907, -4.4881, -4.6152, -4.9787, -4.2550,\n",
      "         -4.5930, -4.5871, -4.4829, -4.2506, -4.2635, -4.5921, -4.6850, -4.5412,\n",
      "         -4.2230, -5.3323, -4.3629, -5.0009, -4.7190, -4.3693, -4.7467, -4.5691,\n",
      "         -4.6055, -4.6104, -4.5004, -4.5863, -4.6399, -4.3593, -4.4300, -4.4667,\n",
      "         -4.4490, -4.6396, -4.6834, -4.3087, -4.5789, -4.3516, -4.5976, -4.9763,\n",
      "         -4.8565, -4.5473, -4.8781, -5.3148, -4.1868, -4.7857, -4.6098, -4.7607,\n",
      "         -4.6441, -4.2393, -4.8084, -4.5427, -5.3022, -3.9058, -5.1036, -4.5646,\n",
      "         -4.7174, -4.0352, -4.5613, -4.8306, -4.8182, -4.1464, -4.6268, -4.2901,\n",
      "         -4.2626]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Then\n",
      "target index is: [65] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3879, -4.5093, -4.9004, -4.7442, -3.9534, -4.8608, -4.6249, -4.7468,\n",
      "         -4.8199, -4.6402, -4.7224, -4.6148, -4.7925, -4.6890, -4.7521, -4.5690,\n",
      "         -4.5429, -4.6790, -5.1213, -4.7207, -4.5947, -4.2167, -4.8875, -4.3373,\n",
      "         -4.4150, -4.7400, -4.7833, -4.2911, -4.3268, -4.4041, -4.6849, -4.5560,\n",
      "         -4.7853, -4.8975, -4.5378, -4.2540, -4.6613, -5.0076, -4.9944, -4.4410,\n",
      "         -4.8874, -4.3967, -4.5264, -4.3541, -4.2791, -4.3508, -4.5068, -4.7076,\n",
      "         -4.3315, -4.9831, -4.6779, -4.5386, -4.9594, -4.0300, -4.5710, -4.4059,\n",
      "         -4.2987, -4.4310, -4.7065, -4.3511, -4.7597, -4.6169, -4.5080, -4.3908,\n",
      "         -4.6752, -4.5658, -4.7621, -4.2759, -4.6145, -4.4653, -4.4248, -4.7312,\n",
      "         -4.8220, -4.7746, -4.9271, -4.9681, -4.4441, -4.5219, -4.9985, -4.9993,\n",
      "         -4.4862, -4.2215, -4.4314, -4.5112, -4.8133, -4.0489, -4.8089, -5.0248,\n",
      "         -4.8599, -4.1146, -4.7083, -4.9219, -4.5349, -4.4135, -4.5136, -4.8704,\n",
      "         -4.6968]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : being\n",
      "target index is: [32] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3659, -4.2651, -4.6216, -5.0589, -4.1717, -4.3759, -4.5136, -4.1281,\n",
      "         -4.9705, -4.4536, -4.8368, -4.3401, -4.6624, -4.4015, -5.0165, -4.4169,\n",
      "         -4.4414, -4.4791, -4.7024, -4.0563, -4.8273, -4.7725, -4.4854, -4.5336,\n",
      "         -4.8892, -4.5746, -4.6420, -4.5323, -4.4188, -4.7851, -4.2543, -4.8257,\n",
      "         -4.9049, -4.5855, -4.5209, -4.8004, -4.4877, -4.9783, -4.9226, -4.8187,\n",
      "         -4.6994, -4.7245, -4.5046, -4.1908, -4.4556, -4.1328, -4.7306, -4.7362,\n",
      "         -4.7697, -4.6883, -4.7092, -4.3833, -4.5273, -4.5330, -4.9994, -4.6891,\n",
      "         -4.5623, -4.6074, -4.5265, -4.5638, -4.9069, -4.8365, -4.7757, -4.2352,\n",
      "         -4.5846, -4.5294, -4.9667, -4.5065, -4.6586, -4.8782, -4.5459, -4.6758,\n",
      "         -4.6728, -5.0775, -4.3872, -4.5459, -4.6102, -4.4127, -4.5053, -4.6895,\n",
      "         -4.6420, -4.4092, -4.4340, -4.8883, -4.8102, -4.4611, -4.3630, -4.2112,\n",
      "         -5.0792, -4.3880, -4.6592, -4.4104, -4.9958, -4.5108, -4.4157, -4.4035,\n",
      "         -4.6859]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : asked,\n",
      "target index is: [23] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2028, -4.6041, -4.5042, -4.6443, -4.1126, -4.8289, -4.6779, -4.3771,\n",
      "         -4.6701, -4.5918, -4.6462, -4.3153, -4.6404, -4.6917, -4.6858, -4.7946,\n",
      "         -4.7341, -5.0764, -4.4386, -4.8148, -4.5367, -4.4901, -4.7132, -4.5982,\n",
      "         -4.4133, -4.8537, -4.5307, -4.4930, -4.3299, -4.5479, -4.5869, -4.8119,\n",
      "         -4.6674, -4.5860, -4.7230, -5.0516, -4.5793, -4.4542, -4.5001, -4.6443,\n",
      "         -4.7569, -4.4162, -4.6514, -4.4984, -4.3955, -4.1942, -4.6500, -4.8708,\n",
      "         -4.7809, -4.5091, -4.5991, -4.3497, -4.8924, -4.4530, -4.8136, -4.3808,\n",
      "         -4.5854, -4.2641, -4.3702, -4.6238, -4.7096, -4.5098, -4.6154, -3.9694,\n",
      "         -4.7861, -4.6239, -4.9477, -4.6785, -4.8655, -4.6372, -4.5240, -4.6106,\n",
      "         -4.9176, -4.5120, -4.6511, -4.9596, -4.7541, -4.2671, -4.5507, -4.9314,\n",
      "         -4.5629, -4.1902, -4.9087, -4.6213, -4.4118, -4.5252, -4.6341, -4.5454,\n",
      "         -5.0254, -4.4373, -4.5246, -4.5152, -4.6259, -4.6355, -4.2805, -4.7086,\n",
      "         -4.4500]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : where\n",
      "target index is: [51] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3663, -4.2905, -4.6709, -4.9593, -4.2693, -4.9407, -4.7437, -4.6583,\n",
      "         -4.8782, -4.6488, -4.9532, -4.6029, -4.8336, -4.6147, -4.6429, -4.9572,\n",
      "         -4.6855, -4.5885, -4.9272, -4.5186, -4.6539, -4.5647, -4.8355, -4.5190,\n",
      "         -4.5852, -4.7486, -4.3747, -4.3886, -4.2827, -4.6426, -4.3209, -4.9332,\n",
      "         -4.7362, -4.6697, -4.5140, -4.9837, -4.4695, -4.6609, -4.7794, -4.5611,\n",
      "         -4.6117, -4.7034, -4.6228, -4.5770, -4.5402, -4.1412, -4.7935, -4.5748,\n",
      "         -4.7560, -4.7875, -4.2407, -4.9042, -4.6810, -4.5002, -4.4967, -4.6891,\n",
      "         -4.5427, -4.3817, -4.5633, -4.5341, -4.5489, -4.4330, -4.5190, -4.3815,\n",
      "         -4.4833, -4.7992, -5.0244, -4.3000, -4.3955, -4.3298, -4.6660, -4.4994,\n",
      "         -5.0777, -4.9636, -4.8519, -4.9428, -4.5947, -4.2262, -4.3842, -4.5037,\n",
      "         -4.4114, -4.3863, -4.7381, -4.8890, -4.8359, -4.2425, -4.3255, -4.4867,\n",
      "         -4.7656, -4.4153, -4.2125, -4.7104, -4.6975, -4.3584, -4.2616, -4.5765,\n",
      "         -4.2119]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : all\n",
      "target index is: [52] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4743, -4.2741, -4.6716, -4.7915, -4.4331, -4.8224, -4.4496, -4.4549,\n",
      "         -4.5443, -4.8804, -4.9987, -4.7013, -4.4983, -4.6110, -4.5900, -4.6446,\n",
      "         -4.6389, -4.7322, -4.5890, -4.2180, -4.7969, -4.7556, -4.7084, -4.4867,\n",
      "         -4.3803, -4.8654, -4.4956, -4.4947, -4.1996, -4.8334, -4.4754, -4.7742,\n",
      "         -4.8661, -4.8389, -4.4889, -4.5482, -4.6154, -4.4827, -4.6613, -4.6114,\n",
      "         -4.7318, -4.6095, -4.7422, -4.4938, -4.7768, -4.2021, -4.8320, -4.6383,\n",
      "         -4.5657, -4.8237, -4.4412, -4.4580, -4.6042, -4.3149, -4.7160, -4.5443,\n",
      "         -4.3811, -4.3716, -4.5979, -4.7426, -4.7740, -4.7252, -4.5758, -4.5641,\n",
      "         -4.8009, -4.5297, -5.0783, -4.3640, -4.6389, -4.6478, -4.4419, -4.5014,\n",
      "         -4.5538, -4.8896, -4.6333, -4.6598, -4.5724, -4.2185, -4.4468, -4.6620,\n",
      "         -4.4985, -4.5764, -4.6273, -4.8179, -4.6459, -4.3165, -4.4652, -4.5749,\n",
      "         -4.7104, -4.3247, -4.6382, -4.6451, -4.6552, -4.5290, -4.3402, -4.4644,\n",
      "         -4.2237]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3861, -4.3591, -4.9419, -4.7803, -4.2734, -4.7784, -4.8654, -4.3899,\n",
      "         -5.0853, -4.2667, -5.0074, -4.3846, -4.5172, -4.6360, -4.6608, -4.8154,\n",
      "         -4.5489, -4.4375, -4.4700, -4.4992, -4.6468, -4.3696, -4.5403, -4.7915,\n",
      "         -4.4254, -5.0737, -4.3567, -4.5296, -4.4905, -4.4929, -4.6888, -4.6639,\n",
      "         -4.8403, -4.6596, -4.8924, -5.0874, -4.6912, -4.6352, -4.8821, -4.6195,\n",
      "         -4.6456, -4.7662, -4.6703, -4.6068, -4.5212, -4.1166, -4.8131, -4.7143,\n",
      "         -4.8882, -4.6539, -4.7513, -4.7664, -4.5648, -4.2802, -4.4665, -4.7762,\n",
      "         -4.3078, -4.3818, -4.4534, -4.5368, -4.7039, -4.5414, -4.2712, -4.3047,\n",
      "         -4.2292, -4.7497, -4.7095, -4.2355, -4.5964, -4.3730, -4.4398, -4.5991,\n",
      "         -4.8062, -4.5967, -4.7841, -4.7313, -4.2319, -4.4661, -4.3237, -4.7063,\n",
      "         -4.4150, -4.5624, -4.8015, -5.0513, -4.8614, -4.4488, -4.7412, -4.6309,\n",
      "         -4.8920, -4.4688, -4.5115, -4.7898, -4.8249, -4.3350, -4.0574, -4.8375,\n",
      "         -4.3813]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty\n",
      "target index is: [0] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3738, -4.6818, -4.7747, -4.9170, -4.2178, -4.6863, -4.4000, -4.2086,\n",
      "         -5.1137, -4.4876, -4.7969, -4.4069, -4.2866, -4.6031, -4.8444, -5.0939,\n",
      "         -4.6940, -4.5597, -4.6687, -4.5167, -4.7681, -4.7276, -4.8734, -4.6423,\n",
      "         -4.4593, -5.1915, -4.3628, -4.4412, -4.2203, -4.6833, -4.5016, -4.3419,\n",
      "         -4.7247, -4.9236, -4.6780, -5.1562, -4.3324, -4.5284, -4.3868, -4.3781,\n",
      "         -4.5486, -4.3781, -4.6370, -4.3241, -4.5362, -4.0818, -4.9053, -4.5937,\n",
      "         -4.8578, -4.7857, -4.5108, -4.6712, -4.8294, -4.5407, -4.5750, -4.5746,\n",
      "         -4.4442, -4.3712, -4.5095, -4.4299, -4.7149, -4.4302, -4.3756, -4.4210,\n",
      "         -4.3012, -5.0146, -4.7871, -4.4213, -4.7653, -4.0273, -4.5746, -4.4843,\n",
      "         -5.1070, -4.9213, -4.7617, -4.7417, -4.5903, -3.9096, -4.2877, -4.7743,\n",
      "         -4.6445, -4.7787, -4.8465, -4.9293, -5.1286, -4.3053, -4.5665, -4.3939,\n",
      "         -5.3310, -4.8487, -4.7612, -4.5799, -4.8797, -4.3598, -4.5227, -4.7978,\n",
      "         -4.2709]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : lies,\n",
      "target index is: [59] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2968, -4.6611, -4.6543, -4.6698, -4.1972, -4.8887, -4.4164, -4.2313,\n",
      "         -4.6705, -5.1501, -4.7647, -4.3930, -4.5358, -4.8048, -4.7644, -4.6496,\n",
      "         -4.4672, -4.9513, -4.8059, -4.9114, -4.4336, -4.4910, -4.6838, -4.5149,\n",
      "         -4.1511, -4.8760, -4.5039, -4.3901, -4.3606, -4.5925, -4.6213, -4.7029,\n",
      "         -4.5258, -5.1208, -4.5032, -4.6492, -4.9020, -4.3141, -4.6829, -4.3821,\n",
      "         -5.0448, -4.2482, -4.7600, -4.4215, -4.4668, -4.1764, -4.4850, -4.5855,\n",
      "         -4.5409, -4.5437, -4.5970, -4.1695, -5.0295, -4.3836, -4.7017, -4.3206,\n",
      "         -4.5793, -4.4670, -4.7574, -4.7737, -4.6643, -4.3002, -4.5297, -4.3591,\n",
      "         -4.6703, -4.6693, -4.7092, -4.3612, -4.6672, -4.4310, -4.4336, -4.6694,\n",
      "         -4.4772, -4.9585, -4.8608, -4.9249, -4.6313, -4.1335, -4.7192, -5.0492,\n",
      "         -4.3954, -4.7280, -4.6900, -4.7860, -4.4277, -4.4393, -4.4636, -5.0375,\n",
      "         -4.9993, -4.5218, -4.7039, -4.6904, -4.4277, -4.6311, -4.7202, -4.5755,\n",
      "         -4.4413]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Where\n",
      "target index is: [18] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5514, -4.4231, -4.3789, -4.5924, -4.2310, -4.9768, -4.7634, -4.5113,\n",
      "         -4.6657, -4.7692, -4.7019, -4.4965, -4.7137, -4.7640, -4.5568, -4.5534,\n",
      "         -4.8523, -4.5942, -4.5650, -4.6131, -4.3845, -4.3162, -4.7549, -4.6425,\n",
      "         -4.3865, -4.7726, -4.6584, -4.4679, -4.3448, -4.5602, -4.7120, -4.6587,\n",
      "         -4.8385, -4.5835, -4.6491, -4.8994, -4.5710, -4.8986, -4.4948, -4.5161,\n",
      "         -4.6590, -4.6635, -4.8449, -4.5222, -4.6330, -4.4069, -4.5537, -4.6756,\n",
      "         -4.4926, -4.8331, -4.4955, -4.8308, -4.5477, -4.6038, -4.7212, -4.7527,\n",
      "         -4.2846, -4.4380, -4.3875, -4.5049, -4.8188, -4.7837, -4.5083, -4.2055,\n",
      "         -4.8993, -4.4365, -4.9224, -4.3628, -4.5767, -4.7091, -4.3019, -4.4666,\n",
      "         -4.8550, -4.9228, -4.8248, -4.7728, -4.2804, -4.3186, -4.7685, -4.5517,\n",
      "         -4.4658, -4.2877, -4.6229, -4.7487, -4.6315, -4.4501, -4.3839, -4.7047,\n",
      "         -4.7753, -4.2446, -4.5439, -4.7181, -4.5553, -4.4247, -4.2585, -4.5000,\n",
      "         -4.5470]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : all\n",
      "target index is: [52] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2874, -4.2320, -4.6131, -4.9357, -4.3325, -4.6071, -4.5642, -4.4700,\n",
      "         -4.7934, -4.9687, -4.8433, -4.4855, -4.7333, -4.6550, -4.5017, -4.7532,\n",
      "         -4.7493, -5.0468, -4.4096, -4.1752, -4.7667, -4.4121, -4.6975, -4.4751,\n",
      "         -4.6081, -4.7423, -4.4011, -4.4741, -4.1975, -4.9886, -4.4433, -4.9385,\n",
      "         -4.8564, -4.6661, -4.3133, -4.7183, -4.5687, -4.7901, -4.7926, -4.7229,\n",
      "         -4.6706, -4.6416, -4.8286, -4.5766, -4.8808, -4.2523, -5.0205, -4.6375,\n",
      "         -4.6228, -4.8693, -4.4261, -4.6452, -4.4043, -4.5115, -5.0111, -4.6047,\n",
      "         -4.6290, -4.4515, -4.6115, -4.7845, -4.5632, -4.5997, -4.7038, -4.4036,\n",
      "         -4.9818, -4.4549, -5.1202, -4.6073, -4.7643, -4.6809, -4.3187, -4.5514,\n",
      "         -4.5785, -4.8090, -4.4023, -4.6243, -4.6562, -4.1755, -4.4014, -4.4088,\n",
      "         -4.4810, -4.4296, -4.7788, -4.8646, -4.4352, -4.4193, -4.3468, -4.5483,\n",
      "         -4.7285, -4.2730, -4.4744, -4.4190, -4.7335, -4.5357, -4.1431, -4.4222,\n",
      "         -4.3568]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : the\n",
      "target index is: [82] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1619, -4.4032, -4.5637, -4.8765, -4.1809, -4.6915, -4.6685, -4.3322,\n",
      "         -4.6311, -4.7105, -4.8778, -4.7260, -4.6329, -4.8015, -4.6996, -4.6556,\n",
      "         -4.4285, -4.5081, -4.4456, -4.6445, -4.8790, -4.5102, -4.8193, -4.6017,\n",
      "         -4.2089, -4.5000, -4.5423, -4.4901, -4.4475, -4.4954, -4.5574, -4.6887,\n",
      "         -4.5581, -4.6620, -4.8827, -4.7718, -4.8418, -4.5463, -4.8658, -4.8083,\n",
      "         -4.7066, -4.5508, -4.7665, -4.3552, -4.6020, -4.1694, -4.6238, -4.5208,\n",
      "         -4.5603, -4.4580, -4.5037, -4.5940, -4.9621, -4.4337, -4.5128, -4.6712,\n",
      "         -4.4369, -4.5246, -4.4177, -4.5701, -5.1443, -4.7034, -4.3986, -4.0338,\n",
      "         -4.8533, -4.7340, -4.7361, -4.5012, -4.6565, -4.7241, -4.7180, -4.6244,\n",
      "         -4.4886, -4.5452, -4.5264, -4.5321, -4.4031, -4.4712, -4.6182, -4.8019,\n",
      "         -4.2375, -4.3349, -4.8710, -4.7721, -4.5788, -4.5664, -4.7660, -4.8055,\n",
      "         -4.9133, -4.3570, -4.6108, -4.5172, -4.6457, -4.5384, -4.3371, -4.6085,\n",
      "         -4.6122]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : treasure\n",
      "target index is: [31] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3763, -4.3601, -4.7223, -4.9671, -4.1159, -4.7633, -4.6633, -4.5864,\n",
      "         -4.7612, -4.5681, -4.6183, -4.2759, -4.8069, -4.7943, -4.8218, -4.8215,\n",
      "         -4.4702, -4.7471, -4.6914, -4.5529, -4.5244, -4.4690, -4.8775, -4.6104,\n",
      "         -4.7358, -4.9785, -4.2888, -4.4426, -4.2833, -4.8938, -4.2490, -5.0194,\n",
      "         -4.6688, -4.5844, -4.4983, -5.0365, -4.3837, -4.6873, -4.7202, -4.7752,\n",
      "         -4.5751, -4.7568, -4.5184, -4.3638, -4.5454, -4.2745, -4.6539, -4.7024,\n",
      "         -4.7541, -4.9058, -4.3025, -4.7648, -4.7436, -4.8305, -4.6963, -4.3855,\n",
      "         -4.5629, -4.2275, -4.4885, -4.6111, -4.5112, -4.3418, -4.7814, -4.2232,\n",
      "         -4.4820, -4.6301, -5.0619, -4.6910, -4.2623, -4.3153, -4.7217, -4.7213,\n",
      "         -4.8647, -4.8477, -4.7562, -5.0159, -4.6805, -4.2802, -4.5686, -4.5539,\n",
      "         -4.6440, -4.1856, -4.8072, -4.9773, -4.6537, -4.4466, -4.3276, -4.2857,\n",
      "         -4.7348, -4.5301, -4.3191, -4.4694, -4.8541, -4.4820, -4.5082, -4.4573,\n",
      "         -4.2875]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : of\n",
      "target index is: [57] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4866, -4.1667, -4.3096, -4.5629, -4.1626, -4.8556, -4.9143, -4.4291,\n",
      "         -4.8200, -4.7645, -5.0740, -4.5449, -4.5960, -4.5657, -4.7851, -4.7644,\n",
      "         -4.6665, -4.5613, -4.5577, -4.5501, -4.5959, -4.3637, -4.7011, -4.3882,\n",
      "         -4.0736, -4.6796, -4.4924, -4.5455, -4.2893, -4.4839, -4.6596, -5.0512,\n",
      "         -5.0276, -4.5695, -4.8648, -4.9039, -4.8108, -4.7500, -4.5353, -4.7039,\n",
      "         -4.8368, -4.4991, -4.6499, -4.4877, -4.5358, -4.3155, -4.7505, -4.9359,\n",
      "         -4.6125, -4.5219, -4.4251, -4.4120, -4.8737, -4.2281, -4.6503, -4.6488,\n",
      "         -4.4471, -4.4086, -4.4623, -4.6987, -4.9019, -4.7179, -4.3789, -4.1469,\n",
      "         -4.7034, -4.7085, -5.0103, -4.5088, -4.7700, -4.6946, -4.5666, -4.4582,\n",
      "         -4.7023, -4.8616, -4.6690, -4.7854, -4.6011, -4.1634, -4.6184, -4.9182,\n",
      "         -4.2250, -4.3519, -4.7545, -4.8179, -4.6090, -4.4737, -4.5665, -4.6922,\n",
      "         -4.7679, -4.2058, -4.6617, -4.8131, -4.5936, -4.3809, -4.3062, -4.6499,\n",
      "         -4.3194]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1486, -4.2768, -4.8886, -5.0351, -4.2012, -4.7467, -4.7508, -4.2545,\n",
      "         -5.2572, -4.3785, -5.1348, -4.1463, -4.5722, -4.3071, -4.7206, -4.9690,\n",
      "         -4.5605, -4.5882, -4.7582, -4.1921, -4.7886, -4.7844, -4.4941, -4.4735,\n",
      "         -4.7309, -4.8543, -4.3927, -4.3452, -4.4124, -4.6837, -4.6225, -4.7567,\n",
      "         -5.0145, -4.7976, -4.8087, -5.2356, -4.5918, -4.5676, -4.9166, -4.4346,\n",
      "         -4.8799, -4.6486, -4.4890, -4.3964, -4.6497, -4.0009, -4.8593, -4.7092,\n",
      "         -4.8493, -4.7199, -4.6161, -4.7404, -4.4364, -4.3278, -4.8132, -4.8073,\n",
      "         -4.4560, -4.4802, -4.6787, -4.6622, -4.6196, -4.6283, -4.2975, -4.5103,\n",
      "         -4.3418, -4.7832, -5.1285, -4.3229, -4.5848, -4.5967, -4.2682, -4.6890,\n",
      "         -4.6892, -5.0381, -4.5540, -4.6997, -4.3027, -4.2060, -4.2598, -4.6051,\n",
      "         -4.4658, -4.5563, -4.6523, -5.0075, -5.1459, -4.2375, -4.6109, -4.3130,\n",
      "         -5.0797, -4.5434, -4.4195, -4.7827, -4.8746, -4.4965, -4.1892, -4.4671,\n",
      "         -4.3561]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : lusty\n",
      "target index is: [30] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2192, -4.6181, -4.4086, -4.9605, -4.2123, -4.7076, -4.5365, -4.1636,\n",
      "         -4.6931, -4.9690, -4.8959, -4.4644, -4.4040, -4.6526, -4.9054, -4.8362,\n",
      "         -4.4375, -4.7384, -4.4071, -4.8164, -4.7076, -5.0446, -4.7194, -4.6748,\n",
      "         -4.3945, -4.7150, -4.5248, -4.4781, -4.2000, -4.5191, -4.2065, -4.6929,\n",
      "         -4.5917, -4.8916, -4.7601, -4.8890, -4.3946, -4.4511, -4.4868, -4.5280,\n",
      "         -4.8219, -4.2786, -4.8034, -4.3219, -4.6584, -4.1607, -4.5251, -4.5826,\n",
      "         -4.6944, -4.5558, -4.6242, -4.3042, -5.0728, -4.5303, -4.8588, -4.7294,\n",
      "         -4.3576, -4.3350, -4.5258, -4.6407, -4.8495, -4.3754, -4.6114, -4.1921,\n",
      "         -4.6863, -4.7927, -4.8247, -4.8181, -4.7884, -4.4181, -4.6372, -4.4263,\n",
      "         -5.0299, -4.9651, -4.6949, -4.6873, -4.9126, -3.8014, -4.4557, -5.0088,\n",
      "         -4.4999, -4.5626, -4.6555, -4.9040, -4.8395, -4.4698, -4.4100, -4.4329,\n",
      "         -5.2503, -4.3935, -4.8019, -4.5036, -4.5296, -4.5862, -4.4025, -4.7664,\n",
      "         -4.4147]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : days;\n",
      "target index is: [48] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5455, -4.7488, -4.4095, -4.4633, -3.7488, -4.7640, -4.5594, -4.4407,\n",
      "         -4.5024, -4.9542, -4.4781, -4.6006, -5.0824, -4.9561, -4.6476, -4.5920,\n",
      "         -4.9357, -5.0824, -4.6165, -4.7421, -4.6267, -4.0565, -4.7300, -4.5253,\n",
      "         -4.4190, -4.8266, -4.4874, -4.5091, -4.5849, -4.5422, -4.5978, -4.6545,\n",
      "         -4.6974, -4.7468, -4.4065, -4.9530, -4.7289, -4.8743, -4.5504, -4.5712,\n",
      "         -4.8234, -4.6573, -5.0347, -4.4346, -4.8538, -4.7059, -4.3619, -4.4300,\n",
      "         -4.2964, -4.3423, -4.4609, -4.6624, -4.7635, -4.4878, -4.7020, -3.9025,\n",
      "         -4.6064, -4.1493, -4.4728, -4.5805, -4.6443, -4.7900, -4.9879, -3.9788,\n",
      "         -5.0441, -4.3795, -4.9403, -4.5376, -4.7419, -5.0557, -4.2211, -4.5348,\n",
      "         -4.8363, -4.9618, -4.4789, -4.9991, -4.7179, -4.5830, -4.6226, -4.6405,\n",
      "         -4.7625, -4.0436, -5.0189, -4.6462, -4.4533, -4.6565, -4.5540, -5.0169,\n",
      "         -4.8453, -4.2516, -4.6695, -4.4008, -4.4688, -4.5493, -4.4009, -4.4589,\n",
      "         -4.5978]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : To\n",
      "target index is: [26] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2594, -4.6503, -5.0163, -4.9554, -4.0726, -4.7810, -4.4733, -4.7087,\n",
      "         -4.5807, -4.6296, -4.9417, -4.4793, -4.8576, -4.4904, -4.8493, -4.6424,\n",
      "         -4.2141, -4.7080, -4.8761, -4.6407, -4.3407, -4.1902, -4.9040, -4.7024,\n",
      "         -4.5186, -4.8601, -4.3903, -4.4215, -4.3732, -4.8381, -4.6309, -4.9306,\n",
      "         -4.9292, -4.9874, -4.5521, -4.5502, -4.5785, -4.5321, -5.1338, -4.6826,\n",
      "         -4.7042, -4.6928, -4.3558, -4.7179, -4.1343, -4.4199, -4.5598, -4.8286,\n",
      "         -4.4457, -4.9978, -4.2513, -4.5931, -4.6207, -4.2483, -4.8075, -4.7259,\n",
      "         -4.6713, -4.5727, -4.5049, -4.5945, -4.6252, -4.3943, -4.5750, -4.2950,\n",
      "         -4.3557, -4.8224, -4.9593, -4.5056, -4.6036, -4.2818, -4.3944, -4.5412,\n",
      "         -4.9152, -4.4973, -4.8697, -4.9880, -4.5559, -4.3711, -4.8013, -4.6638,\n",
      "         -4.1516, -4.3529, -4.5608, -4.7117, -4.4293, -4.3572, -4.6461, -4.7323,\n",
      "         -4.8642, -4.5920, -4.4669, -4.9753, -4.5283, -4.2194, -4.4133, -4.7219,\n",
      "         -4.3248]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : say,\n",
      "target index is: [96] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7765, -4.3232, -4.6535, -4.9207, -3.9660, -4.7185, -4.6141, -4.2841,\n",
      "         -4.7518, -4.5027, -4.7703, -4.6258, -4.6810, -4.7588, -4.5935, -4.8483,\n",
      "         -4.8186, -4.3579, -4.7476, -4.2344, -4.6798, -4.5922, -4.7157, -4.7194,\n",
      "         -4.4660, -4.8248, -4.4171, -4.5307, -4.2753, -4.5204, -4.6152, -4.6295,\n",
      "         -4.8514, -4.7761, -4.4723, -4.8520, -4.4923, -4.8364, -4.5421, -4.4610,\n",
      "         -4.5845, -4.6722, -4.6737, -4.4300, -4.6690, -4.4878, -4.4090, -4.5077,\n",
      "         -4.5444, -4.6948, -4.3553, -4.8297, -4.6440, -4.5587, -4.7546, -4.3848,\n",
      "         -4.6638, -4.3937, -4.4815, -4.6741, -4.6813, -4.6395, -4.5616, -4.2234,\n",
      "         -4.5772, -4.4545, -4.5136, -4.6178, -4.5590, -4.8464, -4.6580, -4.4908,\n",
      "         -4.8128, -5.1501, -4.6747, -4.7378, -4.3786, -4.5368, -4.5128, -4.8651,\n",
      "         -4.7761, -4.3956, -4.7056, -4.6778, -4.9538, -4.2179, -4.4072, -4.7283,\n",
      "         -4.6197, -4.1534, -4.7238, -4.5768, -4.6328, -4.2963, -4.6893, -4.4035,\n",
      "         -4.4945]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : within\n",
      "target index is: [34] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2103, -4.3353, -4.7224, -4.8875, -4.5052, -4.8538, -4.5003, -4.0752,\n",
      "         -5.1486, -4.5690, -4.9918, -4.3884, -4.2841, -4.6247, -5.1745, -5.0525,\n",
      "         -4.5615, -4.5730, -4.7269, -4.5982, -4.5306, -4.7355, -4.7523, -4.9226,\n",
      "         -4.4737, -4.9383, -4.2225, -4.3648, -4.1201, -4.5150, -4.5323, -4.6629,\n",
      "         -4.9573, -4.8582, -4.8295, -5.0034, -4.7734, -4.3564, -4.5638, -4.5295,\n",
      "         -4.6891, -4.6584, -4.4174, -4.3510, -4.3337, -4.0069, -4.7034, -4.7728,\n",
      "         -4.6286, -4.7593, -4.6535, -4.1929, -4.6779, -4.6149, -4.5361, -4.6496,\n",
      "         -4.5844, -4.2017, -4.4258, -4.9501, -4.8435, -4.5938, -4.5074, -4.4192,\n",
      "         -4.3567, -4.9521, -4.9522, -4.5315, -4.5045, -4.1664, -4.4360, -4.5999,\n",
      "         -4.7621, -4.7725, -4.6881, -4.8848, -4.5338, -4.0331, -4.3989, -5.0646,\n",
      "         -4.3148, -4.7377, -4.6199, -4.9388, -4.9006, -4.6542, -4.6863, -4.3822,\n",
      "         -5.1304, -4.6106, -4.5157, -4.4333, -4.8155, -4.5535, -4.4271, -4.5481,\n",
      "         -4.4010]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thine\n",
      "target index is: [56] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1455, -4.9250, -4.1302, -4.5908, -4.0775, -4.7172, -4.8522, -4.3220,\n",
      "         -4.7103, -4.8710, -4.7695, -4.7894, -4.7074, -4.7171, -4.7734, -4.6807,\n",
      "         -4.6122, -4.7509, -4.4974, -4.9906, -4.8318, -4.6003, -4.8212, -4.4555,\n",
      "         -4.3112, -4.7530, -4.6600, -4.5145, -4.3061, -4.3762, -4.3547, -4.5474,\n",
      "         -4.6338, -4.5375, -4.6866, -4.8831, -4.3781, -4.8540, -4.6546, -4.7033,\n",
      "         -5.0060, -4.3033, -4.9555, -4.2413, -4.8477, -4.2960, -4.6120, -4.4722,\n",
      "         -4.7772, -4.3160, -4.5519, -4.6982, -5.1768, -4.5735, -4.9079, -4.6027,\n",
      "         -4.1849, -4.3249, -4.4113, -4.2966, -4.7311, -4.5818, -4.6146, -4.0574,\n",
      "         -4.7702, -4.4740, -5.0792, -4.7618, -4.9246, -5.0004, -4.4793, -4.4483,\n",
      "         -5.2566, -5.0205, -4.5838, -4.7982, -4.6599, -4.0833, -4.5272, -4.8315,\n",
      "         -4.4870, -4.0651, -4.6735, -4.8195, -4.6788, -4.6251, -4.4051, -4.5575,\n",
      "         -5.2699, -4.3024, -4.4121, -4.3881, -4.4653, -4.8012, -4.2338, -4.7105,\n",
      "         -4.4806]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : own\n",
      "target index is: [92] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4079, -4.4228, -4.4708, -4.9467, -3.7352, -4.4342, -4.7159, -4.6285,\n",
      "         -4.9189, -5.0493, -4.8475, -4.6174, -5.1006, -4.8038, -4.7897, -4.7181,\n",
      "         -4.5948, -5.1546, -4.5056, -4.3385, -4.4753, -4.0484, -4.7479, -4.5810,\n",
      "         -4.7677, -4.7665, -4.5093, -4.5914, -4.5755, -5.0565, -4.1975, -4.8349,\n",
      "         -4.6490, -4.4162, -4.2080, -4.8802, -4.6081, -5.1345, -4.8373, -4.8470,\n",
      "         -4.4958, -4.7634, -5.0365, -4.2577, -4.9192, -4.3998, -4.6073, -4.5070,\n",
      "         -4.7549, -4.7087, -4.6173, -4.7896, -4.6429, -4.6005, -4.9523, -4.2132,\n",
      "         -4.8418, -4.3991, -4.4836, -4.5857, -4.4788, -4.6956, -5.0655, -3.8228,\n",
      "         -4.7835, -4.4932, -5.1475, -4.5967, -4.6326, -4.9684, -4.4645, -4.5205,\n",
      "         -4.5764, -5.0857, -4.4140, -4.6237, -4.8124, -4.6017, -4.5786, -4.4233,\n",
      "         -4.7381, -4.1937, -4.9037, -4.8547, -4.2283, -4.5283, -4.1569, -4.5998,\n",
      "         -4.8303, -4.3945, -4.3777, -4.3567, -4.7291, -4.6497, -3.9299, -4.6695,\n",
      "         -4.3218]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : deep\n",
      "target index is: [76] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3231, -4.6593, -4.6737, -4.8056, -4.2624, -4.5399, -4.3754, -4.2462,\n",
      "         -4.6950, -4.9175, -5.0403, -4.3655, -4.5026, -4.4762, -4.6623, -4.4273,\n",
      "         -4.0953, -4.7402, -4.6413, -4.6213, -4.5812, -4.6050, -4.6444, -4.6394,\n",
      "         -4.4713, -4.6386, -4.5809, -4.5062, -4.4697, -4.6140, -4.6399, -4.8732,\n",
      "         -4.8933, -4.8939, -4.7193, -4.8158, -4.7909, -4.4458, -5.1265, -4.7453,\n",
      "         -4.7239, -4.5039, -4.8822, -4.3976, -4.5285, -4.3485, -4.6320, -4.7877,\n",
      "         -4.5208, -4.4441, -4.5945, -4.3187, -4.7897, -4.3378, -4.9103, -4.6586,\n",
      "         -4.4203, -4.6415, -4.7476, -4.6186, -4.8007, -4.6233, -4.4561, -3.9795,\n",
      "         -4.6011, -4.4752, -4.9105, -4.4444, -4.5769, -4.6270, -4.4300, -4.6534,\n",
      "         -4.5348, -4.4054, -4.4819, -4.6135, -4.6881, -4.5768, -4.6271, -4.7163,\n",
      "         -4.0561, -4.5208, -4.6812, -4.7333, -4.4724, -4.4076, -4.7894, -4.7338,\n",
      "         -5.0045, -4.4772, -4.5260, -4.8091, -4.6672, -4.6628, -4.2331, -4.5783,\n",
      "         -4.6145]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : sunken\n",
      "target index is: [91] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4258, -4.5296, -4.7063, -4.8580, -4.2014, -4.8790, -4.5988, -4.7653,\n",
      "         -4.7278, -4.4402, -4.9372, -4.4898, -4.8106, -4.6438, -4.6746, -4.8379,\n",
      "         -4.8993, -4.7926, -4.7524, -4.3218, -4.4844, -4.2202, -4.9249, -4.5418,\n",
      "         -4.5675, -4.8959, -4.3673, -4.6681, -4.3273, -4.6452, -4.8807, -4.6497,\n",
      "         -4.6506, -4.8032, -4.7382, -5.0143, -4.7185, -4.6818, -4.7757, -4.2431,\n",
      "         -4.8095, -4.7420, -4.8388, -4.3654, -4.4997, -4.5904, -4.6973, -4.5637,\n",
      "         -4.3420, -4.9140, -3.9343, -5.2365, -4.3650, -4.4660, -4.7636, -4.2420,\n",
      "         -4.8146, -4.4682, -4.4172, -4.5023, -4.5204, -4.3890, -4.6485, -3.9902,\n",
      "         -4.5173, -4.6214, -4.9829, -4.5769, -4.6404, -4.5366, -4.4432, -4.6296,\n",
      "         -4.8436, -4.7697, -4.5723, -5.0236, -4.1964, -4.5971, -4.5305, -4.5439,\n",
      "         -4.6333, -4.1859, -4.9227, -4.5858, -4.7891, -4.2753, -4.7796, -4.8522,\n",
      "         -4.7712, -4.2993, -4.4042, -4.7113, -4.5260, -4.3601, -4.5166, -4.2640,\n",
      "         -4.3752]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : eyes,\n",
      "target index is: [58] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2762, -4.5005, -5.0769, -5.3272, -3.8786, -4.6402, -4.3556, -4.5003,\n",
      "         -4.7248, -4.6147, -5.1152, -4.6452, -4.8024, -4.5880, -4.6237, -4.6703,\n",
      "         -4.5844, -4.7085, -5.0054, -4.5343, -4.7305, -4.3171, -5.0120, -4.6296,\n",
      "         -4.5279, -4.8552, -4.4453, -4.3689, -4.3238, -4.7072, -4.7629, -4.5563,\n",
      "         -4.6492, -5.0886, -4.5954, -4.7103, -4.5063, -4.5033, -5.1078, -4.3083,\n",
      "         -4.5791, -4.3524, -4.7807, -4.4242, -4.5922, -4.3247, -4.8624, -4.4567,\n",
      "         -4.4868, -5.0424, -4.3155, -4.9807, -4.5100, -4.2771, -4.4834, -4.6683,\n",
      "         -4.5673, -4.7494, -4.6296, -4.4079, -4.5805, -4.3058, -4.1197, -4.4662,\n",
      "         -4.2515, -4.6794, -4.6861, -4.5574, -4.6272, -4.2602, -4.5128, -4.6209,\n",
      "         -4.8992, -4.7876, -4.7760, -4.7887, -4.4270, -4.5042, -4.6040, -4.7271,\n",
      "         -4.4178, -4.5054, -4.9306, -4.9039, -4.9032, -4.0211, -4.6447, -4.6579,\n",
      "         -4.6922, -4.4655, -4.7920, -4.6551, -4.8539, -4.1930, -4.6981, -4.5988,\n",
      "         -4.2434]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Were\n",
      "target index is: [37] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2553, -4.5135, -4.6937, -4.6469, -4.2248, -4.6990, -4.4057, -4.2761,\n",
      "         -4.7965, -4.9089, -4.5952, -4.4391, -4.5355, -4.8380, -4.9925, -4.6718,\n",
      "         -4.7217, -4.5451, -4.6583, -4.7100, -4.3268, -4.4407, -4.8788, -5.0293,\n",
      "         -4.2830, -4.9269, -4.5798, -4.4057, -4.2049, -4.4126, -4.6227, -4.6540,\n",
      "         -4.5698, -4.8872, -4.3595, -4.8286, -4.8528, -4.3758, -4.7610, -4.3753,\n",
      "         -4.7054, -4.5324, -4.6954, -4.6783, -4.5634, -4.2146, -4.2485, -4.7900,\n",
      "         -4.4762, -4.8777, -4.7225, -4.3241, -4.8113, -4.5103, -4.4670, -4.4684,\n",
      "         -4.3831, -4.3683, -4.4590, -4.8838, -4.6341, -4.1450, -4.5589, -4.3421,\n",
      "         -4.4912, -4.6914, -4.5983, -4.3623, -4.6860, -4.1668, -4.5309, -4.5882,\n",
      "         -4.6816, -5.1151, -4.9385, -4.9262, -4.6358, -4.2688, -4.6832, -4.8876,\n",
      "         -4.5642, -4.7117, -4.7653, -4.7984, -4.6182, -4.3434, -4.4596, -4.8149,\n",
      "         -4.8882, -4.4150, -4.7973, -4.4967, -4.6308, -4.5436, -4.8498, -4.6905,\n",
      "         -4.6143]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : an\n",
      "target index is: [74] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5026, -4.6918, -4.6816, -4.4965, -4.0988, -4.9827, -4.6466, -4.5435,\n",
      "         -4.7230, -4.4955, -4.9781, -4.7198, -4.8439, -4.9062, -4.7814, -4.8533,\n",
      "         -4.8190, -4.5783, -4.6653, -4.7162, -4.3810, -4.0757, -4.8144, -4.8828,\n",
      "         -4.4110, -5.2016, -4.3498, -4.2066, -4.6354, -4.3675, -4.8356, -4.5527,\n",
      "         -4.8554, -4.9424, -4.3904, -4.7106, -4.7527, -4.5887, -4.7719, -4.4737,\n",
      "         -4.9094, -4.7459, -4.5808, -4.5241, -4.4182, -4.4266, -4.5388, -4.5637,\n",
      "         -4.3586, -4.9990, -4.4231, -4.4603, -4.6418, -4.4002, -4.4379, -4.3325,\n",
      "         -4.4581, -4.3198, -4.2074, -4.8231, -4.5621, -4.5502, -4.5947, -4.3477,\n",
      "         -4.5969, -4.3687, -4.8415, -4.2914, -4.7093, -4.5638, -4.3983, -4.6653,\n",
      "         -4.8452, -4.8236, -5.0242, -5.1064, -4.3356, -4.2575, -4.4962, -4.8784,\n",
      "         -4.3549, -4.5977, -4.4629, -4.8064, -4.5227, -4.2654, -4.6607, -5.0433,\n",
      "         -4.8100, -4.5839, -4.3657, -4.4497, -4.5631, -4.5578, -4.6222, -4.4836,\n",
      "         -4.3601]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : all-eating\n",
      "target index is: [60] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4762, -4.5658, -4.8549, -4.7433, -3.9420, -4.7135, -4.7253, -4.4181,\n",
      "         -4.8294, -4.4378, -5.0235, -4.6753, -4.8956, -4.6058, -4.7167, -4.6870,\n",
      "         -4.4669, -4.4377, -4.8338, -4.5047, -4.7380, -4.5842, -4.8709, -4.8909,\n",
      "         -4.6867, -4.9171, -4.6935, -4.2703, -4.2522, -4.4172, -4.5366, -4.5456,\n",
      "         -4.8383, -4.9381, -4.3565, -4.7333, -4.2887, -4.9244, -4.8292, -4.6210,\n",
      "         -4.7589, -4.4744, -4.4735, -4.5534, -4.3622, -4.4475, -4.5440, -4.6428,\n",
      "         -4.6715, -4.8551, -4.5111, -4.8301, -4.8428, -4.2427, -4.6646, -4.7643,\n",
      "         -4.3228, -4.4054, -4.6443, -4.4796, -4.6623, -4.6167, -4.4756, -4.4639,\n",
      "         -4.4388, -4.3959, -4.5747, -4.2922, -4.7507, -4.5875, -4.4102, -4.2739,\n",
      "         -5.0656, -4.8964, -4.7604, -4.8126, -4.3484, -4.3508, -4.4978, -5.0282,\n",
      "         -4.4165, -4.3257, -4.3167, -4.9248, -4.9946, -4.0358, -4.7365, -4.5637,\n",
      "         -4.8686, -4.2392, -4.5165, -4.6675, -4.7409, -4.4778, -4.6044, -4.5492,\n",
      "         -4.5567]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : shame,\n",
      "target index is: [41] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6953, -4.7293, -4.8741, -4.5176, -4.1496, -4.5971, -4.6514, -4.4566,\n",
      "         -4.5938, -4.6362, -4.5731, -4.5007, -4.8673, -4.7333, -4.7785, -4.4845,\n",
      "         -4.4564, -4.9088, -4.5699, -4.4994, -4.5718, -4.2220, -4.7214, -4.6020,\n",
      "         -4.5320, -4.9712, -4.3688, -4.5045, -4.4958, -4.6066, -4.4292, -5.0178,\n",
      "         -5.0990, -4.8073, -4.5548, -4.7061, -4.4958, -5.0410, -4.8125, -4.7274,\n",
      "         -4.8041, -4.3771, -4.4929, -4.5725, -4.5003, -4.4855, -4.6209, -4.6521,\n",
      "         -4.4212, -4.6453, -4.8630, -4.2319, -4.8256, -4.3282, -4.8858, -4.1639,\n",
      "         -4.4803, -4.2860, -4.4313, -4.4981, -4.6426, -5.0167, -4.7093, -4.2155,\n",
      "         -4.7878, -4.2505, -5.0330, -4.5139, -4.6425, -4.6756, -3.9872, -4.4620,\n",
      "         -4.7517, -4.5986, -4.6153, -4.8671, -4.8652, -4.3303, -4.9057, -4.8405,\n",
      "         -4.6605, -4.4679, -4.4459, -4.5756, -4.3307, -4.5066, -4.3807, -4.7543,\n",
      "         -4.7685, -4.1897, -4.6916, -4.4126, -4.7340, -4.6508, -4.5030, -4.7289,\n",
      "         -4.4519]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : and\n",
      "target index is: [44] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6954, -4.4867, -4.5664, -4.6345, -4.1997, -4.7424, -4.5197, -4.4107,\n",
      "         -4.7115, -4.8021, -4.4681, -4.4699, -4.8433, -4.8393, -4.4990, -4.5136,\n",
      "         -4.6192, -4.9095, -4.6399, -4.5500, -4.3592, -4.3154, -4.4793, -4.4675,\n",
      "         -4.5365, -4.7057, -4.3626, -4.4429, -4.6274, -4.5591, -4.6443, -4.8377,\n",
      "         -4.8039, -4.7562, -4.4013, -4.4956, -4.7785, -4.9190, -4.6064, -4.5407,\n",
      "         -4.7912, -4.6815, -4.8149, -4.5438, -4.5558, -4.6108, -4.3783, -4.5823,\n",
      "         -4.2874, -4.5374, -4.6013, -4.5784, -4.6028, -4.3815, -4.9028, -4.4803,\n",
      "         -4.7566, -4.6540, -4.6174, -4.6836, -4.8127, -4.7342, -4.8049, -4.1919,\n",
      "         -4.9254, -4.4369, -4.8730, -4.3913, -4.6518, -4.8426, -4.3089, -4.8077,\n",
      "         -4.6121, -4.6247, -4.4047, -4.7402, -4.5827, -4.4765, -4.7626, -4.4225,\n",
      "         -4.4563, -4.3522, -4.6626, -4.6522, -4.6060, -4.3349, -4.6004, -4.8110,\n",
      "         -4.8694, -4.1454, -4.7966, -4.7546, -4.3182, -4.3579, -4.4376, -4.4095,\n",
      "         -4.5680]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thriftless\n",
      "target index is: [43] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3769, -4.4348, -4.5478, -4.7392, -4.1077, -4.5562, -4.6675, -4.4821,\n",
      "         -4.7372, -4.5242, -4.9509, -4.3858, -4.7712, -4.6126, -4.6372, -4.9161,\n",
      "         -4.8727, -4.5515, -4.8906, -4.1971, -4.6908, -4.8133, -4.6314, -4.5943,\n",
      "         -4.8436, -4.7505, -4.5484, -4.4784, -4.1710, -4.7385, -4.6585, -4.5090,\n",
      "         -4.7363, -4.5778, -4.6313, -5.0392, -4.6329, -4.9052, -4.5334, -4.4776,\n",
      "         -4.5526, -4.5831, -4.7201, -4.1956, -4.4746, -4.2848, -4.4862, -4.1510,\n",
      "         -4.5527, -4.7035, -4.8435, -4.9384, -4.6239, -4.6512, -4.9276, -4.7548,\n",
      "         -4.4037, -4.4484, -4.5292, -4.6906, -4.5665, -4.6980, -4.5820, -4.3933,\n",
      "         -4.6695, -4.8222, -4.8844, -4.4099, -4.4619, -4.7332, -4.2101, -4.6841,\n",
      "         -4.7759, -5.0731, -4.5826, -4.5725, -4.4562, -4.4849, -4.4887, -4.3779,\n",
      "         -4.7221, -4.3012, -4.5177, -4.7784, -5.0490, -4.2972, -4.4945, -4.5288,\n",
      "         -5.2545, -4.4532, -4.7308, -4.4552, -4.5121, -4.5419, -4.1545, -4.2785,\n",
      "         -4.6104]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : praise.\n",
      "target index is: [94] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-3.9354, -5.0505, -4.7071, -5.1331, -3.7642, -4.7162, -4.8419, -4.4002,\n",
      "         -4.6741, -5.0071, -4.6470, -4.2815, -4.4944, -4.5544, -4.8216, -4.5696,\n",
      "         -4.8904, -5.0722, -4.7038, -4.5304, -4.7772, -4.0666, -5.1686, -4.9670,\n",
      "         -4.3924, -4.8610, -4.4851, -4.1126, -3.9094, -4.8676, -4.5756, -4.8052,\n",
      "         -4.8742, -4.8058, -4.4469, -5.2900, -4.6832, -4.6364, -4.9850, -4.9364,\n",
      "         -4.6649, -4.3410, -4.9119, -4.5821, -4.7102, -4.4213, -4.8689, -4.6555,\n",
      "         -4.7193, -4.8410, -4.3158, -4.7977, -4.4559, -4.6408, -4.8754, -4.5215,\n",
      "         -3.9381, -4.3880, -4.5151, -4.6918, -4.4070, -4.4089, -4.3311, -4.3284,\n",
      "         -4.5696, -4.6538, -5.0362, -4.9968, -4.8743, -4.8247, -4.1891, -4.2940,\n",
      "         -4.8605, -5.0851, -4.5689, -4.5304, -4.7439, -4.0393, -4.4527, -4.4381,\n",
      "         -4.5555, -4.1985, -5.1987, -5.0422, -4.1081, -4.6354, -4.2987, -4.7774,\n",
      "         -5.2104, -4.9422, -5.0300, -4.2686, -4.7274, -4.3682, -4.5384, -4.4288,\n",
      "         -4.4802]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : How\n",
      "target index is: [12] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1802, -4.6983, -4.4881, -5.0365, -4.0235, -4.9972, -4.6291, -4.3618,\n",
      "         -5.1430, -4.9563, -5.0371, -5.0825, -4.7453, -4.5197, -5.3343, -5.0951,\n",
      "         -4.8481, -4.4099, -4.7805, -4.7290, -4.6299, -4.8626, -4.8178, -5.0148,\n",
      "         -4.4005, -5.1052, -4.5800, -4.1883, -4.2748, -4.5906, -4.3060, -3.9738,\n",
      "         -4.6473, -4.7365, -4.4455, -5.1893, -4.5556, -4.5061, -4.5264, -4.5272,\n",
      "         -4.3528, -4.8600, -4.8117, -4.1991, -4.6112, -4.0025, -4.4978, -4.1568,\n",
      "         -5.0286, -4.5410, -4.3836, -4.7807, -4.6731, -4.7615, -4.5291, -4.8040,\n",
      "         -4.4084, -4.4226, -4.2833, -4.6650, -4.6618, -4.2925, -4.2651, -4.2133,\n",
      "         -4.5261, -4.9059, -4.6464, -4.3535, -4.3137, -4.4463, -4.5544, -4.3399,\n",
      "         -5.2970, -5.3101, -4.9326, -4.7762, -4.5470, -4.0973, -4.3966, -4.5779,\n",
      "         -4.6072, -4.9679, -4.6945, -5.1500, -4.9947, -4.1210, -4.1685, -4.8280,\n",
      "         -5.5451, -4.4454, -4.4648, -4.1475, -4.8215, -4.8538, -4.3870, -4.7865,\n",
      "         -4.5655]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : much\n",
      "target index is: [68] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4491, -4.9960, -4.6308, -4.4490, -3.4663, -4.4782, -4.7435, -4.2699,\n",
      "         -4.9930, -4.5442, -4.4805, -4.4714, -4.8357, -4.7676, -4.9950, -4.7945,\n",
      "         -4.8067, -4.8793, -4.1152, -4.8545, -4.7511, -4.1080, -5.0111, -4.8165,\n",
      "         -4.4975, -5.1123, -4.5010, -4.3718, -4.5933, -4.6024, -4.2276, -4.9779,\n",
      "         -4.6815, -4.5369, -4.4425, -5.3164, -4.4530, -5.0732, -4.6739, -4.9751,\n",
      "         -4.8625, -4.5791, -4.9382, -4.6375, -4.8384, -4.4052, -4.6648, -5.1296,\n",
      "         -4.9790, -4.5965, -4.9217, -4.4118, -5.0475, -4.1469, -4.6072, -4.0001,\n",
      "         -4.2463, -3.9633, -4.2425, -4.1724, -4.5385, -4.8027, -4.5585, -3.8634,\n",
      "         -4.6451, -4.3911, -4.6654, -4.5274, -5.1142, -4.7350, -4.4597, -4.3209,\n",
      "         -5.4803, -5.0414, -4.5924, -5.0599, -4.8987, -4.1643, -4.4422, -5.1412,\n",
      "         -4.8444, -4.1374, -4.9643, -4.8713, -4.3503, -4.5739, -4.5856, -4.8600,\n",
      "         -5.3026, -4.4939, -4.8791, -4.1380, -4.6592, -4.6277, -4.3309, -5.1603,\n",
      "         -4.3976]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : more\n",
      "target index is: [4] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3213, -4.8104, -4.7144, -4.3985, -4.1534, -4.6080, -4.8576, -4.4371,\n",
      "         -4.8833, -4.4805, -4.8685, -4.3047, -4.7254, -4.3770, -4.8335, -4.7896,\n",
      "         -4.5985, -4.7842, -4.6950, -4.6489, -4.4547, -4.4721, -4.6652, -4.6266,\n",
      "         -4.5662, -4.8142, -4.5848, -4.4525, -4.3979, -4.5682, -4.7567, -4.6838,\n",
      "         -4.8748, -4.5782, -4.9215, -5.0068, -4.8976, -4.6898, -4.7474, -4.6451,\n",
      "         -4.6100, -4.5499, -4.5862, -4.5080, -4.0745, -4.3035, -4.5269, -4.7125,\n",
      "         -4.7044, -4.5300, -4.9195, -4.3057, -4.7640, -4.3655, -4.8060, -4.4126,\n",
      "         -4.4742, -4.2069, -4.4754, -4.6776, -4.6060, -4.6000, -4.6011, -3.8924,\n",
      "         -4.5049, -4.6237, -4.8477, -4.6067, -4.6439, -4.6099, -4.0393, -4.5835,\n",
      "         -4.6943, -4.4651, -4.5028, -4.8323, -4.6790, -4.4887, -4.6435, -4.8105,\n",
      "         -4.4800, -4.2575, -4.6689, -4.7745, -4.5401, -4.5635, -4.7661, -4.7368,\n",
      "         -5.2276, -4.4892, -4.7141, -4.6812, -4.6340, -4.5555, -4.1005, -4.9367,\n",
      "         -4.5226]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : praise\n",
      "target index is: [45] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4195, -4.5039, -4.7064, -5.1971, -4.0333, -4.5950, -4.4811, -4.2737,\n",
      "         -5.2204, -4.6091, -4.8326, -4.3321, -4.7635, -4.5395, -5.1042, -4.8228,\n",
      "         -4.6693, -4.4944, -4.7865, -4.2215, -4.6984, -4.6995, -4.9141, -4.7349,\n",
      "         -4.8933, -4.9146, -4.5240, -4.2555, -4.2953, -4.6269, -4.2852, -4.4392,\n",
      "         -4.8656, -4.8696, -4.4724, -5.1786, -4.3281, -5.0176, -4.5258, -4.6029,\n",
      "         -4.4859, -4.5861, -4.7167, -4.1895, -4.6371, -4.1348, -4.7594, -4.4085,\n",
      "         -4.8100, -5.1248, -4.2467, -5.0928, -4.4307, -4.7668, -4.5936, -4.6438,\n",
      "         -4.3658, -4.4500, -4.4447, -4.5101, -4.5434, -4.3033, -4.6100, -4.4107,\n",
      "         -4.3216, -4.6210, -5.1138, -4.5847, -4.5496, -4.3277, -4.6933, -4.6580,\n",
      "         -5.2129, -5.2522, -4.6826, -4.9071, -4.5192, -4.1013, -4.2742, -4.4479,\n",
      "         -4.8537, -4.6422, -4.7254, -5.0102, -4.9856, -4.2415, -4.2186, -4.2996,\n",
      "         -5.1111, -4.7014, -4.5646, -4.0503, -5.0452, -4.5182, -4.6513, -4.3741,\n",
      "         -4.3879]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : deserv'd\n",
      "target index is: [66] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4261, -4.7156, -4.5443, -4.3397, -4.0502, -4.7333, -4.6039, -4.3491,\n",
      "         -4.8569, -4.8346, -4.4508, -4.7288, -4.7843, -4.7448, -4.8965, -4.8217,\n",
      "         -4.8380, -4.8456, -4.4873, -4.9236, -4.4276, -4.4630, -4.7748, -4.6471,\n",
      "         -4.2531, -5.0982, -4.6885, -4.5020, -4.3305, -4.6489, -4.2242, -4.7116,\n",
      "         -4.8102, -4.7723, -4.5601, -5.2308, -4.5082, -4.6736, -4.5420, -4.6108,\n",
      "         -4.7955, -4.6097, -4.8476, -4.5491, -4.7988, -4.2816, -4.7437, -4.5677,\n",
      "         -4.7786, -4.4717, -4.8395, -4.3091, -5.1328, -4.4457, -4.5769, -4.4798,\n",
      "         -4.0679, -4.1163, -4.2702, -4.4239, -4.6445, -4.4847, -4.5950, -4.2325,\n",
      "         -4.6373, -4.4479, -4.6316, -4.2880, -4.5357, -4.3413, -4.5374, -4.4895,\n",
      "         -5.2588, -4.9305, -4.8646, -4.9628, -4.9537, -3.9860, -4.6637, -4.8803,\n",
      "         -4.5891, -4.4910, -4.8816, -4.8599, -4.6613, -4.2942, -4.1915, -4.6436,\n",
      "         -5.1964, -4.3171, -4.4473, -4.5148, -4.7459, -4.7122, -4.2701, -4.8379,\n",
      "         -4.4076]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2961, -4.2360, -4.9242, -4.6751, -4.2350, -4.7552, -4.8682, -4.2123,\n",
      "         -5.0409, -4.7847, -5.3246, -4.5170, -4.4109, -4.6554, -4.6036, -4.7740,\n",
      "         -4.4962, -4.5398, -4.3865, -4.4378, -4.6391, -4.2677, -4.7218, -4.7189,\n",
      "         -4.3431, -5.0152, -4.3222, -4.4662, -4.5651, -4.6445, -4.7408, -4.7957,\n",
      "         -5.2310, -4.7116, -4.6301, -5.0740, -4.7189, -4.7913, -5.0160, -4.8351,\n",
      "         -4.8705, -4.7152, -4.7987, -4.5977, -4.7527, -4.0178, -4.8493, -4.9176,\n",
      "         -4.8532, -4.4964, -4.8409, -4.3328, -4.5350, -4.2078, -4.4831, -4.7666,\n",
      "         -4.3073, -4.1915, -4.5794, -4.5857, -4.7531, -4.6765, -4.1216, -4.4141,\n",
      "         -4.4558, -4.7230, -4.8842, -4.2289, -4.8235, -4.7735, -4.3312, -4.5220,\n",
      "         -4.7884, -4.8279, -4.7198, -4.6398, -4.3381, -4.3277, -4.3181, -4.7372,\n",
      "         -4.0106, -4.6609, -4.7733, -5.0922, -4.6381, -4.4108, -4.7213, -4.8987,\n",
      "         -4.7720, -4.4177, -4.5846, -4.7557, -4.9599, -4.3121, -3.8509, -4.9456,\n",
      "         -4.1650]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty's\n",
      "target index is: [80] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2949, -4.4853, -4.7339, -4.5386, -4.2106, -4.9352, -4.5369, -4.3074,\n",
      "         -4.4084, -5.1367, -4.9715, -4.1632, -4.6437, -4.7360, -4.6135, -4.7510,\n",
      "         -4.8953, -5.1609, -4.5291, -4.4096, -4.9414, -4.7520, -4.5868, -4.4927,\n",
      "         -4.2106, -4.6564, -4.6577, -4.4474, -3.8551, -4.5781, -4.8054, -4.5900,\n",
      "         -4.7160, -4.5959, -4.6551, -5.1464, -4.8561, -4.6190, -4.6633, -4.5244,\n",
      "         -4.6893, -4.2474, -4.9912, -4.0636, -4.5032, -4.0944, -4.4554, -4.4849,\n",
      "         -4.5157, -4.8971, -4.7706, -4.4582, -4.7514, -4.3683, -4.6217, -4.4123,\n",
      "         -4.3146, -4.2819, -4.7351, -5.0352, -4.8368, -4.1916, -4.4873, -4.1092,\n",
      "         -5.0411, -4.8072, -5.0748, -4.6809, -4.8123, -4.6192, -4.3113, -4.7577,\n",
      "         -4.5111, -4.8547, -4.7956, -4.9134, -5.1560, -4.1423, -4.4804, -4.4649,\n",
      "         -4.7638, -4.3230, -5.2037, -4.7638, -4.8744, -4.1076, -4.6148, -5.0079,\n",
      "         -5.0440, -4.5882, -5.2021, -4.4835, -4.5737, -4.5062, -4.2725, -4.3319,\n",
      "         -4.5542]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : use,\n",
      "target index is: [11] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1463, -4.6041, -5.0119, -5.2885, -3.7564, -5.0909, -4.6968, -4.6578,\n",
      "         -4.6988, -4.6031, -4.9240, -4.7865, -5.2625, -4.7802, -4.6719, -4.8529,\n",
      "         -5.0191, -4.4870, -4.7586, -4.3346, -4.8331, -4.1597, -5.1802, -4.6681,\n",
      "         -4.3302, -4.8807, -4.2301, -4.2164, -4.0665, -5.0336, -4.7193, -4.5815,\n",
      "         -4.8028, -4.6830, -4.9655, -5.1906, -5.0860, -4.7562, -5.1012, -4.7224,\n",
      "         -4.6892, -5.3303, -4.8920, -4.6177, -4.7131, -4.4412, -4.8074, -4.3491,\n",
      "         -4.4474, -4.8479, -3.9557, -5.5059, -4.2761, -4.5220, -4.8736, -4.3315,\n",
      "         -4.5257, -4.3770, -4.3184, -4.2346, -4.6588, -4.3555, -4.3662, -3.6660,\n",
      "         -4.5680, -4.8448, -4.9038, -4.9135, -4.3656, -4.4928, -4.2350, -4.6286,\n",
      "         -5.0959, -4.5634, -4.7119, -4.8249, -4.0714, -4.6564, -4.6069, -4.4959,\n",
      "         -4.5648, -4.0374, -5.4882, -5.0815, -4.5921, -4.6027, -4.6482, -5.0116,\n",
      "         -4.7751, -4.3559, -4.2916, -4.4333, -4.6255, -4.0640, -4.2807, -4.6108,\n",
      "         -4.6143]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : If\n",
      "target index is: [61] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7191, -4.3146, -4.8920, -4.9716, -4.4721, -4.7818, -4.7537, -4.2915,\n",
      "         -4.6216, -4.7824, -4.8077, -4.1639, -4.7385, -4.4728, -4.8549, -4.8410,\n",
      "         -4.4012, -4.6290, -4.9103, -4.4716, -4.5085, -4.9149, -4.7907, -4.5933,\n",
      "         -4.5577, -4.8240, -4.5224, -4.2766, -4.3264, -4.4673, -4.4077, -4.7827,\n",
      "         -5.2044, -4.7218, -4.9553, -5.3588, -4.4093, -4.9237, -4.4675, -4.4826,\n",
      "         -4.2698, -4.8409, -4.2692, -4.4731, -4.1938, -4.3689, -4.5214, -4.7941,\n",
      "         -4.5598, -4.8042, -4.2999, -4.3845, -4.5983, -4.3745, -4.5352, -4.5168,\n",
      "         -4.6021, -4.3568, -4.8467, -4.6145, -4.6172, -4.2937, -4.4649, -3.7456,\n",
      "         -4.4150, -4.4117, -4.7381, -4.6540, -4.3110, -3.9952, -4.5031, -4.5648,\n",
      "         -4.8850, -4.8498, -5.0784, -5.0247, -4.8147, -4.0572, -4.7058, -4.7844,\n",
      "         -5.0157, -4.5697, -4.9142, -5.1362, -5.0026, -4.3224, -4.4198, -4.5712,\n",
      "         -5.0558, -4.1757, -4.6911, -4.8684, -4.9495, -4.2791, -4.6546, -4.7978,\n",
      "         -4.6355]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thou\n",
      "target index is: [22] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5433, -4.4337, -4.9594, -4.6279, -4.4131, -4.8848, -4.4465, -4.3835,\n",
      "         -4.4408, -4.7323, -4.6028, -4.4480, -4.7527, -4.8973, -4.5834, -4.5674,\n",
      "         -4.7492, -5.0874, -4.5218, -4.3870, -4.5644, -4.4488, -4.8303, -4.3484,\n",
      "         -4.2532, -4.5853, -4.4720, -4.6776, -4.5145, -4.7229, -4.8940, -4.9384,\n",
      "         -4.6838, -4.7584, -4.3638, -4.5097, -4.5415, -4.6644, -4.7140, -4.5154,\n",
      "         -5.0585, -4.1773, -4.8260, -4.7375, -4.4628, -4.3924, -4.3601, -4.5378,\n",
      "         -4.1491, -5.1387, -4.8630, -4.2785, -4.7328, -4.3759, -4.6893, -4.4460,\n",
      "         -4.5554, -4.4492, -4.5011, -4.7110, -4.7470, -4.4707, -4.3068, -4.4367,\n",
      "         -4.9286, -4.6378, -4.5573, -4.4723, -4.6067, -4.4478, -4.1906, -4.9471,\n",
      "         -4.5270, -4.7229, -4.6744, -4.8792, -4.5116, -4.3850, -4.6767, -4.4155,\n",
      "         -4.6183, -4.5815, -4.8538, -4.4591, -4.5369, -4.5798, -4.7084, -4.7198,\n",
      "         -4.7913, -4.3087, -4.9820, -4.4125, -4.5583, -4.5274, -4.6588, -4.5165,\n",
      "         -4.4825]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : couldst\n",
      "target index is: [47] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4795, -4.3551, -4.4962, -4.7856, -4.2224, -4.8041, -4.7795, -4.3953,\n",
      "         -4.6062, -4.7762, -4.6255, -4.5173, -4.6146, -4.8548, -4.6918, -4.3047,\n",
      "         -4.5642, -4.5308, -4.4563, -4.5787, -4.5224, -4.3235, -4.7025, -4.7753,\n",
      "         -4.2516, -4.5780, -4.4467, -4.6150, -4.3006, -4.6820, -4.5571, -4.8158,\n",
      "         -4.8146, -4.5110, -4.6406, -4.8277, -4.5856, -4.7985, -4.7519, -4.8435,\n",
      "         -4.5931, -4.7417, -4.7719, -4.6834, -4.6027, -4.5768, -4.6482, -4.7779,\n",
      "         -4.5944, -4.6107, -4.4955, -4.6450, -4.5971, -4.5076, -4.7446, -4.6525,\n",
      "         -4.4529, -4.4820, -4.4303, -4.4942, -4.7932, -4.5977, -4.4280, -4.1710,\n",
      "         -4.7495, -4.4758, -4.7953, -4.7153, -4.5021, -4.6014, -4.3735, -4.4152,\n",
      "         -4.7578, -4.8068, -4.7202, -4.7040, -4.3471, -4.3968, -4.7341, -4.6489,\n",
      "         -4.4663, -4.4117, -4.7888, -4.8175, -4.4992, -4.6186, -4.3780, -4.6765,\n",
      "         -4.6115, -4.3272, -4.5302, -4.7608, -4.6463, -4.2744, -4.4364, -4.5936,\n",
      "         -4.5856]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : answer\n",
      "target index is: [53] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3888, -4.7473, -4.7346, -4.7873, -4.2231, -4.5561, -4.6781, -4.2979,\n",
      "         -4.7936, -4.7770, -4.7275, -4.4263, -4.5263, -4.7003, -4.8223, -4.6856,\n",
      "         -4.2621, -4.6302, -4.3727, -4.6935, -4.5782, -4.3893, -4.6102, -4.5242,\n",
      "         -4.2764, -5.0271, -4.3334, -4.7912, -4.5741, -4.5057, -4.5467, -4.7460,\n",
      "         -4.8018, -4.7451, -4.3946, -4.8935, -4.5740, -4.3502, -4.7853, -4.7768,\n",
      "         -4.7930, -4.6446, -4.8011, -4.6577, -4.3810, -4.3294, -4.5371, -4.7169,\n",
      "         -4.7563, -4.3420, -4.7805, -4.4498, -4.8106, -4.3816, -4.5861, -4.5449,\n",
      "         -4.6147, -4.4129, -4.4227, -4.4439, -4.6153, -4.5737, -4.4507, -4.0119,\n",
      "         -4.5533, -4.6181, -4.8079, -4.6220, -4.6384, -4.5758, -4.4131, -4.6107,\n",
      "         -4.8014, -4.6607, -4.8319, -4.7561, -4.3903, -4.3169, -4.5245, -4.9129,\n",
      "         -4.3489, -4.6195, -4.6967, -4.8428, -4.6392, -4.7033, -4.4986, -4.5752,\n",
      "         -5.0924, -4.3252, -4.4310, -4.6842, -4.7531, -4.5236, -4.5067, -4.8153,\n",
      "         -4.3324]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : 'This\n",
      "target index is: [9] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4229, -4.7121, -4.8400, -4.7001, -3.7057, -4.6336, -4.3674, -4.3298,\n",
      "         -4.9149, -4.8386, -4.9018, -4.5870, -4.8783, -4.7662, -4.7662, -4.8084,\n",
      "         -4.4614, -4.8647, -4.6983, -4.5434, -4.4753, -4.3433, -4.8086, -4.4024,\n",
      "         -4.5490, -4.9843, -4.4496, -4.4493, -4.5512, -4.7714, -4.5404, -4.6889,\n",
      "         -4.5829, -4.9477, -4.3099, -4.6449, -4.5448, -4.7520, -4.8467, -4.3801,\n",
      "         -4.8207, -4.2168, -4.7324, -4.3985, -4.6993, -4.1772, -4.5208, -4.5489,\n",
      "         -4.5972, -4.8416, -4.9317, -4.5040, -4.9840, -4.0324, -4.4310, -4.2664,\n",
      "         -4.6236, -4.3267, -4.6651, -4.5660, -4.5060, -4.4547, -4.6631, -4.4670,\n",
      "         -4.4762, -4.6739, -4.4473, -4.2277, -4.6761, -4.7650, -4.3946, -4.6027,\n",
      "         -4.7830, -5.0637, -4.8845, -5.0192, -4.7068, -4.4078, -4.6255, -4.7849,\n",
      "         -4.7423, -4.4848, -4.7026, -4.7918, -4.6472, -4.1988, -4.4093, -4.8388,\n",
      "         -4.9375, -4.4041, -4.6851, -4.4883, -4.6025, -4.6814, -4.5320, -4.7008,\n",
      "         -4.3283]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : fair\n",
      "target index is: [21] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3808, -4.4466, -4.8855, -4.5897, -4.0923, -4.5883, -4.8281, -4.2964,\n",
      "         -4.6778, -4.4127, -4.8316, -4.4859, -4.6111, -4.6590, -4.7618, -4.5897,\n",
      "         -4.6363, -4.4761, -4.6127, -4.3663, -4.5662, -4.2648, -4.8907, -4.8973,\n",
      "         -4.4359, -4.7773, -4.4558, -4.3966, -4.3111, -4.6366, -4.6113, -4.7027,\n",
      "         -4.9779, -4.8092, -4.4861, -4.6608, -4.7787, -4.7902, -5.1391, -4.8304,\n",
      "         -4.7585, -4.5517, -4.4580, -4.6989, -4.4199, -4.2551, -4.5962, -4.8222,\n",
      "         -4.5613, -4.8690, -4.7210, -4.3096, -4.7034, -4.3946, -4.7072, -4.6964,\n",
      "         -4.2712, -4.3621, -4.5166, -4.5850, -4.6683, -4.5394, -4.5780, -4.4724,\n",
      "         -4.4596, -4.7190, -4.6817, -4.5534, -4.8068, -4.6381, -4.3608, -4.6207,\n",
      "         -4.5976, -4.8719, -4.5906, -4.6414, -4.4993, -4.5168, -4.6098, -4.7477,\n",
      "         -4.3412, -4.3367, -4.5300, -4.7156, -4.5780, -4.2638, -4.7749, -4.7500,\n",
      "         -4.7232, -4.3836, -4.8480, -4.8085, -4.7640, -4.2034, -4.3786, -4.6692,\n",
      "         -4.4068]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : child\n",
      "target index is: [5] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3778, -4.4417, -4.9765, -4.6447, -4.1185, -4.7664, -4.5839, -4.6837,\n",
      "         -4.7151, -4.4872, -4.9830, -4.5516, -4.8836, -4.7609, -4.7760, -4.8696,\n",
      "         -4.5836, -4.6759, -4.7947, -4.4809, -4.5507, -4.3648, -4.8774, -4.6333,\n",
      "         -4.7170, -5.2358, -4.5703, -4.4811, -4.1553, -4.7144, -4.4890, -4.7956,\n",
      "         -4.6947, -4.7125, -4.5579, -4.8039, -4.4586, -4.6573, -4.7091, -4.5225,\n",
      "         -4.6491, -4.4622, -4.5102, -4.4110, -4.5579, -4.2597, -4.7202, -4.5862,\n",
      "         -4.6011, -4.9023, -4.7626, -4.6107, -5.0287, -4.3752, -4.4098, -4.2391,\n",
      "         -4.3437, -4.1852, -4.5803, -4.7438, -4.5247, -4.4090, -4.7729, -4.4335,\n",
      "         -4.4414, -4.5709, -4.7603, -4.3141, -4.4533, -4.4000, -4.4167, -4.5550,\n",
      "         -4.8041, -4.9773, -5.0033, -5.2120, -4.8132, -4.2668, -4.5896, -4.7777,\n",
      "         -4.6134, -4.3816, -4.6603, -4.9867, -4.7178, -4.1540, -4.3954, -4.3021,\n",
      "         -4.8685, -4.4416, -4.4356, -4.3846, -4.6420, -4.5331, -4.6265, -4.5733,\n",
      "         -4.1796]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : of\n",
      "target index is: [57] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6087, -4.0662, -4.5695, -4.7162, -4.1039, -4.8161, -4.8191, -4.5377,\n",
      "         -4.7532, -4.8605, -5.0994, -4.4967, -4.5794, -4.5405, -4.6602, -4.5820,\n",
      "         -4.7611, -4.5568, -4.6731, -4.3995, -4.5057, -4.2029, -4.7934, -4.4438,\n",
      "         -4.2551, -4.6028, -4.4819, -4.4579, -4.2421, -4.7531, -4.7076, -4.9756,\n",
      "         -5.0677, -4.5670, -4.7089, -4.7223, -4.8583, -4.8788, -4.8360, -4.7482,\n",
      "         -4.6995, -4.4334, -4.5949, -4.5671, -4.5167, -4.2883, -4.8400, -4.9244,\n",
      "         -4.5177, -4.7558, -4.4913, -4.4728, -4.5951, -4.3056, -4.7755, -4.7259,\n",
      "         -4.4017, -4.4547, -4.4913, -4.5699, -4.8632, -4.8127, -4.4139, -4.2753,\n",
      "         -4.6251, -4.7303, -5.0499, -4.4465, -4.7808, -4.7043, -4.5270, -4.5358,\n",
      "         -4.6353, -4.9320, -4.6110, -4.7182, -4.5309, -4.3930, -4.6661, -4.7986,\n",
      "         -4.1293, -4.3744, -4.6154, -4.6563, -4.4595, -4.3430, -4.5756, -4.8271,\n",
      "         -4.5076, -4.2790, -4.8482, -4.8483, -4.6271, -4.2191, -4.1871, -4.7797,\n",
      "         -4.3367]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : mine\n",
      "target index is: [86] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1044, -4.3444, -4.6086, -5.0195, -4.1357, -4.6360, -4.8074, -4.4958,\n",
      "         -4.6949, -4.7820, -5.0193, -4.3037, -4.9140, -4.5350, -4.5920, -4.7878,\n",
      "         -4.6675, -4.8608, -4.5724, -4.1904, -4.9332, -4.7216, -4.5811, -4.1230,\n",
      "         -4.5150, -4.4844, -4.6777, -4.4695, -4.2000, -4.6277, -4.5806, -4.9972,\n",
      "         -4.7710, -4.5114, -4.6465, -4.6923, -4.6475, -4.7440, -4.8108, -4.7299,\n",
      "         -4.8924, -4.4722, -4.7812, -4.5348, -4.7870, -4.1700, -4.8719, -4.6181,\n",
      "         -4.5580, -4.5978, -4.6567, -4.8701, -4.6178, -4.3547, -4.8124, -4.6679,\n",
      "         -4.3323, -4.4288, -4.6807, -4.5608, -4.5999, -4.6026, -4.4290, -4.3613,\n",
      "         -4.7563, -4.6275, -5.1680, -4.8105, -4.6393, -4.7798, -4.2765, -4.5653,\n",
      "         -4.5853, -4.9101, -4.6080, -4.6012, -4.5836, -4.2244, -4.5807, -4.4859,\n",
      "         -4.6373, -4.2892, -4.7099, -4.7959, -4.6709, -4.4579, -4.4158, -4.4196,\n",
      "         -4.8975, -4.2513, -4.5159, -4.6103, -4.5122, -4.5184, -4.3177, -4.5986,\n",
      "         -4.3952]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Shall\n",
      "target index is: [81] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2548, -4.3828, -4.5777, -5.0843, -4.0483, -4.7211, -4.6804, -4.5532,\n",
      "         -4.7181, -4.9461, -4.7645, -4.2986, -4.6607, -4.7700, -4.7187, -4.6149,\n",
      "         -4.3328, -4.7078, -4.5022, -4.6319, -4.5892, -4.5166, -4.6998, -4.4099,\n",
      "         -4.3894, -4.5365, -4.3697, -4.4570, -4.4089, -4.8519, -4.1571, -5.0087,\n",
      "         -4.5656, -4.6398, -4.5682, -4.9882, -4.4539, -4.6414, -4.8605, -4.9636,\n",
      "         -4.6461, -4.7726, -4.7620, -4.6212, -4.6219, -4.1922, -4.5121, -4.7057,\n",
      "         -4.7626, -4.6537, -4.5607, -4.6036, -4.6748, -4.4359, -4.5754, -4.9881,\n",
      "         -4.5982, -4.6231, -4.5338, -4.4992, -4.6917, -4.5422, -4.6347, -4.1482,\n",
      "         -4.7831, -4.7485, -4.8053, -4.5573, -4.5156, -4.3736, -4.7387, -4.6360,\n",
      "         -4.8282, -4.8203, -4.7185, -4.5357, -4.6212, -4.1830, -4.5134, -4.5126,\n",
      "         -4.5054, -4.3665, -4.7723, -5.0714, -4.5344, -4.5600, -4.1789, -4.5804,\n",
      "         -4.9116, -4.3913, -4.5337, -4.7720, -4.7861, -4.3819, -4.1396, -4.6892,\n",
      "         -4.4606]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : sum\n",
      "target index is: [70] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3098, -4.3865, -4.6879, -4.8267, -4.1850, -4.8754, -4.5383, -4.3693,\n",
      "         -4.6537, -4.7696, -4.7073, -4.3181, -4.5668, -4.9656, -4.8049, -4.6855,\n",
      "         -4.5236, -5.1662, -4.7131, -4.6382, -4.5998, -4.3106, -4.7166, -4.5858,\n",
      "         -4.3053, -4.9723, -4.3058, -4.4734, -4.4678, -4.6323, -4.5721, -4.8897,\n",
      "         -4.8689, -4.9360, -4.3224, -4.4764, -4.7202, -4.4623, -4.6858, -4.5915,\n",
      "         -5.0590, -4.4044, -4.5938, -4.5188, -4.4093, -4.2267, -4.4098, -4.6211,\n",
      "         -4.3340, -4.7926, -4.6050, -4.1280, -4.9616, -4.4378, -4.6937, -4.5500,\n",
      "         -4.6240, -4.4450, -4.5915, -4.9415, -4.8100, -4.5869, -4.6801, -4.3214,\n",
      "         -4.9337, -4.6008, -4.8466, -4.3886, -4.5798, -4.6104, -4.3334, -4.8031,\n",
      "         -4.5500, -4.8271, -4.6599, -4.7977, -4.5640, -4.1688, -4.6416, -4.8284,\n",
      "         -4.3254, -4.6618, -4.5496, -4.6473, -4.2626, -4.5891, -4.4916, -4.6865,\n",
      "         -5.0226, -4.4377, -4.6556, -4.5516, -4.5542, -4.6981, -4.4882, -4.4232,\n",
      "         -4.4110]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : my\n",
      "target index is: [90] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4030, -4.3761, -4.6032, -5.1562, -4.2264, -5.1498, -4.4868, -4.4795,\n",
      "         -4.7341, -4.6292, -5.1285, -4.5770, -4.7416, -4.7705, -4.3767, -4.6243,\n",
      "         -4.6257, -4.6844, -4.9459, -4.3448, -4.8109, -4.2952, -4.7730, -4.6037,\n",
      "         -4.3918, -5.0035, -4.2254, -4.4748, -4.1344, -4.5978, -4.6723, -4.8701,\n",
      "         -4.7858, -4.9083, -4.7376, -4.5680, -4.6783, -4.4151, -4.8720, -4.5249,\n",
      "         -4.9400, -4.7795, -4.8753, -4.3877, -4.8445, -4.3349, -4.8149, -4.6517,\n",
      "         -4.5406, -5.1732, -4.1135, -5.0939, -4.4467, -4.5559, -4.7222, -4.4485,\n",
      "         -4.5361, -4.4416, -4.3138, -5.0237, -4.6040, -4.3708, -4.4855, -4.2765,\n",
      "         -4.6123, -4.3708, -5.0693, -4.5960, -4.4046, -4.5438, -4.6005, -4.6062,\n",
      "         -4.7443, -4.7320, -4.7365, -5.0161, -4.3842, -4.3305, -4.3929, -4.6513,\n",
      "         -4.4268, -4.4975, -4.8313, -4.4465, -4.6498, -4.1767, -4.5194, -4.8507,\n",
      "         -4.4868, -4.6051, -4.3783, -4.5617, -4.7123, -4.3342, -4.6407, -4.3086,\n",
      "         -4.1723]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : count,\n",
      "target index is: [55] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5917, -4.2487, -4.7237, -4.9521, -4.4937, -4.9501, -4.6435, -4.4486,\n",
      "         -4.6175, -4.8802, -4.9735, -4.6547, -4.6980, -4.7550, -4.7320, -4.6545,\n",
      "         -4.5752, -4.5922, -4.8580, -4.6479, -4.6152, -4.6776, -4.9074, -4.3931,\n",
      "         -4.4013, -4.7029, -4.5145, -4.2162, -4.2910, -4.6178, -4.2233, -4.8777,\n",
      "         -5.0172, -4.7903, -4.8459, -4.6431, -4.5666, -4.8103, -4.7240, -4.5086,\n",
      "         -4.6183, -4.6514, -4.3840, -4.5744, -4.4820, -4.2336, -4.9856, -4.6665,\n",
      "         -4.6470, -4.9443, -4.2718, -4.6599, -4.7705, -4.3237, -4.6227, -4.4418,\n",
      "         -4.2160, -4.2418, -4.6527, -4.4580, -4.6023, -4.5352, -4.3160, -4.1570,\n",
      "         -4.5952, -4.5039, -4.9647, -4.4088, -4.2198, -4.1766, -4.4599, -4.5370,\n",
      "         -4.8089, -4.8084, -5.0062, -5.1155, -4.3512, -4.2334, -4.7229, -4.9206,\n",
      "         -4.6900, -4.7307, -4.8503, -4.8547, -4.7578, -4.3017, -4.1943, -4.5570,\n",
      "         -4.7771, -4.3369, -4.3411, -4.9330, -4.7863, -4.3008, -4.5601, -4.7233,\n",
      "         -4.3937]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : and\n",
      "target index is: [44] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6677, -4.4691, -4.7087, -4.6770, -4.1976, -4.9018, -4.4179, -4.2668,\n",
      "         -4.7488, -4.9916, -4.6526, -4.4970, -4.6481, -4.8844, -4.7128, -4.4039,\n",
      "         -4.3162, -4.8225, -4.5509, -4.6789, -4.4893, -4.2878, -4.4497, -4.5412,\n",
      "         -4.2002, -4.8322, -4.4590, -4.5115, -4.7617, -4.4509, -4.6169, -4.8473,\n",
      "         -4.8100, -4.8463, -4.3602, -4.2743, -4.9208, -4.7970, -4.8286, -4.6630,\n",
      "         -4.9751, -4.6252, -4.8653, -4.5624, -4.4472, -4.5306, -4.3168, -4.7961,\n",
      "         -4.2486, -4.5727, -4.6473, -4.3313, -4.8098, -4.1928, -4.5600, -4.5977,\n",
      "         -4.5370, -4.6110, -4.6853, -4.7915, -4.9785, -4.6970, -4.3896, -4.1446,\n",
      "         -4.9430, -4.4671, -4.7169, -4.1392, -4.6701, -4.8342, -4.5498, -4.8776,\n",
      "         -4.3711, -4.6474, -4.7738, -4.8476, -4.3068, -4.4764, -4.7440, -4.4714,\n",
      "         -4.3167, -4.5331, -4.7753, -4.8017, -4.6416, -4.4988, -4.6954, -4.7949,\n",
      "         -4.9649, -4.1365, -4.8684, -4.9364, -4.3401, -4.4326, -4.4857, -4.4519,\n",
      "         -4.5600]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : make\n",
      "target index is: [14] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4580, -4.2529, -4.7349, -5.1343, -4.3435, -4.6399, -4.5914, -4.4176,\n",
      "         -4.6761, -4.6876, -4.7779, -4.5551, -4.8316, -4.6508, -4.4163, -4.5912,\n",
      "         -4.6153, -4.7389, -4.7507, -4.1688, -4.8616, -4.6798, -4.8960, -4.4096,\n",
      "         -4.7072, -4.6875, -4.4221, -4.3600, -4.2889, -4.6676, -4.5711, -4.7944,\n",
      "         -4.8850, -4.7713, -4.4447, -4.4373, -4.5226, -4.9687, -4.7990, -4.6188,\n",
      "         -4.7100, -4.6414, -4.6282, -4.4569, -4.7497, -4.3510, -5.0697, -4.5209,\n",
      "         -4.4135, -4.9796, -4.2271, -4.8783, -4.2503, -4.5609, -4.9931, -4.2630,\n",
      "         -4.5235, -4.3662, -4.8215, -4.4677, -4.5855, -4.6092, -4.3968, -4.4392,\n",
      "         -4.6281, -4.4525, -5.2232, -4.8845, -4.4484, -4.5524, -4.2210, -4.6788,\n",
      "         -4.5729, -4.8387, -4.5044, -4.7830, -4.4715, -4.2751, -4.7165, -4.7193,\n",
      "         -4.6665, -4.6131, -4.6899, -4.7534, -4.5982, -4.4492, -4.4672, -4.5610,\n",
      "         -4.5103, -4.1727, -4.5485, -4.4039, -4.7830, -4.4420, -4.6306, -4.5221,\n",
      "         -4.3716]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : my\n",
      "target index is: [90] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3414, -4.2396, -4.8775, -5.0389, -4.2050, -5.0033, -4.3472, -4.4061,\n",
      "         -4.8218, -4.6813, -4.6765, -4.4008, -4.6237, -4.9838, -4.7734, -4.4791,\n",
      "         -4.3883, -4.8088, -4.7694, -4.6197, -4.8002, -4.1499, -4.7295, -4.9146,\n",
      "         -4.2484, -5.0300, -4.1765, -4.5449, -4.1661, -4.6949, -4.3647, -4.8945,\n",
      "         -4.5970, -4.7193, -4.7396, -4.6609, -4.8501, -4.3505, -5.0189, -4.8339,\n",
      "         -4.7066, -4.9084, -4.6406, -4.5702, -4.5313, -4.3020, -4.5798, -4.8815,\n",
      "         -4.6399, -4.7861, -4.5292, -4.5995, -4.6815, -4.6272, -4.5163, -4.7209,\n",
      "         -4.7561, -4.5065, -4.5053, -4.8705, -4.8097, -4.1608, -4.5008, -4.0274,\n",
      "         -4.7176, -4.8662, -4.8202, -4.5314, -4.4825, -4.0505, -4.7028, -4.7411,\n",
      "         -4.6057, -4.5728, -4.7792, -4.9280, -4.4539, -4.4721, -4.3585, -4.5645,\n",
      "         -4.4638, -4.4854, -4.9999, -4.7472, -4.6156, -4.6334, -4.6550, -4.5739,\n",
      "         -4.6154, -4.2742, -4.5052, -4.7615, -4.8159, -4.2352, -4.3479, -4.4660,\n",
      "         -4.3089]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : old\n",
      "target index is: [84] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.0874, -4.3451, -4.4101, -5.0298, -4.2672, -5.2511, -4.4011, -4.4172,\n",
      "         -4.5121, -4.9269, -4.9699, -4.7977, -4.2666, -4.8084, -4.9280, -4.4202,\n",
      "         -4.5194, -4.5843, -4.8683, -4.7501, -4.7183, -4.2671, -5.0799, -4.7474,\n",
      "         -4.0278, -4.8603, -4.3411, -4.5122, -3.9429, -4.7171, -4.6034, -4.6849,\n",
      "         -4.6428, -4.9832, -4.8693, -4.5975, -4.7853, -4.3300, -4.7317, -4.5544,\n",
      "         -4.8505, -4.4978, -4.7863, -4.2812, -4.5203, -4.4091, -4.8293, -4.5603,\n",
      "         -4.6177, -4.9114, -4.0740, -4.7269, -4.9240, -4.6735, -4.7157, -4.5701,\n",
      "         -4.2502, -4.5479, -4.4086, -4.8297, -4.9499, -4.3695, -4.3881, -4.2882,\n",
      "         -4.7095, -4.7422, -4.8874, -4.5770, -4.4906, -4.3846, -4.5762, -4.4276,\n",
      "         -4.7646, -4.8811, -4.7425, -4.9561, -4.3272, -4.3551, -4.6977, -4.8833,\n",
      "         -4.1238, -4.5661, -4.8275, -4.7464, -4.5007, -4.5025, -4.6113, -4.7773,\n",
      "         -4.8646, -4.5517, -4.5519, -4.6145, -4.6093, -4.4376, -4.8357, -4.3729,\n",
      "         -4.4183]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : excuse,'\n",
      "target index is: [64] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4858, -4.4310, -4.5220, -4.7937, -4.1713, -4.9162, -4.6251, -4.3562,\n",
      "         -4.7545, -4.8097, -4.7439, -4.6525, -4.4947, -4.5031, -4.8298, -4.6247,\n",
      "         -4.7243, -4.2832, -4.6431, -4.6076, -4.4087, -4.6910, -4.4910, -4.7652,\n",
      "         -4.2662, -4.7492, -4.5885, -4.5605, -4.3762, -4.2434, -4.6439, -4.6835,\n",
      "         -4.8909, -4.7479, -4.6646, -5.2255, -4.8060, -4.6701, -4.6035, -4.5256,\n",
      "         -4.3689, -4.7953, -4.8062, -4.6346, -4.5734, -4.5995, -4.5466, -4.4610,\n",
      "         -4.5023, -4.4598, -4.3120, -4.5133, -4.4904, -4.4904, -4.5718, -4.4260,\n",
      "         -4.6172, -4.4500, -4.3803, -4.6153, -4.9426, -4.5267, -4.5346, -3.7578,\n",
      "         -4.6856, -4.4232, -4.6732, -4.3566, -4.5084, -4.6379, -4.6086, -4.5898,\n",
      "         -4.9437, -4.8576, -4.8464, -4.6462, -4.6317, -4.5016, -4.4775, -4.5742,\n",
      "         -4.7420, -4.7024, -4.9453, -4.9306, -4.6711, -4.2223, -4.4210, -4.9576,\n",
      "         -4.8880, -4.1664, -4.4980, -4.7058, -4.5904, -4.5074, -4.6663, -4.5547,\n",
      "         -4.8673]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Proving\n",
      "target index is: [25] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4707, -4.6009, -4.9612, -4.7329, -4.4767, -4.6914, -4.6379, -4.4679,\n",
      "         -4.6057, -4.5668, -4.9521, -4.4068, -4.4469, -4.5168, -4.5420, -4.8637,\n",
      "         -4.5884, -4.8648, -4.3910, -4.5945, -4.5048, -4.4777, -4.7445, -4.5024,\n",
      "         -4.4257, -4.7114, -4.2211, -4.5864, -4.4519, -4.4698, -5.0707, -4.8185,\n",
      "         -4.8205, -4.8212, -4.9805, -5.0134, -4.4643, -4.7193, -4.6193, -4.3633,\n",
      "         -4.7729, -4.5834, -4.6245, -4.6865, -4.3371, -4.3786, -4.7392, -4.8152,\n",
      "         -4.4524, -4.9515, -4.2938, -4.5316, -4.5255, -4.1453, -4.5477, -4.2675,\n",
      "         -4.6970, -4.3731, -4.5543, -4.3695, -4.4863, -4.3438, -4.3829, -4.0319,\n",
      "         -4.4286, -4.5926, -4.7127, -4.7051, -4.9487, -4.1887, -4.0415, -4.5612,\n",
      "         -5.1025, -4.3482, -4.8161, -4.9779, -4.3651, -4.4521, -4.4774, -4.6141,\n",
      "         -4.6945, -4.6191, -4.9236, -4.8911, -4.8846, -4.5566, -5.1137, -4.9992,\n",
      "         -4.8386, -4.4136, -4.6220, -4.6846, -4.7292, -4.2172, -4.6194, -4.8375,\n",
      "         -4.3614]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : his\n",
      "target index is: [49] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6777, -4.3172, -4.9177, -5.1028, -4.2625, -4.5952, -4.2331, -4.3758,\n",
      "         -4.9834, -4.4562, -4.7238, -4.3063, -4.7320, -4.6860, -4.9005, -4.5414,\n",
      "         -4.5027, -4.4747, -4.6938, -4.3395, -4.4686, -4.3876, -4.5165, -4.6437,\n",
      "         -4.6377, -4.7827, -4.4186, -4.5637, -4.7502, -4.5553, -4.7075, -4.5823,\n",
      "         -4.7636, -4.7794, -4.5074, -4.6809, -4.4978, -4.8236, -4.7344, -4.3416,\n",
      "         -4.4166, -4.5060, -4.4742, -4.3122, -4.4811, -4.6829, -4.4643, -4.3863,\n",
      "         -4.3571, -5.1846, -4.4528, -4.7686, -4.3828, -4.3566, -4.6142, -4.5482,\n",
      "         -4.9075, -4.7113, -4.2522, -4.7029, -4.9180, -4.4913, -4.5187, -4.3567,\n",
      "         -4.4637, -4.6621, -4.5344, -4.3804, -4.6717, -4.3011, -4.7654, -4.8909,\n",
      "         -4.7410, -4.8018, -4.6906, -4.9318, -4.3943, -4.5188, -4.3773, -4.4954,\n",
      "         -4.8104, -4.6752, -4.8419, -4.5728, -4.9951, -4.3480, -4.7271, -4.5998,\n",
      "         -4.8354, -4.2842, -4.6271, -4.3012, -4.9307, -4.5425, -4.6972, -4.5991,\n",
      "         -4.5248]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty\n",
      "target index is: [0] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5708, -4.4787, -4.8488, -4.6828, -4.3971, -4.7211, -4.7233, -4.0882,\n",
      "         -4.7805, -4.4633, -4.6224, -4.3335, -4.4036, -4.7486, -4.7734, -4.7167,\n",
      "         -4.6957, -4.4911, -4.3253, -4.4707, -4.5899, -4.4576, -4.7376, -4.9233,\n",
      "         -4.2636, -5.2796, -4.3011, -4.7540, -4.0339, -4.4472, -4.6229, -4.6201,\n",
      "         -4.9897, -4.6965, -4.5304, -5.0296, -4.4633, -4.5991, -4.6441, -4.7913,\n",
      "         -4.7255, -4.6454, -4.7342, -4.7322, -4.6020, -4.4454, -4.7704, -5.0186,\n",
      "         -4.8606, -4.8057, -4.6694, -4.4551, -4.8432, -4.5851, -4.6637, -4.5741,\n",
      "         -4.2508, -4.1118, -4.4261, -4.3742, -4.6666, -4.5476, -4.4806, -4.3974,\n",
      "         -4.4261, -4.6911, -4.6081, -4.7261, -4.6586, -4.3420, -4.4692, -4.4866,\n",
      "         -5.1489, -4.6155, -4.9189, -4.8954, -4.4313, -4.2435, -4.3286, -4.8978,\n",
      "         -4.4263, -4.4290, -4.6913, -4.8168, -4.7808, -4.5078, -4.6981, -4.2805,\n",
      "         -4.7595, -4.5680, -4.6067, -4.5787, -4.8557, -4.3062, -4.6291, -4.6200,\n",
      "         -4.2320]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : by\n",
      "target index is: [62] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.0280, -4.6746, -4.6774, -4.6721, -3.8819, -4.7153, -4.4380, -4.1186,\n",
      "         -4.8953, -4.9222, -4.7099, -4.4818, -4.4166, -4.6917, -4.7662, -4.7948,\n",
      "         -4.4152, -4.6788, -4.5542, -4.8019, -4.7294, -4.4142, -4.9066, -4.7270,\n",
      "         -4.1501, -4.7866, -4.4944, -4.3883, -4.5202, -4.7236, -4.5501, -4.4536,\n",
      "         -4.5552, -4.9546, -4.5818, -5.1336, -4.8025, -4.2392, -4.7130, -4.3792,\n",
      "         -4.6912, -4.4565, -4.8380, -4.3436, -4.5147, -3.9115, -4.5133, -4.7544,\n",
      "         -4.8823, -4.5157, -4.7468, -4.3747, -4.8916, -4.2875, -4.4006, -4.4705,\n",
      "         -4.3120, -4.3908, -4.6826, -4.7814, -4.8386, -4.2395, -4.3522, -4.3620,\n",
      "         -4.5512, -4.8256, -4.5786, -4.2066, -4.9743, -4.6435, -4.7215, -4.7570,\n",
      "         -4.5075, -5.0273, -4.7331, -4.8064, -4.6595, -4.3089, -4.5690, -5.0197,\n",
      "         -4.3419, -4.5023, -5.0199, -5.0104, -4.6781, -4.3058, -4.7581, -5.1021,\n",
      "         -5.1498, -4.6044, -4.8886, -4.7139, -4.5101, -4.5109, -4.6173, -4.8082,\n",
      "         -4.5224]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : succession\n",
      "target index is: [7] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6449, -4.4034, -4.6613, -4.6801, -4.1905, -4.6706, -4.7052, -4.4300,\n",
      "         -4.7039, -4.5659, -4.7148, -4.2480, -4.7741, -4.5056, -4.9662, -4.6661,\n",
      "         -4.6407, -4.4955, -4.8468, -4.5099, -4.3456, -4.5792, -4.8068, -4.8747,\n",
      "         -4.5232, -4.7060, -4.4923, -4.2644, -4.1889, -4.4459, -4.4735, -4.7668,\n",
      "         -4.9388, -4.5465, -4.8834, -5.1999, -4.5436, -4.9384, -4.5332, -4.5187,\n",
      "         -4.3008, -4.6817, -4.4382, -4.7204, -4.2874, -4.5362, -4.3264, -4.8212,\n",
      "         -4.4120, -4.8545, -4.5214, -4.5300, -4.5539, -4.4021, -4.6716, -4.5212,\n",
      "         -4.5806, -4.3516, -4.6009, -4.7200, -4.5023, -4.4163, -4.4154, -3.8997,\n",
      "         -4.3908, -4.5350, -4.5955, -4.5412, -4.4100, -4.1165, -4.3774, -4.4297,\n",
      "         -4.9845, -4.8120, -4.8017, -4.9194, -4.7711, -4.3363, -4.6084, -4.8758,\n",
      "         -4.9731, -4.5336, -4.7116, -4.8885, -4.7379, -4.4166, -4.4517, -4.5944,\n",
      "         -4.9860, -4.4768, -4.7614, -4.6533, -4.7979, -4.6985, -4.5853, -4.9904,\n",
      "         -4.7040]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thine!\n",
      "target index is: [40] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6260, -4.3277, -4.6893, -4.4725, -4.2164, -4.7528, -4.5997, -4.2853,\n",
      "         -4.7142, -4.6441, -4.6322, -4.3985, -4.7087, -4.7269, -4.4823, -4.8276,\n",
      "         -4.8862, -5.0502, -4.6341, -4.5764, -4.5437, -4.5726, -4.6399, -4.5309,\n",
      "         -4.5276, -4.5995, -4.2025, -4.3981, -4.3996, -4.6671, -4.8601, -4.8519,\n",
      "         -4.9185, -4.5623, -4.5114, -4.8765, -4.7721, -4.7684, -4.5721, -4.4323,\n",
      "         -4.7275, -4.6253, -4.6166, -4.5760, -4.6224, -4.4734, -4.5773, -4.5484,\n",
      "         -4.3269, -4.7235, -4.3842, -4.4514, -4.5085, -4.5221, -4.9786, -4.1497,\n",
      "         -4.7686, -4.3026, -4.6933, -4.7627, -4.5183, -4.4917, -4.6236, -4.1895,\n",
      "         -4.8745, -4.5332, -4.7233, -4.6198, -4.7873, -4.6500, -4.1875, -4.7973,\n",
      "         -4.7938, -4.5343, -4.3385, -4.9315, -4.6943, -4.4250, -4.4839, -4.4442,\n",
      "         -4.6860, -4.3518, -4.9291, -4.8272, -4.7315, -4.4265, -4.8782, -4.8030,\n",
      "         -4.7166, -4.3929, -4.7729, -4.3410, -4.5704, -4.2942, -4.5421, -4.2661,\n",
      "         -4.6757]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : This\n",
      "target index is: [1] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4719, -4.3480, -4.7531, -4.7766, -4.2004, -4.5647, -4.7647, -4.4691,\n",
      "         -4.5401, -4.5582, -4.7860, -4.6919, -4.8332, -4.6857, -4.4420, -4.7197,\n",
      "         -4.6103, -4.6133, -4.8342, -4.3952, -4.6885, -4.6204, -5.0670, -4.5042,\n",
      "         -4.5447, -4.6690, -4.5145, -4.4181, -4.2652, -4.7221, -4.5720, -4.7669,\n",
      "         -4.7750, -4.6984, -4.6224, -4.8602, -4.4451, -4.8552, -4.6901, -4.6476,\n",
      "         -4.6122, -4.4083, -4.6436, -4.6417, -4.5859, -4.2421, -4.7485, -4.5641,\n",
      "         -4.3102, -4.7427, -4.4674, -4.7209, -4.6540, -4.5481, -4.7909, -4.4477,\n",
      "         -4.3083, -4.2113, -4.7192, -4.3131, -4.6090, -4.6945, -4.3740, -4.2933,\n",
      "         -4.5575, -4.7609, -4.9108, -4.7637, -4.4729, -4.3606, -4.1734, -4.3413,\n",
      "         -4.9547, -4.8766, -4.6519, -4.8021, -4.4340, -4.3702, -4.7102, -4.6719,\n",
      "         -4.5574, -4.4295, -4.5987, -4.8181, -4.7574, -4.5481, -4.5487, -4.4999,\n",
      "         -4.7486, -4.2905, -4.5702, -4.5587, -4.8838, -4.4131, -4.4840, -4.7523,\n",
      "         -4.4957]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : were\n",
      "target index is: [93] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2669, -4.4740, -4.7719, -4.8933, -3.8267, -4.5478, -4.4139, -4.2805,\n",
      "         -4.6414, -4.8782, -4.6159, -4.4620, -4.6331, -4.9273, -4.7622, -4.5292,\n",
      "         -4.4925, -4.9827, -4.5885, -4.4261, -4.8586, -4.1556, -4.7342, -4.9475,\n",
      "         -4.3526, -4.6835, -4.4029, -4.3516, -4.2761, -4.8634, -4.3955, -4.9210,\n",
      "         -4.6589, -4.6151, -4.3018, -4.8324, -4.9105, -4.5581, -5.1135, -4.7831,\n",
      "         -4.6788, -4.6877, -4.7675, -4.5900, -4.8029, -4.2443, -4.2550, -4.7243,\n",
      "         -4.4733, -4.7595, -4.8383, -4.3361, -4.7731, -4.6211, -4.6110, -4.4416,\n",
      "         -4.3893, -4.3906, -4.4307, -4.7600, -4.6312, -4.4802, -4.8443, -4.0632,\n",
      "         -4.7435, -4.6906, -4.7404, -4.5967, -4.7800, -4.5141, -4.5830, -4.6181,\n",
      "         -4.3294, -4.8072, -4.6641, -4.5192, -4.7368, -4.7057, -4.5976, -4.4411,\n",
      "         -4.6877, -4.5200, -5.0451, -4.7842, -4.2291, -4.6249, -4.4515, -4.7601,\n",
      "         -4.7370, -4.4401, -4.7672, -4.5567, -4.8038, -4.4682, -4.5017, -4.5118,\n",
      "         -4.5372]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : to\n",
      "target index is: [72] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5632, -4.5550, -4.7180, -4.4741, -4.4817, -4.7672, -4.9811, -4.2584,\n",
      "         -4.7128, -4.6997, -4.6266, -4.6384, -4.5474, -4.7242, -4.8052, -4.5591,\n",
      "         -4.7695, -4.2219, -4.6186, -4.5975, -4.3713, -4.4983, -5.0715, -4.8444,\n",
      "         -4.3460, -4.9907, -4.5345, -4.2855, -4.1878, -4.7240, -4.6347, -4.2698,\n",
      "         -5.1013, -4.7818, -4.5728, -5.1698, -4.5271, -4.7109, -4.6215, -4.7385,\n",
      "         -4.4836, -4.5338, -4.5964, -4.5933, -4.5069, -4.3234, -4.7088, -4.7371,\n",
      "         -4.7625, -4.6730, -4.3745, -4.5836, -4.6717, -4.7947, -4.8379, -4.6772,\n",
      "         -3.9742, -4.1245, -4.4982, -4.3277, -4.5452, -4.4548, -4.2865, -4.1569,\n",
      "         -4.4474, -4.5378, -4.8616, -4.9458, -4.4682, -4.4278, -4.1677, -4.1872,\n",
      "         -5.1947, -4.9969, -4.8875, -4.9050, -4.2909, -4.2641, -4.6415, -4.6805,\n",
      "         -4.4746, -4.5680, -4.5695, -4.9874, -4.7777, -4.5756, -4.5387, -4.5256,\n",
      "         -5.0546, -4.5072, -4.6446, -4.6733, -5.0998, -4.2601, -4.5259, -4.8717,\n",
      "         -4.6067]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : be\n",
      "target index is: [24] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2015, -4.8413, -4.8095, -5.0705, -4.0286, -4.8119, -4.6069, -4.2290,\n",
      "         -4.8912, -5.0902, -4.9452, -4.3146, -4.6713, -4.9109, -4.9848, -4.5684,\n",
      "         -3.9747, -5.0242, -4.5827, -5.0322, -4.3704, -4.2094, -4.6396, -4.4766,\n",
      "         -4.2740, -5.0100, -4.0573, -4.6544, -4.5834, -4.7303, -4.1971, -5.3494,\n",
      "         -4.8492, -5.1052, -4.3327, -4.7128, -4.8267, -4.4560, -5.0472, -4.9699,\n",
      "         -5.0684, -4.4255, -4.6628, -4.4834, -4.2378, -4.1015, -4.4667, -4.6851,\n",
      "         -4.5844, -4.4692, -4.4664, -4.1067, -5.2388, -4.3734, -4.7154, -4.6829,\n",
      "         -4.8245, -4.4549, -4.5581, -4.9007, -4.9613, -4.5784, -4.6946, -3.9335,\n",
      "         -4.6368, -4.7489, -4.9802, -4.4487, -4.4009, -4.5195, -4.3324, -4.7495,\n",
      "         -4.6879, -4.8311, -4.6855, -4.8626, -4.7514, -4.0575, -4.6499, -5.0119,\n",
      "         -4.1232, -4.8221, -4.7023, -4.6677, -4.3297, -4.8299, -4.3059, -4.9201,\n",
      "         -4.9963, -4.4577, -4.3403, -4.6756, -4.7696, -4.5994, -4.3362, -4.6459,\n",
      "         -4.3085]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : new\n",
      "target index is: [27] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5513, -4.4782, -4.3587, -4.7205, -4.1741, -4.7265, -4.6570, -4.3853,\n",
      "         -4.6069, -4.6470, -4.8564, -4.5212, -4.6253, -4.7414, -4.5869, -4.6397,\n",
      "         -4.5264, -4.5600, -4.4757, -4.6098, -4.7725, -4.6175, -4.5504, -4.4792,\n",
      "         -4.3904, -4.6458, -4.4689, -4.6470, -4.4672, -4.4132, -4.5099, -4.6463,\n",
      "         -4.8422, -4.7151, -4.5588, -4.7084, -4.6457, -4.6816, -4.5730, -4.7022,\n",
      "         -4.6601, -4.5406, -4.9785, -4.6331, -4.7123, -4.6045, -4.6591, -4.5566,\n",
      "         -4.5401, -4.3646, -4.3162, -4.5378, -4.6708, -4.3336, -4.7257, -4.4776,\n",
      "         -4.5316, -4.6077, -4.5249, -4.6561, -4.7274, -4.6069, -4.5594, -4.0968,\n",
      "         -4.9823, -4.4575, -4.8744, -4.4344, -4.6998, -4.9962, -4.5795, -4.6024,\n",
      "         -4.7183, -4.7528, -4.6548, -4.6933, -4.4827, -4.4385, -4.4755, -4.8253,\n",
      "         -4.4372, -4.3443, -4.6054, -4.7748, -4.6908, -4.3204, -4.5703, -4.7690,\n",
      "         -4.7741, -4.1800, -4.6025, -4.8204, -4.3858, -4.5555, -4.3763, -4.4145,\n",
      "         -4.6963]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : made\n",
      "target index is: [16] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3557, -4.6290, -4.7537, -4.8511, -4.2423, -4.6783, -4.4193, -4.5256,\n",
      "         -4.6839, -4.4005, -4.8801, -4.4653, -4.6666, -4.5537, -4.6939, -4.8137,\n",
      "         -4.4563, -4.7055, -4.5971, -4.5990, -4.3466, -4.3809, -4.7168, -4.5625,\n",
      "         -4.6472, -5.1468, -4.1439, -4.6869, -4.6160, -4.7370, -4.5329, -4.8842,\n",
      "         -4.5582, -4.9322, -4.5157, -4.9676, -4.5321, -4.3607, -4.6383, -4.4045,\n",
      "         -4.6407, -4.5330, -4.5425, -4.4155, -4.4711, -4.4612, -4.6997, -4.5277,\n",
      "         -4.5855, -4.8519, -4.3721, -4.7962, -4.8223, -4.4892, -4.6128, -4.4257,\n",
      "         -4.7834, -4.5488, -4.4028, -4.5938, -4.5591, -4.5029, -4.5837, -4.2383,\n",
      "         -4.3329, -4.8678, -4.8034, -4.3660, -4.6099, -4.3926, -4.5670, -4.6717,\n",
      "         -4.8195, -4.6955, -4.7649, -4.8742, -4.5007, -4.3784, -4.3202, -4.6011,\n",
      "         -4.4551, -4.5890, -4.7425, -4.7497, -4.7825, -4.4018, -4.7384, -4.5228,\n",
      "         -4.9519, -4.6515, -4.3450, -4.5957, -4.6641, -4.5327, -4.5277, -4.4650,\n",
      "         -4.3270]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : when\n",
      "target index is: [85] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4544, -4.5644, -4.8393, -4.7606, -4.2410, -4.6461, -4.2775, -4.3736,\n",
      "         -4.8782, -4.5459, -4.9286, -4.4682, -4.7265, -4.6050, -4.4798, -4.5265,\n",
      "         -4.2603, -4.6634, -4.7339, -4.4440, -4.4632, -4.3449, -4.7451, -4.7450,\n",
      "         -4.6250, -5.0830, -4.5220, -4.2635, -4.7708, -4.7687, -4.6974, -4.5856,\n",
      "         -4.7158, -5.0376, -4.4712, -4.7553, -4.3659, -4.5739, -4.8708, -4.3695,\n",
      "         -4.5960, -4.6838, -4.6695, -4.3749, -4.5873, -4.1664, -4.7545, -4.8849,\n",
      "         -4.7277, -4.9462, -4.5872, -4.6686, -4.5255, -3.8296, -4.3918, -4.5777,\n",
      "         -4.5932, -4.5580, -4.5796, -4.6119, -4.5929, -4.4966, -4.4212, -4.5725,\n",
      "         -4.4552, -4.4316, -4.8874, -4.1769, -4.7625, -4.5154, -4.6127, -4.8881,\n",
      "         -4.8485, -4.7795, -4.8871, -5.0037, -4.4811, -4.4206, -4.4229, -4.8688,\n",
      "         -4.4931, -4.4464, -4.6375, -4.7314, -4.9170, -4.0638, -4.9597, -4.9310,\n",
      "         -4.8207, -4.4004, -4.4360, -4.6617, -4.7410, -4.4945, -4.4856, -4.7148,\n",
      "         -4.2717]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thou\n",
      "target index is: [22] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6337, -4.5928, -4.9566, -4.6581, -4.1922, -4.7631, -4.4850, -4.7075,\n",
      "         -4.6430, -4.5415, -4.6906, -4.2406, -4.7992, -4.6959, -4.7276, -4.2605,\n",
      "         -4.7235, -4.6511, -4.8147, -4.4916, -4.7690, -4.1735, -4.8111, -4.6018,\n",
      "         -4.2151, -4.7087, -4.7622, -4.3759, -4.3011, -4.3565, -4.7173, -4.5721,\n",
      "         -4.7390, -4.8344, -4.5948, -4.4862, -4.6038, -4.8186, -4.9566, -4.3473,\n",
      "         -4.8929, -4.1904, -4.6494, -4.5476, -4.3882, -4.4987, -4.5692, -4.8075,\n",
      "         -4.3727, -5.1477, -4.7243, -4.6910, -4.6422, -4.2401, -4.6111, -4.4227,\n",
      "         -4.2600, -4.4839, -4.6320, -4.4156, -4.6664, -4.5423, -4.3379, -4.5621,\n",
      "         -4.7342, -4.4656, -4.5820, -4.4430, -4.7803, -4.2538, -4.3017, -4.6413,\n",
      "         -4.8884, -4.8905, -4.7964, -4.9273, -4.5044, -4.6124, -4.7033, -4.6583,\n",
      "         -4.6324, -4.4067, -4.5513, -4.3830, -4.7112, -4.1739, -4.7281, -4.8742,\n",
      "         -4.8263, -4.4356, -4.7944, -4.6623, -4.5761, -4.5920, -4.6332, -4.6210,\n",
      "         -4.6840]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : art\n",
      "target index is: [15] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3582, -4.4690, -4.7629, -4.9253, -4.2506, -4.7777, -4.5855, -4.3877,\n",
      "         -4.6408, -4.8075, -4.6734, -4.4483, -4.4354, -4.7631, -4.7558, -4.2556,\n",
      "         -4.4947, -4.4832, -4.2751, -4.5675, -4.5969, -4.2503, -4.8283, -4.8817,\n",
      "         -4.1925, -4.7131, -4.4230, -4.5407, -4.1910, -4.5801, -4.5364, -4.8459,\n",
      "         -4.8744, -4.6164, -4.5744, -4.9320, -4.6288, -4.6118, -4.9341, -4.9269,\n",
      "         -4.8276, -4.8542, -4.7527, -4.7956, -4.6163, -4.4923, -4.6472, -4.9642,\n",
      "         -4.6020, -4.6635, -4.4456, -4.7777, -4.4989, -4.5172, -4.7611, -4.6675,\n",
      "         -4.3712, -4.4261, -4.4781, -4.4243, -4.6965, -4.3798, -4.3871, -4.1423,\n",
      "         -4.6274, -4.4609, -4.8265, -4.8316, -4.6307, -4.4518, -4.5108, -4.5290,\n",
      "         -4.8983, -4.7278, -4.6196, -4.7959, -4.3820, -4.4257, -4.6559, -4.6534,\n",
      "         -4.4316, -4.4563, -4.9452, -4.8609, -4.4427, -4.6733, -4.5583, -4.6560,\n",
      "         -4.5235, -4.3667, -4.5271, -4.7121, -4.5909, -4.1724, -4.6904, -4.5213,\n",
      "         -4.4826]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : old,\n",
      "target index is: [8] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4431, -4.5508, -4.9784, -4.6909, -4.3248, -4.7140, -4.5455, -4.3363,\n",
      "         -4.7154, -4.5913, -4.7865, -4.3810, -4.5790, -4.9569, -5.0404, -4.9535,\n",
      "         -4.6973, -4.7482, -4.5710, -4.6683, -4.3316, -4.2936, -4.7737, -4.6043,\n",
      "         -4.3689, -5.1317, -4.2975, -4.7060, -4.6475, -4.5908, -4.6908, -4.7796,\n",
      "         -4.6846, -4.8772, -4.4821, -4.8600, -4.7421, -4.3864, -4.5942, -4.3379,\n",
      "         -4.6395, -4.5830, -4.6397, -4.5709, -4.2637, -4.3070, -4.4551, -4.3825,\n",
      "         -4.4805, -4.9160, -4.7726, -4.2607, -4.8867, -4.3752, -4.3334, -4.4008,\n",
      "         -4.5834, -4.2209, -4.2747, -4.7443, -4.7572, -4.4000, -4.4543, -4.2065,\n",
      "         -4.5086, -4.7486, -4.6834, -4.3988, -4.3740, -4.1718, -4.3924, -4.7367,\n",
      "         -4.6511, -4.8669, -4.9317, -4.9429, -4.4520, -4.3453, -4.6725, -4.8153,\n",
      "         -4.6087, -4.7548, -4.8710, -4.7323, -4.5870, -4.5716, -4.5964, -4.8505,\n",
      "         -5.0277, -4.3316, -4.7557, -4.7020, -4.6839, -4.2900, -4.6645, -4.7032,\n",
      "         -4.2833]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : And\n",
      "target index is: [6] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4861, -4.3609, -4.5017, -4.5610, -4.3533, -5.0154, -4.5240, -4.4539,\n",
      "         -4.6454, -4.8005, -4.8430, -4.3749, -4.5518, -4.6323, -4.6465, -4.7096,\n",
      "         -4.6631, -4.6252, -4.9554, -4.5665, -4.4830, -4.5116, -4.6007, -4.5903,\n",
      "         -4.2026, -4.7048, -4.6175, -4.4253, -4.2919, -4.5336, -4.7162, -4.7812,\n",
      "         -4.6537, -4.7232, -4.6164, -4.5415, -4.7815, -4.5909, -4.5550, -4.4083,\n",
      "         -4.8574, -4.3829, -4.7123, -4.4231, -4.4869, -4.3823, -4.4407, -4.6184,\n",
      "         -4.5298, -4.7850, -4.5333, -4.4605, -4.9091, -4.3325, -4.5897, -4.5346,\n",
      "         -4.4358, -4.5721, -4.5671, -4.8043, -4.6907, -4.4901, -4.5277, -4.4033,\n",
      "         -4.7103, -4.6617, -4.7531, -4.2570, -4.7043, -4.6155, -4.6064, -4.6870,\n",
      "         -4.5365, -4.9619, -4.7892, -4.7950, -4.5736, -4.2995, -4.6732, -4.7672,\n",
      "         -4.2827, -4.4549, -4.5931, -4.7177, -4.5472, -4.3143, -4.6028, -4.7668,\n",
      "         -4.8687, -4.5054, -4.7923, -4.7698, -4.2877, -4.5432, -4.5389, -4.5356,\n",
      "         -4.5179]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : see\n",
      "target index is: [67] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4316, -4.5503, -4.7726, -4.9948, -4.4389, -4.7307, -4.5591, -4.4468,\n",
      "         -4.7903, -4.6186, -5.0377, -4.8725, -4.6629, -4.7230, -4.6880, -4.7287,\n",
      "         -4.5367, -4.5459, -4.7163, -4.3811, -4.7637, -4.7243, -4.9548, -4.7281,\n",
      "         -4.6340, -4.9204, -4.5719, -4.3221, -4.3558, -4.7670, -4.5157, -4.7157,\n",
      "         -5.0359, -4.9216, -4.2837, -4.5869, -4.2413, -4.5552, -4.7378, -4.7552,\n",
      "         -4.7676, -4.6140, -4.5703, -4.6173, -4.4924, -4.1031, -4.7993, -4.7157,\n",
      "         -4.7952, -4.8499, -4.2551, -4.5939, -4.6059, -4.3634, -4.7326, -4.7625,\n",
      "         -4.4123, -4.3160, -4.6402, -4.4447, -4.7571, -4.5768, -4.4517, -4.6050,\n",
      "         -4.5572, -4.4624, -5.0867, -4.4400, -4.5370, -4.6839, -4.2527, -4.1512,\n",
      "         -5.0345, -4.9334, -4.7866, -4.8770, -4.3463, -4.1080, -4.4173, -4.7526,\n",
      "         -4.2810, -4.7143, -4.3467, -4.9446, -4.7548, -4.3236, -4.4778, -4.5215,\n",
      "         -4.7267, -4.3162, -4.2531, -4.5416, -4.9438, -4.3810, -4.4390, -4.5580,\n",
      "         -4.1516]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6148, -4.4056, -4.9647, -4.5668, -4.1849, -4.6540, -4.6473, -4.2280,\n",
      "         -5.1301, -4.3834, -4.7454, -4.1957, -4.3152, -4.6016, -4.7726, -4.8527,\n",
      "         -4.3708, -4.5333, -4.3751, -4.5621, -4.6442, -4.3937, -4.3696, -4.7331,\n",
      "         -4.3785, -5.1656, -4.2768, -4.9267, -4.5742, -4.4776, -4.6452, -4.5789,\n",
      "         -4.8333, -4.6343, -4.6025, -5.1063, -4.5921, -4.5270, -4.6093, -4.7170,\n",
      "         -4.4614, -4.7892, -4.8567, -4.6271, -4.4047, -4.1523, -4.5836, -5.0471,\n",
      "         -5.0226, -4.4681, -4.8331, -4.4191, -4.4276, -4.3167, -4.4341, -4.4984,\n",
      "         -4.6455, -4.2660, -4.3163, -4.5355, -4.7346, -4.7250, -4.4361, -4.0190,\n",
      "         -4.4460, -4.6914, -4.7007, -4.4178, -4.8212, -4.5121, -4.6580, -4.6634,\n",
      "         -4.8737, -4.5507, -4.8420, -4.8591, -4.3523, -4.5232, -4.4019, -4.9105,\n",
      "         -4.5348, -4.4633, -4.7642, -4.8186, -4.8318, -4.5745, -4.7747, -4.7308,\n",
      "         -4.9831, -4.4652, -4.6423, -4.7844, -4.8781, -4.3333, -4.2706, -4.9067,\n",
      "         -4.4406]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : blood\n",
      "target index is: [39] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5599, -4.4847, -4.8299, -4.5026, -4.3729, -4.7679, -4.3735, -4.3644,\n",
      "         -4.8391, -4.7560, -4.9712, -4.3806, -4.6943, -4.4639, -4.5218, -4.8760,\n",
      "         -4.6564, -4.8045, -4.3507, -4.4106, -4.7900, -4.8250, -4.6453, -4.4510,\n",
      "         -4.6427, -5.1393, -4.7852, -4.5011, -4.1577, -4.7215, -4.4759, -4.5402,\n",
      "         -4.7225, -4.6912, -4.7028, -5.3084, -4.3755, -4.7082, -4.4498, -4.2687,\n",
      "         -4.4819, -4.4284, -4.6969, -4.1723, -4.7891, -4.1509, -5.0211, -4.6505,\n",
      "         -4.6759, -4.8661, -4.7828, -4.7449, -4.7118, -4.2843, -4.3838, -4.5065,\n",
      "         -4.2693, -4.1046, -4.7171, -4.6679, -4.6441, -4.2216, -4.5825, -4.3480,\n",
      "         -4.5604, -4.5939, -4.6984, -4.2339, -4.6877, -4.1277, -4.4950, -4.6147,\n",
      "         -5.0367, -5.0438, -4.8865, -5.2908, -5.0685, -3.9669, -4.3275, -4.5670,\n",
      "         -5.0576, -4.6128, -5.0060, -5.0639, -5.2656, -4.0466, -4.4460, -4.4944,\n",
      "         -5.2265, -4.3676, -4.8315, -4.5796, -4.7647, -4.5073, -4.4187, -4.5233,\n",
      "         -4.3289]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : warm\n",
      "target index is: [2] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5452, -4.3860, -4.6724, -4.8192, -4.5839, -4.6419, -4.4285, -4.4691,\n",
      "         -4.7646, -5.0566, -4.9586, -4.7913, -4.7285, -4.7934, -4.6114, -4.5061,\n",
      "         -4.7052, -4.9755, -4.5410, -4.2253, -4.8457, -4.2771, -5.1245, -4.4783,\n",
      "         -4.1412, -4.7170, -4.3952, -4.2800, -4.3512, -4.7180, -4.7272, -4.7769,\n",
      "         -4.9382, -4.8449, -4.5870, -4.4272, -4.8088, -4.9411, -4.8831, -4.7180,\n",
      "         -4.8268, -4.5775, -4.6770, -4.5471, -4.7023, -4.3123, -4.8455, -4.8317,\n",
      "         -4.2401, -4.8714, -4.4621, -4.3958, -4.4168, -4.1476, -4.7000, -4.1885,\n",
      "         -4.4803, -4.1298, -4.6853, -4.6750, -4.7837, -4.7532, -4.3571, -4.4006,\n",
      "         -4.8044, -4.4571, -5.1351, -4.5369, -4.6838, -4.3382, -4.1077, -4.6923,\n",
      "         -4.3875, -4.5256, -4.5641, -4.8004, -4.4479, -4.3255, -4.6422, -4.8131,\n",
      "         -4.4490, -4.8337, -4.7563, -4.5694, -4.3456, -4.5837, -4.7850, -5.0660,\n",
      "         -4.5605, -4.1150, -4.6492, -4.5592, -4.7276, -4.7611, -4.3386, -4.6983,\n",
      "         -4.2551]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : when\n",
      "target index is: [85] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4842, -4.3358, -4.7573, -4.9845, -4.2498, -4.7521, -4.3393, -4.4223,\n",
      "         -4.7153, -4.3676, -4.6520, -4.6706, -4.8321, -4.6306, -4.4510, -4.5014,\n",
      "         -4.3009, -4.6411, -4.8031, -4.5817, -4.4916, -4.4346, -4.6843, -4.6820,\n",
      "         -4.5295, -5.0667, -4.4103, -4.3574, -4.8364, -4.6162, -4.6609, -4.5777,\n",
      "         -4.7416, -4.9489, -4.5954, -4.7005, -4.5283, -4.4032, -4.9143, -4.5337,\n",
      "         -4.5524, -4.9269, -4.6608, -4.3622, -4.3970, -4.3807, -4.6886, -4.7928,\n",
      "         -4.5463, -4.6904, -4.4382, -4.8419, -4.6839, -4.2594, -4.6317, -4.6329,\n",
      "         -4.6378, -4.7418, -4.5180, -4.4894, -4.8044, -4.4460, -4.5346, -4.1207,\n",
      "         -4.5202, -4.4485, -4.7409, -4.3182, -4.5710, -4.6303, -4.7674, -5.0713,\n",
      "         -4.9926, -4.2283, -4.7211, -4.9607, -4.4936, -4.7241, -4.5949, -4.6799,\n",
      "         -4.3222, -4.3281, -4.8750, -4.5726, -4.9209, -4.1888, -5.0940, -4.5635,\n",
      "         -4.6179, -4.2193, -4.3049, -4.7298, -4.7733, -4.2244, -4.5175, -4.5798,\n",
      "         -4.6746]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thou\n",
      "target index is: [22] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6346, -4.5943, -4.9510, -4.6587, -4.1933, -4.7634, -4.4799, -4.7079,\n",
      "         -4.6377, -4.5423, -4.6905, -4.2410, -4.8002, -4.6961, -4.7280, -4.2426,\n",
      "         -4.7238, -4.6518, -4.8156, -4.4929, -4.7697, -4.1739, -4.8036, -4.6025,\n",
      "         -4.2160, -4.7092, -4.7637, -4.3770, -4.3020, -4.3571, -4.7181, -4.5731,\n",
      "         -4.7398, -4.8349, -4.5958, -4.4865, -4.6045, -4.8194, -4.9579, -4.3433,\n",
      "         -4.8938, -4.1903, -4.6501, -4.5482, -4.3894, -4.4998, -4.5704, -4.8083,\n",
      "         -4.3736, -5.1485, -4.7253, -4.6922, -4.6433, -4.2413, -4.6126, -4.4240,\n",
      "         -4.2603, -4.4855, -4.6330, -4.4165, -4.6675, -4.5432, -4.3386, -4.5631,\n",
      "         -4.7344, -4.4655, -4.5823, -4.4382, -4.7816, -4.2547, -4.3025, -4.6423,\n",
      "         -4.8890, -4.8918, -4.7971, -4.9285, -4.5052, -4.6135, -4.6996, -4.6587,\n",
      "         -4.6332, -4.4076, -4.5523, -4.3840, -4.7122, -4.1641, -4.7290, -4.8752,\n",
      "         -4.8281, -4.4366, -4.7958, -4.6629, -4.5770, -4.5934, -4.6343, -4.6213,\n",
      "         -4.6854]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : feel'st\n",
      "target index is: [35] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4925, -4.2184, -4.7245, -4.8659, -4.1373, -4.7386, -4.7208, -4.1943,\n",
      "         -4.7837, -4.4855, -4.7064, -4.6307, -4.7607, -4.8417, -4.6876, -4.5538,\n",
      "         -4.6135, -4.3364, -4.6080, -4.4955, -4.5828, -4.5001, -4.5232, -4.8825,\n",
      "         -4.5581, -4.8025, -4.4284, -4.5264, -4.5554, -4.5205, -4.4865, -4.6579,\n",
      "         -4.8641, -4.6392, -4.3127, -4.9178, -4.5163, -4.8150, -4.7633, -4.7788,\n",
      "         -4.5867, -4.8633, -4.5782, -4.6777, -4.4296, -4.4031, -4.4763, -4.6145,\n",
      "         -4.7019, -4.5564, -4.5844, -4.6949, -4.6125, -4.6224, -4.6769, -4.6225,\n",
      "         -4.5698, -4.3647, -4.3929, -4.5134, -4.9260, -4.6066, -4.5378, -4.1868,\n",
      "         -4.5369, -4.5072, -4.5268, -4.5701, -4.5141, -4.6701, -4.6708, -4.5507,\n",
      "         -4.8616, -4.9380, -4.7339, -4.7247, -4.3382, -4.4832, -4.4791, -4.7409,\n",
      "         -4.4940, -4.5004, -4.7232, -4.9022, -4.7620, -4.4127, -4.3876, -4.5601,\n",
      "         -4.5976, -4.1183, -4.4225, -4.5565, -4.8777, -4.3934, -4.5521, -4.6441,\n",
      "         -4.5066]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : it\n",
      "target index is: [88] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5527, -4.3995, -4.7862, -4.7061, -4.1280, -4.8812, -4.6000, -4.2208,\n",
      "         -4.6329, -4.6322, -4.6670, -4.3399, -4.4759, -4.8343, -4.6862, -4.6186,\n",
      "         -4.5349, -5.0279, -4.5438, -4.6541, -4.6792, -4.3742, -4.9964, -4.6304,\n",
      "         -4.1548, -4.8226, -4.1385, -4.6220, -4.0996, -4.6892, -4.6456, -5.2854,\n",
      "         -5.0646, -4.7488, -4.8999, -5.1066, -4.4992, -4.7071, -4.7352, -4.7402,\n",
      "         -4.9493, -4.4274, -4.6300, -4.6201, -4.4949, -4.3065, -4.6751, -4.8603,\n",
      "         -4.4700, -4.7619, -4.6966, -4.1057, -4.9023, -4.3517, -4.8195, -4.4349,\n",
      "         -4.5389, -4.1294, -4.6702, -4.6889, -4.6394, -4.5876, -4.3037, -4.1519,\n",
      "         -4.7348, -4.8386, -4.7539, -4.6604, -4.5312, -4.2566, -4.1479, -4.3381,\n",
      "         -4.8739, -4.7480, -4.7085, -4.7183, -4.7934, -3.9726, -4.6474, -4.7971,\n",
      "         -4.5393, -4.5627, -4.8694, -4.8112, -4.5048, -4.7181, -4.3753, -4.6184,\n",
      "         -4.7880, -4.6313, -4.8784, -4.7576, -4.7440, -4.2996, -4.5607, -4.6500,\n",
      "         -4.2183]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : cold.\n",
      "target index is: [79] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3667, -4.1145, -4.7891, -4.8189, -4.1114, -5.0264, -4.4891, -4.4951,\n",
      "         -4.8306, -4.4843, -4.7932, -4.5575, -4.6865, -4.7628, -5.0651, -4.7207,\n",
      "         -4.6094, -4.1646, -4.8400, -4.4120, -4.7361, -4.3550, -4.6532, -4.8541,\n",
      "         -4.3500, -4.7589, -4.4630, -4.2550, -4.2383, -4.4651, -4.3675, -4.5897,\n",
      "         -4.6863, -4.7398, -4.5276, -4.5123, -4.6854, -4.7494, -4.7276, -4.6948,\n",
      "         -4.6830, -4.5255, -4.5227, -4.3925, -4.4307, -4.2980, -4.4586, -4.7280,\n",
      "         -4.7442, -5.0543, -4.5662, -4.6011, -4.6695, -4.5544, -4.3758, -4.7795,\n",
      "         -4.4303, -4.4453, -4.3215, -4.6763, -4.8647, -4.4253, -4.6005, -4.4973,\n",
      "         -4.5474, -4.9867, -4.5922, -4.2588, -4.5427, -4.4163, -4.6794, -4.6870,\n",
      "         -4.9136, -5.0282, -4.9246, -4.8234, -4.5024, -4.5838, -4.4965, -4.7431,\n",
      "         -4.2619, -4.4891, -4.6260, -4.6647, -4.8873, -4.2680, -4.7960, -4.5640,\n",
      "         -4.7997, -4.4613, -4.6066, -4.5322, -4.7507, -4.5209, -4.4353, -4.6591,\n",
      "         -4.6072]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : winters\n",
      "target index is: [3] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2801, -4.6727, -4.3812, -4.6781, -4.1939, -4.5972, -4.5116, -4.2532,\n",
      "         -4.7483, -4.9127, -4.8432, -4.7921, -4.5401, -4.2572, -4.5738, -4.3826,\n",
      "         -4.1198, -4.6864, -4.6371, -4.8215, -4.8237, -4.6397, -4.6412, -4.5944,\n",
      "         -4.3827, -4.8981, -4.4647, -4.4808, -4.3891, -4.5717, -4.2714, -5.0524,\n",
      "         -4.8989, -4.6473, -4.9395, -4.8950, -4.5756, -4.7029, -5.0252, -4.6843,\n",
      "         -4.9515, -4.3851, -4.8611, -4.3848, -5.0790, -4.3745, -5.1328, -5.1956,\n",
      "         -4.8984, -4.2462, -4.6398, -4.3883, -4.8243, -4.1559, -4.9575, -4.1498,\n",
      "         -4.2816, -4.1393, -4.8647, -4.3955, -4.2920, -4.6489, -4.4625, -4.1126,\n",
      "         -4.5654, -3.9785, -5.3829, -4.5125, -4.8575, -4.6460, -4.5913, -4.2925,\n",
      "         -4.9447, -4.8559, -4.6087, -5.1770, -4.8471, -4.1521, -4.4861, -4.7980,\n",
      "         -4.3203, -4.5723, -4.6898, -5.0558, -4.7516, -4.3746, -4.6947, -4.6493,\n",
      "         -5.1056, -4.3919, -4.3839, -4.6812, -4.6373, -4.6927, -4.4574, -4.7826,\n",
      "         -4.3850]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : shall\n",
      "target index is: [10] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5046, -4.3537, -5.1045, -4.8482, -4.2533, -4.7477, -4.3886, -4.6965,\n",
      "         -4.7586, -4.4435, -4.7340, -4.4103, -4.8056, -4.6799, -5.0421, -4.5071,\n",
      "         -4.7477, -4.5727, -4.6834, -4.4837, -4.5193, -3.9980, -4.6188, -4.5235,\n",
      "         -4.1868, -4.7823, -4.6010, -4.6073, -4.4402, -4.6075, -4.8751, -4.6736,\n",
      "         -4.6046, -4.8313, -4.6972, -4.4344, -4.9353, -4.4949, -5.0136, -4.3859,\n",
      "         -4.9342, -4.7216, -4.6861, -4.7356, -4.3901, -4.4799, -4.6305, -4.6224,\n",
      "         -4.4355, -5.0723, -4.4721, -4.7646, -4.5833, -4.3202, -4.5021, -4.5267,\n",
      "         -4.6703, -4.5261, -4.2205, -4.5720, -4.7912, -4.3970, -4.2565, -4.1519,\n",
      "         -4.4518, -4.7570, -4.6533, -4.5696, -4.6647, -4.1877, -4.3997, -4.7435,\n",
      "         -4.5415, -4.6581, -4.9245, -4.7274, -4.0628, -4.7706, -4.7304, -4.6920,\n",
      "         -4.3783, -4.5232, -4.9334, -4.6324, -4.5873, -4.4274, -4.8517, -4.9669,\n",
      "         -4.7821, -4.3148, -4.6566, -4.9201, -4.6062, -4.2338, -4.6310, -4.7799,\n",
      "         -4.3789]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : besiege\n",
      "target index is: [75] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3726, -4.5292, -4.3923, -4.7739, -4.1086, -4.7801, -4.5518, -4.2637,\n",
      "         -4.6902, -4.7127, -4.9480, -4.6691, -4.6580, -4.5570, -5.0306, -4.6863,\n",
      "         -4.5758, -4.4348, -4.8293, -4.6088, -4.5670, -4.8801, -4.5507, -4.5633,\n",
      "         -4.3817, -4.7091, -4.6757, -4.5952, -4.2901, -4.3696, -4.4937, -4.6025,\n",
      "         -4.7433, -4.7147, -4.8564, -4.7862, -4.6323, -4.6683, -4.6795, -4.4950,\n",
      "         -4.4671, -4.6824, -4.7677, -4.1606, -4.4990, -4.4819, -4.3501, -4.4010,\n",
      "         -4.5354, -4.6032, -4.5647, -4.3361, -4.7687, -4.3855, -4.7293, -4.5591,\n",
      "         -4.5335, -4.4524, -4.4660, -4.6934, -5.0619, -4.4612, -4.6032, -3.8009,\n",
      "         -4.6819, -4.4656, -4.8243, -4.6506, -4.5131, -4.7802, -4.5785, -4.5750,\n",
      "         -4.7909, -4.9323, -4.7651, -4.7362, -4.7255, -4.2355, -4.5839, -4.8821,\n",
      "         -4.6815, -4.5184, -4.6253, -4.9233, -4.7185, -4.2740, -4.3560, -4.7893,\n",
      "         -5.3059, -4.1857, -4.6880, -4.6732, -4.4987, -4.6006, -4.3251, -4.5853,\n",
      "         -4.8317]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1977, -4.5054, -4.7431, -4.9475, -3.9994, -4.6756, -4.8162, -4.4024,\n",
      "         -5.2612, -4.3362, -4.8742, -4.1587, -4.8276, -4.4851, -4.7168, -5.0285,\n",
      "         -4.9168, -4.6293, -4.5326, -4.4693, -4.4922, -4.5412, -4.7452, -4.5062,\n",
      "         -4.8763, -4.8486, -4.0927, -4.6057, -4.5672, -4.5738, -4.6162, -4.9016,\n",
      "         -4.9016, -4.6099, -4.5393, -5.1965, -4.5692, -4.9905, -4.7992, -4.6568,\n",
      "         -4.8680, -4.9655, -4.7535, -4.5742, -4.6513, -4.3273, -4.8760, -4.8283,\n",
      "         -4.8080, -4.6843, -4.3601, -5.0545, -4.3290, -4.4286, -5.0537, -4.2318,\n",
      "         -4.8156, -4.4511, -4.4493, -4.2278, -4.3024, -4.3666, -4.6498, -3.9548,\n",
      "         -4.3557, -4.6981, -5.0499, -4.6360, -4.6904, -4.7344, -4.3278, -4.8120,\n",
      "         -5.2089, -4.6536, -4.4878, -4.9373, -4.3194, -4.2902, -4.3003, -4.5481,\n",
      "         -4.5722, -4.2818, -4.9578, -4.9753, -4.6649, -4.3996, -4.4416, -4.5423,\n",
      "         -4.8299, -4.5866, -4.0521, -4.4214, -4.5949, -4.4721, -4.1520, -4.6512,\n",
      "         -4.5920]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : brow,\n",
      "target index is: [13] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4329, -4.3131, -4.6080, -4.6432, -4.2903, -4.8740, -4.6705, -4.4247,\n",
      "         -4.7258, -4.7736, -4.8419, -4.4795, -4.8132, -4.4004, -4.7574, -4.8906,\n",
      "         -4.6839, -4.7351, -4.4952, -4.4834, -4.8028, -4.9171, -4.6798, -4.3276,\n",
      "         -4.6110, -4.8178, -4.7354, -4.2705, -4.0950, -4.3749, -4.2435, -4.7449,\n",
      "         -4.8837, -4.5888, -4.9329, -5.0276, -4.5391, -4.9010, -4.3443, -4.3697,\n",
      "         -4.7213, -4.6033, -4.4772, -4.1480, -4.5573, -4.1532, -4.7445, -4.8228,\n",
      "         -4.5745, -4.8039, -4.8707, -4.4761, -4.8846, -4.1542, -4.6156, -4.4218,\n",
      "         -4.4032, -4.0419, -4.7433, -4.6251, -4.8853, -4.4417, -4.5679, -4.1421,\n",
      "         -4.7737, -4.5903, -5.0672, -4.5527, -4.5936, -4.4346, -4.3948, -4.5565,\n",
      "         -4.8440, -4.9129, -4.8188, -5.0426, -5.0529, -3.8611, -4.6309, -4.9910,\n",
      "         -4.9723, -4.5440, -4.7314, -5.0351, -5.0236, -4.3709, -4.3750, -4.5338,\n",
      "         -4.9305, -4.0148, -4.8412, -4.5970, -4.6644, -4.5710, -4.3161, -4.8468,\n",
      "         -4.3232]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : And\n",
      "target index is: [6] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3965, -4.3153, -4.6392, -4.8013, -4.1984, -4.8278, -4.7233, -4.5172,\n",
      "         -4.8404, -4.5854, -4.4756, -4.3434, -4.8790, -4.9165, -4.3709, -4.8763,\n",
      "         -4.8751, -4.9983, -4.5123, -4.4024, -4.4215, -4.3933, -4.6795, -4.6203,\n",
      "         -4.6478, -4.7061, -4.2885, -4.4263, -4.3277, -4.9559, -4.5469, -5.2319,\n",
      "         -4.7571, -4.6671, -4.4655, -4.8320, -4.6541, -4.9057, -4.7565, -4.6297,\n",
      "         -4.8229, -4.9733, -4.7788, -4.7046, -4.6901, -4.4897, -4.5308, -4.5989,\n",
      "         -4.4932, -4.9956, -4.5238, -4.6709, -4.3980, -4.7180, -5.1825, -4.5819,\n",
      "         -4.5773, -4.4624, -4.4600, -4.6077, -4.6150, -4.5329, -4.8996, -4.2301,\n",
      "         -4.9678, -4.6640, -4.9568, -4.6123, -4.6467, -4.6776, -4.0950, -4.8439,\n",
      "         -5.0565, -4.5397, -4.2704, -4.8081, -4.6710, -4.3527, -4.6444, -4.2168,\n",
      "         -4.5578, -4.0260, -4.8946, -4.6685, -4.3744, -4.4180, -4.5194, -4.5406,\n",
      "         -4.7819, -4.3184, -4.5572, -4.5347, -4.2708, -4.1096, -4.1302, -4.4041,\n",
      "         -4.5037]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : dig\n",
      "target index is: [42] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4124, -4.6316, -4.6978, -4.9397, -4.2432, -4.8264, -4.6769, -4.5333,\n",
      "         -4.5255, -4.6735, -4.8461, -4.9850, -4.7258, -4.8199, -4.5527, -4.7189,\n",
      "         -4.6795, -4.7381, -4.7014, -4.4087, -4.8404, -4.4928, -5.0423, -4.6947,\n",
      "         -4.4334, -4.9588, -4.4960, -4.4934, -4.1309, -4.7803, -4.5177, -4.8248,\n",
      "         -4.8834, -4.8182, -4.2452, -4.5069, -4.3733, -4.6672, -4.8347, -4.7242,\n",
      "         -4.8093, -4.4340, -4.7389, -4.6393, -4.6405, -4.2666, -4.9023, -4.4983,\n",
      "         -4.6508, -4.8556, -4.3756, -4.7542, -4.6167, -4.5207, -4.7297, -4.5843,\n",
      "         -4.2281, -4.2325, -4.6273, -4.4171, -4.5697, -4.6656, -4.6744, -4.6262,\n",
      "         -4.6579, -4.3756, -4.9746, -4.5719, -4.6210, -4.7812, -4.2325, -4.1945,\n",
      "         -5.0117, -4.8482, -4.7478, -4.7784, -4.5967, -4.1839, -4.6026, -4.4801,\n",
      "         -4.4087, -4.4773, -4.4824, -4.9646, -4.5041, -4.3438, -4.3095, -4.4411,\n",
      "         -4.6964, -4.2068, -4.4469, -4.4337, -4.7594, -4.4263, -4.5820, -4.4170,\n",
      "         -4.2761]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : deep\n",
      "target index is: [76] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5665, -4.9028, -4.6990, -4.6226, -4.2539, -4.8156, -4.3725, -4.1788,\n",
      "         -4.7142, -5.0022, -4.8029, -4.4383, -4.5730, -4.8829, -4.7954, -4.3001,\n",
      "         -4.2432, -4.8090, -4.4516, -4.9201, -4.4909, -4.2356, -4.5869, -4.7253,\n",
      "         -4.1402, -4.9018, -4.4508, -4.7072, -4.6761, -4.4690, -4.7319, -4.6622,\n",
      "         -4.9001, -4.9233, -4.4134, -4.6214, -4.9745, -4.5169, -5.0101, -4.7227,\n",
      "         -4.8357, -4.6683, -4.8788, -4.5422, -4.3965, -4.3387, -4.5175, -4.6214,\n",
      "         -4.4761, -4.3144, -4.5034, -4.1702, -4.7377, -4.4262, -4.5855, -4.4633,\n",
      "         -4.5312, -4.5548, -4.5086, -4.6600, -5.0311, -4.6776, -4.5491, -3.9402,\n",
      "         -4.6902, -4.4623, -4.8895, -4.4140, -4.6915, -4.5815, -4.3926, -4.7163,\n",
      "         -4.6000, -4.5111, -4.6183, -4.9166, -4.4959, -4.5847, -4.7664, -4.7180,\n",
      "         -4.1293, -4.7836, -4.6989, -4.6354, -4.3468, -4.5386, -4.6691, -5.0650,\n",
      "         -4.9444, -4.3711, -4.4964, -4.7056, -4.6875, -4.4323, -4.4755, -4.4557,\n",
      "         -4.5686]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : trenches\n",
      "target index is: [54] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4353, -4.5351, -4.9338, -5.3991, -4.0920, -4.6604, -4.4282, -4.4249,\n",
      "         -4.8187, -4.4114, -4.8978, -4.4180, -4.8007, -4.7842, -4.9659, -4.7142,\n",
      "         -4.4752, -4.6430, -4.6944, -4.6389, -4.5483, -4.2706, -4.8163, -4.5640,\n",
      "         -4.4393, -4.8827, -4.1783, -4.5648, -4.5785, -4.7059, -4.4918, -5.0542,\n",
      "         -4.9207, -4.9304, -4.5010, -4.5729, -4.3573, -4.7370, -5.0248, -4.6893,\n",
      "         -4.8536, -4.8027, -4.5753, -4.5356, -4.4127, -4.4745, -4.5259, -4.7416,\n",
      "         -4.4156, -5.1659, -4.1533, -4.7768, -4.6166, -4.3905, -4.4876, -4.6698,\n",
      "         -4.9249, -4.6152, -4.2864, -4.4730, -4.6804, -4.3753, -4.5030, -4.1423,\n",
      "         -4.5124, -4.6392, -4.7030, -4.5073, -4.4548, -4.3585, -4.6419, -4.7379,\n",
      "         -5.2059, -4.5895, -4.8565, -5.0574, -4.2559, -4.2312, -4.2809, -4.5450,\n",
      "         -4.5397, -4.5487, -4.6387, -4.5333, -4.6750, -4.4005, -4.5436, -4.7031,\n",
      "         -4.6820, -4.6543, -4.0708, -4.5702, -4.7267, -4.2773, -4.5912, -4.6727,\n",
      "         -4.4942]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : in\n",
      "target index is: [95] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7281, -4.4352, -4.5667, -4.5217, -4.1171, -4.6690, -4.6818, -4.1921,\n",
      "         -4.7434, -4.5698, -4.6511, -4.2527, -4.4541, -4.6794, -4.8351, -4.6637,\n",
      "         -4.5815, -4.7367, -4.2141, -4.5243, -4.5219, -4.5717, -4.5622, -4.6465,\n",
      "         -4.2383, -4.9417, -4.4236, -4.8132, -4.3943, -4.4615, -4.7200, -4.7112,\n",
      "         -4.9236, -4.7025, -4.6002, -5.0847, -4.4976, -4.6660, -4.3044, -4.6777,\n",
      "         -4.5061, -4.6006, -4.9538, -4.7063, -4.5164, -4.4036, -4.4758, -4.9126,\n",
      "         -4.8305, -4.5086, -4.6295, -4.1623, -4.6352, -4.2771, -4.7342, -4.4331,\n",
      "         -4.5372, -4.2460, -4.3391, -4.7174, -4.8181, -4.6689, -4.4881, -4.1019,\n",
      "         -4.7956, -4.4543, -4.7175, -4.6087, -4.7912, -4.8464, -4.4592, -4.5383,\n",
      "         -5.0080, -4.8165, -4.8446, -4.8263, -4.6675, -4.3454, -4.4604, -5.0099,\n",
      "         -4.7392, -4.2470, -4.6903, -4.7031, -4.7342, -4.4284, -4.6525, -4.6871,\n",
      "         -4.8467, -4.2542, -4.9039, -4.7553, -4.6128, -4.3467, -4.4961, -4.6172,\n",
      "         -4.5671]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2043, -4.5190, -5.1138, -4.8431, -4.2774, -4.7144, -4.7485, -4.3549,\n",
      "         -5.2709, -4.2340, -4.9049, -4.2180, -4.4678, -4.3244, -5.0065, -5.1150,\n",
      "         -4.6507, -4.6009, -4.6306, -4.4259, -4.5325, -4.5434, -4.5543, -4.6023,\n",
      "         -4.5479, -5.0571, -4.2917, -4.5233, -4.5958, -4.7434, -4.7053, -4.5058,\n",
      "         -4.9883, -4.8276, -4.8368, -5.4024, -4.7087, -4.5560, -4.6386, -4.3083,\n",
      "         -4.5555, -4.6738, -4.3768, -4.4524, -4.2073, -4.1473, -4.7172, -4.7068,\n",
      "         -4.9625, -4.7754, -4.6058, -4.6875, -4.4138, -4.3922, -4.5142, -4.5590,\n",
      "         -4.5728, -4.3091, -4.4345, -4.6023, -4.6871, -4.4216, -4.3302, -4.2556,\n",
      "         -4.0436, -4.8313, -4.8213, -4.5230, -4.6021, -4.2369, -4.3569, -4.6843,\n",
      "         -4.7788, -4.7327, -4.8016, -4.7217, -4.2772, -4.1990, -4.3219, -4.6961,\n",
      "         -4.6498, -4.7680, -4.8427, -5.0385, -5.0853, -4.4314, -4.6956, -4.5127,\n",
      "         -5.1523, -4.6220, -4.4259, -4.7855, -4.9318, -4.4106, -4.2615, -4.8628,\n",
      "         -4.4785]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty's\n",
      "target index is: [80] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2936, -4.4786, -4.7184, -4.5372, -4.2190, -4.9326, -4.5144, -4.2954,\n",
      "         -4.4101, -5.1378, -4.9649, -4.1278, -4.6492, -4.7337, -4.6089, -4.7449,\n",
      "         -4.8926, -5.1665, -4.5353, -4.4160, -4.9464, -4.7465, -4.5692, -4.4989,\n",
      "         -4.2099, -4.6534, -4.6651, -4.4471, -3.8613, -4.5839, -4.8100, -4.5958,\n",
      "         -4.7204, -4.6003, -4.6606, -5.1424, -4.8612, -4.6247, -4.6678, -4.5248,\n",
      "         -4.6858, -4.2536, -4.9863, -4.0700, -4.5014, -4.1017, -4.4617, -4.4773,\n",
      "         -4.5232, -4.8912, -4.7766, -4.4651, -4.7559, -4.3727, -4.6189, -4.4082,\n",
      "         -4.3221, -4.2792, -4.7403, -5.0418, -4.8417, -4.1865, -4.4880, -4.1178,\n",
      "         -5.0349, -4.8124, -5.0792, -4.6763, -4.8177, -4.6243, -4.3117, -4.7631,\n",
      "         -4.5035, -4.8608, -4.7999, -4.9123, -5.1543, -4.1505, -4.4556, -4.4582,\n",
      "         -4.7596, -4.3143, -5.2104, -4.7675, -4.8704, -4.0970, -4.6111, -5.0112,\n",
      "         -5.0466, -4.5960, -5.1880, -4.4898, -4.5784, -4.5065, -4.2785, -4.3352,\n",
      "         -4.5616]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : field,\n",
      "target index is: [77] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-3.9960, -4.1656, -4.7834, -5.6600, -4.0850, -5.1001, -4.5390, -4.4761,\n",
      "         -4.8736, -4.8295, -4.6846, -5.1545, -5.0511, -4.8151, -4.6832, -4.8249,\n",
      "         -4.9200, -4.7145, -4.8454, -4.5328, -4.7476, -4.3619, -4.9876, -4.6680,\n",
      "         -4.5766, -4.8612, -4.3180, -4.0700, -4.1916, -4.9228, -4.2837, -4.7761,\n",
      "         -4.8030, -4.7414, -4.5033, -4.9561, -4.7058, -4.9875, -4.9750, -4.8588,\n",
      "         -4.5717, -5.1611, -4.8335, -4.6569, -4.5338, -4.0870, -5.1083, -4.4315,\n",
      "         -4.6360, -5.0053, -3.8299, -5.2469, -4.3565, -4.8133, -4.8117, -4.4945,\n",
      "         -4.5660, -4.3404, -4.4727, -4.2770, -4.7574, -4.3652, -4.4405, -3.8103,\n",
      "         -4.4813, -4.5307, -4.9539, -4.7384, -4.4438, -4.4626, -4.6141, -4.5033,\n",
      "         -5.3886, -4.7087, -4.8380, -4.8798, -4.3245, -4.1810, -4.3399, -4.5073,\n",
      "         -4.5039, -4.3887, -5.2108, -5.2250, -4.5181, -4.4333, -4.2863, -4.8591,\n",
      "         -4.6137, -4.2602, -4.0883, -4.3480, -4.9432, -4.1687, -4.4867, -4.8692,\n",
      "         -4.4803]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Thy\n",
      "target index is: [73] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3007, -4.5997, -4.7292, -4.6661, -4.2253, -4.9322, -4.6366, -4.1468,\n",
      "         -4.7142, -4.9005, -4.6467, -4.2276, -4.3176, -4.7167, -4.6387, -4.3753,\n",
      "         -4.6787, -4.8271, -4.1424, -4.7019, -4.5346, -4.2721, -4.7798, -4.8171,\n",
      "         -4.1139, -4.8539, -4.5753, -4.7234, -4.0617, -4.4377, -4.7797, -4.7066,\n",
      "         -4.8853, -4.6105, -4.7190, -5.1194, -4.9160, -4.5649, -4.7776, -4.9354,\n",
      "         -4.7653, -4.4428, -4.9635, -4.6718, -4.4946, -4.4279, -4.6194, -5.0975,\n",
      "         -4.6990, -4.5010, -4.6189, -4.2898, -4.7685, -4.4965, -4.7853, -4.4971,\n",
      "         -4.2397, -4.1443, -4.5677, -4.4334, -4.8525, -4.3916, -4.4795, -3.9330,\n",
      "         -4.8208, -4.6529, -4.8049, -4.9002, -4.8984, -4.6651, -4.3549, -4.4449,\n",
      "         -4.8572, -4.6927, -4.7716, -4.9021, -4.5772, -4.3597, -4.6301, -4.7169,\n",
      "         -4.4357, -4.3073, -5.1161, -4.7002, -4.3478, -4.7544, -4.7113, -4.6750,\n",
      "         -4.6856, -4.5866, -4.7253, -4.6431, -4.6936, -4.1603, -4.4989, -4.6100,\n",
      "         -4.4969]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : youth's\n",
      "target index is: [89] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2031, -4.7514, -4.7370, -4.8770, -4.1694, -4.7501, -4.8444, -4.5510,\n",
      "         -4.8251, -5.0031, -4.8921, -4.4175, -4.7286, -4.3707, -5.0343, -4.8563,\n",
      "         -4.6821, -4.6738, -4.6560, -4.6500, -4.3962, -4.5031, -4.4913, -4.5462,\n",
      "         -4.3020, -4.7000, -4.6776, -4.7830, -4.4852, -4.3904, -5.0005, -4.3745,\n",
      "         -4.9398, -4.6728, -4.6763, -5.2090, -4.7859, -4.7528, -4.8147, -4.3110,\n",
      "         -4.6375, -4.6692, -4.9034, -4.3508, -4.3010, -4.4930, -4.4843, -4.4139,\n",
      "         -4.5473, -4.4296, -4.2814, -4.8605, -4.4424, -4.2436, -4.3909, -4.4386,\n",
      "         -4.4956, -4.5119, -4.5542, -4.4890, -4.7432, -4.3627, -4.5106, -3.6752,\n",
      "         -4.3007, -4.3551, -4.8748, -4.6357, -4.7228, -4.6169, -4.3574, -4.6958,\n",
      "         -4.9288, -4.7856, -4.8700, -4.6255, -4.4147, -4.3109, -4.6718, -4.3053,\n",
      "         -4.6772, -4.7456, -4.9808, -5.1877, -4.5854, -4.2921, -4.5003, -5.0492,\n",
      "         -5.2576, -4.2017, -4.4473, -4.7251, -4.6365, -4.4982, -4.4299, -4.7106,\n",
      "         -4.8789]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : proud\n",
      "target index is: [50] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4762, -4.3365, -4.9241, -5.0987, -4.3925, -4.6617, -4.3653, -4.5554,\n",
      "         -5.3719, -4.5226, -4.8958, -4.4391, -4.8834, -4.5266, -4.6181, -5.1470,\n",
      "         -4.9685, -4.7101, -4.5476, -4.0416, -4.4021, -4.3875, -4.8182, -4.4843,\n",
      "         -4.9138, -4.9366, -4.4686, -4.3926, -4.6590, -4.8842, -4.7272, -4.6271,\n",
      "         -4.8791, -4.8605, -4.3575, -5.1387, -4.6125, -5.0038, -4.6701, -4.2023,\n",
      "         -4.3866, -4.6354, -4.6148, -4.4512, -4.5831, -4.2533, -4.8866, -4.2917,\n",
      "         -4.4822, -5.3808, -4.2856, -5.1290, -4.2537, -4.5308, -4.5374, -4.5433,\n",
      "         -4.8394, -4.3998, -4.3905, -4.7519, -4.6580, -4.2480, -4.6542, -4.3884,\n",
      "         -4.3793, -4.8593, -4.8630, -4.2748, -4.6395, -4.2681, -4.4501, -4.8894,\n",
      "         -4.9533, -4.8954, -4.6178, -4.8076, -4.4856, -4.2826, -4.1526, -4.1441,\n",
      "         -4.8200, -4.8130, -5.1078, -4.8066, -5.0164, -4.2787, -4.5550, -4.5704,\n",
      "         -4.7204, -4.3330, -4.3456, -4.1857, -4.8924, -4.5206, -4.2314, -4.6101,\n",
      "         -4.2755]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : livery\n",
      "target index is: [28] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6428, -4.4216, -4.9915, -4.7522, -4.0819, -5.1162, -4.4189, -4.3659,\n",
      "         -4.5731, -4.4928, -4.8638, -4.5802, -4.6994, -4.8459, -4.3203, -4.5765,\n",
      "         -4.8190, -5.0190, -4.7737, -4.3840, -4.7795, -4.1029, -5.0074, -4.8060,\n",
      "         -4.1867, -4.9267, -4.1836, -4.4543, -4.1256, -4.8417, -4.9300, -5.1524,\n",
      "         -4.9208, -4.7988, -4.6641, -4.7867, -4.5866, -4.6888, -5.0547, -4.5140,\n",
      "         -4.9546, -4.5495, -4.7722, -4.7654, -4.7684, -4.3201, -4.6689, -4.8806,\n",
      "         -4.4155, -5.0351, -4.4181, -4.6563, -4.5214, -4.3007, -4.6890, -4.3282,\n",
      "         -4.3335, -4.1652, -4.7122, -4.8873, -4.5286, -4.4295, -4.2243, -4.5225,\n",
      "         -4.5781, -4.5638, -4.7294, -4.7493, -4.7262, -4.2894, -4.2680, -4.4676,\n",
      "         -4.8099, -4.8838, -4.6663, -4.9073, -4.5849, -4.1732, -4.4919, -4.4935,\n",
      "         -4.5143, -4.6398, -4.8954, -4.6809, -4.4853, -4.3456, -4.4545, -4.8400,\n",
      "         -4.4570, -4.5259, -4.8964, -4.5872, -4.7708, -4.3157, -4.5382, -4.5108,\n",
      "         -4.0032]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : so\n",
      "target index is: [69] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3829, -4.3270, -4.9273, -4.7881, -4.2869, -5.0170, -4.6037, -4.4061,\n",
      "         -4.5532, -4.6567, -4.8038, -4.8396, -4.4641, -5.0239, -4.8485, -4.6170,\n",
      "         -4.7385, -4.3457, -4.5601, -4.5822, -4.4131, -4.2815, -5.0164, -4.8286,\n",
      "         -4.2739, -4.9243, -4.3960, -4.5032, -4.2319, -4.6662, -4.8390, -4.7781,\n",
      "         -4.9583, -5.0081, -4.6072, -4.7838, -4.8856, -4.4176, -4.8481, -4.6991,\n",
      "         -4.6470, -4.6694, -4.6449, -4.6064, -4.3567, -4.3050, -4.4928, -4.5477,\n",
      "         -4.5099, -4.8927, -4.5883, -4.4916, -4.8131, -4.3661, -4.4716, -4.6971,\n",
      "         -4.2163, -4.3128, -4.3166, -4.6475, -4.8843, -4.4981, -4.2003, -4.1933,\n",
      "         -4.4071, -4.8464, -4.4818, -4.4580, -4.2865, -4.4443, -4.3163, -4.5163,\n",
      "         -4.8075, -4.8543, -4.9810, -4.8287, -4.2603, -4.5203, -4.8770, -4.8106,\n",
      "         -4.3155, -4.6391, -4.8748, -4.7617, -4.7145, -4.3930, -4.5614, -4.6534,\n",
      "         -4.7420, -4.2700, -4.7385, -4.8668, -4.7576, -4.1607, -4.7046, -4.6580,\n",
      "         -4.3235]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : gazed\n",
      "target index is: [17] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4637, -4.3424, -4.6819, -4.7870, -4.3209, -4.6381, -4.5027, -4.3504,\n",
      "         -4.5783, -4.7463, -4.6884, -4.5608, -4.5863, -4.7142, -4.7678, -4.6301,\n",
      "         -4.4494, -4.6632, -4.6432, -4.5138, -4.6756, -4.6125, -4.6925, -4.6074,\n",
      "         -4.3801, -4.8715, -4.4395, -4.5539, -4.3482, -4.6148, -4.4072, -4.8404,\n",
      "         -4.8748, -4.7597, -4.5857, -4.6770, -4.5898, -4.6144, -4.7008, -4.6001,\n",
      "         -4.6968, -4.5984, -4.4427, -4.4370, -4.5463, -4.2940, -4.6804, -4.5701,\n",
      "         -4.4412, -4.6051, -4.5578, -4.3003, -4.8584, -4.5039, -4.6605, -4.3866,\n",
      "         -4.5737, -4.2696, -4.5653, -4.7119, -4.7454, -4.6291, -4.6804, -4.3397,\n",
      "         -4.6411, -4.6237, -4.8149, -4.4718, -4.5667, -4.5153, -4.4750, -4.4764,\n",
      "         -4.4983, -4.8271, -4.7064, -4.8400, -4.6227, -4.1880, -4.7156, -4.8474,\n",
      "         -4.5977, -4.6280, -4.6868, -4.8196, -4.5113, -4.4829, -4.3113, -4.6597,\n",
      "         -4.6824, -4.3160, -4.6514, -4.5580, -4.8082, -4.5056, -4.5947, -4.5507,\n",
      "         -4.5150]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : on\n",
      "target index is: [87] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4798, -4.6610, -4.6086, -4.6273, -4.2344, -4.6148, -4.3675, -4.2691,\n",
      "         -4.6873, -4.7127, -4.5962, -4.7784, -4.7662, -4.5876, -4.6576, -4.4693,\n",
      "         -4.3093, -4.6360, -4.6796, -4.7245, -4.8045, -4.6629, -4.6261, -4.5135,\n",
      "         -4.4382, -4.7582, -4.5976, -4.5171, -4.6356, -4.4271, -4.4679, -4.6633,\n",
      "         -4.7242, -4.7423, -4.7590, -4.6283, -4.7113, -4.6654, -4.9507, -4.6061,\n",
      "         -4.7184, -4.5326, -4.8192, -4.2964, -4.6601, -4.3828, -4.6156, -4.5769,\n",
      "         -4.4489, -4.3450, -4.7569, -4.4258, -5.1046, -4.2920, -4.6333, -4.3156,\n",
      "         -4.2814, -4.3071, -4.6470, -4.5181, -4.7372, -4.7155, -4.4828, -4.0034,\n",
      "         -4.8165, -4.2803, -4.8196, -4.5404, -4.5846, -4.5716, -4.5235, -4.6670,\n",
      "         -4.6796, -4.4174, -4.5889, -4.8141, -4.6495, -4.5404, -4.8330, -4.8009,\n",
      "         -4.4135, -4.4702, -4.7739, -4.6719, -4.6568, -4.4622, -4.6303, -4.7641,\n",
      "         -4.9312, -4.2556, -4.4985, -4.3331, -4.7456, -4.6542, -4.5258, -4.6821,\n",
      "         -4.7990]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : now,\n",
      "target index is: [63] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4404, -4.6199, -4.8469, -4.9157, -3.8023, -4.5054, -4.5240, -4.5463,\n",
      "         -4.6629, -4.6596, -4.5794, -4.3916, -5.0233, -4.8110, -4.7861, -4.4954,\n",
      "         -4.5781, -4.8109, -4.6312, -4.3983, -4.5757, -4.0935, -4.8387, -4.9094,\n",
      "         -4.6085, -4.9853, -4.6771, -4.3610, -4.3345, -4.7809, -4.4482, -5.0152,\n",
      "         -4.7077, -4.6761, -4.2595, -4.8706, -4.4434, -4.8613, -5.0986, -4.7529,\n",
      "         -4.6705, -4.4797, -4.7088, -4.4857, -4.5739, -4.4082, -4.4088, -4.8860,\n",
      "         -4.5538, -5.1419, -4.7853, -4.5938, -4.4894, -4.4963, -4.5899, -4.4692,\n",
      "         -4.2589, -4.4035, -4.4355, -4.5611, -4.5081, -4.5445, -4.8196, -4.3398,\n",
      "         -4.4750, -4.4075, -4.6528, -4.5720, -4.7046, -4.4284, -4.4470, -4.6283,\n",
      "         -4.9978, -4.8788, -4.6245, -4.8430, -4.9195, -4.4437, -4.6665, -4.4573,\n",
      "         -4.6348, -4.1026, -4.9012, -4.8086, -4.3284, -4.3117, -4.5990, -4.5613,\n",
      "         -4.8546, -4.4311, -4.6603, -4.2168, -4.7103, -4.3494, -4.5915, -4.5582,\n",
      "         -4.6148]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Will\n",
      "target index is: [36] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3964, -4.8065, -4.8181, -4.8698, -4.1052, -4.6229, -4.6443, -4.2896,\n",
      "         -4.5328, -4.7480, -4.6140, -4.6685, -4.5766, -4.8704, -4.9276, -4.2899,\n",
      "         -4.4995, -4.5713, -4.3757, -4.5384, -4.7989, -4.1582, -4.9120, -5.0551,\n",
      "         -4.0377, -5.0288, -4.4258, -4.4282, -4.2313, -4.4306, -4.4954, -4.9001,\n",
      "         -5.0336, -4.9056, -4.3667, -4.6672, -4.6048, -4.6602, -5.0908, -4.7990,\n",
      "         -4.9810, -4.5722, -4.4474, -4.6424, -4.6469, -4.4012, -4.6854, -4.6811,\n",
      "         -4.5800, -4.9019, -4.4252, -4.6117, -4.9004, -4.5972, -4.6391, -4.4588,\n",
      "         -4.1252, -4.2811, -4.3321, -4.5356, -4.9736, -4.7141, -4.4751, -4.4847,\n",
      "         -4.5136, -4.4411, -4.6768, -4.5924, -4.7366, -4.6696, -4.3053, -4.3432,\n",
      "         -4.7951, -4.8876, -4.7251, -4.7539, -4.3870, -4.3362, -4.5707, -4.7794,\n",
      "         -4.4585, -4.6740, -4.6405, -4.7334, -4.4352, -4.4748, -4.5595, -4.7982,\n",
      "         -4.6528, -4.3386, -4.6399, -4.5409, -4.8130, -4.5013, -4.8625, -4.3766,\n",
      "         -4.3169]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : be\n",
      "target index is: [24] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3471, -4.6831, -4.7902, -4.7502, -4.1725, -4.9919, -4.5628, -4.3576,\n",
      "         -4.7505, -4.7783, -4.6408, -4.3078, -4.6912, -5.0085, -5.0760, -4.3678,\n",
      "         -4.4012, -4.7463, -4.6793, -4.9821, -4.3723, -3.9717, -4.4617, -4.6856,\n",
      "         -4.0887, -5.0798, -4.3225, -4.7580, -4.4363, -4.5603, -4.3938, -5.2521,\n",
      "         -4.8259, -4.8163, -4.6079, -4.5477, -4.7012, -4.5555, -4.9604, -4.8401,\n",
      "         -5.0275, -4.7489, -4.6325, -4.6827, -4.3494, -4.5196, -4.4754, -4.7612,\n",
      "         -4.6147, -4.6245, -4.7316, -4.0823, -5.0416, -4.4208, -4.6509, -4.6612,\n",
      "         -4.5206, -4.4447, -4.3397, -4.7209, -4.8949, -4.5406, -4.5792, -4.0718,\n",
      "         -4.6677, -4.5121, -4.8738, -4.4239, -4.3137, -4.4152, -4.2000, -4.6919,\n",
      "         -4.9397, -4.7508, -5.0733, -5.1582, -4.4907, -4.3116, -4.7348, -4.8808,\n",
      "         -4.1613, -4.6003, -4.6695, -4.4972, -4.3144, -4.4615, -4.3919, -4.8799,\n",
      "         -5.0032, -4.5275, -4.1909, -4.7692, -4.5475, -4.4440, -4.5695, -4.5780,\n",
      "         -4.5371]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : a\n",
      "target index is: [46] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3646, -4.5228, -4.6603, -5.3652, -4.1540, -4.6994, -4.2675, -4.0521,\n",
      "         -4.7597, -4.5626, -4.8135, -4.9170, -4.3873, -4.7482, -4.6938, -4.3125,\n",
      "         -4.2056, -4.6267, -4.6807, -4.5748, -4.9950, -4.3586, -4.7853, -4.9518,\n",
      "         -4.2740, -5.2720, -4.2024, -4.4335, -4.3115, -4.6489, -4.4746, -4.7593,\n",
      "         -4.9051, -5.0686, -4.4408, -4.6609, -4.5326, -4.3566, -4.9306, -4.5808,\n",
      "         -4.8684, -4.6043, -4.9715, -4.3427, -4.9215, -4.2449, -4.8697, -4.7680,\n",
      "         -4.7210, -4.7865, -4.1746, -4.6396, -4.5618, -4.5270, -4.6556, -4.5585,\n",
      "         -4.3363, -4.5082, -4.4053, -4.7356, -4.8506, -4.7035, -4.4656, -4.3566,\n",
      "         -4.6290, -4.3610, -4.9975, -4.4018, -4.7658, -4.8051, -4.7441, -4.5240,\n",
      "         -4.8782, -4.8131, -4.6706, -4.8855, -4.4092, -4.3065, -4.1925, -4.7001,\n",
      "         -4.3696, -4.6266, -4.7182, -4.7180, -4.8528, -4.3354, -4.6205, -4.7310,\n",
      "         -4.7252, -4.3567, -4.5420, -4.3915, -5.0738, -4.3648, -4.8065, -4.3079,\n",
      "         -4.3345]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : totter'd\n",
      "target index is: [20] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6942, -4.6789, -4.9462, -4.8724, -4.3875, -4.7992, -4.6329, -4.0660,\n",
      "         -4.8696, -4.5984, -4.8286, -4.2825, -4.3185, -4.6823, -5.0013, -4.6071,\n",
      "         -4.7171, -4.4202, -4.3084, -4.7303, -4.5919, -4.3896, -4.6369, -4.8204,\n",
      "         -4.0358, -5.1530, -4.5154, -4.7617, -4.1840, -4.2753, -4.5171, -4.7971,\n",
      "         -4.8212, -4.9083, -4.8705, -5.1924, -4.6560, -4.5103, -4.7792, -4.5308,\n",
      "         -4.7315, -4.7655, -4.7077, -4.6675, -4.6029, -4.4493, -4.8207, -4.8269,\n",
      "         -4.8073, -4.6917, -4.3823, -4.4926, -4.8221, -4.5415, -4.5412, -4.4298,\n",
      "         -4.3971, -4.2034, -4.2705, -4.3964, -4.7865, -4.4724, -4.4925, -3.9549,\n",
      "         -4.5364, -4.6379, -4.4304, -4.6983, -4.6268, -4.0332, -4.4182, -4.3195,\n",
      "         -5.0649, -4.8371, -4.9993, -5.0017, -4.3084, -4.3498, -4.2783, -4.9006,\n",
      "         -4.6456, -4.6126, -4.9958, -4.6393, -4.8281, -4.5596, -4.6495, -4.7053,\n",
      "         -4.8108, -4.4331, -4.5523, -4.7138, -4.8308, -4.1344, -4.7071, -4.6937,\n",
      "         -4.3168]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : weed\n",
      "target index is: [29] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6063, -4.7396, -4.5383, -4.6622, -4.1479, -4.7628, -4.5085, -4.3231,\n",
      "         -4.6858, -4.8050, -4.6573, -4.6459, -4.6942, -4.8072, -5.0391, -4.8095,\n",
      "         -4.4259, -4.4147, -4.4394, -4.5881, -4.5541, -4.6574, -4.6763, -4.4702,\n",
      "         -4.1887, -4.8291, -4.5492, -4.7150, -4.5695, -4.4595, -4.3111, -4.5944,\n",
      "         -4.5452, -4.7611, -4.6348, -4.7245, -4.3937, -4.5852, -4.3804, -4.6030,\n",
      "         -4.6278, -4.6991, -4.8181, -4.6264, -4.5092, -4.2875, -4.2301, -4.5236,\n",
      "         -4.6534, -4.4880, -4.7366, -4.3229, -4.8659, -4.3930, -4.4461, -4.5385,\n",
      "         -4.4532, -4.2462, -4.3282, -4.6589, -5.0257, -4.5324, -4.5254, -4.2273,\n",
      "         -4.8447, -4.6858, -4.6494, -4.6177, -4.4807, -4.4918, -4.5602, -4.6690,\n",
      "         -4.8345, -4.9242, -4.8243, -4.7779, -4.6030, -4.2466, -4.7454, -4.8855,\n",
      "         -4.6847, -4.5480, -4.6518, -4.5760, -4.7207, -4.5264, -4.4461, -4.7888,\n",
      "         -4.9770, -4.1617, -4.6904, -4.5094, -4.6503, -4.4984, -4.5479, -4.7908,\n",
      "         -4.6205]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : of\n",
      "target index is: [57] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5227, -4.3986, -4.3735, -4.6310, -3.9038, -4.7277, -4.9775, -4.4980,\n",
      "         -4.7179, -4.6025, -4.6316, -4.2480, -4.8568, -4.7740, -4.6296, -4.5766,\n",
      "         -4.5696, -4.9442, -4.4781, -4.7807, -4.4386, -4.1871, -4.5499, -4.4657,\n",
      "         -4.3929, -4.7361, -4.4276, -4.6911, -4.4023, -4.6165, -4.4545, -5.2707,\n",
      "         -4.7161, -4.3230, -4.6606, -5.0153, -4.5869, -4.9082, -4.5245, -4.8676,\n",
      "         -4.7123, -4.8198, -4.7901, -4.6619, -4.4608, -4.4169, -4.4460, -4.9584,\n",
      "         -4.8347, -4.4533, -4.6383, -4.4570, -4.8012, -4.3119, -4.9852, -4.5139,\n",
      "         -4.6684, -4.3934, -4.4887, -4.4552, -4.7547, -4.7750, -4.7155, -3.8309,\n",
      "         -4.7938, -4.6515, -5.0431, -4.6574, -4.6308, -4.7533, -4.3164, -4.5622,\n",
      "         -4.9693, -4.6745, -4.6580, -4.7680, -4.7035, -4.4520, -4.6417, -4.8851,\n",
      "         -4.5983, -4.0845, -4.8161, -4.7648, -4.4351, -4.5722, -4.3934, -4.5814,\n",
      "         -4.9063, -4.1625, -4.6028, -4.7543, -4.5410, -4.4758, -4.0893, -4.8120,\n",
      "         -4.4557]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : small\n",
      "target index is: [38] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3548, -4.2936, -4.6345, -4.8615, -4.3248, -4.7513, -4.5369, -4.5312,\n",
      "         -4.7012, -4.9334, -4.8555, -4.5970, -4.7710, -4.4898, -4.2918, -4.7689,\n",
      "         -4.8303, -5.0272, -4.6077, -4.2459, -4.8099, -4.5566, -4.6125, -4.4146,\n",
      "         -4.7321, -5.0970, -4.7413, -4.4378, -4.0923, -4.6202, -4.4655, -4.9988,\n",
      "         -4.7721, -4.6831, -4.4610, -4.8682, -4.7532, -4.8364, -4.9072, -4.4291,\n",
      "         -4.6404, -4.5925, -4.8676, -4.1383, -4.8444, -4.1613, -5.0128, -4.4152,\n",
      "         -4.4372, -4.8595, -4.9108, -4.7040, -4.7542, -4.4728, -4.6374, -4.6529,\n",
      "         -4.2845, -4.2089, -4.6484, -4.6622, -4.6142, -4.7071, -4.8493, -4.2820,\n",
      "         -4.9852, -4.4825, -5.1399, -4.2455, -4.6837, -4.7745, -4.2205, -4.6909,\n",
      "         -4.7711, -4.6579, -4.8466, -4.7208, -5.0490, -4.3001, -4.5212, -4.2138,\n",
      "         -4.6857, -4.4033, -4.7706, -4.8672, -4.6480, -4.0726, -4.3291, -4.4250,\n",
      "         -5.0284, -4.2322, -4.5192, -4.2562, -4.6518, -4.6013, -4.2393, -4.4047,\n",
      "         -4.3494]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : worth\n",
      "target index is: [83] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6841, -4.6214, -4.7777, -5.0623, -4.2565, -4.8399, -4.3471, -4.5369,\n",
      "         -4.7037, -4.7367, -5.0477, -4.8359, -4.8953, -4.7692, -4.4419, -4.5419,\n",
      "         -4.5402, -4.8639, -4.6282, -4.2413, -4.7735, -3.9773, -5.0639, -4.7063,\n",
      "         -4.1680, -5.1247, -4.2311, -4.0813, -4.5612, -4.5929, -5.0023, -4.9166,\n",
      "         -5.0441, -4.9487, -4.5590, -4.2930, -4.8023, -4.9088, -5.1901, -4.6912,\n",
      "         -4.9865, -5.1865, -4.7546, -4.6177, -4.7147, -4.5119, -4.8060, -5.0007,\n",
      "         -4.3031, -4.8873, -3.9430, -4.7892, -4.1964, -3.9114, -4.9774, -4.0378,\n",
      "         -4.8673, -4.4296, -4.4988, -4.5721, -4.7737, -4.7194, -4.5935, -4.1819,\n",
      "         -4.8517, -4.1725, -5.0758, -4.5788, -4.8779, -4.5783, -4.2347, -4.7767,\n",
      "         -4.8815, -4.2071, -4.5126, -5.0398, -4.4258, -4.4540, -4.7771, -4.7235,\n",
      "         -4.2123, -4.3647, -4.7680, -4.4663, -4.2735, -4.2303, -5.0466, -5.2676,\n",
      "         -4.5254, -4.2657, -4.4984, -4.6920, -4.5390, -4.3526, -4.4388, -4.8007,\n",
      "         -4.2972]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : held:\n",
      "target index is: [19] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3616, -4.3909, -5.0612, -5.0678, -4.0457, -4.9004, -4.3491, -4.5684,\n",
      "         -4.6647, -4.1754, -5.0504, -4.6285, -4.8775, -4.7275, -4.4219, -4.6472,\n",
      "         -4.6174, -4.6818, -5.0038, -4.4591, -4.3673, -4.3874, -4.8844, -4.7374,\n",
      "         -4.8098, -5.2122, -4.4507, -4.4658, -4.6034, -4.6568, -4.7511, -4.6432,\n",
      "         -4.7154, -5.2222, -4.5921, -4.5861, -4.4868, -4.6064, -4.9840, -4.2581,\n",
      "         -4.5961, -4.5835, -4.4845, -4.2518, -4.2590, -4.5983, -4.6884, -4.5402,\n",
      "         -4.2302, -5.3289, -4.3662, -5.0079, -4.7136, -4.3777, -4.7500, -4.5663,\n",
      "         -4.6108, -4.6011, -4.4960, -4.5889, -4.6370, -4.3510, -4.4324, -4.4713,\n",
      "         -4.4496, -4.6186, -4.6787, -4.3141, -4.5817, -4.3527, -4.6072, -4.9872,\n",
      "         -4.8587, -4.5383, -4.8807, -5.3095, -4.1814, -4.7916, -4.5850, -4.7657,\n",
      "         -4.6403, -4.2436, -4.8121, -4.5433, -5.3000, -3.9004, -5.1093, -4.5702,\n",
      "         -4.7187, -4.0434, -4.5562, -4.8317, -4.8221, -4.1508, -4.6291, -4.2861,\n",
      "         -4.2636]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Then\n",
      "target index is: [65] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3850, -4.5139, -4.9020, -4.7429, -3.9550, -4.8581, -4.6135, -4.7514,\n",
      "         -4.8234, -4.6428, -4.7236, -4.6164, -4.7976, -4.6904, -4.7484, -4.5615,\n",
      "         -4.5458, -4.6777, -5.1217, -4.7154, -4.5969, -4.2140, -4.8646, -4.3408,\n",
      "         -4.4134, -4.7420, -4.7836, -4.2954, -4.3302, -4.4079, -4.6902, -4.5566,\n",
      "         -4.7664, -4.9053, -4.5389, -4.2469, -4.6593, -5.0048, -4.9934, -4.4444,\n",
      "         -4.8869, -4.3934, -4.5289, -4.3533, -4.2681, -4.3527, -4.5052, -4.7047,\n",
      "         -4.3333, -4.9805, -4.6782, -4.5426, -4.9533, -4.0356, -4.5710, -4.4103,\n",
      "         -4.3059, -4.4226, -4.7053, -4.3570, -4.7590, -4.6178, -4.5155, -4.3925,\n",
      "         -4.6765, -4.5608, -4.7638, -4.2772, -4.6187, -4.4686, -4.4325, -4.7412,\n",
      "         -4.8237, -4.7739, -4.9275, -4.9627, -4.4369, -4.5247, -4.9642, -4.9986,\n",
      "         -4.4845, -4.2254, -4.4348, -4.5113, -4.8175, -4.0439, -4.8076, -5.0273,\n",
      "         -4.8629, -4.1199, -4.7026, -4.9235, -4.5327, -4.4155, -4.5178, -4.8693,\n",
      "         -4.6953]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : being\n",
      "target index is: [32] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3573, -4.2675, -4.6238, -5.0566, -4.1736, -4.3727, -4.5115, -4.1338,\n",
      "         -4.9693, -4.4564, -4.8390, -4.3402, -4.6629, -4.3942, -5.0166, -4.4210,\n",
      "         -4.4424, -4.4821, -4.7084, -4.0568, -4.8261, -4.7772, -4.4705, -4.5171,\n",
      "         -4.8855, -4.5744, -4.6458, -4.5335, -4.4211, -4.7893, -4.2496, -4.8256,\n",
      "         -4.9067, -4.5936, -4.5211, -4.8027, -4.4856, -4.9787, -4.9221, -4.8200,\n",
      "         -4.7017, -4.7246, -4.5002, -4.1938, -4.4523, -4.1348, -4.7340, -4.7396,\n",
      "         -4.7703, -4.6929, -4.7126, -4.3877, -4.5240, -4.5371, -5.0032, -4.6936,\n",
      "         -4.5628, -4.5993, -4.5326, -4.5650, -4.9089, -4.8346, -4.7781, -4.2412,\n",
      "         -4.5919, -4.5318, -4.9582, -4.5133, -4.6563, -4.8835, -4.5452, -4.6847,\n",
      "         -4.6693, -5.0707, -4.3903, -4.5481, -4.5985, -4.4167, -4.4679, -4.6923,\n",
      "         -4.6326, -4.4077, -4.4294, -4.8837, -4.8116, -4.4613, -4.3646, -4.2134,\n",
      "         -5.0757, -4.3945, -4.6531, -4.4125, -4.9951, -4.5156, -4.4128, -4.4052,\n",
      "         -4.6918]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : asked,\n",
      "target index is: [23] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2003, -4.6024, -4.5022, -4.6471, -4.1066, -4.8305, -4.6694, -4.3768,\n",
      "         -4.6739, -4.5926, -4.6422, -4.3091, -4.6357, -4.6855, -4.6910, -4.7991,\n",
      "         -4.7368, -5.0814, -4.4393, -4.8174, -4.5394, -4.4940, -4.7058, -4.6006,\n",
      "         -4.4128, -4.8559, -4.5291, -4.4925, -4.3353, -4.5476, -4.5853, -4.8126,\n",
      "         -4.6694, -4.5934, -4.7262, -5.0542, -4.5819, -4.4577, -4.4937, -4.6425,\n",
      "         -4.7602, -4.4213, -4.6498, -4.5028, -4.3936, -4.1949, -4.6515, -4.8728,\n",
      "         -4.7793, -4.5096, -4.6025, -4.3409, -4.8911, -4.4604, -4.8159, -4.3833,\n",
      "         -4.5871, -4.2545, -4.3718, -4.6204, -4.7100, -4.5096, -4.6151, -3.9759,\n",
      "         -4.7881, -4.6274, -4.9490, -4.6832, -4.8664, -4.6371, -4.5296, -4.6190,\n",
      "         -4.9184, -4.5117, -4.6536, -4.9618, -4.7509, -4.2631, -4.5103, -4.9286,\n",
      "         -4.5524, -4.1928, -4.9087, -4.6216, -4.4130, -4.5240, -4.6364, -4.5470,\n",
      "         -5.0285, -4.4347, -4.5207, -4.5183, -4.6187, -4.6407, -4.2853, -4.7126,\n",
      "         -4.4562]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : where\n",
      "target index is: [51] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3627, -4.2941, -4.6699, -4.9595, -4.2754, -4.9426, -4.7374, -4.6642,\n",
      "         -4.8793, -4.6505, -4.9533, -4.6072, -4.8338, -4.6073, -4.6453, -4.9605,\n",
      "         -4.6896, -4.5886, -4.9303, -4.5168, -4.6558, -4.5682, -4.8222, -4.5214,\n",
      "         -4.5837, -4.7492, -4.3790, -4.3897, -4.2794, -4.6452, -4.3191, -4.9362,\n",
      "         -4.7368, -4.6767, -4.5146, -4.9866, -4.4719, -4.6589, -4.7784, -4.5641,\n",
      "         -4.6123, -4.7049, -4.6198, -4.5813, -4.5324, -4.1467, -4.7960, -4.5795,\n",
      "         -4.7592, -4.7879, -4.2417, -4.9064, -4.6655, -4.5027, -4.5019, -4.6884,\n",
      "         -4.5453, -4.3712, -4.5625, -4.5322, -4.5495, -4.4283, -4.5218, -4.3913,\n",
      "         -4.4850, -4.7998, -5.0202, -4.3031, -4.3958, -4.3301, -4.6652, -4.5070,\n",
      "         -5.0800, -4.9533, -4.8559, -4.9431, -4.5844, -4.2320, -4.3527, -4.5035,\n",
      "         -4.4031, -4.3878, -4.7354, -4.8864, -4.8360, -4.2387, -4.3253, -4.4897,\n",
      "         -4.7645, -4.4216, -4.2074, -4.7144, -4.6980, -4.3609, -4.2638, -4.5748,\n",
      "         -4.2125]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : all\n",
      "target index is: [52] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4738, -4.2756, -4.6687, -4.7925, -4.4394, -4.8222, -4.4429, -4.4559,\n",
      "         -4.5458, -4.8831, -4.9957, -4.6981, -4.4987, -4.6129, -4.5888, -4.6475,\n",
      "         -4.6404, -4.7327, -4.5888, -4.2157, -4.7922, -4.7572, -4.6951, -4.4859,\n",
      "         -4.3784, -4.8668, -4.5004, -4.4955, -4.2010, -4.8383, -4.4739, -4.7753,\n",
      "         -4.8672, -4.8455, -4.4902, -4.5510, -4.6190, -4.4825, -4.6639, -4.6138,\n",
      "         -4.7354, -4.6125, -4.7428, -4.4974, -4.7697, -4.2101, -4.8367, -4.6393,\n",
      "         -4.5660, -4.8262, -4.4452, -4.4612, -4.6005, -4.3204, -4.7184, -4.5430,\n",
      "         -4.3834, -4.3652, -4.6028, -4.7418, -4.7750, -4.7285, -4.5805, -4.5704,\n",
      "         -4.8017, -4.5309, -5.0765, -4.3654, -4.6391, -4.6449, -4.4448, -4.5090,\n",
      "         -4.5549, -4.8863, -4.6355, -4.6627, -4.5622, -4.2178, -4.4005, -4.6617,\n",
      "         -4.4901, -4.5750, -4.6202, -4.8118, -4.6475, -4.3103, -4.4631, -4.5729,\n",
      "         -4.7109, -4.3303, -4.6250, -4.6468, -4.6562, -4.5339, -4.3437, -4.4692,\n",
      "         -4.2293]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3692, -4.3612, -4.9417, -4.7787, -4.2750, -4.7769, -4.8600, -4.3915,\n",
      "         -5.0854, -4.2671, -5.0081, -4.3902, -4.5168, -4.6245, -4.6634, -4.8215,\n",
      "         -4.5516, -4.4348, -4.4766, -4.4998, -4.6487, -4.3783, -4.5279, -4.7939,\n",
      "         -4.4191, -5.0730, -4.3622, -4.5323, -4.4933, -4.4900, -4.6798, -4.6641,\n",
      "         -4.8431, -4.6694, -4.8939, -5.0919, -4.6969, -4.6355, -4.8796, -4.6127,\n",
      "         -4.6493, -4.7704, -4.6703, -4.6120, -4.5226, -4.1190, -4.8155, -4.7178,\n",
      "         -4.8939, -4.6502, -4.7514, -4.7664, -4.5589, -4.2860, -4.4689, -4.7781,\n",
      "         -4.3066, -4.3768, -4.4546, -4.5324, -4.7035, -4.5327, -4.2684, -4.3155,\n",
      "         -4.2331, -4.7505, -4.7092, -4.2402, -4.5934, -4.3744, -4.4455, -4.6090,\n",
      "         -4.8084, -4.5913, -4.7871, -4.7279, -4.2345, -4.4735, -4.2874, -4.7071,\n",
      "         -4.3841, -4.5660, -4.8034, -5.0555, -4.8593, -4.4465, -4.7405, -4.6354,\n",
      "         -4.8914, -4.4699, -4.5102, -4.7938, -4.8264, -4.3408, -4.0600, -4.8397,\n",
      "         -4.3874]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty\n",
      "target index is: [0] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3631, -4.6881, -4.7628, -4.9172, -4.2186, -4.6885, -4.3869, -4.2060,\n",
      "         -5.1166, -4.4881, -4.7930, -4.4084, -4.2789, -4.5981, -4.8505, -5.0986,\n",
      "         -4.7011, -4.5591, -4.6687, -4.5256, -4.7678, -4.7292, -4.8588, -4.6457,\n",
      "         -4.4513, -5.1938, -4.3720, -4.4455, -4.2200, -4.6793, -4.4959, -4.3462,\n",
      "         -4.7299, -4.9330, -4.6807, -5.1603, -4.3376, -4.5242, -4.3900, -4.3749,\n",
      "         -4.5516, -4.3817, -4.6421, -4.3360, -4.5366, -4.0909, -4.9125, -4.5968,\n",
      "         -4.8519, -4.7824, -4.5151, -4.6690, -4.8269, -4.5500, -4.5819, -4.5788,\n",
      "         -4.4410, -4.3560, -4.5150, -4.4092, -4.7180, -4.4328, -4.3727, -4.4342,\n",
      "         -4.3020, -5.0159, -4.7753, -4.4261, -4.7606, -4.0266, -4.5788, -4.4951,\n",
      "         -5.1121, -4.9196, -4.7611, -4.7412, -4.5889, -3.9118, -4.2423, -4.7700,\n",
      "         -4.6211, -4.7824, -4.8495, -4.9310, -5.1292, -4.3030, -4.5720, -4.3988,\n",
      "         -5.3339, -4.8528, -4.7581, -4.5880, -4.8770, -4.3641, -4.5272, -4.7992,\n",
      "         -4.2775]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : lies,\n",
      "target index is: [59] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2993, -4.6661, -4.6519, -4.6718, -4.2006, -4.8924, -4.4017, -4.2267,\n",
      "         -4.6740, -5.1491, -4.7614, -4.3871, -4.5358, -4.8101, -4.7605, -4.6499,\n",
      "         -4.4706, -4.9512, -4.7937, -4.9119, -4.4338, -4.4865, -4.6729, -4.5195,\n",
      "         -4.1498, -4.8782, -4.5053, -4.3845, -4.3672, -4.5928, -4.6241, -4.7051,\n",
      "         -4.5236, -5.1279, -4.5074, -4.6513, -4.9054, -4.3145, -4.6850, -4.3859,\n",
      "         -5.0473, -4.2520, -4.7639, -4.4247, -4.4621, -4.1808, -4.4834, -4.5839,\n",
      "         -4.5366, -4.5438, -4.5976, -4.1700, -5.0270, -4.3906, -4.6971, -4.3240,\n",
      "         -4.5807, -4.4580, -4.7613, -4.7722, -4.6634, -4.3065, -4.5342, -4.3647,\n",
      "         -4.6660, -4.6728, -4.7110, -4.3597, -4.6658, -4.4309, -4.4382, -4.6784,\n",
      "         -4.4776, -4.9606, -4.8562, -4.9255, -4.6286, -4.1306, -4.6816, -5.0451,\n",
      "         -4.3936, -4.7322, -4.6924, -4.7842, -4.4298, -4.4335, -4.4653, -5.0372,\n",
      "         -5.0024, -4.5243, -4.6947, -4.6900, -4.4280, -4.6360, -4.7259, -4.5775,\n",
      "         -4.4433]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Where\n",
      "target index is: [18] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5481, -4.4262, -4.3814, -4.5933, -4.2355, -4.9771, -4.7587, -4.5170,\n",
      "         -4.6646, -4.7708, -4.7037, -4.4999, -4.7140, -4.7587, -4.5545, -4.5538,\n",
      "         -4.8513, -4.5932, -4.5674, -4.6122, -4.3879, -4.3203, -4.7471, -4.6449,\n",
      "         -4.3817, -4.7702, -4.6557, -4.4705, -4.3461, -4.5629, -4.7141, -4.6599,\n",
      "         -4.8362, -4.5903, -4.6468, -4.9003, -4.5723, -4.9011, -4.4917, -4.5183,\n",
      "         -4.6578, -4.6653, -4.8410, -4.5211, -4.6268, -4.4103, -4.5522, -4.6768,\n",
      "         -4.4965, -4.8335, -4.4921, -4.8335, -4.5310, -4.6024, -4.7212, -4.7547,\n",
      "         -4.2896, -4.4334, -4.3836, -4.5087, -4.8171, -4.7774, -4.5118, -4.2128,\n",
      "         -4.9000, -4.4381, -4.9228, -4.3642, -4.5763, -4.7138, -4.3041, -4.4747,\n",
      "         -4.8574, -4.9172, -4.8269, -4.7707, -4.2718, -4.3233, -4.7336, -4.5528,\n",
      "         -4.4617, -4.2900, -4.6226, -4.7490, -4.6348, -4.4496, -4.3821, -4.7094,\n",
      "         -4.7745, -4.2471, -4.5388, -4.7216, -4.5522, -4.4273, -4.2580, -4.4990,\n",
      "         -4.5500]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : all\n",
      "target index is: [52] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2847, -4.2314, -4.6117, -4.9411, -4.3383, -4.6094, -4.5602, -4.4755,\n",
      "         -4.7947, -4.9719, -4.8402, -4.4830, -4.7283, -4.6496, -4.5028, -4.7609,\n",
      "         -4.7520, -5.0519, -4.4138, -4.1692, -4.7668, -4.4168, -4.6859, -4.4722,\n",
      "         -4.6080, -4.7455, -4.4034, -4.4741, -4.1923, -4.9942, -4.4404, -4.9396,\n",
      "         -4.8610, -4.6755, -4.3161, -4.7228, -4.5694, -4.7898, -4.7924, -4.7277,\n",
      "         -4.6771, -4.6468, -4.8200, -4.5791, -4.8732, -4.2595, -5.0258, -4.6387,\n",
      "         -4.6250, -4.8709, -4.4281, -4.6477, -4.3975, -4.5174, -5.0152, -4.6044,\n",
      "         -4.6344, -4.4449, -4.6145, -4.7858, -4.5669, -4.5954, -4.7106, -4.4128,\n",
      "         -4.9875, -4.4597, -5.1166, -4.6142, -4.7660, -4.6785, -4.3184, -4.5614,\n",
      "         -4.5776, -4.7980, -4.4084, -4.6274, -4.6368, -4.1749, -4.3612, -4.4102,\n",
      "         -4.4723, -4.4272, -4.7655, -4.8552, -4.4368, -4.4106, -4.3468, -4.5494,\n",
      "         -4.7292, -4.2786, -4.4596, -4.4219, -4.7345, -4.5402, -4.1470, -4.4255,\n",
      "         -4.3614]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : the\n",
      "target index is: [82] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1573, -4.4047, -4.5664, -4.8761, -4.1824, -4.6914, -4.6658, -4.3317,\n",
      "         -4.6326, -4.7139, -4.8771, -4.7229, -4.6313, -4.8006, -4.6985, -4.6580,\n",
      "         -4.4290, -4.5076, -4.4489, -4.6410, -4.8790, -4.5159, -4.8107, -4.6020,\n",
      "         -4.2045, -4.5005, -4.5426, -4.4938, -4.4527, -4.4978, -4.5575, -4.6794,\n",
      "         -4.5570, -4.6698, -4.8856, -4.7721, -4.8438, -4.5463, -4.8656, -4.8114,\n",
      "         -4.7108, -4.5518, -4.7665, -4.3573, -4.6018, -4.1707, -4.6274, -4.5206,\n",
      "         -4.5598, -4.4576, -4.5044, -4.5947, -4.9612, -4.4384, -4.5122, -4.6735,\n",
      "         -4.4403, -4.5217, -4.4202, -4.5732, -5.1452, -4.6934, -4.4037, -4.0360,\n",
      "         -4.8518, -4.7360, -4.7370, -4.5057, -4.6540, -4.7268, -4.7221, -4.6325,\n",
      "         -4.4868, -4.5379, -4.5300, -4.5315, -4.3977, -4.4691, -4.5860, -4.8041,\n",
      "         -4.2296, -4.3349, -4.8721, -4.7714, -4.5800, -4.5640, -4.7677, -4.8089,\n",
      "         -4.9134, -4.3580, -4.6070, -4.5159, -4.6419, -4.5388, -4.3375, -4.6109,\n",
      "         -4.6175]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : treasure\n",
      "target index is: [31] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3718, -4.3627, -4.7208, -4.9679, -4.1165, -4.7644, -4.6583, -4.5916,\n",
      "         -4.7607, -4.5702, -4.6180, -4.2777, -4.8007, -4.7865, -4.8266, -4.8246,\n",
      "         -4.4750, -4.7488, -4.6945, -4.5547, -4.5251, -4.4730, -4.8649, -4.6098,\n",
      "         -4.7291, -4.9802, -4.2902, -4.4443, -4.2818, -4.8948, -4.2493, -5.0235,\n",
      "         -4.6713, -4.5921, -4.4986, -5.0376, -4.3795, -4.6871, -4.7172, -4.7772,\n",
      "         -4.5753, -4.7602, -4.5132, -4.3697, -4.5405, -4.2808, -4.6545, -4.7073,\n",
      "         -4.7566, -4.9090, -4.3067, -4.7642, -4.7360, -4.8341, -4.7021, -4.3858,\n",
      "         -4.5649, -4.2064, -4.4907, -4.6095, -4.5120, -4.3372, -4.7807, -4.2330,\n",
      "         -4.4853, -4.6300, -5.0527, -4.6978, -4.2632, -4.3154, -4.7220, -4.7294,\n",
      "         -4.8614, -4.8386, -4.7576, -5.0158, -4.6680, -4.2842, -4.5433, -4.5533,\n",
      "         -4.6382, -4.1884, -4.8055, -4.9755, -4.6513, -4.4463, -4.3319, -4.2872,\n",
      "         -4.7331, -4.5335, -4.3145, -4.4752, -4.8537, -4.4838, -4.5122, -4.4562,\n",
      "         -4.2905]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : of\n",
      "target index is: [57] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4841, -4.1692, -4.3109, -4.5627, -4.1649, -4.8555, -4.9033, -4.4298,\n",
      "         -4.8209, -4.7648, -5.0732, -4.5454, -4.5988, -4.5625, -4.7836, -4.7682,\n",
      "         -4.6671, -4.5597, -4.5594, -4.5493, -4.5983, -4.3689, -4.6934, -4.3913,\n",
      "         -4.0709, -4.6801, -4.4950, -4.5432, -4.2953, -4.4868, -4.6576, -5.0500,\n",
      "         -5.0265, -4.5778, -4.8646, -4.9080, -4.8162, -4.7539, -4.5290, -4.7022,\n",
      "         -4.8375, -4.5054, -4.6511, -4.4908, -4.5295, -4.3174, -4.7497, -4.9376,\n",
      "         -4.6147, -4.5225, -4.4247, -4.4123, -4.8633, -4.2315, -4.6503, -4.6499,\n",
      "         -4.4493, -4.4031, -4.4646, -4.6996, -4.9024, -4.7177, -4.3819, -4.1562,\n",
      "         -4.7036, -4.7144, -5.0135, -4.5081, -4.7701, -4.6950, -4.5701, -4.4661,\n",
      "         -4.7053, -4.8610, -4.6715, -4.7853, -4.5977, -4.1645, -4.5615, -4.9148,\n",
      "         -4.2092, -4.3527, -4.7534, -4.8196, -4.6112, -4.4711, -4.5596, -4.6929,\n",
      "         -4.7685, -4.2058, -4.6542, -4.8155, -4.5918, -4.3871, -4.3101, -4.6544,\n",
      "         -4.3243]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1355, -4.2769, -4.8863, -5.0379, -4.2074, -4.7462, -4.7463, -4.2560,\n",
      "         -5.2585, -4.3802, -5.1327, -4.1490, -4.5693, -4.2937, -4.7235, -4.9788,\n",
      "         -4.5619, -4.5900, -4.7646, -4.1926, -4.7896, -4.7920, -4.4789, -4.4697,\n",
      "         -4.7302, -4.8544, -4.3988, -4.3488, -4.4115, -4.6876, -4.6057, -4.7596,\n",
      "         -5.0197, -4.8089, -4.8107, -5.2423, -4.5971, -4.5653, -4.9185, -4.4344,\n",
      "         -4.8871, -4.6511, -4.4850, -4.4019, -4.6498, -4.0037, -4.8664, -4.7154,\n",
      "         -4.8530, -4.7179, -4.6176, -4.7412, -4.4303, -4.3368, -4.8200, -4.8092,\n",
      "         -4.4542, -4.4749, -4.6808, -4.6551, -4.6210, -4.6217, -4.3008, -4.5223,\n",
      "         -4.3488, -4.7844, -5.1236, -4.3286, -4.5826, -4.5998, -4.2726, -4.7001,\n",
      "         -4.6918, -5.0323, -4.5587, -4.7022, -4.2986, -4.2109, -4.2175, -4.6081,\n",
      "         -4.4367, -4.5538, -4.6481, -5.0053, -5.1473, -4.2344, -4.6117, -4.3165,\n",
      "         -5.0808, -4.5499, -4.4120, -4.7857, -4.8765, -4.5031, -4.1885, -4.4705,\n",
      "         -4.3618]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : lusty\n",
      "target index is: [30] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2186, -4.6238, -4.4006, -4.9626, -4.2151, -4.7112, -4.5232, -4.1623,\n",
      "         -4.6948, -4.9698, -4.8906, -4.4584, -4.3961, -4.6556, -4.9069, -4.8398,\n",
      "         -4.4417, -4.7401, -4.4031, -4.8217, -4.7064, -5.0459, -4.7105, -4.6760,\n",
      "         -4.3896, -4.7162, -4.5304, -4.4789, -4.2045, -4.5176, -4.2077, -4.6932,\n",
      "         -4.5943, -4.8993, -4.7647, -4.8921, -4.3968, -4.4518, -4.4890, -4.5319,\n",
      "         -4.8226, -4.2809, -4.8074, -4.3288, -4.6563, -4.1661, -4.5294, -4.5837,\n",
      "         -4.6794, -4.5537, -4.6242, -4.3032, -5.0722, -4.5382, -4.8604, -4.7351,\n",
      "         -4.3566, -4.3234, -4.5323, -4.6337, -4.8544, -4.3798, -4.6148, -4.1991,\n",
      "         -4.6853, -4.7992, -4.8182, -4.8221, -4.7815, -4.4210, -4.6393, -4.4374,\n",
      "         -5.0313, -4.9649, -4.6927, -4.6905, -4.9081, -3.7971, -4.4083, -5.0046,\n",
      "         -4.4933, -4.5641, -4.6583, -4.9003, -4.8432, -4.4685, -4.4145, -4.4351,\n",
      "         -5.2535, -4.3958, -4.7966, -4.5047, -4.5230, -4.5890, -4.4062, -4.7678,\n",
      "         -4.4204]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : days;\n",
      "target index is: [48] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5439, -4.7435, -4.4136, -4.4683, -3.7426, -4.7656, -4.5552, -4.4441,\n",
      "         -4.5021, -4.9562, -4.4781, -4.6001, -5.0771, -4.9468, -4.6468, -4.5957,\n",
      "         -4.9342, -5.0866, -4.6193, -4.7376, -4.6286, -4.0587, -4.7216, -4.5278,\n",
      "         -4.4178, -4.8262, -4.4691, -4.5121, -4.5868, -4.5464, -4.5994, -4.6560,\n",
      "         -4.6957, -4.7574, -4.4046, -4.9542, -4.7259, -4.8787, -4.5438, -4.5741,\n",
      "         -4.8277, -4.6589, -5.0255, -4.4318, -4.8490, -4.7092, -4.3624, -4.4305,\n",
      "         -4.3014, -4.3441, -4.4596, -4.6617, -4.7558, -4.4921, -4.7027, -3.9052,\n",
      "         -4.6164, -4.1396, -4.4686, -4.5887, -4.6417, -4.7776, -4.9952, -3.9837,\n",
      "         -5.0475, -4.3822, -4.9414, -4.5452, -4.7431, -5.0590, -4.2274, -4.5469,\n",
      "         -4.8316, -4.9537, -4.4832, -5.0000, -4.7023, -4.5859, -4.5852, -4.6423,\n",
      "         -4.7597, -4.0487, -5.0179, -4.6457, -4.4583, -4.6537, -4.5587, -5.0202,\n",
      "         -4.8447, -4.2524, -4.6638, -4.4069, -4.4623, -4.5533, -4.4031, -4.4605,\n",
      "         -4.6040]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : To\n",
      "target index is: [26] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2571, -4.6552, -5.0202, -4.9569, -4.0804, -4.7801, -4.4687, -4.7148,\n",
      "         -4.5797, -4.6306, -4.9417, -4.4845, -4.8555, -4.4874, -4.8491, -4.6419,\n",
      "         -4.2198, -4.7075, -4.8773, -4.6313, -4.3440, -4.1928, -4.8858, -4.7062,\n",
      "         -4.5144, -4.8631, -4.3953, -4.4189, -4.3729, -4.8396, -4.6333, -4.9329,\n",
      "         -4.9249, -4.9946, -4.5579, -4.5502, -4.5769, -4.5286, -5.1345, -4.6880,\n",
      "         -4.7043, -4.6925, -4.3515, -4.7192, -4.1267, -4.4226, -4.5583, -4.8297,\n",
      "         -4.4480, -4.9946, -4.2525, -4.5986, -4.6131, -4.2518, -4.8060, -4.7280,\n",
      "         -4.6738, -4.5653, -4.5044, -4.5974, -4.6238, -4.3868, -4.5794, -4.3029,\n",
      "         -4.3547, -4.8200, -4.9587, -4.5101, -4.6080, -4.2824, -4.3974, -4.5503,\n",
      "         -4.9141, -4.4901, -4.8719, -4.9830, -4.5475, -4.3778, -4.7813, -4.6628,\n",
      "         -4.1493, -4.3568, -4.5620, -4.7134, -4.4295, -4.3497, -4.6473, -4.7346,\n",
      "         -4.8669, -4.5959, -4.4617, -4.9731, -4.5310, -4.2208, -4.4182, -4.7162,\n",
      "         -4.3131]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : say,\n",
      "target index is: [96] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7701, -4.3220, -4.6542, -4.9198, -3.9658, -4.7173, -4.6105, -4.2866,\n",
      "         -4.7497, -4.5057, -4.7730, -4.6302, -4.6813, -4.7523, -4.5956, -4.8497,\n",
      "         -4.8174, -4.3574, -4.7529, -4.2354, -4.6766, -4.5942, -4.6999, -4.7189,\n",
      "         -4.4619, -4.8197, -4.4144, -4.5359, -4.2785, -4.5209, -4.6147, -4.6330,\n",
      "         -4.8504, -4.7842, -4.4622, -4.8532, -4.4925, -4.8353, -4.5419, -4.4606,\n",
      "         -4.5849, -4.6693, -4.6738, -4.4334, -4.6663, -4.4957, -4.4126, -4.5110,\n",
      "         -4.5486, -4.6971, -4.3565, -4.8326, -4.6357, -4.5614, -4.7589, -4.3831,\n",
      "         -4.6685, -4.3859, -4.4804, -4.6757, -4.6798, -4.6346, -4.5620, -4.2312,\n",
      "         -4.5800, -4.4523, -4.5080, -4.6214, -4.5565, -4.8484, -4.6632, -4.5001,\n",
      "         -4.8122, -5.1454, -4.6765, -4.7367, -4.3708, -4.5438, -4.4725, -4.8666,\n",
      "         -4.7685, -4.3997, -4.7058, -4.6801, -4.9571, -4.2194, -4.4090, -4.7303,\n",
      "         -4.6156, -4.1585, -4.7194, -4.5843, -4.6325, -4.3015, -4.6896, -4.4029,\n",
      "         -4.5018]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : within\n",
      "target index is: [34] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2023, -4.3374, -4.7200, -4.8860, -4.5103, -4.8530, -4.4892, -4.0750,\n",
      "         -5.1512, -4.5706, -4.9934, -4.3893, -4.2828, -4.6239, -5.1777, -5.0588,\n",
      "         -4.5662, -4.5712, -4.7260, -4.6022, -4.5306, -4.7414, -4.7437, -4.9218,\n",
      "         -4.4685, -4.9380, -4.2310, -4.3634, -4.1234, -4.5147, -4.5270, -4.6646,\n",
      "         -4.9614, -4.8659, -4.8332, -5.0079, -4.7783, -4.3597, -4.5662, -4.5278,\n",
      "         -4.6893, -4.6614, -4.4206, -4.3581, -4.3331, -4.0082, -4.7043, -4.7749,\n",
      "         -4.6253, -4.7588, -4.6563, -4.1930, -4.6775, -4.6226, -4.5374, -4.6546,\n",
      "         -4.5725, -4.1917, -4.4323, -4.9430, -4.8425, -4.5947, -4.5071, -4.4290,\n",
      "         -4.3568, -4.9556, -4.9476, -4.5345, -4.4978, -4.1690, -4.4406, -4.6083,\n",
      "         -4.7648, -4.7722, -4.6858, -4.8856, -4.5360, -4.0349, -4.3591, -5.0611,\n",
      "         -4.2944, -4.7414, -4.6217, -4.9397, -4.9007, -4.6512, -4.6881, -4.3823,\n",
      "         -5.1316, -4.6147, -4.5093, -4.4363, -4.8171, -4.5581, -4.4271, -4.5515,\n",
      "         -4.4041]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thine\n",
      "target index is: [56] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1455, -4.9286, -4.1293, -4.5939, -4.0742, -4.7196, -4.8458, -4.3238,\n",
      "         -4.7115, -4.8718, -4.7635, -4.7849, -4.7003, -4.7112, -4.7766, -4.6828,\n",
      "         -4.6110, -4.7537, -4.4991, -4.9945, -4.8332, -4.6032, -4.8147, -4.4559,\n",
      "         -4.3039, -4.7543, -4.6558, -4.5178, -4.3117, -4.3792, -4.3565, -4.5455,\n",
      "         -4.6322, -4.5465, -4.6883, -4.8848, -4.3797, -4.8573, -4.6509, -4.7067,\n",
      "         -5.0099, -4.3058, -4.9555, -4.2466, -4.8452, -4.2995, -4.6143, -4.4739,\n",
      "         -4.7722, -4.3159, -4.5515, -4.6951, -5.1690, -4.5774, -4.9098, -4.6072,\n",
      "         -4.1910, -4.3137, -4.4122, -4.2964, -4.7328, -4.5783, -4.6180, -4.0628,\n",
      "         -4.7719, -4.4806, -5.0767, -4.7666, -4.9205, -5.0064, -4.4830, -4.4610,\n",
      "         -5.2575, -5.0176, -4.5884, -4.8010, -4.6479, -4.0827, -4.4756, -4.8328,\n",
      "         -4.4822, -4.0636, -4.6761, -4.8177, -4.6855, -4.6256, -4.4094, -4.5634,\n",
      "         -5.2728, -4.3014, -4.4081, -4.3911, -4.4457, -4.8026, -4.2342, -4.7125,\n",
      "         -4.4888]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : own\n",
      "target index is: [92] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4061, -4.4241, -4.4728, -4.9510, -3.7353, -4.4349, -4.7119, -4.6334,\n",
      "         -4.9201, -5.0506, -4.8461, -4.6169, -5.0923, -4.7952, -4.7913, -4.7235,\n",
      "         -4.5988, -5.1606, -4.5111, -4.3347, -4.4795, -4.0493, -4.7354, -4.5774,\n",
      "         -4.7653, -4.7694, -4.5024, -4.5904, -4.5710, -5.0629, -4.1992, -4.8348,\n",
      "         -4.6500, -4.4277, -4.2100, -4.8825, -4.6009, -5.1360, -4.8304, -4.8513,\n",
      "         -4.5007, -4.7675, -5.0257, -4.2586, -4.9111, -4.4032, -4.6098, -4.5097,\n",
      "         -4.7603, -4.7138, -4.6165, -4.7912, -4.6327, -4.6065, -4.9560, -4.2182,\n",
      "         -4.8512, -4.3834, -4.4852, -4.5921, -4.4814, -4.6864, -5.0746, -3.8312,\n",
      "         -4.7906, -4.4987, -5.1426, -4.6056, -4.6338, -4.9730, -4.4628, -4.5313,\n",
      "         -4.5676, -5.0742, -4.4188, -4.6236, -4.7792, -4.6031, -4.5433, -4.4271,\n",
      "         -4.7326, -4.1941, -4.8947, -4.8478, -4.2305, -4.5213, -4.1582, -4.6019,\n",
      "         -4.8299, -4.3986, -4.3697, -4.3599, -4.7257, -4.6529, -3.9321, -4.6709,\n",
      "         -4.3258]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : deep\n",
      "target index is: [76] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3218, -4.6615, -4.6760, -4.8087, -4.2684, -4.5406, -4.3732, -4.2468,\n",
      "         -4.6961, -4.9177, -5.0345, -4.3634, -4.5009, -4.4757, -4.6584, -4.4306,\n",
      "         -4.0966, -4.7428, -4.6411, -4.6139, -4.5815, -4.6093, -4.6288, -4.6387,\n",
      "         -4.4707, -4.6387, -4.5838, -4.5055, -4.4744, -4.6162, -4.6389, -4.8708,\n",
      "         -4.8915, -4.9011, -4.7247, -4.8168, -4.7905, -4.4456, -5.1271, -4.7492,\n",
      "         -4.7273, -4.5052, -4.8800, -4.3976, -4.5261, -4.3470, -4.6334, -4.7889,\n",
      "         -4.5195, -4.4426, -4.5919, -4.3208, -4.7888, -4.3442, -4.9052, -4.6616,\n",
      "         -4.4234, -4.6408, -4.7491, -4.6227, -4.8031, -4.6198, -4.4624, -3.9812,\n",
      "         -4.6013, -4.4769, -4.9122, -4.4480, -4.5791, -4.6306, -4.4334, -4.6612,\n",
      "         -4.5327, -4.4029, -4.4839, -4.6140, -4.6835, -4.5750, -4.5997, -4.7180,\n",
      "         -4.0508, -4.5216, -4.6797, -4.7292, -4.4734, -4.4021, -4.7901, -4.7368,\n",
      "         -5.0069, -4.4778, -4.5213, -4.7987, -4.6670, -4.6666, -4.2355, -4.5797,\n",
      "         -4.6122]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : sunken\n",
      "target index is: [91] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4183, -4.5290, -4.7104, -4.8612, -4.2073, -4.8818, -4.5954, -4.7718,\n",
      "         -4.7282, -4.4425, -4.9392, -4.4932, -4.8070, -4.6307, -4.6766, -4.8394,\n",
      "         -4.8995, -4.7945, -4.7570, -4.3142, -4.4866, -4.2267, -4.9077, -4.5472,\n",
      "         -4.5676, -4.8936, -4.3643, -4.6733, -4.3257, -4.6451, -4.8800, -4.6524,\n",
      "         -4.6485, -4.8124, -4.7373, -5.0142, -4.7199, -4.6802, -4.7748, -4.2449,\n",
      "         -4.8126, -4.7435, -4.8331, -4.3649, -4.4980, -4.5942, -4.6991, -4.5658,\n",
      "         -4.3492, -4.9094, -3.9292, -5.2396, -4.3537, -4.4702, -4.7653, -4.2397,\n",
      "         -4.8209, -4.4642, -4.4048, -4.5066, -4.5183, -4.3744, -4.6540, -4.0007,\n",
      "         -4.5177, -4.6159, -4.9815, -4.5819, -4.6441, -4.5394, -4.4504, -4.6418,\n",
      "         -4.8464, -4.7604, -4.5776, -5.0198, -4.1905, -4.6022, -4.5048, -4.5476,\n",
      "         -4.6264, -4.1899, -4.9234, -4.5880, -4.7899, -4.2703, -4.7820, -4.8588,\n",
      "         -4.7737, -4.3026, -4.3984, -4.7135, -4.5251, -4.3654, -4.5186, -4.2606,\n",
      "         -4.3762]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : eyes,\n",
      "target index is: [58] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2684, -4.5064, -5.0733, -5.3280, -3.8866, -4.6405, -4.3495, -4.5019,\n",
      "         -4.7243, -4.6176, -5.1133, -4.6473, -4.7957, -4.5874, -4.6260, -4.6676,\n",
      "         -4.5902, -4.7056, -5.0074, -4.5320, -4.7271, -4.3165, -4.9885, -4.6341,\n",
      "         -4.5212, -4.8574, -4.4507, -4.3764, -4.3224, -4.7086, -4.7628, -4.5578,\n",
      "         -4.6464, -5.0969, -4.5971, -4.7084, -4.5052, -4.4881, -5.1128, -4.3136,\n",
      "         -4.5806, -4.3514, -4.7836, -4.4311, -4.5879, -4.3343, -4.8686, -4.4572,\n",
      "         -4.4884, -5.0390, -4.3184, -4.9862, -4.5063, -4.2835, -4.4886, -4.6679,\n",
      "         -4.5725, -4.7403, -4.6303, -4.4038, -4.5831, -4.2977, -4.1227, -4.4742,\n",
      "         -4.2495, -4.6713, -4.6777, -4.5627, -4.6279, -4.2569, -4.5170, -4.6309,\n",
      "         -4.8998, -4.7778, -4.7770, -4.7838, -4.4164, -4.5085, -4.5770, -4.7275,\n",
      "         -4.4120, -4.5081, -4.9328, -4.9037, -4.9026, -4.0177, -4.6501, -4.6630,\n",
      "         -4.6946, -4.4719, -4.7865, -4.6584, -4.8556, -4.1942, -4.7018, -4.5959,\n",
      "         -4.2443]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Were\n",
      "target index is: [37] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2545, -4.5195, -4.6915, -4.6448, -4.2283, -4.6976, -4.3960, -4.2727,\n",
      "         -4.7961, -4.9083, -4.5962, -4.4387, -4.5331, -4.8423, -4.9921, -4.6712,\n",
      "         -4.7267, -4.5411, -4.6528, -4.7144, -4.3254, -4.4397, -4.8680, -5.0321,\n",
      "         -4.2764, -4.9262, -4.5823, -4.4054, -4.2116, -4.4092, -4.6259, -4.6568,\n",
      "         -4.5693, -4.8930, -4.3608, -4.8286, -4.8516, -4.3756, -4.7627, -4.3767,\n",
      "         -4.7038, -4.5342, -4.6988, -4.6829, -4.5624, -4.2200, -4.2460, -4.7903,\n",
      "         -4.4735, -4.8801, -4.7239, -4.3276, -4.8094, -4.5144, -4.4665, -4.4712,\n",
      "         -4.3829, -4.3532, -4.4642, -4.8817, -4.6326, -4.1486, -4.5577, -4.3482,\n",
      "         -4.4892, -4.6916, -4.5959, -4.3641, -4.6802, -4.1691, -4.5335, -4.5957,\n",
      "         -4.6789, -5.1173, -4.9273, -4.9244, -4.6339, -4.2697, -4.6521, -4.8866,\n",
      "         -4.5616, -4.7184, -4.7686, -4.7991, -4.6173, -4.3450, -4.4626, -4.8146,\n",
      "         -4.8878, -4.4166, -4.7963, -4.4990, -4.6325, -4.5478, -4.8537, -4.6931,\n",
      "         -4.6167]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : an\n",
      "target index is: [74] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4982, -4.6932, -4.6837, -4.4959, -4.1001, -4.9818, -4.6402, -4.5463,\n",
      "         -4.7266, -4.4995, -4.9807, -4.7214, -4.8439, -4.9014, -4.7835, -4.8546,\n",
      "         -4.8219, -4.5783, -4.6651, -4.7091, -4.3817, -4.0793, -4.7984, -4.8873,\n",
      "         -4.4052, -5.2023, -4.3490, -4.2083, -4.6386, -4.3697, -4.8367, -4.5552,\n",
      "         -4.8533, -4.9502, -4.3914, -4.7110, -4.7538, -4.5916, -4.7740, -4.4762,\n",
      "         -4.9111, -4.7441, -4.5797, -4.5264, -4.4147, -4.4296, -4.5381, -4.5656,\n",
      "         -4.3633, -4.9993, -4.4244, -4.4638, -4.6346, -4.4064, -4.4377, -4.3309,\n",
      "         -4.4601, -4.3114, -4.2059, -4.8264, -4.5496, -4.5445, -4.5974, -4.3556,\n",
      "         -4.5954, -4.3660, -4.8412, -4.2935, -4.7063, -4.5643, -4.4069, -4.6744,\n",
      "         -4.8471, -4.8197, -5.0246, -5.1050, -4.3314, -4.2614, -4.4621, -4.8802,\n",
      "         -4.3481, -4.6044, -4.4658, -4.8080, -4.5255, -4.2597, -4.6620, -5.0463,\n",
      "         -4.8115, -4.5898, -4.3591, -4.4530, -4.5620, -4.5642, -4.6235, -4.4827,\n",
      "         -4.3612]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : all-eating\n",
      "target index is: [60] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4737, -4.5685, -4.8545, -4.7432, -3.9416, -4.7111, -4.7205, -4.4209,\n",
      "         -4.8310, -4.4433, -5.0208, -4.6785, -4.8957, -4.6043, -4.7189, -4.6840,\n",
      "         -4.4693, -4.4370, -4.8378, -4.4995, -4.7358, -4.5830, -4.8486, -4.8910,\n",
      "         -4.6799, -4.9173, -4.6946, -4.2758, -4.2547, -4.4212, -4.5368, -4.5464,\n",
      "         -4.8324, -4.9459, -4.3552, -4.7298, -4.2868, -4.9208, -4.8333, -4.6256,\n",
      "         -4.7571, -4.4626, -4.4748, -4.5563, -4.3555, -4.4517, -4.5483, -4.6459,\n",
      "         -4.6717, -4.8545, -4.5141, -4.8353, -4.8374, -4.2491, -4.6691, -4.7656,\n",
      "         -4.3273, -4.3984, -4.6454, -4.4811, -4.6594, -4.6126, -4.4792, -4.4682,\n",
      "         -4.4401, -4.3911, -4.5698, -4.2963, -4.7474, -4.5892, -4.4164, -4.2840,\n",
      "         -5.0656, -4.8899, -4.7623, -4.8139, -4.3396, -4.3566, -4.4643, -5.0305,\n",
      "         -4.4140, -4.3297, -4.3183, -4.9227, -5.0004, -4.0336, -4.7395, -4.5665,\n",
      "         -4.8667, -4.2473, -4.5138, -4.6705, -4.7391, -4.4790, -4.6055, -4.5482,\n",
      "         -4.5582]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : shame,\n",
      "target index is: [41] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6956, -4.7308, -4.8764, -4.5220, -4.1464, -4.5964, -4.6425, -4.4627,\n",
      "         -4.5947, -4.6375, -4.5691, -4.5034, -4.8690, -4.7321, -4.7786, -4.4830,\n",
      "         -4.4600, -4.9106, -4.5714, -4.4930, -4.5744, -4.2200, -4.7062, -4.6029,\n",
      "         -4.5273, -4.9730, -4.3660, -4.5020, -4.4976, -4.6098, -4.4333, -5.0220,\n",
      "         -5.0932, -4.8140, -4.5555, -4.7044, -4.4919, -5.0436, -4.8090, -4.7309,\n",
      "         -4.8029, -4.3777, -4.4894, -4.5712, -4.4815, -4.4874, -4.6185, -4.6516,\n",
      "         -4.4231, -4.6435, -4.8654, -4.2342, -4.8196, -4.3308, -4.8845, -4.1688,\n",
      "         -4.4858, -4.2781, -4.4340, -4.5032, -4.6430, -5.0176, -4.7141, -4.2194,\n",
      "         -4.7921, -4.2528, -5.0333, -4.5189, -4.6468, -4.6768, -3.9925, -4.4707,\n",
      "         -4.7505, -4.5957, -4.6188, -4.8681, -4.8517, -4.3349, -4.8726, -4.8365,\n",
      "         -4.6588, -4.4714, -4.4442, -4.5737, -4.3358, -4.4995, -4.3801, -4.7543,\n",
      "         -4.7701, -4.1942, -4.6836, -4.4146, -4.7326, -4.6520, -4.5098, -4.7284,\n",
      "         -4.4515]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : and\n",
      "target index is: [44] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6910, -4.4840, -4.5699, -4.6384, -4.2022, -4.7429, -4.5158, -4.4164,\n",
      "         -4.7119, -4.8036, -4.4687, -4.4720, -4.8441, -4.8329, -4.4904, -4.5167,\n",
      "         -4.6191, -4.9118, -4.6428, -4.5402, -4.3610, -4.3196, -4.4652, -4.4672,\n",
      "         -4.5402, -4.7054, -4.3577, -4.4438, -4.6285, -4.5645, -4.6447, -4.8392,\n",
      "         -4.8011, -4.7643, -4.4012, -4.4971, -4.7778, -4.9208, -4.6029, -4.5433,\n",
      "         -4.7943, -4.6825, -4.8043, -4.5354, -4.5498, -4.6122, -4.3778, -4.5803,\n",
      "         -4.2906, -4.5365, -4.5998, -4.5823, -4.5950, -4.3856, -4.9014, -4.4827,\n",
      "         -4.7636, -4.6530, -4.6159, -4.6907, -4.8123, -4.7277, -4.8125, -4.1977,\n",
      "         -4.9281, -4.4365, -4.8746, -4.3949, -4.6559, -4.8452, -4.3135, -4.8171,\n",
      "         -4.6113, -4.6200, -4.4075, -4.7397, -4.5740, -4.4796, -4.7344, -4.4229,\n",
      "         -4.4531, -4.3552, -4.6589, -4.6493, -4.6092, -4.3298, -4.6005, -4.8143,\n",
      "         -4.8689, -4.1486, -4.7896, -4.7547, -4.3190, -4.3636, -4.4401, -4.4081,\n",
      "         -4.5692]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thriftless\n",
      "target index is: [43] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3700, -4.4337, -4.5483, -4.7387, -4.1126, -4.5557, -4.6648, -4.4855,\n",
      "         -4.7395, -4.5275, -4.9559, -4.3820, -4.7653, -4.6048, -4.6381, -4.9200,\n",
      "         -4.8728, -4.5527, -4.8951, -4.2000, -4.6934, -4.8175, -4.6231, -4.5896,\n",
      "         -4.8416, -4.7510, -4.5474, -4.4867, -4.1701, -4.7453, -4.6539, -4.5083,\n",
      "         -4.7367, -4.5861, -4.6317, -5.0419, -4.6324, -4.9049, -4.5348, -4.4809,\n",
      "         -4.5553, -4.5819, -4.7134, -4.1974, -4.4776, -4.2854, -4.4921, -4.1520,\n",
      "         -4.5536, -4.7058, -4.8432, -4.9421, -4.6164, -4.6571, -4.9332, -4.7599,\n",
      "         -4.4048, -4.4399, -4.5283, -4.6912, -4.5655, -4.6884, -4.5869, -4.4002,\n",
      "         -4.6741, -4.8225, -4.8771, -4.4146, -4.4565, -4.7392, -4.2146, -4.6931,\n",
      "         -4.7758, -5.0665, -4.5847, -4.5735, -4.4464, -4.4842, -4.4582, -4.3829,\n",
      "         -4.7140, -4.2987, -4.5170, -4.7725, -5.0535, -4.2979, -4.4985, -4.5334,\n",
      "         -5.2547, -4.4589, -4.7266, -4.4592, -4.5059, -4.5420, -4.1422, -4.2809,\n",
      "         -4.6156]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : praise.\n",
      "target index is: [94] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-3.9337, -5.0529, -4.7047, -5.1385, -3.7622, -4.7157, -4.8404, -4.4028,\n",
      "         -4.6724, -5.0094, -4.6420, -4.2752, -4.4609, -4.5467, -4.8297, -4.5748,\n",
      "         -4.8957, -5.0761, -4.7053, -4.5322, -4.7762, -4.0745, -5.1678, -4.9702,\n",
      "         -4.3767, -4.8650, -4.4856, -4.1197, -3.9138, -4.8702, -4.5745, -4.8074,\n",
      "         -4.8818, -4.8164, -4.4519, -5.2913, -4.6775, -4.6337, -4.9850, -4.9422,\n",
      "         -4.6682, -4.3468, -4.9049, -4.5911, -4.7118, -4.4277, -4.8775, -4.6598,\n",
      "         -4.7176, -4.8435, -4.3177, -4.7957, -4.4548, -4.6482, -4.8828, -4.5222,\n",
      "         -3.9426, -4.3755, -4.5169, -4.6862, -4.4094, -4.3951, -4.3332, -4.3431,\n",
      "         -4.5695, -4.6611, -5.0268, -5.0051, -4.8739, -4.8188, -4.1934, -4.3060,\n",
      "         -4.8537, -5.0759, -4.5704, -4.5319, -4.7264, -4.0355, -4.4153, -4.4349,\n",
      "         -4.5437, -4.1990, -5.1960, -5.0405, -4.1099, -4.6354, -4.3044, -4.7822,\n",
      "         -5.2139, -4.9395, -5.0221, -4.2723, -4.7213, -4.3700, -4.5419, -4.4330,\n",
      "         -4.4852]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : How\n",
      "target index is: [12] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1737, -4.7063, -4.4822, -5.0323, -4.0288, -5.0004, -4.6199, -4.3586,\n",
      "         -5.1443, -4.9615, -5.0394, -5.0807, -4.7416, -4.5199, -5.3376, -5.1022,\n",
      "         -4.8499, -4.4069, -4.7795, -4.7358, -4.6289, -4.8668, -4.8042, -5.0145,\n",
      "         -4.3880, -5.0986, -4.5827, -4.1910, -4.2799, -4.5887, -4.3055, -3.9727,\n",
      "         -4.6530, -4.7462, -4.4473, -5.1933, -4.5618, -4.5062, -4.5309, -4.5308,\n",
      "         -4.3522, -4.8586, -4.8168, -4.2083, -4.6130, -4.0086, -4.5004, -4.1627,\n",
      "         -5.0229, -4.5431, -4.3778, -4.7830, -4.6672, -4.7694, -4.5324, -4.8087,\n",
      "         -4.4070, -4.4050, -4.2884, -4.6611, -4.6589, -4.2859, -4.2684, -4.2222,\n",
      "         -4.5253, -4.9118, -4.6361, -4.3603, -4.2831, -4.4548, -4.5569, -4.3525,\n",
      "         -5.2976, -5.2986, -4.9301, -4.7787, -4.5412, -4.0997, -4.3405, -4.5821,\n",
      "         -4.5913, -4.9728, -4.6981, -5.1479, -4.9976, -4.1243, -4.1782, -4.8305,\n",
      "         -5.5412, -4.4553, -4.4649, -4.1542, -4.8167, -4.8593, -4.3853, -4.7899,\n",
      "         -4.5737]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : much\n",
      "target index is: [68] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4415, -4.9949, -4.6280, -4.4529, -3.4381, -4.4760, -4.7357, -4.2712,\n",
      "         -4.9950, -4.5497, -4.4746, -4.4719, -4.8259, -4.7530, -5.0022, -4.7973,\n",
      "         -4.8123, -4.8873, -4.1210, -4.8511, -4.7531, -4.1091, -4.9970, -4.8172,\n",
      "         -4.4856, -5.1181, -4.4939, -4.3775, -4.5980, -4.6025, -4.2295, -4.9796,\n",
      "         -4.6839, -4.5501, -4.4436, -5.3168, -4.4475, -5.0792, -4.6657, -4.9726,\n",
      "         -4.8634, -4.5781, -4.9330, -4.6429, -4.8328, -4.4096, -4.6721, -5.1350,\n",
      "         -4.9796, -4.5961, -4.9290, -4.4066, -5.0446, -4.1576, -4.6141, -4.0072,\n",
      "         -4.2549, -3.9488, -4.2485, -4.1697, -4.5376, -4.7961, -4.5581, -3.8750,\n",
      "         -4.6543, -4.3992, -4.6623, -4.5404, -5.1135, -4.7348, -4.4671, -4.3359,\n",
      "         -5.4777, -5.0348, -4.5979, -5.0633, -4.8863, -4.1681, -4.3857, -5.1370,\n",
      "         -4.8276, -4.1459, -4.9661, -4.8750, -4.3584, -4.5707, -4.5913, -4.8649,\n",
      "         -5.3041, -4.4952, -4.8790, -4.1478, -4.6524, -4.6335, -4.3393, -5.1617,\n",
      "         -4.4083]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : more\n",
      "target index is: [4] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3162, -4.8088, -4.7160, -4.4023, -4.1526, -4.6055, -4.8504, -4.4382,\n",
      "         -4.8867, -4.4805, -4.8664, -4.3019, -4.7210, -4.3717, -4.8341, -4.7948,\n",
      "         -4.6014, -4.7866, -4.6980, -4.6474, -4.4609, -4.4775, -4.6571, -4.6278,\n",
      "         -4.5632, -4.8156, -4.5836, -4.4541, -4.4031, -4.5696, -4.7544, -4.6841,\n",
      "         -4.8733, -4.5860, -4.9269, -5.0093, -4.8975, -4.6933, -4.7434, -4.6445,\n",
      "         -4.6109, -4.5514, -4.5816, -4.5095, -4.0721, -4.2931, -4.5277, -4.7157,\n",
      "         -4.7052, -4.5262, -4.9164, -4.3048, -4.7620, -4.3734, -4.8052, -4.4202,\n",
      "         -4.4750, -4.2003, -4.4765, -4.6802, -4.6059, -4.5930, -4.6047, -3.8970,\n",
      "         -4.5086, -4.6280, -4.8507, -4.6111, -4.6438, -4.6150, -4.0462, -4.5925,\n",
      "         -4.6935, -4.4637, -4.5048, -4.8335, -4.6749, -4.4870, -4.6118, -4.8101,\n",
      "         -4.4641, -4.2588, -4.6708, -4.7729, -4.5439, -4.5608, -4.7660, -4.7401,\n",
      "         -5.2298, -4.4881, -4.7125, -4.6794, -4.6320, -4.5585, -4.0995, -4.9414,\n",
      "         -4.5232]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : praise\n",
      "target index is: [45] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4078, -4.5095, -4.6999, -5.1966, -4.0348, -4.5971, -4.4762, -4.2787,\n",
      "         -5.2193, -4.6149, -4.8320, -4.3318, -4.7532, -4.5311, -5.1108, -4.8255,\n",
      "         -4.6753, -4.4973, -4.7901, -4.2264, -4.6942, -4.7027, -4.8959, -4.7294,\n",
      "         -4.8812, -4.9148, -4.5289, -4.2618, -4.2893, -4.6283, -4.2819, -4.4439,\n",
      "         -4.8712, -4.8798, -4.4715, -5.1791, -4.3250, -5.0118, -4.5303, -4.6071,\n",
      "         -4.4859, -4.5858, -4.7131, -4.1997, -4.6338, -4.1458, -4.7666, -4.4133,\n",
      "         -4.8078, -5.1262, -4.2486, -5.0957, -4.4248, -4.7742, -4.6030, -4.6441,\n",
      "         -4.3666, -4.4308, -4.4483, -4.5017, -4.5427, -4.2979, -4.6101, -4.4240,\n",
      "         -4.3257, -4.6204, -5.0915, -4.5933, -4.5416, -4.3281, -4.6943, -4.6695,\n",
      "         -5.2126, -5.2378, -4.6838, -4.9083, -4.5054, -4.1051, -4.2374, -4.4502,\n",
      "         -4.8429, -4.6441, -4.7237, -5.0064, -4.9863, -4.2415, -4.2281, -4.3039,\n",
      "         -5.1092, -4.7111, -4.5580, -4.0591, -5.0427, -4.5202, -4.6511, -4.3718,\n",
      "         -4.3949]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : deserv'd\n",
      "target index is: [66] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4247, -4.7198, -4.5360, -4.3392, -4.0453, -4.7350, -4.5886, -4.3482,\n",
      "         -4.8599, -4.8364, -4.4472, -4.7262, -4.7827, -4.7449, -4.8986, -4.8254,\n",
      "         -4.8446, -4.8458, -4.4847, -4.9302, -4.4276, -4.4620, -4.7620, -4.6506,\n",
      "         -4.2434, -5.0997, -4.6901, -4.5013, -4.3350, -4.6470, -4.2273, -4.7141,\n",
      "         -4.8103, -4.7806, -4.5612, -5.2336, -4.5080, -4.6777, -4.5402, -4.6111,\n",
      "         -4.7954, -4.6150, -4.8521, -4.5572, -4.7908, -4.2884, -4.7427, -4.5708,\n",
      "         -4.7753, -4.4753, -4.8438, -4.3072, -5.1271, -4.4518, -4.5791, -4.4847,\n",
      "         -4.0705, -4.0966, -4.2776, -4.4180, -4.6439, -4.4897, -4.5939, -4.2407,\n",
      "         -4.6393, -4.4534, -4.6284, -4.2915, -4.5295, -4.3416, -4.5412, -4.4997,\n",
      "         -5.2612, -4.9285, -4.8632, -4.9656, -4.9465, -3.9868, -4.6052, -4.8756,\n",
      "         -4.5799, -4.4975, -4.8824, -4.8578, -4.6635, -4.2946, -4.1953, -4.6440,\n",
      "         -5.1958, -4.3198, -4.4440, -4.5221, -4.7417, -4.7183, -4.2759, -4.8432,\n",
      "         -4.4172]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2826, -4.2383, -4.9273, -4.6757, -4.2334, -4.7514, -4.8641, -4.2130,\n",
      "         -5.0414, -4.7864, -5.3222, -4.5236, -4.4097, -4.6449, -4.6050, -4.7836,\n",
      "         -4.4986, -4.5392, -4.3943, -4.4340, -4.6406, -4.2768, -4.7109, -4.7191,\n",
      "         -4.3349, -5.0170, -4.3278, -4.4664, -4.5700, -4.6462, -4.7317, -4.7949,\n",
      "         -5.2367, -4.7238, -4.6321, -5.0807, -4.7255, -4.7939, -5.0147, -4.8281,\n",
      "         -4.8771, -4.7192, -4.7990, -4.6031, -4.7520, -4.0203, -4.8538, -4.9229,\n",
      "         -4.8596, -4.4946, -4.8432, -4.3342, -4.5293, -4.2155, -4.4837, -4.7696,\n",
      "         -4.3074, -4.1891, -4.5853, -4.5827, -4.7530, -4.6707, -4.1215, -4.4271,\n",
      "         -4.4612, -4.7293, -4.8860, -4.2339, -4.8216, -4.7731, -4.3374, -4.5332,\n",
      "         -4.7909, -4.8234, -4.7257, -4.6389, -4.3359, -4.3353, -4.2659, -4.7365,\n",
      "         -3.9720, -4.6639, -4.7705, -5.0965, -4.6390, -4.4042, -4.7152, -4.9015,\n",
      "         -4.7717, -4.4201, -4.5782, -4.7583, -4.9628, -4.3209, -3.8549, -4.9509,\n",
      "         -4.1728]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty's\n",
      "target index is: [80] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2949, -4.4854, -4.7246, -4.5423, -4.2155, -4.9382, -4.5216, -4.3032,\n",
      "         -4.4157, -5.1428, -4.9698, -4.1355, -4.6341, -4.7396, -4.6148, -4.7522,\n",
      "         -4.9001, -5.1656, -4.5262, -4.4143, -4.9438, -4.7552, -4.5743, -4.4966,\n",
      "         -4.2121, -4.6581, -4.6605, -4.4548, -3.8587, -4.5831, -4.8066, -4.5881,\n",
      "         -4.7160, -4.6064, -4.6629, -5.1479, -4.8574, -4.6204, -4.6641, -4.5301,\n",
      "         -4.6925, -4.2535, -4.9909, -4.0689, -4.5017, -4.0980, -4.4636, -4.4839,\n",
      "         -4.5101, -4.8971, -4.7700, -4.4565, -4.7516, -4.3800, -4.6245, -4.4150,\n",
      "         -4.3194, -4.2698, -4.7387, -5.0341, -4.8405, -4.1934, -4.4944, -4.1169,\n",
      "         -5.0419, -4.8110, -5.0727, -4.6845, -4.8106, -4.6167, -4.3189, -4.7695,\n",
      "         -4.5089, -4.8559, -4.7960, -4.9170, -5.1478, -4.1180, -4.4271, -4.4641,\n",
      "         -4.7597, -4.3224, -5.2023, -4.7512, -4.8770, -4.1060, -4.6161, -5.0083,\n",
      "         -5.0498, -4.5907, -5.1932, -4.4846, -4.5685, -4.5120, -4.2736, -4.3414,\n",
      "         -4.5644]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : use,\n",
      "target index is: [11] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1338, -4.6033, -5.0206, -5.2933, -3.7618, -5.0926, -4.6990, -4.6685,\n",
      "         -4.6953, -4.6104, -4.9278, -4.7920, -5.2498, -4.7581, -4.6781, -4.8594,\n",
      "         -5.0215, -4.4886, -4.7716, -4.3193, -4.8368, -4.1762, -5.1625, -4.6736,\n",
      "         -4.3195, -4.8810, -4.2262, -4.2284, -4.0651, -5.0376, -4.7162, -4.5769,\n",
      "         -4.8061, -4.6984, -4.9685, -5.1925, -5.0831, -4.7508, -5.0986, -4.7318,\n",
      "         -4.6939, -5.3352, -4.8757, -4.6211, -4.7116, -4.4461, -4.8146, -4.3523,\n",
      "         -4.4596, -4.8429, -3.9524, -5.5108, -4.2644, -4.5267, -4.8798, -4.3312,\n",
      "         -4.5352, -4.3733, -4.3123, -4.2420, -4.6569, -4.3093, -4.3747, -3.6813,\n",
      "         -4.5695, -4.8433, -4.9009, -4.9278, -4.3645, -4.4931, -4.2425, -4.6462,\n",
      "         -5.0929, -4.5292, -4.7225, -4.8203, -4.0557, -4.6653, -4.5754, -4.5018,\n",
      "         -4.5489, -4.0397, -5.4881, -5.0863, -4.5914, -4.5971, -4.6549, -5.0213,\n",
      "         -4.7746, -4.3605, -4.2834, -4.4373, -4.6258, -4.0641, -4.2810, -4.6085,\n",
      "         -4.6158]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : If\n",
      "target index is: [61] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7140, -4.3175, -4.8855, -4.9761, -4.4795, -4.7855, -4.7393, -4.2958,\n",
      "         -4.6222, -4.7847, -4.8043, -4.1648, -4.7390, -4.4709, -4.8561, -4.8422,\n",
      "         -4.4061, -4.6291, -4.9119, -4.4713, -4.5112, -4.9194, -4.7584, -4.5951,\n",
      "         -4.5530, -4.8186, -4.5294, -4.2797, -4.3261, -4.4632, -4.4088, -4.7867,\n",
      "         -5.2016, -4.7288, -4.9546, -5.3599, -4.4113, -4.9223, -4.4672, -4.4851,\n",
      "         -4.2634, -4.8428, -4.2728, -4.4777, -4.1807, -4.3730, -4.5227, -4.7982,\n",
      "         -4.5592, -4.7968, -4.2945, -4.3873, -4.5920, -4.3788, -4.5383, -4.5192,\n",
      "         -4.6035, -4.3455, -4.8479, -4.6131, -4.6209, -4.2932, -4.4676, -3.7533,\n",
      "         -4.4187, -4.4113, -4.7322, -4.6584, -4.3083, -3.9982, -4.5049, -4.5732,\n",
      "         -4.8870, -4.8415, -5.0795, -5.0254, -4.8121, -4.0596, -4.6701, -4.7817,\n",
      "         -5.0076, -4.5741, -4.9165, -5.1352, -5.0023, -4.3211, -4.4225, -4.5726,\n",
      "         -5.0543, -4.1811, -4.6877, -4.8700, -4.9525, -4.2822, -4.6615, -4.7969,\n",
      "         -4.6367]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thou\n",
      "target index is: [22] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5392, -4.4338, -4.9589, -4.6290, -4.4174, -4.8871, -4.4361, -4.3857,\n",
      "         -4.4432, -4.7327, -4.6043, -4.4435, -4.7505, -4.8982, -4.5783, -4.5650,\n",
      "         -4.7520, -5.0852, -4.5215, -4.3856, -4.5663, -4.4491, -4.8207, -4.3527,\n",
      "         -4.2515, -4.5898, -4.4718, -4.6800, -4.5151, -4.7255, -4.8966, -4.9383,\n",
      "         -4.6809, -4.7659, -4.3676, -4.5069, -4.5424, -4.6635, -4.7160, -4.5197,\n",
      "         -5.0627, -4.1819, -4.8225, -4.7374, -4.4578, -4.3978, -4.3619, -4.5250,\n",
      "         -4.1495, -5.1351, -4.8651, -4.2821, -4.7304, -4.3819, -4.6895, -4.4500,\n",
      "         -4.5605, -4.4441, -4.5018, -4.7115, -4.7483, -4.4674, -4.3117, -4.4424,\n",
      "         -4.9266, -4.6366, -4.5574, -4.4747, -4.6104, -4.4446, -4.1968, -4.9561,\n",
      "         -4.5283, -4.7190, -4.6753, -4.8753, -4.5034, -4.3825, -4.6460, -4.4124,\n",
      "         -4.6153, -4.5831, -4.8521, -4.4574, -4.5392, -4.5721, -4.7118, -4.7233,\n",
      "         -4.7949, -4.3112, -4.9701, -4.4161, -4.5577, -4.5283, -4.6613, -4.5161,\n",
      "         -4.4870]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : couldst\n",
      "target index is: [47] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4771, -4.3584, -4.5002, -4.7866, -4.2262, -4.8031, -4.7781, -4.4011,\n",
      "         -4.6011, -4.7761, -4.6269, -4.5210, -4.6128, -4.8516, -4.6911, -4.3059,\n",
      "         -4.5645, -4.5274, -4.4595, -4.5775, -4.5226, -4.3278, -4.6964, -4.7763,\n",
      "         -4.2427, -4.5756, -4.4466, -4.6153, -4.3048, -4.6820, -4.5602, -4.8163,\n",
      "         -4.8151, -4.5175, -4.6396, -4.8295, -4.5859, -4.7996, -4.7484, -4.8451,\n",
      "         -4.5923, -4.7449, -4.7688, -4.6853, -4.5957, -4.5823, -4.6454, -4.7803,\n",
      "         -4.5980, -4.6125, -4.4960, -4.6487, -4.5865, -4.5025, -4.7441, -4.6541,\n",
      "         -4.4577, -4.4766, -4.4309, -4.4976, -4.7952, -4.5899, -4.4295, -4.1781,\n",
      "         -4.7491, -4.4789, -4.7952, -4.7195, -4.5034, -4.6024, -4.3734, -4.4238,\n",
      "         -4.7555, -4.7987, -4.7221, -4.7011, -4.3380, -4.4032, -4.7041, -4.6483,\n",
      "         -4.4618, -4.4135, -4.7880, -4.8202, -4.4988, -4.6191, -4.3780, -4.6786,\n",
      "         -4.6083, -4.3269, -4.5267, -4.7643, -4.6449, -4.2748, -4.4400, -4.5934,\n",
      "         -4.5875]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : answer\n",
      "target index is: [53] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3841, -4.7517, -4.7358, -4.7893, -4.2259, -4.5566, -4.6710, -4.2984,\n",
      "         -4.7914, -4.7684, -4.7260, -4.4307, -4.5240, -4.6956, -4.8206, -4.6910,\n",
      "         -4.2639, -4.6283, -4.3721, -4.6984, -4.5790, -4.3912, -4.6029, -4.5267,\n",
      "         -4.2713, -5.0274, -4.3349, -4.7863, -4.5789, -4.5034, -4.5461, -4.7488,\n",
      "         -4.8044, -4.7527, -4.3972, -4.8982, -4.5769, -4.3506, -4.7828, -4.7724,\n",
      "         -4.7965, -4.6501, -4.8013, -4.6616, -4.3800, -4.3317, -4.5343, -4.7179,\n",
      "         -4.7554, -4.3415, -4.7787, -4.4510, -4.8058, -4.3839, -4.5850, -4.5502,\n",
      "         -4.6159, -4.4044, -4.4243, -4.4413, -4.6175, -4.5735, -4.4497, -4.0196,\n",
      "         -4.5546, -4.6221, -4.8081, -4.6248, -4.6383, -4.5799, -4.4135, -4.6192,\n",
      "         -4.8013, -4.6597, -4.8308, -4.7537, -4.3856, -4.3229, -4.4921, -4.9111,\n",
      "         -4.3355, -4.6213, -4.6975, -4.8454, -4.6407, -4.7017, -4.5012, -4.5778,\n",
      "         -5.0917, -4.3231, -4.4278, -4.6866, -4.7512, -4.5274, -4.5102, -4.8156,\n",
      "         -4.3349]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : 'This\n",
      "target index is: [9] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4218, -4.7160, -4.8341, -4.7010, -3.7037, -4.6336, -4.3531, -4.3270,\n",
      "         -4.9191, -4.8386, -4.8992, -4.5867, -4.8800, -4.7675, -4.7633, -4.8072,\n",
      "         -4.4676, -4.8662, -4.6942, -4.5458, -4.4754, -4.3302, -4.7908, -4.4041,\n",
      "         -4.5478, -4.9880, -4.4487, -4.4491, -4.5511, -4.7761, -4.5438, -4.6918,\n",
      "         -4.5770, -4.9564, -4.3108, -4.6441, -4.5426, -4.7489, -4.8489, -4.3824,\n",
      "         -4.8230, -4.2155, -4.7349, -4.4016, -4.6924, -4.1843, -4.5236, -4.5474,\n",
      "         -4.5957, -4.8438, -4.9350, -4.5079, -4.9796, -4.0406, -4.4335, -4.2721,\n",
      "         -4.6302, -4.3108, -4.6693, -4.5654, -4.5070, -4.4608, -4.6695, -4.4718,\n",
      "         -4.4790, -4.6735, -4.4440, -4.2305, -4.6770, -4.7676, -4.3978, -4.6125,\n",
      "         -4.7821, -5.0642, -4.8817, -5.0199, -4.6915, -4.4099, -4.5863, -4.7841,\n",
      "         -4.7411, -4.4892, -4.7025, -4.7871, -4.6519, -4.1939, -4.4125, -4.8398,\n",
      "         -4.9386, -4.4116, -4.6796, -4.4931, -4.6016, -4.6861, -4.5364, -4.7017,\n",
      "         -4.3316]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : fair\n",
      "target index is: [21] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3749, -4.4494, -4.8886, -4.5873, -4.0908, -4.5777, -4.8267, -4.2980,\n",
      "         -4.6764, -4.4146, -4.8328, -4.4897, -4.6069, -4.6557, -4.7628, -4.5892,\n",
      "         -4.6397, -4.4740, -4.6181, -4.3643, -4.5665, -4.2681, -4.8805, -4.8954,\n",
      "         -4.4251, -4.7791, -4.4590, -4.4001, -4.3173, -4.6372, -4.6110, -4.7035,\n",
      "         -4.9759, -4.8165, -4.4862, -4.6600, -4.7760, -4.7905, -5.1384, -4.8288,\n",
      "         -4.7598, -4.5502, -4.4570, -4.7025, -4.4185, -4.2561, -4.5976, -4.8246,\n",
      "         -4.5654, -4.8706, -4.7261, -4.3125, -4.7022, -4.3980, -4.7089, -4.6988,\n",
      "         -4.2729, -4.3552, -4.5209, -4.5866, -4.6668, -4.5354, -4.5774, -4.4798,\n",
      "         -4.4620, -4.7183, -4.6801, -4.5575, -4.8090, -4.6373, -4.3656, -4.6291,\n",
      "         -4.5929, -4.8699, -4.5906, -4.6379, -4.4933, -4.5218, -4.5810, -4.7473,\n",
      "         -4.3271, -4.3406, -4.5309, -4.7184, -4.5779, -4.2629, -4.7723, -4.7525,\n",
      "         -4.7220, -4.3848, -4.8456, -4.8105, -4.7666, -4.2076, -4.3803, -4.6714,\n",
      "         -4.4088]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : child\n",
      "target index is: [5] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3773, -4.4462, -4.9697, -4.6443, -4.1208, -4.7657, -4.5723, -4.6838,\n",
      "         -4.7185, -4.4890, -4.9801, -4.5517, -4.8820, -4.7611, -4.7795, -4.8702,\n",
      "         -4.5894, -4.6739, -4.7940, -4.4850, -4.5512, -4.3616, -4.8622, -4.6350,\n",
      "         -4.7111, -5.2387, -4.5737, -4.4840, -4.1564, -4.7156, -4.4906, -4.7986,\n",
      "         -4.6929, -4.7191, -4.5600, -4.8044, -4.4566, -4.6547, -4.7105, -4.5253,\n",
      "         -4.6498, -4.4625, -4.5126, -4.4170, -4.5507, -4.2637, -4.7219, -4.5883,\n",
      "         -4.6013, -4.9036, -4.7673, -4.6120, -5.0245, -4.3804, -4.4144, -4.2409,\n",
      "         -4.3461, -4.1619, -4.5845, -4.7397, -4.5242, -4.4117, -4.7742, -4.4391,\n",
      "         -4.4416, -4.5688, -4.7552, -4.3170, -4.4514, -4.4002, -4.4205, -4.5627,\n",
      "         -4.8043, -4.9761, -5.0010, -5.2135, -4.8021, -4.2675, -4.5562, -4.7778,\n",
      "         -4.6094, -4.3839, -4.6610, -4.9819, -4.7193, -4.1528, -4.3985, -4.3026,\n",
      "         -4.8697, -4.4465, -4.4312, -4.3899, -4.6413, -4.5347, -4.6291, -4.5771,\n",
      "         -4.1819]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : of\n",
      "target index is: [57] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6059, -4.0699, -4.5724, -4.7157, -4.1078, -4.8122, -4.8118, -4.5417,\n",
      "         -4.7534, -4.8625, -5.1004, -4.4986, -4.5809, -4.5376, -4.6579, -4.5834,\n",
      "         -4.7636, -4.5554, -4.6764, -4.3945, -4.5082, -4.2082, -4.7836, -4.4438,\n",
      "         -4.2517, -4.6041, -4.4855, -4.4574, -4.2458, -4.7571, -4.7076, -4.9759,\n",
      "         -5.0639, -4.5749, -4.7085, -4.7233, -4.8617, -4.8804, -4.8303, -4.7478,\n",
      "         -4.6997, -4.4369, -4.5944, -4.5693, -4.5081, -4.2897, -4.8404, -4.9273,\n",
      "         -4.5222, -4.7571, -4.4925, -4.4765, -4.5839, -4.3076, -4.7758, -4.7271,\n",
      "         -4.4066, -4.4515, -4.4934, -4.5732, -4.8627, -4.8110, -4.4186, -4.2849,\n",
      "         -4.6266, -4.7347, -5.0524, -4.4471, -4.7841, -4.7038, -4.5300, -4.5450,\n",
      "         -4.6356, -4.9294, -4.6145, -4.7164, -4.5237, -4.3954, -4.6186, -4.7962,\n",
      "         -4.1150, -4.3754, -4.6122, -4.6568, -4.4617, -4.3377, -4.5644, -4.8287,\n",
      "         -4.5077, -4.2804, -4.8403, -4.8489, -4.6279, -4.2242, -4.1909, -4.7826,\n",
      "         -4.3380]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : mine\n",
      "target index is: [86] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1021, -4.3455, -4.6080, -5.0229, -4.1423, -4.6372, -4.8029, -4.4996,\n",
      "         -4.6948, -4.7817, -5.0157, -4.3002, -4.9078, -4.5306, -4.5930, -4.7937,\n",
      "         -4.6676, -4.8626, -4.5755, -4.1906, -4.9339, -4.7260, -4.5745, -4.1211,\n",
      "         -4.5126, -4.4875, -4.6800, -4.4735, -4.2005, -4.6339, -4.5755, -4.9961,\n",
      "         -4.7726, -4.5209, -4.6500, -4.6968, -4.6481, -4.7416, -4.8103, -4.7349,\n",
      "         -4.8994, -4.4775, -4.7767, -4.5392, -4.7825, -4.1722, -4.8778, -4.6193,\n",
      "         -4.5581, -4.5985, -4.6562, -4.8721, -4.6122, -4.3589, -4.8161, -4.6699,\n",
      "         -4.3368, -4.4208, -4.6816, -4.5611, -4.6044, -4.5959, -4.4360, -4.3677,\n",
      "         -4.7603, -4.6313, -5.1654, -4.8138, -4.6407, -4.7817, -4.2782, -4.5748,\n",
      "         -4.5857, -4.9022, -4.6135, -4.6036, -4.5688, -4.2228, -4.5422, -4.4885,\n",
      "         -4.6279, -4.2793, -4.7047, -4.7890, -4.6750, -4.4549, -4.4154, -4.4216,\n",
      "         -4.8992, -4.2534, -4.5038, -4.6120, -4.5073, -4.5185, -4.3164, -4.6022,\n",
      "         -4.3990]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Shall\n",
      "target index is: [81] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2503, -4.3884, -4.5762, -5.0848, -4.0532, -4.7224, -4.6757, -4.5572,\n",
      "         -4.7148, -4.9454, -4.7642, -4.3006, -4.6563, -4.7665, -4.7174, -4.6185,\n",
      "         -4.3363, -4.7088, -4.5042, -4.6336, -4.5908, -4.5195, -4.6901, -4.4083,\n",
      "         -4.3857, -4.5363, -4.3737, -4.4549, -4.4086, -4.8529, -4.1570, -5.0091,\n",
      "         -4.5684, -4.6471, -4.5704, -4.9913, -4.4534, -4.6398, -4.8574, -4.9650,\n",
      "         -4.6469, -4.7770, -4.7593, -4.6251, -4.6173, -4.1983, -4.5136, -4.7080,\n",
      "         -4.7609, -4.6554, -4.5601, -4.6071, -4.6645, -4.4370, -4.5782, -4.9922,\n",
      "         -4.6014, -4.6143, -4.5375, -4.4978, -4.6972, -4.5382, -4.6374, -4.1577,\n",
      "         -4.7860, -4.7535, -4.8012, -4.5624, -4.5145, -4.3754, -4.7307, -4.6435,\n",
      "         -4.8256, -4.8123, -4.7202, -4.5341, -4.6084, -4.1862, -4.4816, -4.5108,\n",
      "         -4.4974, -4.3666, -4.7682, -5.0701, -4.5330, -4.5588, -4.1806, -4.5833,\n",
      "         -4.9093, -4.3941, -4.5297, -4.7749, -4.7854, -4.3837, -4.1435, -4.6874,\n",
      "         -4.4626]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : sum\n",
      "target index is: [70] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3082, -4.3876, -4.6897, -4.8283, -4.1900, -4.8765, -4.5278, -4.3695,\n",
      "         -4.6563, -4.7687, -4.7086, -4.3157, -4.5675, -4.9673, -4.8011, -4.6887,\n",
      "         -4.5253, -5.1672, -4.7081, -4.6370, -4.5990, -4.3113, -4.7093, -4.5871,\n",
      "         -4.3061, -4.9741, -4.3069, -4.4657, -4.4717, -4.6356, -4.5729, -4.8918,\n",
      "         -4.8691, -4.9432, -4.3250, -4.4792, -4.7232, -4.4651, -4.6859, -4.5929,\n",
      "         -5.0629, -4.4097, -4.5925, -4.5201, -4.4054, -4.2309, -4.4056, -4.6191,\n",
      "         -4.3334, -4.7957, -4.6072, -4.1281, -4.9571, -4.4437, -4.6910, -4.5518,\n",
      "         -4.6233, -4.4376, -4.5954, -4.9421, -4.8074, -4.5906, -4.6848, -4.3293,\n",
      "         -4.9318, -4.6040, -4.8482, -4.3890, -4.5799, -4.6101, -4.3373, -4.8110,\n",
      "         -4.5512, -4.8284, -4.6594, -4.7971, -4.5587, -4.1691, -4.6018, -4.8243,\n",
      "         -4.3191, -4.6652, -4.5473, -4.6466, -4.2631, -4.5825, -4.4914, -4.6857,\n",
      "         -5.0246, -4.4415, -4.6401, -4.5532, -4.5549, -4.7045, -4.4918, -4.4236,\n",
      "         -4.4138]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : my\n",
      "target index is: [90] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3987, -4.3779, -4.6037, -5.1571, -4.2335, -5.1506, -4.4852, -4.4849,\n",
      "         -4.7337, -4.6340, -5.1262, -4.5789, -4.7363, -4.7642, -4.3816, -4.6264,\n",
      "         -4.6276, -4.6841, -4.9500, -4.3355, -4.8031, -4.3034, -4.7552, -4.6075,\n",
      "         -4.3881, -5.0017, -4.2291, -4.4788, -4.1376, -4.5994, -4.6708, -4.8736,\n",
      "         -4.7879, -4.9164, -4.7370, -4.5686, -4.6806, -4.4115, -4.8743, -4.5282,\n",
      "         -4.9440, -4.7822, -4.8726, -4.3929, -4.8399, -4.3454, -4.8158, -4.6559,\n",
      "         -4.5456, -5.1751, -4.1194, -5.0959, -4.4405, -4.5594, -4.7260, -4.4353,\n",
      "         -4.5405, -4.4332, -4.3116, -5.0242, -4.6007, -4.3626, -4.4878, -4.2870,\n",
      "         -4.6076, -4.3659, -5.0638, -4.6001, -4.4067, -4.5365, -4.6067, -4.6153,\n",
      "         -4.7442, -4.7221, -4.7401, -5.0151, -4.3773, -4.3348, -4.3586, -4.6518,\n",
      "         -4.4206, -4.5021, -4.8284, -4.4457, -4.6451, -4.1728, -4.5205, -4.8539,\n",
      "         -4.4872, -4.6103, -4.3677, -4.5649, -4.7146, -4.3420, -4.6462, -4.3086,\n",
      "         -4.1757]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : count,\n",
      "target index is: [55] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5888, -4.2543, -4.7202, -4.9546, -4.5021, -4.9528, -4.6310, -4.4550,\n",
      "         -4.6193, -4.8823, -4.9690, -4.6581, -4.6987, -4.7568, -4.7322, -4.6536,\n",
      "         -4.5799, -4.5885, -4.8589, -4.6443, -4.6131, -4.6791, -4.8827, -4.3995,\n",
      "         -4.3952, -4.7028, -4.5224, -4.2176, -4.2917, -4.6171, -4.2257, -4.8803,\n",
      "         -5.0129, -4.7968, -4.8482, -4.6433, -4.5709, -4.8084, -4.7263, -4.5138,\n",
      "         -4.6171, -4.6544, -4.3878, -4.5800, -4.4620, -4.2404, -4.9858, -4.6681,\n",
      "         -4.6482, -4.9408, -4.2734, -4.6650, -4.7616, -4.3256, -4.6241, -4.4417,\n",
      "         -4.2203, -4.2323, -4.6533, -4.4575, -4.6043, -4.5329, -4.3211, -4.1623,\n",
      "         -4.5916, -4.5016, -4.9613, -4.4104, -4.2204, -4.1745, -4.4649, -4.5465,\n",
      "         -4.8136, -4.7981, -5.0090, -5.1158, -4.3440, -4.2377, -4.6816, -4.9165,\n",
      "         -4.6861, -4.7321, -4.8499, -4.8523, -4.7581, -4.2960, -4.1950, -4.5588,\n",
      "         -4.7774, -4.3431, -4.3308, -4.9355, -4.7881, -4.3016, -4.5677, -4.7249,\n",
      "         -4.3965]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : and\n",
      "target index is: [44] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6633, -4.4710, -4.7114, -4.6781, -4.2042, -4.9023, -4.4107, -4.2680,\n",
      "         -4.7487, -4.9915, -4.6532, -4.4967, -4.6522, -4.8860, -4.6961, -4.4053,\n",
      "         -4.3164, -4.8211, -4.5497, -4.6719, -4.4901, -4.2898, -4.4332, -4.5431,\n",
      "         -4.2019, -4.8327, -4.4589, -4.5096, -4.7666, -4.4552, -4.6191, -4.8455,\n",
      "         -4.8056, -4.8544, -4.3622, -4.2750, -4.9240, -4.7981, -4.8270, -4.6649,\n",
      "         -4.9788, -4.6283, -4.8615, -4.5563, -4.4427, -4.5352, -4.3143, -4.7905,\n",
      "         -4.2505, -4.5720, -4.6460, -4.3368, -4.8036, -4.1976, -4.5547, -4.6011,\n",
      "         -4.5434, -4.6099, -4.6873, -4.7981, -4.9781, -4.6964, -4.3967, -4.1492,\n",
      "         -4.9433, -4.4662, -4.7204, -4.1393, -4.6737, -4.8365, -4.5541, -4.8867,\n",
      "         -4.3702, -4.6461, -4.7749, -4.8438, -4.3026, -4.4773, -4.7064, -4.4705,\n",
      "         -4.3112, -4.5363, -4.7741, -4.7991, -4.6420, -4.4934, -4.6938, -4.7974,\n",
      "         -4.9653, -4.1402, -4.8603, -4.9344, -4.3426, -4.4395, -4.4898, -4.4526,\n",
      "         -4.5620]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : make\n",
      "target index is: [14] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4520, -4.2534, -4.7361, -5.1393, -4.3500, -4.6416, -4.5872, -4.4254,\n",
      "         -4.6758, -4.6919, -4.7745, -4.5583, -4.8279, -4.6461, -4.4195, -4.5917,\n",
      "         -4.6165, -4.7407, -4.7561, -4.1613, -4.8585, -4.6845, -4.8774, -4.4105,\n",
      "         -4.7003, -4.6906, -4.4251, -4.3653, -4.2846, -4.6719, -4.5708, -4.7952,\n",
      "         -4.8844, -4.7801, -4.4451, -4.4363, -4.5214, -4.9638, -4.8018, -4.6257,\n",
      "         -4.7137, -4.6445, -4.6236, -4.4600, -4.7381, -4.3589, -5.0752, -4.5207,\n",
      "         -4.4172, -4.9763, -4.2306, -4.8832, -4.2443, -4.5648, -4.9965, -4.2617,\n",
      "         -4.5290, -4.3592, -4.8208, -4.4704, -4.5879, -4.5984, -4.4022, -4.4463,\n",
      "         -4.6302, -4.4490, -5.2169, -4.8908, -4.4523, -4.5497, -4.2264, -4.6890,\n",
      "         -4.5752, -4.8220, -4.5124, -4.7827, -4.4560, -4.2797, -4.6877, -4.7207,\n",
      "         -4.6623, -4.6106, -4.6847, -4.7515, -4.6003, -4.4406, -4.4692, -4.5630,\n",
      "         -4.5114, -4.1794, -4.5297, -4.4075, -4.7841, -4.4398, -4.6337, -4.5213,\n",
      "         -4.3745]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : my\n",
      "target index is: [90] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3331, -4.2417, -4.8783, -5.0364, -4.2117, -5.0018, -4.3427, -4.4100,\n",
      "         -4.8192, -4.6813, -4.6778, -4.4022, -4.6213, -4.9816, -4.7727, -4.4816,\n",
      "         -4.3930, -4.8071, -4.7720, -4.6166, -4.7969, -4.1562, -4.7142, -4.9176,\n",
      "         -4.2458, -5.0290, -4.1817, -4.5440, -4.1698, -4.6928, -4.3656, -4.8959,\n",
      "         -4.5992, -4.7270, -4.7424, -4.6621, -4.8508, -4.3491, -5.0165, -4.8321,\n",
      "         -4.7097, -4.9154, -4.6386, -4.5751, -4.5303, -4.3095, -4.5758, -4.8829,\n",
      "         -4.6442, -4.7886, -4.5350, -4.6018, -4.6781, -4.6302, -4.5171, -4.7175,\n",
      "         -4.7570, -4.4967, -4.5074, -4.8708, -4.8118, -4.1556, -4.5011, -4.0364,\n",
      "         -4.7161, -4.8636, -4.8186, -4.5375, -4.4851, -4.0465, -4.7036, -4.7497,\n",
      "         -4.6008, -4.5669, -4.7785, -4.9215, -4.4499, -4.4759, -4.3320, -4.5616,\n",
      "         -4.4524, -4.4915, -4.9978, -4.7481, -4.6031, -4.6313, -4.6557, -4.5761,\n",
      "         -4.6136, -4.2741, -4.4995, -4.7630, -4.8204, -4.2426, -4.3546, -4.4662,\n",
      "         -4.3118]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : old\n",
      "target index is: [84] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.0870, -4.3516, -4.4111, -5.0288, -4.2772, -5.2512, -4.3948, -4.4173,\n",
      "         -4.5117, -4.9276, -4.9690, -4.7984, -4.2613, -4.8117, -4.9289, -4.4199,\n",
      "         -4.5221, -4.5769, -4.8658, -4.7488, -4.7137, -4.2715, -5.0702, -4.7532,\n",
      "         -4.0184, -4.8607, -4.3458, -4.5130, -3.9512, -4.7166, -4.6058, -4.6843,\n",
      "         -4.6426, -4.9896, -4.8728, -4.5982, -4.7897, -4.3265, -4.7347, -4.5592,\n",
      "         -4.8522, -4.5015, -4.7891, -4.2872, -4.5165, -4.4166, -4.8278, -4.5603,\n",
      "         -4.6167, -4.9122, -4.0765, -4.7303, -4.9183, -4.6755, -4.7141, -4.5673,\n",
      "         -4.2522, -4.5396, -4.4096, -4.8280, -4.9499, -4.3631, -4.3910, -4.2952,\n",
      "         -4.6949, -4.7420, -4.8854, -4.5780, -4.4873, -4.3819, -4.5817, -4.4359,\n",
      "         -4.7663, -4.8771, -4.7404, -4.9530, -4.3236, -4.3567, -4.6591, -4.8804,\n",
      "         -4.1205, -4.5695, -4.8308, -4.7496, -4.4993, -4.5004, -4.6132, -4.7796,\n",
      "         -4.8665, -4.5525, -4.5436, -4.6163, -4.6083, -4.4388, -4.8406, -4.3740,\n",
      "         -4.4215]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : excuse,'\n",
      "target index is: [64] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4824, -4.4313, -4.5220, -4.7943, -4.1765, -4.9184, -4.6199, -4.3570,\n",
      "         -4.7524, -4.8117, -4.7426, -4.6526, -4.4951, -4.4995, -4.8293, -4.6282,\n",
      "         -4.7221, -4.2824, -4.6449, -4.6085, -4.4068, -4.6971, -4.4748, -4.7668,\n",
      "         -4.2636, -4.7371, -4.5875, -4.5626, -4.3814, -4.2412, -4.6446, -4.6850,\n",
      "         -4.8916, -4.7558, -4.6610, -5.2289, -4.8117, -4.6722, -4.6031, -4.5259,\n",
      "         -4.3669, -4.7962, -4.8081, -4.6374, -4.5703, -4.6047, -4.5464, -4.4668,\n",
      "         -4.5032, -4.4600, -4.3048, -4.5149, -4.4837, -4.4921, -4.5714, -4.4256,\n",
      "         -4.6204, -4.4453, -4.3796, -4.6177, -4.9414, -4.5229, -4.5374, -3.7631,\n",
      "         -4.6862, -4.4245, -4.6726, -4.3602, -4.5009, -4.6435, -4.6123, -4.5991,\n",
      "         -4.9434, -4.8528, -4.8462, -4.6471, -4.6319, -4.5044, -4.4372, -4.5768,\n",
      "         -4.7352, -4.7073, -4.9475, -4.9310, -4.6727, -4.2252, -4.4244, -4.9594,\n",
      "         -4.8842, -4.1683, -4.4977, -4.7076, -4.5903, -4.5138, -4.6698, -4.5562,\n",
      "         -4.8732]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Proving\n",
      "target index is: [25] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4602, -4.6007, -4.9597, -4.7388, -4.4786, -4.6936, -4.6276, -4.4728,\n",
      "         -4.6068, -4.5679, -4.9464, -4.4088, -4.4461, -4.5089, -4.5429, -4.8649,\n",
      "         -4.5926, -4.8662, -4.3940, -4.5861, -4.5092, -4.4831, -4.7209, -4.5095,\n",
      "         -4.4222, -4.7137, -4.2260, -4.5918, -4.4492, -4.4659, -5.0687, -4.8183,\n",
      "         -4.8187, -4.8297, -4.9854, -5.0137, -4.4688, -4.7176, -4.6203, -4.3648,\n",
      "         -4.7744, -4.5851, -4.6240, -4.6878, -4.3298, -4.3792, -4.7449, -4.8142,\n",
      "         -4.4522, -4.9311, -4.2883, -4.5344, -4.5235, -4.1516, -4.5478, -4.2710,\n",
      "         -4.7010, -4.3726, -4.5494, -4.3680, -4.4889, -4.3358, -4.3866, -4.0381,\n",
      "         -4.4324, -4.5906, -4.7132, -4.7110, -4.9531, -4.1905, -4.0506, -4.5722,\n",
      "         -5.1066, -4.3384, -4.8211, -4.9762, -4.3653, -4.4558, -4.4505, -4.6114,\n",
      "         -4.6790, -4.6211, -4.9262, -4.8920, -4.8882, -4.5473, -5.1167, -5.0057,\n",
      "         -4.8433, -4.4156, -4.6177, -4.6853, -4.7289, -4.2179, -4.6261, -4.8350,\n",
      "         -4.3619]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : his\n",
      "target index is: [49] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6597, -4.3183, -4.9163, -5.1003, -4.2659, -4.5969, -4.2266, -4.3812,\n",
      "         -4.9857, -4.4604, -4.7277, -4.3080, -4.7335, -4.6823, -4.9003, -4.5384,\n",
      "         -4.5068, -4.4768, -4.6991, -4.3363, -4.4664, -4.3895, -4.4920, -4.6413,\n",
      "         -4.6353, -4.7834, -4.4216, -4.5689, -4.7428, -4.5549, -4.7086, -4.5840,\n",
      "         -4.7610, -4.7869, -4.5075, -4.6769, -4.4952, -4.8189, -4.7380, -4.3431,\n",
      "         -4.4170, -4.5062, -4.4744, -4.3145, -4.4786, -4.6908, -4.4681, -4.3835,\n",
      "         -4.3591, -5.1820, -4.4549, -4.7746, -4.3809, -4.3638, -4.6188, -4.5498,\n",
      "         -4.9104, -4.7037, -4.2538, -4.7027, -4.9184, -4.4883, -4.5204, -4.3642,\n",
      "         -4.4672, -4.6553, -4.5260, -4.3874, -4.6723, -4.3030, -4.7680, -4.8997,\n",
      "         -4.7418, -4.7920, -4.6920, -4.9265, -4.3881, -4.5228, -4.3557, -4.4968,\n",
      "         -4.8060, -4.6802, -4.8426, -4.5737, -4.9933, -4.3430, -4.7327, -4.6035,\n",
      "         -4.8347, -4.2926, -4.6209, -4.3060, -4.9330, -4.5466, -4.6999, -4.5919,\n",
      "         -4.5288]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty\n",
      "target index is: [0] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5618, -4.4825, -4.8472, -4.6809, -4.3953, -4.7192, -4.7186, -4.0898,\n",
      "         -4.7775, -4.4623, -4.6210, -4.3391, -4.4006, -4.7422, -4.7773, -4.7185,\n",
      "         -4.7002, -4.4876, -4.3288, -4.4761, -4.5886, -4.4630, -4.7268, -4.9260,\n",
      "         -4.2503, -5.2801, -4.3064, -4.7573, -4.0400, -4.4391, -4.6226, -4.6244,\n",
      "         -4.9931, -4.7032, -4.5296, -5.0314, -4.4647, -4.6000, -4.6434, -4.7851,\n",
      "         -4.7269, -4.6492, -4.7361, -4.7398, -4.6028, -4.4515, -4.7703, -5.0214,\n",
      "         -4.8621, -4.8051, -4.6749, -4.4541, -4.8398, -4.5882, -4.6658, -4.5755,\n",
      "         -4.2508, -4.0997, -4.4294, -4.3671, -4.6681, -4.5470, -4.4689, -4.4066,\n",
      "         -4.4274, -4.6914, -4.6043, -4.7308, -4.6590, -4.3419, -4.4746, -4.4952,\n",
      "         -5.1498, -4.6149, -4.9179, -4.8925, -4.4318, -4.2500, -4.2936, -4.8945,\n",
      "         -4.4099, -4.4354, -4.6948, -4.8220, -4.7794, -4.5093, -4.7020, -4.2852,\n",
      "         -4.7578, -4.5640, -4.6073, -4.5841, -4.8545, -4.3101, -4.6340, -4.6204,\n",
      "         -4.2375]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : by\n",
      "target index is: [62] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.0257, -4.6785, -4.6717, -4.6735, -3.8810, -4.7141, -4.4275, -4.1044,\n",
      "         -4.8989, -4.9235, -4.7060, -4.4756, -4.4124, -4.6932, -4.7657, -4.7980,\n",
      "         -4.4178, -4.6789, -4.5491, -4.8068, -4.7290, -4.4110, -4.8915, -4.7317,\n",
      "         -4.1455, -4.7873, -4.4952, -4.3909, -4.5277, -4.7235, -4.5490, -4.4530,\n",
      "         -4.5551, -4.9643, -4.5839, -5.1368, -4.8065, -4.2384, -4.7170, -4.3775,\n",
      "         -4.6950, -4.4575, -4.8448, -4.3499, -4.5185, -3.9161, -4.5186, -4.7565,\n",
      "         -4.8797, -4.5163, -4.7480, -4.3736, -4.8931, -4.2982, -4.4008, -4.4747,\n",
      "         -4.3144, -4.3797, -4.6877, -4.7771, -4.8403, -4.2425, -4.3553, -4.3684,\n",
      "         -4.5499, -4.8286, -4.5781, -4.2077, -4.9694, -4.6457, -4.7276, -4.7680,\n",
      "         -4.5044, -5.0303, -4.7292, -4.8077, -4.6572, -4.3046, -4.5227, -5.0194,\n",
      "         -4.3281, -4.5067, -5.0238, -5.0104, -4.6806, -4.3046, -4.7612, -5.1050,\n",
      "         -5.1527, -4.6056, -4.8872, -4.7154, -4.5097, -4.5185, -4.6209, -4.8142,\n",
      "         -4.5298]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : succession\n",
      "target index is: [7] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6405, -4.4067, -4.6583, -4.6806, -4.1908, -4.6705, -4.6968, -4.4338,\n",
      "         -4.7042, -4.5704, -4.7153, -4.2477, -4.7719, -4.5045, -4.9683, -4.6656,\n",
      "         -4.6442, -4.4962, -4.8492, -4.5108, -4.3487, -4.5830, -4.7908, -4.8760,\n",
      "         -4.5165, -4.7022, -4.4957, -4.2675, -4.1916, -4.4447, -4.4765, -4.7696,\n",
      "         -4.9368, -4.5528, -4.8826, -5.1986, -4.5429, -4.9383, -4.5312, -4.5203,\n",
      "         -4.2899, -4.6802, -4.4399, -4.7251, -4.2799, -4.5375, -4.3271, -4.8249,\n",
      "         -4.4112, -4.8519, -4.5194, -4.5323, -4.5473, -4.4047, -4.6745, -4.5260,\n",
      "         -4.5809, -4.3420, -4.6031, -4.7191, -4.5031, -4.4127, -4.4165, -3.9082,\n",
      "         -4.3933, -4.5372, -4.5905, -4.5452, -4.4062, -4.1175, -4.3799, -4.4374,\n",
      "         -4.9850, -4.8063, -4.8006, -4.9183, -4.7682, -4.3377, -4.5787, -4.8726,\n",
      "         -4.9682, -4.5390, -4.7141, -4.8892, -4.7395, -4.4172, -4.4540, -4.5972,\n",
      "         -4.9851, -4.4811, -4.7613, -4.6577, -4.7991, -4.6991, -4.5880, -4.9888,\n",
      "         -4.7049]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thine!\n",
      "target index is: [40] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6189, -4.3164, -4.6888, -4.4775, -4.2148, -4.7533, -4.5951, -4.2882,\n",
      "         -4.7159, -4.6489, -4.6323, -4.3956, -4.7045, -4.7160, -4.4834, -4.8338,\n",
      "         -4.8867, -5.0554, -4.6388, -4.5698, -4.5455, -4.5791, -4.6272, -4.5317,\n",
      "         -4.5298, -4.5995, -4.1973, -4.4036, -4.3990, -4.6708, -4.8566, -4.8533,\n",
      "         -4.9209, -4.5709, -4.5121, -4.8799, -4.7734, -4.7704, -4.5695, -4.4341,\n",
      "         -4.7310, -4.6270, -4.6075, -4.5743, -4.6195, -4.4748, -4.5833, -4.5488,\n",
      "         -4.3311, -4.7197, -4.3856, -4.4503, -4.5060, -4.5295, -4.9820, -4.1512,\n",
      "         -4.7728, -4.2995, -4.6921, -4.7645, -4.5171, -4.4811, -4.6278, -4.1964,\n",
      "         -4.8793, -4.5335, -4.7236, -4.6266, -4.7899, -4.6486, -4.1951, -4.8068,\n",
      "         -4.7922, -4.5267, -4.3434, -4.9339, -4.6884, -4.4242, -4.4518, -4.4430,\n",
      "         -4.6756, -4.3547, -4.9259, -4.8251, -4.7345, -4.4223, -4.8810, -4.8054,\n",
      "         -4.7169, -4.3947, -4.7642, -4.3452, -4.5710, -4.2989, -4.5429, -4.2685,\n",
      "         -4.6813]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : This\n",
      "target index is: [1] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4687, -4.3511, -4.7531, -4.7799, -4.2031, -4.5648, -4.7595, -4.4751,\n",
      "         -4.5400, -4.5610, -4.7843, -4.6946, -4.8274, -4.6837, -4.4459, -4.7189,\n",
      "         -4.6138, -4.6112, -4.8379, -4.3946, -4.6901, -4.6228, -5.0559, -4.5073,\n",
      "         -4.5322, -4.6741, -4.5170, -4.4240, -4.2639, -4.7257, -4.5735, -4.7651,\n",
      "         -4.7718, -4.7064, -4.6249, -4.8588, -4.4434, -4.8514, -4.6914, -4.6545,\n",
      "         -4.6122, -4.4089, -4.6415, -4.6460, -4.5762, -4.2452, -4.7538, -4.5641,\n",
      "         -4.3114, -4.7385, -4.4688, -4.7251, -4.6479, -4.5503, -4.7947, -4.4521,\n",
      "         -4.3124, -4.2012, -4.7205, -4.3129, -4.6114, -4.6825, -4.3772, -4.2983,\n",
      "         -4.5582, -4.7601, -4.9059, -4.7692, -4.4740, -4.3599, -4.1784, -4.3507,\n",
      "         -4.9554, -4.8638, -4.6562, -4.8009, -4.4205, -4.3732, -4.6832, -4.6710,\n",
      "         -4.5523, -4.4274, -4.6001, -4.8171, -4.7615, -4.5447, -4.5529, -4.5037,\n",
      "         -4.7492, -4.2941, -4.5611, -4.5635, -4.8809, -4.4038, -4.4854, -4.7529,\n",
      "         -4.4981]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : were\n",
      "target index is: [93] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2652, -4.4738, -4.7730, -4.8949, -3.8272, -4.5437, -4.4125, -4.2802,\n",
      "         -4.6390, -4.8787, -4.6154, -4.4581, -4.6232, -4.9267, -4.7617, -4.5331,\n",
      "         -4.4959, -4.9843, -4.5905, -4.4257, -4.8573, -4.1579, -4.7261, -4.9452,\n",
      "         -4.3478, -4.6834, -4.4001, -4.3528, -4.2817, -4.8656, -4.3966, -4.9212,\n",
      "         -4.6608, -4.6237, -4.3042, -4.8331, -4.9045, -4.5583, -5.1116, -4.7852,\n",
      "         -4.6819, -4.6908, -4.7617, -4.5924, -4.8021, -4.2491, -4.2562, -4.7258,\n",
      "         -4.4748, -4.7646, -4.8419, -4.3383, -4.7741, -4.6251, -4.6131, -4.4445,\n",
      "         -4.3942, -4.3808, -4.4370, -4.7636, -4.6337, -4.4748, -4.8471, -4.0690,\n",
      "         -4.7460, -4.6942, -4.7379, -4.6032, -4.7803, -4.5125, -4.5844, -4.6277,\n",
      "         -4.3134, -4.8028, -4.6610, -4.5187, -4.7224, -4.7047, -4.5720, -4.4405,\n",
      "         -4.6822, -4.5236, -5.0416, -4.7797, -4.2259, -4.6248, -4.4544, -4.7605,\n",
      "         -4.7348, -4.4393, -4.7646, -4.5578, -4.8049, -4.4734, -4.5055, -4.5161,\n",
      "         -4.5413]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : to\n",
      "target index is: [72] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5584, -4.5625, -4.7171, -4.4742, -4.4837, -4.7656, -4.9774, -4.2609,\n",
      "         -4.7102, -4.7012, -4.6246, -4.6435, -4.5392, -4.7228, -4.8101, -4.5614,\n",
      "         -4.7752, -4.2153, -4.6210, -4.6029, -4.3730, -4.5043, -5.0629, -4.8484,\n",
      "         -4.3209, -4.9908, -4.5406, -4.2921, -4.1925, -4.7205, -4.6372, -4.2706,\n",
      "         -5.1032, -4.7903, -4.5729, -5.1718, -4.5284, -4.7112, -4.6228, -4.7397,\n",
      "         -4.4820, -4.5363, -4.5993, -4.6016, -4.5021, -4.3274, -4.7112, -4.7422,\n",
      "         -4.7632, -4.6712, -4.3736, -4.5856, -4.6644, -4.7945, -4.8398, -4.6805,\n",
      "         -3.9750, -4.1103, -4.5016, -4.3230, -4.5461, -4.4467, -4.2830, -4.1668,\n",
      "         -4.4474, -4.5408, -4.8556, -4.9500, -4.4623, -4.4298, -4.1726, -4.1971,\n",
      "         -5.1979, -4.9901, -4.8878, -4.9033, -4.2845, -4.2702, -4.6014, -4.6804,\n",
      "         -4.4608, -4.5707, -4.5749, -4.9907, -4.7810, -4.5785, -4.5421, -4.5306,\n",
      "         -5.0524, -4.5061, -4.6431, -4.6787, -5.0961, -4.2565, -4.5280, -4.8758,\n",
      "         -4.6122]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : be\n",
      "target index is: [24] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2012, -4.8461, -4.8133, -5.0724, -4.0329, -4.8140, -4.5940, -4.2324,\n",
      "         -4.8920, -5.0855, -4.9435, -4.3181, -4.6731, -4.9113, -4.9810, -4.5727,\n",
      "         -3.9791, -5.0255, -4.5772, -5.0302, -4.3712, -4.2093, -4.6296, -4.4776,\n",
      "         -4.2716, -5.0116, -4.0599, -4.6353, -4.5882, -4.7292, -4.1999, -5.3517,\n",
      "         -4.8498, -5.1140, -4.3373, -4.7174, -4.8301, -4.4603, -5.0421, -4.9703,\n",
      "         -5.0707, -4.4321, -4.6630, -4.4865, -4.2277, -4.1053, -4.4568, -4.6869,\n",
      "         -4.5825, -4.4724, -4.4682, -4.1079, -5.2308, -4.3774, -4.7095, -4.6887,\n",
      "         -4.8234, -4.4440, -4.5637, -4.9019, -4.9618, -4.5827, -4.6998, -3.9437,\n",
      "         -4.6362, -4.7564, -4.9827, -4.4510, -4.4003, -4.5211, -4.3316, -4.7596,\n",
      "         -4.6882, -4.8300, -4.6858, -4.8615, -4.7433, -4.0645, -4.6041, -5.0047,\n",
      "         -4.1142, -4.8274, -4.7004, -4.6689, -4.3284, -4.8215, -4.3058, -4.9192,\n",
      "         -4.9972, -4.4597, -4.3278, -4.6756, -4.7705, -4.6066, -4.3442, -4.6432,\n",
      "         -4.3075]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : new\n",
      "target index is: [27] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5487, -4.4776, -4.3606, -4.7227, -4.1769, -4.7274, -4.6547, -4.3863,\n",
      "         -4.6062, -4.6476, -4.8546, -4.5210, -4.6253, -4.7349, -4.5852, -4.6427,\n",
      "         -4.5188, -4.5615, -4.4784, -4.6088, -4.7694, -4.6228, -4.5411, -4.4792,\n",
      "         -4.3920, -4.6417, -4.4655, -4.6491, -4.4729, -4.4164, -4.5076, -4.6467,\n",
      "         -4.8425, -4.7226, -4.5559, -4.7114, -4.6504, -4.6831, -4.5709, -4.7030,\n",
      "         -4.6624, -4.5430, -4.9764, -4.6335, -4.7110, -4.6086, -4.6602, -4.5589,\n",
      "         -4.5411, -4.3665, -4.3152, -4.5387, -4.6632, -4.3354, -4.7260, -4.4777,\n",
      "         -4.5371, -4.6059, -4.5233, -4.6598, -4.7277, -4.6023, -4.5630, -4.1012,\n",
      "         -4.9827, -4.4594, -4.8754, -4.4361, -4.6988, -4.9995, -4.5839, -4.6112,\n",
      "         -4.7187, -4.7498, -4.6578, -4.6942, -4.4785, -4.4406, -4.4341, -4.8270,\n",
      "         -4.4316, -4.3448, -4.6044, -4.7754, -4.6943, -4.3212, -4.5708, -4.7723,\n",
      "         -4.7743, -4.1803, -4.5968, -4.8224, -4.3818, -4.5604, -4.3770, -4.4144,\n",
      "         -4.7026]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : made\n",
      "target index is: [16] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3502, -4.6313, -4.7520, -4.8532, -4.2449, -4.6814, -4.4127, -4.5273,\n",
      "         -4.6857, -4.3994, -4.8790, -4.4677, -4.6664, -4.5480, -4.6946, -4.8163,\n",
      "         -4.4603, -4.7069, -4.5967, -4.5990, -4.3476, -4.3803, -4.7014, -4.5647,\n",
      "         -4.6474, -5.1482, -4.1469, -4.6864, -4.6127, -4.7369, -4.5313, -4.8876,\n",
      "         -4.5593, -4.9380, -4.5180, -4.9695, -4.5325, -4.3586, -4.6395, -4.4055,\n",
      "         -4.6437, -4.5340, -4.5405, -4.4180, -4.4693, -4.4650, -4.7007, -4.5291,\n",
      "         -4.5866, -4.8492, -4.3722, -4.7978, -4.8170, -4.4951, -4.6149, -4.4271,\n",
      "         -4.7840, -4.5402, -4.4014, -4.5905, -4.5586, -4.5020, -4.5846, -4.2454,\n",
      "         -4.3348, -4.8651, -4.7993, -4.3692, -4.6110, -4.3952, -4.5689, -4.6786,\n",
      "         -4.8218, -4.6931, -4.7657, -4.8733, -4.4960, -4.3826, -4.3033, -4.6023,\n",
      "         -4.4480, -4.5917, -4.7430, -4.7486, -4.7830, -4.3953, -4.7421, -4.5256,\n",
      "         -4.9534, -4.6559, -4.3420, -4.5964, -4.6638, -4.5363, -4.5301, -4.4617,\n",
      "         -4.3259]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : when\n",
      "target index is: [85] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4484, -4.5681, -4.8348, -4.7600, -4.2419, -4.6464, -4.2690, -4.3720,\n",
      "         -4.8836, -4.5493, -4.9224, -4.4712, -4.7302, -4.6046, -4.4799, -4.5246,\n",
      "         -4.2642, -4.6656, -4.7350, -4.4347, -4.4596, -4.3417, -4.7065, -4.7470,\n",
      "         -4.6242, -5.0852, -4.5263, -4.2678, -4.7687, -4.7717, -4.6971, -4.5887,\n",
      "         -4.7103, -5.0448, -4.4737, -4.7532, -4.3656, -4.5711, -4.8760, -4.3700,\n",
      "         -4.6000, -4.6805, -4.6731, -4.3775, -4.5813, -4.1741, -4.7577, -4.8874,\n",
      "         -4.7305, -4.9433, -4.5924, -4.6736, -4.5243, -3.8398, -4.3937, -4.5767,\n",
      "         -4.5987, -4.5496, -4.5809, -4.6126, -4.5901, -4.5006, -4.4260, -4.5746,\n",
      "         -4.4584, -4.4229, -4.8841, -4.1807, -4.7656, -4.5160, -4.6186, -4.8968,\n",
      "         -4.8497, -4.7771, -4.8884, -5.0033, -4.4732, -4.4261, -4.3893, -4.8717,\n",
      "         -4.4872, -4.4517, -4.6374, -4.7285, -4.9186, -4.0550, -4.9611, -4.9345,\n",
      "         -4.8233, -4.4088, -4.4293, -4.6611, -4.7430, -4.5018, -4.4917, -4.7134,\n",
      "         -4.2739]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thou\n",
      "target index is: [22] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6291, -4.5988, -4.9570, -4.6558, -4.1932, -4.7604, -4.4790, -4.7109,\n",
      "         -4.6454, -4.5454, -4.6906, -4.2390, -4.7978, -4.6981, -4.7265, -4.2485,\n",
      "         -4.7258, -4.6511, -4.8163, -4.4879, -4.7701, -4.1736, -4.7942, -4.6055,\n",
      "         -4.2077, -4.7121, -4.7647, -4.3819, -4.3044, -4.3560, -4.7231, -4.5727,\n",
      "         -4.7293, -4.8406, -4.5973, -4.4745, -4.5988, -4.8156, -4.9590, -4.3510,\n",
      "         -4.8919, -4.1876, -4.6517, -4.5492, -4.3814, -4.5031, -4.5707, -4.8045,\n",
      "         -4.3743, -5.1462, -4.7278, -4.6949, -4.6406, -4.2447, -4.6130, -4.4259,\n",
      "         -4.2662, -4.4790, -4.6327, -4.4184, -4.6664, -4.5414, -4.3418, -4.5661,\n",
      "         -4.7330, -4.4598, -4.5802, -4.4454, -4.7847, -4.2522, -4.3080, -4.6492,\n",
      "         -4.8892, -4.8885, -4.7960, -4.9226, -4.4992, -4.6117, -4.6821, -4.6577,\n",
      "         -4.6333, -4.4114, -4.5541, -4.3844, -4.7127, -4.1704, -4.7308, -4.8781,\n",
      "         -4.8302, -4.4393, -4.7900, -4.6639, -4.5765, -4.5935, -4.6373, -4.6191,\n",
      "         -4.6857]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : art\n",
      "target index is: [15] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3554, -4.4725, -4.7670, -4.9274, -4.2550, -4.7767, -4.5859, -4.3923,\n",
      "         -4.6316, -4.8066, -4.6715, -4.4538, -4.4289, -4.7592, -4.7556, -4.2565,\n",
      "         -4.4957, -4.4807, -4.2789, -4.5635, -4.5943, -4.2570, -4.8174, -4.8839,\n",
      "         -4.1812, -4.7110, -4.4246, -4.5426, -4.1964, -4.5784, -4.5390, -4.8476,\n",
      "         -4.8768, -4.6238, -4.5754, -4.9334, -4.6270, -4.6099, -4.9329, -4.9286,\n",
      "         -4.8281, -4.8569, -4.7493, -4.7984, -4.6113, -4.4990, -4.6462, -4.9660,\n",
      "         -4.6046, -4.6632, -4.4465, -4.7818, -4.4938, -4.5152, -4.7606, -4.6676,\n",
      "         -4.3758, -4.4221, -4.4787, -4.4268, -4.6995, -4.3703, -4.3863, -4.1501,\n",
      "         -4.6264, -4.4622, -4.8253, -4.8373, -4.6323, -4.4507, -4.5118, -4.5382,\n",
      "         -4.8954, -4.7195, -4.6210, -4.7927, -4.3754, -4.4330, -4.6304, -4.6522,\n",
      "         -4.4259, -4.4594, -4.9452, -4.8645, -4.4420, -4.6730, -4.5604, -4.6594,\n",
      "         -4.5210, -4.3642, -4.5237, -4.7136, -4.5926, -4.1747, -4.6963, -4.5207,\n",
      "         -4.4831]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : old,\n",
      "target index is: [8] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4359, -4.5550, -4.9777, -4.6894, -4.3299, -4.7145, -4.5286, -4.3365,\n",
      "         -4.7175, -4.5885, -4.7907, -4.3847, -4.5811, -4.9574, -5.0391, -4.9556,\n",
      "         -4.7025, -4.7428, -4.5686, -4.6720, -4.3340, -4.2940, -4.7611, -4.6096,\n",
      "         -4.3643, -5.1323, -4.3005, -4.7029, -4.6488, -4.5877, -4.6926, -4.7839,\n",
      "         -4.6834, -4.8847, -4.4839, -4.8621, -4.7453, -4.3868, -4.5940, -4.3347,\n",
      "         -4.6405, -4.5891, -4.6426, -4.5751, -4.2606, -4.3115, -4.4508, -4.3801,\n",
      "         -4.4819, -4.9152, -4.7724, -4.2635, -4.8809, -4.3810, -4.3324, -4.4048,\n",
      "         -4.5819, -4.2063, -4.2765, -4.7402, -4.7562, -4.4016, -4.4542, -4.2158,\n",
      "         -4.5083, -4.7474, -4.6825, -4.4000, -4.3722, -4.1728, -4.3962, -4.7446,\n",
      "         -4.6530, -4.8679, -4.9275, -4.9365, -4.4507, -4.3501, -4.6363, -4.8118,\n",
      "         -4.5957, -4.7614, -4.8736, -4.7353, -4.5866, -4.5680, -4.5987, -4.8522,\n",
      "         -5.0276, -4.3349, -4.7495, -4.7072, -4.6876, -4.2948, -4.6691, -4.7031,\n",
      "         -4.2861]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : And\n",
      "target index is: [6] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4866, -4.3636, -4.5008, -4.5601, -4.3589, -5.0149, -4.5146, -4.4525,\n",
      "         -4.6475, -4.8014, -4.8432, -4.3712, -4.5540, -4.6330, -4.6422, -4.7095,\n",
      "         -4.6642, -4.6247, -4.9512, -4.5666, -4.4843, -4.5120, -4.5920, -4.5932,\n",
      "         -4.2042, -4.7044, -4.6200, -4.4250, -4.2974, -4.5364, -4.7165, -4.7830,\n",
      "         -4.6509, -4.7289, -4.6173, -4.5420, -4.7847, -4.5911, -4.5544, -4.4093,\n",
      "         -4.8580, -4.3850, -4.7139, -4.4249, -4.4847, -4.3850, -4.4407, -4.6173,\n",
      "         -4.5293, -4.7863, -4.5332, -4.4614, -4.9026, -4.3368, -4.5888, -4.5347,\n",
      "         -4.4374, -4.5665, -4.5676, -4.8048, -4.6879, -4.4938, -4.5305, -4.4093,\n",
      "         -4.7081, -4.6626, -4.7545, -4.2519, -4.7043, -4.6165, -4.6093, -4.6927,\n",
      "         -4.5388, -4.9648, -4.7871, -4.7941, -4.5724, -4.2976, -4.6388, -4.7663,\n",
      "         -4.2786, -4.4570, -4.5937, -4.7163, -4.5494, -4.3120, -4.6010, -4.7672,\n",
      "         -4.8707, -4.5075, -4.7866, -4.7710, -4.2872, -4.5488, -4.5400, -4.5386,\n",
      "         -4.5195]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : see\n",
      "target index is: [67] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4280, -4.5546, -4.7724, -4.9969, -4.4434, -4.7322, -4.5547, -4.4521,\n",
      "         -4.7905, -4.6215, -5.0344, -4.8779, -4.6632, -4.7211, -4.6903, -4.7318,\n",
      "         -4.5391, -4.5451, -4.7190, -4.3767, -4.7596, -4.7263, -4.9385, -4.7275,\n",
      "         -4.6253, -4.9230, -4.5770, -4.3233, -4.3550, -4.7703, -4.5139, -4.7175,\n",
      "         -5.0369, -4.9285, -4.2848, -4.5893, -4.2438, -4.5527, -4.7418, -4.7605,\n",
      "         -4.7710, -4.6126, -4.5708, -4.6218, -4.4831, -4.1107, -4.8031, -4.7181,\n",
      "         -4.7957, -4.8497, -4.2586, -4.5986, -4.5977, -4.3679, -4.7349, -4.7620,\n",
      "         -4.4146, -4.3092, -4.6435, -4.4431, -4.7558, -4.5745, -4.4542, -4.6122,\n",
      "         -4.5583, -4.4621, -5.0814, -4.4445, -4.5339, -4.6835, -4.2564, -4.1600,\n",
      "         -5.0390, -4.9240, -4.7915, -4.8798, -4.3345, -4.1156, -4.3759, -4.7531,\n",
      "         -4.2725, -4.7137, -4.3443, -4.9429, -4.7589, -4.3172, -4.4796, -4.5231,\n",
      "         -4.7261, -4.3248, -4.2421, -4.5441, -4.9432, -4.3819, -4.4424, -4.5561,\n",
      "         -4.1534]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6017, -4.4064, -4.9634, -4.5653, -4.1807, -4.6517, -4.6398, -4.2253,\n",
      "         -5.1297, -4.3813, -4.7451, -4.2002, -4.3174, -4.5934, -4.7738, -4.8561,\n",
      "         -4.3717, -4.5327, -4.3795, -4.5679, -4.6445, -4.3977, -4.3557, -4.7349,\n",
      "         -4.3738, -5.1630, -4.2787, -4.9266, -4.5794, -4.4726, -4.6413, -4.5821,\n",
      "         -4.8351, -4.6422, -4.6002, -5.1095, -4.5966, -4.5308, -4.6058, -4.7034,\n",
      "         -4.4628, -4.7939, -4.8603, -4.6328, -4.4070, -4.1555, -4.5841, -5.0499,\n",
      "         -5.0263, -4.4666, -4.8348, -4.4166, -4.4243, -4.3219, -4.4349, -4.5022,\n",
      "         -4.6446, -4.2577, -4.3181, -4.5307, -4.7358, -4.7268, -4.4308, -4.0288,\n",
      "         -4.4510, -4.6929, -4.7009, -4.4211, -4.8207, -4.5151, -4.6637, -4.6731,\n",
      "         -4.8744, -4.5531, -4.8426, -4.8554, -4.3556, -4.5291, -4.3600, -4.9093,\n",
      "         -4.5092, -4.4700, -4.7670, -4.8251, -4.8305, -4.5748, -4.7747, -4.7341,\n",
      "         -4.9817, -4.4627, -4.6423, -4.7892, -4.8792, -4.3412, -4.2751, -4.9089,\n",
      "         -4.4491]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : blood\n",
      "target index is: [39] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5564, -4.4884, -4.8088, -4.5055, -4.3749, -4.7711, -4.3544, -4.3618,\n",
      "         -4.8443, -4.7605, -4.9652, -4.3716, -4.6892, -4.4645, -4.5244, -4.8785,\n",
      "         -4.6630, -4.8061, -4.3488, -4.4168, -4.7903, -4.8225, -4.6218, -4.4536,\n",
      "         -4.6399, -5.1408, -4.7926, -4.5083, -4.1550, -4.7218, -4.4743, -4.5440,\n",
      "         -4.7243, -4.7000, -4.7058, -5.3108, -4.3767, -4.7057, -4.4539, -4.2726,\n",
      "         -4.4826, -4.4311, -4.7006, -4.1808, -4.7836, -4.1592, -5.0300, -4.6537,\n",
      "         -4.6706, -4.8636, -4.7846, -4.7457, -4.7093, -4.2944, -4.3921, -4.5104,\n",
      "         -4.2720, -4.0867, -4.7226, -4.6566, -4.6471, -4.2282, -4.5857, -4.3565,\n",
      "         -4.5640, -4.5951, -4.6896, -4.2385, -4.6834, -4.1260, -4.4988, -4.6244,\n",
      "         -5.0384, -5.0411, -4.8858, -5.2951, -5.0600, -3.9601, -4.2790, -4.5656,\n",
      "         -5.0469, -4.6155, -5.0045, -5.0543, -5.2678, -4.0450, -4.4510, -4.4964,\n",
      "         -5.2298, -4.3748, -4.8270, -4.5871, -4.7641, -4.5126, -4.4234, -4.5283,\n",
      "         -4.3370]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : warm\n",
      "target index is: [2] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5424, -4.3871, -4.6739, -4.8230, -4.5883, -4.6434, -4.4194, -4.4745,\n",
      "         -4.7696, -5.0616, -4.9549, -4.7894, -4.7277, -4.7946, -4.6092, -4.5062,\n",
      "         -4.7088, -4.9775, -4.5428, -4.2085, -4.8464, -4.2817, -5.1046, -4.4816,\n",
      "         -4.1367, -4.7224, -4.3983, -4.2809, -4.3507, -4.7219, -4.7300, -4.7749,\n",
      "         -4.9352, -4.8545, -4.5926, -4.4255, -4.8101, -4.9427, -4.8853, -4.7246,\n",
      "         -4.8326, -4.5808, -4.6745, -4.5487, -4.6894, -4.3173, -4.8502, -4.8280,\n",
      "         -4.2436, -4.8677, -4.4648, -4.4001, -4.4138, -4.1558, -4.6982, -4.1905,\n",
      "         -4.4854, -4.1294, -4.6879, -4.6808, -4.7830, -4.7466, -4.3669, -4.4060,\n",
      "         -4.8043, -4.4580, -5.1376, -4.5424, -4.6879, -4.3331, -4.1150, -4.7027,\n",
      "         -4.3887, -4.5139, -4.5706, -4.7987, -4.4352, -4.3259, -4.6006, -4.8108,\n",
      "         -4.4397, -4.8361, -4.7489, -4.5657, -4.3479, -4.5634, -4.7821, -5.0681,\n",
      "         -4.5637, -4.1208, -4.6315, -4.5580, -4.7306, -4.7635, -4.3466, -4.6997,\n",
      "         -4.2568]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : when\n",
      "target index is: [85] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4755, -4.3369, -4.7576, -4.9828, -4.2554, -4.7527, -4.3367, -4.4242,\n",
      "         -4.7173, -4.3708, -4.6505, -4.6756, -4.8357, -4.6252, -4.4481, -4.5014,\n",
      "         -4.3035, -4.6410, -4.8083, -4.5721, -4.4869, -4.4398, -4.6458, -4.6830,\n",
      "         -4.5294, -5.0655, -4.4140, -4.3647, -4.8369, -4.6172, -4.6612, -4.5772,\n",
      "         -4.7376, -4.9556, -4.5966, -4.6985, -4.5265, -4.3998, -4.9159, -4.5355,\n",
      "         -4.5577, -4.9253, -4.6602, -4.3620, -4.3939, -4.3860, -4.6888, -4.7938,\n",
      "         -4.5526, -4.6891, -4.4424, -4.8457, -4.6828, -4.2667, -4.6334, -4.6319,\n",
      "         -4.6440, -4.7353, -4.5169, -4.4950, -4.8049, -4.4393, -4.5371, -4.1210,\n",
      "         -4.5218, -4.4363, -4.7394, -4.3237, -4.5734, -4.6338, -4.7725, -5.0803,\n",
      "         -4.9921, -4.2198, -4.7238, -4.9580, -4.4885, -4.7310, -4.5739, -4.6847,\n",
      "         -4.3179, -4.3339, -4.8772, -4.5705, -4.9170, -4.1849, -5.0979, -4.5682,\n",
      "         -4.6170, -4.2234, -4.3030, -4.7272, -4.7753, -4.2290, -4.5214, -4.5770,\n",
      "         -4.6763]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thou\n",
      "target index is: [22] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6300, -4.6004, -4.9513, -4.6564, -4.1942, -4.7607, -4.4740, -4.7113,\n",
      "         -4.6402, -4.5461, -4.6906, -4.2394, -4.7988, -4.6983, -4.7269, -4.2307,\n",
      "         -4.7260, -4.6518, -4.8171, -4.4893, -4.7709, -4.1739, -4.7867, -4.6063,\n",
      "         -4.2085, -4.7126, -4.7662, -4.3831, -4.3054, -4.3565, -4.7239, -4.5737,\n",
      "         -4.7301, -4.8411, -4.5984, -4.4749, -4.5995, -4.8164, -4.9603, -4.3470,\n",
      "         -4.8928, -4.1874, -4.6524, -4.5498, -4.3826, -4.5042, -4.5720, -4.8053,\n",
      "         -4.3752, -5.1470, -4.7289, -4.6959, -4.6418, -4.2459, -4.6145, -4.4272,\n",
      "         -4.2665, -4.4806, -4.6337, -4.4193, -4.6676, -4.5424, -4.3424, -4.5671,\n",
      "         -4.7332, -4.4597, -4.5806, -4.4406, -4.7860, -4.2531, -4.3089, -4.6501,\n",
      "         -4.8899, -4.8898, -4.7967, -4.9238, -4.5000, -4.6128, -4.6785, -4.6580,\n",
      "         -4.6341, -4.4122, -4.5551, -4.3855, -4.7136, -4.1606, -4.7317, -4.8791,\n",
      "         -4.8320, -4.4402, -4.7915, -4.6644, -4.5774, -4.5948, -4.6384, -4.6195,\n",
      "         -4.6871]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : feel'st\n",
      "target index is: [35] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4839, -4.2205, -4.7273, -4.8636, -4.1382, -4.7367, -4.7197, -4.1988,\n",
      "         -4.7807, -4.4871, -4.7099, -4.6361, -4.7632, -4.8362, -4.6877, -4.5574,\n",
      "         -4.6158, -4.3345, -4.6127, -4.4948, -4.5808, -4.5045, -4.5088, -4.8796,\n",
      "         -4.5508, -4.7988, -4.4292, -4.5286, -4.5584, -4.5194, -4.4865, -4.6581,\n",
      "         -4.8647, -4.6462, -4.3096, -4.9203, -4.5163, -4.8152, -4.7617, -4.7779,\n",
      "         -4.5874, -4.8629, -4.5770, -4.6805, -4.4255, -4.4086, -4.4761, -4.6184,\n",
      "         -4.7073, -4.5593, -4.5866, -4.6985, -4.6065, -4.6227, -4.6794, -4.6235,\n",
      "         -4.5729, -4.3570, -4.3959, -4.5160, -4.9257, -4.6005, -4.5363, -4.1931,\n",
      "         -4.5412, -4.5063, -4.5237, -4.5763, -4.5109, -4.6726, -4.6719, -4.5590,\n",
      "         -4.8599, -4.9278, -4.7356, -4.7238, -4.3319, -4.4910, -4.4484, -4.7431,\n",
      "         -4.4838, -4.5042, -4.7230, -4.9034, -4.7605, -4.4142, -4.3894, -4.5615,\n",
      "         -4.5890, -4.1223, -4.4197, -4.5608, -4.8794, -4.3965, -4.5544, -4.6449,\n",
      "         -4.5119]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : it\n",
      "target index is: [88] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5495, -4.4004, -4.7846, -4.7100, -4.1267, -4.8807, -4.5866, -4.2239,\n",
      "         -4.6333, -4.6322, -4.6648, -4.3399, -4.4700, -4.8319, -4.6875, -4.6207,\n",
      "         -4.5392, -5.0276, -4.5437, -4.6529, -4.6811, -4.3778, -4.9871, -4.6347,\n",
      "         -4.1497, -4.8267, -4.1427, -4.6191, -4.1054, -4.6884, -4.6462, -5.2884,\n",
      "         -5.0658, -4.7565, -4.9036, -5.1087, -4.5023, -4.7086, -4.7311, -4.7399,\n",
      "         -4.9485, -4.4333, -4.6292, -4.6248, -4.4860, -4.3105, -4.6758, -4.8587,\n",
      "         -4.4675, -4.7601, -4.7029, -4.1060, -4.8970, -4.3560, -4.8198, -4.4388,\n",
      "         -4.5391, -4.1209, -4.6755, -4.6835, -4.6440, -4.5871, -4.3048, -4.1634,\n",
      "         -4.7342, -4.8444, -4.7541, -4.6646, -4.5345, -4.2480, -4.1529, -4.3479,\n",
      "         -4.8735, -4.7463, -4.7105, -4.7177, -4.7882, -3.9737, -4.6025, -4.7805,\n",
      "         -4.5271, -4.5676, -4.8687, -4.8138, -4.5052, -4.7135, -4.3755, -4.6195,\n",
      "         -4.7906, -4.6312, -4.8691, -4.7622, -4.7448, -4.3017, -4.5686, -4.6503,\n",
      "         -4.2206]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : cold.\n",
      "target index is: [79] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3581, -4.1204, -4.7895, -4.8073, -4.1144, -5.0228, -4.4842, -4.4968,\n",
      "         -4.8319, -4.4882, -4.7984, -4.5593, -4.6875, -4.7626, -5.0656, -4.7189,\n",
      "         -4.6141, -4.1611, -4.8421, -4.4139, -4.7348, -4.3582, -4.6417, -4.8529,\n",
      "         -4.3422, -4.7586, -4.4676, -4.2588, -4.2417, -4.4639, -4.3693, -4.5888,\n",
      "         -4.6841, -4.7461, -4.5291, -4.5106, -4.6846, -4.7479, -4.7269, -4.6934,\n",
      "         -4.6820, -4.5248, -4.5253, -4.3980, -4.4310, -4.3026, -4.4574, -4.7287,\n",
      "         -4.7456, -5.0579, -4.5713, -4.6029, -4.6653, -4.5580, -4.3789, -4.7813,\n",
      "         -4.4309, -4.4341, -4.3247, -4.6758, -4.8628, -4.4231, -4.5997, -4.5047,\n",
      "         -4.5468, -4.9854, -4.5873, -4.2608, -4.5382, -4.4177, -4.6814, -4.6943,\n",
      "         -4.9138, -5.0237, -4.9224, -4.8179, -4.5008, -4.5868, -4.4657, -4.7448,\n",
      "         -4.2532, -4.4944, -4.6292, -4.6666, -4.8843, -4.2691, -4.7972, -4.5673,\n",
      "         -4.7982, -4.4659, -4.6062, -4.5369, -4.7502, -4.5250, -4.4356, -4.6577,\n",
      "         -4.6108]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : winters\n",
      "target index is: [3] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2824, -4.6739, -4.3774, -4.6850, -4.1916, -4.5994, -4.5053, -4.2540,\n",
      "         -4.7495, -4.9125, -4.8204, -4.7930, -4.5356, -4.2539, -4.5763, -4.3852,\n",
      "         -4.1221, -4.6918, -4.6369, -4.8151, -4.8202, -4.6403, -4.6192, -4.5972,\n",
      "         -4.3772, -4.8996, -4.4658, -4.4831, -4.3949, -4.5732, -4.2707, -5.0544,\n",
      "         -4.8985, -4.6551, -4.9440, -4.8971, -4.5769, -4.7026, -5.0244, -4.6878,\n",
      "         -4.9560, -4.3861, -4.8628, -4.3893, -5.0697, -4.3783, -5.1375, -5.2019,\n",
      "         -4.8960, -4.2419, -4.6422, -4.3877, -4.8228, -4.1635, -4.9583, -4.1494,\n",
      "         -4.2879, -4.1322, -4.8681, -4.3937, -4.2946, -4.6506, -4.4662, -4.1140,\n",
      "         -4.5679, -3.9823, -5.3831, -4.5183, -4.8596, -4.6445, -4.5976, -4.3034,\n",
      "         -4.9446, -4.8523, -4.6136, -5.1818, -4.8373, -4.1546, -4.4421, -4.7959,\n",
      "         -4.3117, -4.5737, -4.6880, -5.0519, -4.7550, -4.3692, -4.6972, -4.6520,\n",
      "         -5.1089, -4.3929, -4.3775, -4.6780, -4.6320, -4.6977, -4.4673, -4.7873,\n",
      "         -4.3896]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : shall\n",
      "target index is: [10] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4940, -4.3586, -5.1087, -4.8455, -4.2598, -4.7453, -4.3821, -4.7009,\n",
      "         -4.7580, -4.4434, -4.7389, -4.4150, -4.8037, -4.6783, -5.0400, -4.5042,\n",
      "         -4.7516, -4.5689, -4.6862, -4.4797, -4.5227, -4.0021, -4.6059, -4.5292,\n",
      "         -4.1796, -4.7828, -4.6040, -4.6093, -4.4420, -4.6057, -4.8790, -4.6747,\n",
      "         -4.6002, -4.8397, -4.6998, -4.4308, -4.9366, -4.4912, -5.0136, -4.3847,\n",
      "         -4.9364, -4.7256, -4.6864, -4.7384, -4.3889, -4.4847, -4.6284, -4.6197,\n",
      "         -4.4410, -5.0702, -4.4716, -4.7696, -4.5779, -4.3229, -4.5016, -4.5294,\n",
      "         -4.6739, -4.5204, -4.2180, -4.5738, -4.7908, -4.3882, -4.2593, -4.1608,\n",
      "         -4.4504, -4.7532, -4.6540, -4.5735, -4.6683, -4.1880, -4.4042, -4.7533,\n",
      "         -4.5412, -4.6534, -4.9251, -4.7123, -4.0604, -4.7751, -4.7057, -4.6925,\n",
      "         -4.3684, -4.5288, -4.9365, -4.6379, -4.5843, -4.4228, -4.8515, -4.9718,\n",
      "         -4.7837, -4.3169, -4.6517, -4.9230, -4.6087, -4.2373, -4.6359, -4.7772,\n",
      "         -4.3787]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : besiege\n",
      "target index is: [75] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3719, -4.5325, -4.3920, -4.7737, -4.1153, -4.7809, -4.5424, -4.2636,\n",
      "         -4.6917, -4.7154, -4.9491, -4.6628, -4.6591, -4.5589, -5.0297, -4.6883,\n",
      "         -4.5740, -4.4345, -4.8288, -4.6112, -4.5673, -4.8832, -4.5381, -4.5617,\n",
      "         -4.3806, -4.7035, -4.6761, -4.5978, -4.2971, -4.3721, -4.4957, -4.6012,\n",
      "         -4.7408, -4.7223, -4.8560, -4.7885, -4.6350, -4.6685, -4.6798, -4.4988,\n",
      "         -4.4645, -4.6832, -4.7699, -4.1635, -4.4963, -4.4834, -4.3499, -4.4032,\n",
      "         -4.5318, -4.6055, -4.5603, -4.3376, -4.7626, -4.3892, -4.7286, -4.5619,\n",
      "         -4.5357, -4.4424, -4.4669, -4.6964, -5.0629, -4.4602, -4.6091, -3.8048,\n",
      "         -4.6822, -4.4694, -4.8237, -4.6532, -4.5044, -4.7877, -4.5821, -4.5838,\n",
      "         -4.7915, -4.9309, -4.7645, -4.7368, -4.7220, -4.2321, -4.5345, -4.8851,\n",
      "         -4.6805, -4.5199, -4.6274, -4.9195, -4.7216, -4.2759, -4.3583, -4.7899,\n",
      "         -5.3055, -4.1898, -4.6845, -4.6731, -4.4937, -4.6044, -4.3238, -4.5873,\n",
      "         -4.8352]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1814, -4.5003, -4.7470, -4.9540, -3.9951, -4.6776, -4.8153, -4.4116,\n",
      "         -5.2611, -4.3399, -4.8755, -4.1652, -4.8218, -4.4523, -4.7239, -5.0395,\n",
      "         -4.9183, -4.6363, -4.5433, -4.4621, -4.4964, -4.5530, -4.7302, -4.5031,\n",
      "         -4.8755, -4.8482, -4.0894, -4.6116, -4.5630, -4.5763, -4.6048, -4.9045,\n",
      "         -4.9079, -4.6231, -4.5406, -5.2029, -4.5709, -4.9924, -4.7921, -4.6544,\n",
      "         -4.8742, -4.9687, -4.7378, -4.5764, -4.6517, -4.3306, -4.8837, -4.8357,\n",
      "         -4.8165, -4.6818, -4.3589, -5.0525, -4.3166, -4.4368, -5.0614, -4.2332,\n",
      "         -4.8208, -4.4448, -4.4439, -4.2275, -4.3010, -4.3450, -4.6514, -3.9717,\n",
      "         -4.3656, -4.7013, -5.0453, -4.6490, -4.6913, -4.7385, -4.3342, -4.8271,\n",
      "         -5.2127, -4.6366, -4.4985, -4.9402, -4.3114, -4.3000, -4.2638, -4.5515,\n",
      "         -4.5461, -4.2848, -4.9556, -4.9788, -4.6680, -4.3946, -4.4464, -4.5489,\n",
      "         -4.8294, -4.5917, -4.0465, -4.4272, -4.5927, -4.4782, -4.1534, -4.6489,\n",
      "         -4.5972]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : brow,\n",
      "target index is: [13] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4324, -4.3155, -4.5978, -4.6468, -4.2923, -4.8775, -4.6469, -4.4261,\n",
      "         -4.7322, -4.7780, -4.8368, -4.4692, -4.8141, -4.4020, -4.7577, -4.8919,\n",
      "         -4.6900, -4.7389, -4.4940, -4.4835, -4.8048, -4.9163, -4.6593, -4.3291,\n",
      "         -4.6127, -4.8197, -4.7402, -4.2736, -4.0943, -4.3784, -4.2446, -4.7454,\n",
      "         -4.8789, -4.5979, -4.9371, -5.0289, -4.5421, -4.9027, -4.3433, -4.3748,\n",
      "         -4.7196, -4.6052, -4.4801, -4.1514, -4.5444, -4.1557, -4.7505, -4.8237,\n",
      "         -4.5675, -4.8008, -4.8711, -4.4772, -4.8800, -4.1632, -4.6199, -4.4270,\n",
      "         -4.4061, -4.0294, -4.7475, -4.6239, -4.8887, -4.4462, -4.5750, -4.1470,\n",
      "         -4.7776, -4.5951, -5.0650, -4.5560, -4.5910, -4.4356, -4.3990, -4.5669,\n",
      "         -4.8479, -4.9096, -4.8206, -5.0467, -5.0453, -3.8535, -4.5763, -4.9873,\n",
      "         -4.9670, -4.5453, -4.7309, -5.0239, -5.0296, -4.3653, -4.3755, -4.5333,\n",
      "         -4.9335, -4.0226, -4.8328, -4.6009, -4.6610, -4.5735, -4.3212, -4.8505,\n",
      "         -4.3294]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : And\n",
      "target index is: [6] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3903, -4.3111, -4.6439, -4.8072, -4.1994, -4.8288, -4.7219, -4.5283,\n",
      "         -4.8407, -4.5876, -4.4786, -4.3450, -4.8729, -4.8983, -4.3697, -4.8827,\n",
      "         -4.8781, -5.0017, -4.5201, -4.3899, -4.4255, -4.4019, -4.6679, -4.6189,\n",
      "         -4.6493, -4.7086, -4.2851, -4.4298, -4.3233, -4.9621, -4.5445, -5.2342,\n",
      "         -4.7599, -4.6777, -4.4692, -4.8353, -4.6501, -4.9081, -4.7504, -4.6335,\n",
      "         -4.8278, -4.9776, -4.7553, -4.7004, -4.6856, -4.4922, -4.5343, -4.5985,\n",
      "         -4.4992, -4.9960, -4.5251, -4.6745, -4.3871, -4.7216, -5.1867, -4.5838,\n",
      "         -4.5842, -4.4578, -4.4573, -4.6145, -4.6157, -4.5155, -4.9059, -4.2424,\n",
      "         -4.9730, -4.6670, -4.9550, -4.6210, -4.6534, -4.6770, -4.0981, -4.8554,\n",
      "         -5.0526, -4.5254, -4.2769, -4.8089, -4.6542, -4.3576, -4.6174, -4.2177,\n",
      "         -4.5500, -4.0279, -4.8866, -4.6638, -4.3758, -4.4111, -4.5209, -4.5458,\n",
      "         -4.7818, -4.3215, -4.5484, -4.5374, -4.2708, -4.1143, -4.1308, -4.4020,\n",
      "         -4.5034]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : dig\n",
      "target index is: [42] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4133, -4.6356, -4.6950, -4.9421, -4.2485, -4.8269, -4.6724, -4.5376,\n",
      "         -4.5246, -4.6763, -4.8423, -4.9868, -4.7202, -4.8205, -4.5546, -4.7198,\n",
      "         -4.6826, -4.7359, -4.7033, -4.4064, -4.8356, -4.4925, -5.0302, -4.6968,\n",
      "         -4.4222, -4.9622, -4.4993, -4.4978, -4.1312, -4.7840, -4.5201, -4.8265,\n",
      "         -4.8837, -4.8246, -4.2460, -4.5076, -4.3712, -4.6631, -4.8385, -4.7320,\n",
      "         -4.8121, -4.4336, -4.7378, -4.6441, -4.6305, -4.2758, -4.9074, -4.4979,\n",
      "         -4.6513, -4.8564, -4.3798, -4.7590, -4.6093, -4.5242, -4.7338, -4.5836,\n",
      "         -4.2339, -4.2212, -4.6301, -4.4167, -4.5707, -4.6621, -4.6774, -4.6326,\n",
      "         -4.6577, -4.3748, -4.9693, -4.5763, -4.6203, -4.7781, -4.2355, -4.2037,\n",
      "         -5.0121, -4.8383, -4.7507, -4.7808, -4.5764, -4.1885, -4.5653, -4.4799,\n",
      "         -4.4073, -4.4761, -4.4790, -4.9591, -4.5078, -4.3401, -4.3132, -4.4423,\n",
      "         -4.6962, -4.2128, -4.4356, -4.4385, -4.7582, -4.4248, -4.5849, -4.4178,\n",
      "         -4.2794]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : deep\n",
      "target index is: [76] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5649, -4.9053, -4.7026, -4.6251, -4.2585, -4.8156, -4.3678, -4.1792,\n",
      "         -4.7137, -5.0001, -4.8016, -4.4402, -4.5751, -4.8855, -4.7880, -4.3027,\n",
      "         -4.2431, -4.8081, -4.4491, -4.9150, -4.4911, -4.2390, -4.5746, -4.7271,\n",
      "         -4.1371, -4.9007, -4.4485, -4.7017, -4.6840, -4.4680, -4.7352, -4.6628,\n",
      "         -4.8971, -4.9305, -4.4165, -4.6223, -4.9774, -4.5204, -5.0093, -4.7232,\n",
      "         -4.8392, -4.6712, -4.8789, -4.5412, -4.3931, -4.3400, -4.5115, -4.6201,\n",
      "         -4.4767, -4.3142, -4.5011, -4.1734, -4.7346, -4.4291, -4.5746, -4.4671,\n",
      "         -4.5345, -4.5531, -4.5094, -4.6662, -5.0296, -4.6775, -4.5537, -3.9429,\n",
      "         -4.6878, -4.4643, -4.8933, -4.4167, -4.6921, -4.5846, -4.3976, -4.7255,\n",
      "         -4.5978, -4.5105, -4.6181, -4.9123, -4.4938, -4.5876, -4.7347, -4.7170,\n",
      "         -4.1239, -4.7898, -4.7000, -4.6372, -4.3468, -4.5328, -4.6686, -5.0676,\n",
      "         -4.9448, -4.3704, -4.4899, -4.7011, -4.6881, -4.4385, -4.4812, -4.4553,\n",
      "         -4.5687]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : trenches\n",
      "target index is: [54] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4240, -4.5393, -4.9366, -5.3990, -4.0962, -4.6639, -4.4244, -4.4337,\n",
      "         -4.8171, -4.4141, -4.9004, -4.4243, -4.8011, -4.7756, -4.9667, -4.7126,\n",
      "         -4.4784, -4.6444, -4.6983, -4.6322, -4.5455, -4.2742, -4.7945, -4.5653,\n",
      "         -4.4354, -4.8833, -4.1822, -4.5649, -4.5754, -4.7052, -4.4938, -5.0582,\n",
      "         -4.9200, -4.9383, -4.5013, -4.5732, -4.3575, -4.7323, -5.0260, -4.6925,\n",
      "         -4.8533, -4.8027, -4.5724, -4.5390, -4.4074, -4.4842, -4.5243, -4.7426,\n",
      "         -4.4186, -5.1639, -4.1554, -4.7815, -4.6072, -4.3943, -4.4903, -4.6696,\n",
      "         -4.9289, -4.6087, -4.2851, -4.4737, -4.6794, -4.3673, -4.5047, -4.1540,\n",
      "         -4.5131, -4.6350, -4.6961, -4.5149, -4.4566, -4.3596, -4.6435, -4.7485,\n",
      "         -5.2078, -4.5763, -4.8613, -5.0526, -4.2489, -4.2415, -4.2538, -4.5443,\n",
      "         -4.5361, -4.5536, -4.6405, -4.5373, -4.6730, -4.3951, -4.5496, -4.7083,\n",
      "         -4.6820, -4.6618, -4.0639, -4.5748, -4.7270, -4.2815, -4.5967, -4.6582,\n",
      "         -4.4927]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : in\n",
      "target index is: [95] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7231, -4.4338, -4.5668, -4.5230, -4.1137, -4.6685, -4.6739, -4.1897,\n",
      "         -4.7420, -4.5684, -4.6506, -4.2527, -4.4552, -4.6738, -4.8355, -4.6669,\n",
      "         -4.5792, -4.7366, -4.2169, -4.5307, -4.5218, -4.5757, -4.5517, -4.6481,\n",
      "         -4.2353, -4.9377, -4.4209, -4.8141, -4.4021, -4.4589, -4.7195, -4.7144,\n",
      "         -4.9240, -4.7106, -4.5961, -5.0887, -4.5022, -4.6704, -4.2996, -4.6703,\n",
      "         -4.5071, -4.6056, -4.9558, -4.7104, -4.5168, -4.4072, -4.4754, -4.9139,\n",
      "         -4.8313, -4.5091, -4.6307, -4.1589, -4.6306, -4.2803, -4.7343, -4.4370,\n",
      "         -4.5397, -4.2365, -4.3399, -4.7168, -4.8209, -4.6716, -4.4851, -4.1098,\n",
      "         -4.7988, -4.4574, -4.7180, -4.6121, -4.7906, -4.8498, -4.4657, -4.5480,\n",
      "         -5.0085, -4.8203, -4.8445, -4.8253, -4.6678, -4.3479, -4.4070, -5.0074,\n",
      "         -4.7261, -4.2514, -4.6922, -4.7084, -4.7371, -4.4324, -4.6540, -4.6898,\n",
      "         -4.8456, -4.2490, -4.9031, -4.7614, -4.6086, -4.3531, -4.4988, -4.6207,\n",
      "         -4.5759]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1893, -4.5196, -5.1103, -4.8442, -4.2800, -4.7148, -4.7368, -4.3541,\n",
      "         -5.2736, -4.2330, -4.9051, -4.2218, -4.4655, -4.3146, -5.0108, -5.1227,\n",
      "         -4.6545, -4.5999, -4.6353, -4.4311, -4.5370, -4.5482, -4.5399, -4.6042,\n",
      "         -4.5433, -5.0565, -4.2975, -4.5249, -4.5944, -4.7405, -4.6950, -4.5095,\n",
      "         -4.9926, -4.8377, -4.8387, -5.4075, -4.7146, -4.5557, -4.6383, -4.3026,\n",
      "         -4.5586, -4.6783, -4.3786, -4.4604, -4.2076, -4.1477, -4.7215, -4.7115,\n",
      "         -4.9652, -4.7701, -4.6034, -4.6862, -4.4099, -4.4016, -4.5187, -4.5639,\n",
      "         -4.5684, -4.2997, -4.4368, -4.5924, -4.6884, -4.4171, -4.3298, -4.2681,\n",
      "         -4.0496, -4.8332, -4.8169, -4.5277, -4.5974, -4.2401, -4.3621, -4.6943,\n",
      "         -4.7827, -4.7294, -4.8034, -4.7206, -4.2784, -4.2041, -4.2831, -4.6959,\n",
      "         -4.6154, -4.7708, -4.8439, -5.0425, -5.0849, -4.4281, -4.6981, -4.5165,\n",
      "         -5.1525, -4.6257, -4.4235, -4.7907, -4.9347, -4.4163, -4.2644, -4.8663,\n",
      "         -4.4841]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty's\n",
      "target index is: [80] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2937, -4.4785, -4.7092, -4.5409, -4.2238, -4.9357, -4.4993, -4.2913,\n",
      "         -4.4174, -5.1440, -4.9636, -4.1004, -4.6395, -4.7374, -4.6101, -4.7462,\n",
      "         -4.8977, -5.1714, -4.5327, -4.4207, -4.9487, -4.7495, -4.5570, -4.5027,\n",
      "         -4.2117, -4.6552, -4.6680, -4.4544, -3.8649, -4.5888, -4.8115, -4.5939,\n",
      "         -4.7205, -4.6108, -4.6686, -5.1439, -4.8628, -4.6261, -4.6689, -4.5305,\n",
      "         -4.6893, -4.2596, -4.9862, -4.0754, -4.5001, -4.1052, -4.4698, -4.4764,\n",
      "         -4.5175, -4.8915, -4.7762, -4.4633, -4.7564, -4.3842, -4.6217, -4.4108,\n",
      "         -4.3268, -4.2673, -4.7439, -5.0409, -4.8453, -4.1883, -4.4953, -4.1256,\n",
      "         -5.0358, -4.8165, -5.0771, -4.6797, -4.8163, -4.6220, -4.3193, -4.7749,\n",
      "         -4.5011, -4.8621, -4.8006, -4.9159, -5.1462, -4.1264, -4.4027, -4.4573,\n",
      "         -4.7556, -4.3137, -5.2089, -4.7550, -4.8728, -4.0952, -4.6123, -5.0118,\n",
      "         -5.0524, -4.5983, -5.1794, -4.4910, -4.5731, -4.5122, -4.2795, -4.3449,\n",
      "         -4.5715]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : field,\n",
      "target index is: [77] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-3.9846, -4.1692, -4.7874, -5.6640, -4.0926, -5.1049, -4.5367, -4.4886,\n",
      "         -4.8717, -4.8388, -4.6850, -5.1601, -5.0457, -4.8017, -4.6890, -4.8296,\n",
      "         -4.9268, -4.7165, -4.8556, -4.5190, -4.7451, -4.3741, -4.9603, -4.6715,\n",
      "         -4.5638, -4.8615, -4.3207, -4.0782, -4.1846, -4.9271, -4.2852, -4.7747,\n",
      "         -4.8057, -4.7560, -4.5059, -4.9574, -4.7039, -4.9819, -4.9757, -4.8698,\n",
      "         -4.5740, -5.1644, -4.8236, -4.6638, -4.5215, -4.0995, -5.1143, -4.4350,\n",
      "         -4.6452, -5.0026, -3.8317, -5.2521, -4.3438, -4.8174, -4.8193, -4.4929,\n",
      "         -4.5745, -4.3318, -4.4735, -4.2827, -4.7585, -4.3345, -4.4480, -3.8247,\n",
      "         -4.4840, -4.5282, -4.9454, -4.7535, -4.4412, -4.4611, -4.6172, -4.5205,\n",
      "         -5.3885, -4.6662, -4.8491, -4.8779, -4.3053, -4.1912, -4.3008, -4.5113,\n",
      "         -4.4946, -4.3920, -5.2058, -5.2239, -4.5149, -4.4249, -4.2939, -4.8650,\n",
      "         -4.6094, -4.2706, -4.0749, -4.3546, -4.9443, -4.1676, -4.4929, -4.8646,\n",
      "         -4.4844]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Thy\n",
      "target index is: [73] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2995, -4.6016, -4.7309, -4.6683, -4.2254, -4.9312, -4.6341, -4.1462,\n",
      "         -4.7105, -4.8975, -4.6430, -4.2258, -4.3086, -4.7132, -4.6394, -4.3782,\n",
      "         -4.6791, -4.8246, -4.1441, -4.7044, -4.5368, -4.2789, -4.7740, -4.8213,\n",
      "         -4.1037, -4.8545, -4.5751, -4.7254, -4.0722, -4.4328, -4.7810, -4.7054,\n",
      "         -4.8867, -4.6188, -4.7224, -5.1212, -4.9177, -4.5673, -4.7730, -4.9323,\n",
      "         -4.7681, -4.4496, -4.9622, -4.6755, -4.4960, -4.4296, -4.6192, -5.0987,\n",
      "         -4.6992, -4.4992, -4.6194, -4.2881, -4.7670, -4.4981, -4.7819, -4.5010,\n",
      "         -4.2435, -4.1363, -4.5693, -4.4338, -4.8584, -4.3871, -4.4767, -3.9407,\n",
      "         -4.8201, -4.6575, -4.8074, -4.9045, -4.9029, -4.6645, -4.3601, -4.4553,\n",
      "         -4.8526, -4.6935, -4.7713, -4.9000, -4.5725, -4.3588, -4.5918, -4.7128,\n",
      "         -4.4244, -4.3083, -5.1172, -4.7037, -4.3483, -4.7560, -4.7125, -4.6796,\n",
      "         -4.6861, -4.5723, -4.7246, -4.6430, -4.6894, -4.1632, -4.5038, -4.6150,\n",
      "         -4.5021]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : youth's\n",
      "target index is: [89] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1970, -4.7543, -4.7362, -4.8821, -4.1793, -4.7552, -4.8344, -4.5529,\n",
      "         -4.8248, -5.0017, -4.8915, -4.4160, -4.7253, -4.3650, -5.0316, -4.8627,\n",
      "         -4.6829, -4.6750, -4.6576, -4.6510, -4.4018, -4.5088, -4.4748, -4.5489,\n",
      "         -4.2980, -4.6933, -4.6755, -4.7849, -4.4853, -4.3916, -4.9994, -4.3758,\n",
      "         -4.9378, -4.6830, -4.6781, -5.2133, -4.7897, -4.7525, -4.8140, -4.3130,\n",
      "         -4.6376, -4.6728, -4.9026, -4.3530, -4.2990, -4.4927, -4.4853, -4.4168,\n",
      "         -4.5482, -4.4233, -4.2606, -4.8654, -4.4324, -4.2498, -4.3894, -4.4440,\n",
      "         -4.5003, -4.5076, -4.5485, -4.4924, -4.7461, -4.3550, -4.5189, -3.6834,\n",
      "         -4.3048, -4.3595, -4.8742, -4.6399, -4.7149, -4.6259, -4.3604, -4.7073,\n",
      "         -4.9305, -4.7778, -4.8717, -4.6238, -4.4086, -4.3112, -4.6324, -4.3101,\n",
      "         -4.6639, -4.7463, -4.9822, -5.1852, -4.5904, -4.2906, -4.5030, -5.0546,\n",
      "         -5.2564, -4.2050, -4.4438, -4.7247, -4.6339, -4.5033, -4.4323, -4.7109,\n",
      "         -4.8817]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : proud\n",
      "target index is: [50] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4603, -4.3366, -4.9194, -5.1015, -4.3975, -4.6667, -4.3563, -4.5637,\n",
      "         -5.3762, -4.5282, -4.8994, -4.4397, -4.8813, -4.5144, -4.6215, -5.1507,\n",
      "         -4.9761, -4.7149, -4.5542, -4.0363, -4.4058, -4.3900, -4.7949, -4.4836,\n",
      "         -4.9138, -4.9412, -4.4727, -4.3977, -4.6389, -4.8885, -4.7223, -4.6312,\n",
      "         -4.8813, -4.8713, -4.3602, -5.1405, -4.6113, -4.9997, -4.6726, -4.2073,\n",
      "         -4.3907, -4.6383, -4.6056, -4.4554, -4.5789, -4.2618, -4.8960, -4.2920,\n",
      "         -4.4874, -5.3766, -4.2867, -5.1336, -4.2440, -4.5411, -4.5458, -4.5457,\n",
      "         -4.8433, -4.3874, -4.3905, -4.7491, -4.6594, -4.2390, -4.6604, -4.4024,\n",
      "         -4.3875, -4.8570, -4.8520, -4.2841, -4.6412, -4.2681, -4.4516, -4.9011,\n",
      "         -4.9563, -4.8788, -4.6242, -4.8057, -4.4689, -4.2861, -4.1233, -4.1476,\n",
      "         -4.8054, -4.8151, -5.0993, -4.8009, -5.0176, -4.2669, -4.5601, -4.5756,\n",
      "         -4.7210, -4.3448, -4.3352, -4.1933, -4.8960, -4.5237, -4.2331, -4.6060,\n",
      "         -4.2798]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : livery\n",
      "target index is: [28] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6387, -4.4220, -4.9891, -4.7555, -4.0827, -5.1134, -4.4124, -4.3703,\n",
      "         -4.5729, -4.4974, -4.8596, -4.5801, -4.6911, -4.8431, -4.3235, -4.5762,\n",
      "         -4.8241, -5.0182, -4.7769, -4.3744, -4.7757, -4.1075, -4.9914, -4.8121,\n",
      "         -4.1797, -4.9316, -4.1888, -4.4590, -4.1282, -4.8437, -4.9298, -5.1563,\n",
      "         -4.9235, -4.8073, -4.6662, -4.7865, -4.5874, -4.6855, -5.0559, -4.5165,\n",
      "         -4.9566, -4.5535, -4.7691, -4.7709, -4.7611, -4.3291, -4.6745, -4.8799,\n",
      "         -4.4197, -5.0331, -4.4279, -4.6587, -4.5187, -4.3064, -4.6929, -4.3233,\n",
      "         -4.3388, -4.1568, -4.7153, -4.8844, -4.5301, -4.4237, -4.2268, -4.5342,\n",
      "         -4.5759, -4.5620, -4.7270, -4.7546, -4.7321, -4.2731, -4.2759, -4.4784,\n",
      "         -4.8086, -4.8764, -4.6700, -4.9064, -4.5754, -4.1756, -4.4529, -4.4846,\n",
      "         -4.5019, -4.6449, -4.8905, -4.6807, -4.4831, -4.3375, -4.4552, -4.8429,\n",
      "         -4.4588, -4.5275, -4.8843, -4.5927, -4.7759, -4.3204, -4.5473, -4.5128,\n",
      "         -4.0071]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : so\n",
      "target index is: [69] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3775, -4.3340, -4.9281, -4.7850, -4.2952, -5.0137, -4.5948, -4.4075,\n",
      "         -4.5516, -4.6563, -4.8077, -4.8452, -4.4650, -5.0265, -4.8478, -4.6178,\n",
      "         -4.7436, -4.3319, -4.5619, -4.5840, -4.4136, -4.2848, -5.0028, -4.8336,\n",
      "         -4.2603, -4.9241, -4.4024, -4.5058, -4.2379, -4.6645, -4.8399, -4.7780,\n",
      "         -4.9556, -5.0163, -4.6073, -4.7856, -4.8894, -4.4145, -4.8501, -4.7008,\n",
      "         -4.6477, -4.6721, -4.6488, -4.6127, -4.3517, -4.3109, -4.4915, -4.5458,\n",
      "         -4.5141, -4.8924, -4.5902, -4.4978, -4.8076, -4.3677, -4.4710, -4.6989,\n",
      "         -4.2171, -4.3020, -4.3203, -4.6469, -4.8839, -4.4926, -4.2007, -4.2010,\n",
      "         -4.4021, -4.8444, -4.4802, -4.4594, -4.2825, -4.4434, -4.3221, -4.5256,\n",
      "         -4.8086, -4.8510, -4.9782, -4.8228, -4.2566, -4.5269, -4.8354, -4.8090,\n",
      "         -4.3032, -4.6426, -4.8788, -4.7650, -4.7144, -4.3918, -4.5616, -4.6552,\n",
      "         -4.7402, -4.2724, -4.7346, -4.8715, -4.7600, -4.1624, -4.7075, -4.6607,\n",
      "         -4.3266]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : gazed\n",
      "target index is: [17] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4637, -4.3447, -4.6802, -4.7882, -4.3238, -4.6379, -4.4934, -4.3515,\n",
      "         -4.5787, -4.7470, -4.6880, -4.5601, -4.5878, -4.7171, -4.7675, -4.6313,\n",
      "         -4.4522, -4.6619, -4.6418, -4.5144, -4.6749, -4.6121, -4.6823, -4.6072,\n",
      "         -4.3757, -4.8722, -4.4413, -4.5509, -4.3519, -4.6154, -4.4090, -4.8416,\n",
      "         -4.8730, -4.7650, -4.5863, -4.6787, -4.5908, -4.6147, -4.7006, -4.6015,\n",
      "         -4.6970, -4.6010, -4.4447, -4.4402, -4.5376, -4.2985, -4.6796, -4.5711,\n",
      "         -4.4405, -4.6070, -4.5602, -4.3030, -4.8562, -4.5068, -4.6607, -4.3885,\n",
      "         -4.5741, -4.2588, -4.5711, -4.7130, -4.7465, -4.6326, -4.6833, -4.3442,\n",
      "         -4.6417, -4.6258, -4.8143, -4.4743, -4.5655, -4.5147, -4.4772, -4.4828,\n",
      "         -4.4971, -4.8257, -4.7055, -4.8413, -4.6159, -4.1893, -4.6811, -4.8435,\n",
      "         -4.5941, -4.6300, -4.6855, -4.8180, -4.5124, -4.4804, -4.3112, -4.6553,\n",
      "         -4.6817, -4.3191, -4.6438, -4.5605, -4.8100, -4.5086, -4.5995, -4.5529,\n",
      "         -4.5174]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : on\n",
      "target index is: [87] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4798, -4.6616, -4.6092, -4.6296, -4.2346, -4.6154, -4.3616, -4.2696,\n",
      "         -4.6896, -4.7141, -4.5896, -4.7783, -4.7691, -4.5887, -4.6556, -4.4694,\n",
      "         -4.3100, -4.6365, -4.6816, -4.7201, -4.8031, -4.6644, -4.6063, -4.5137,\n",
      "         -4.4361, -4.7591, -4.5954, -4.5200, -4.6411, -4.4304, -4.4701, -4.6602,\n",
      "         -4.7186, -4.7487, -4.7629, -4.6265, -4.7104, -4.6660, -4.9511, -4.6103,\n",
      "         -4.7215, -4.5321, -4.8190, -4.2967, -4.6528, -4.3838, -4.6161, -4.5770,\n",
      "         -4.4488, -4.3439, -4.7588, -4.4276, -5.1049, -4.2975, -4.6320, -4.3193,\n",
      "         -4.2875, -4.2999, -4.6499, -4.5242, -4.7388, -4.7118, -4.4879, -3.9984,\n",
      "         -4.8179, -4.2794, -4.8209, -4.5454, -4.5841, -4.5760, -4.5290, -4.6753,\n",
      "         -4.6766, -4.4126, -4.5916, -4.8153, -4.6422, -4.5410, -4.8035, -4.8030,\n",
      "         -4.4125, -4.4724, -4.7757, -4.6669, -4.6601, -4.4589, -4.6339, -4.7659,\n",
      "         -4.9318, -4.2583, -4.4948, -4.3301, -4.7421, -4.6542, -4.5295, -4.6850,\n",
      "         -4.8026]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : now,\n",
      "target index is: [63] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4366, -4.6231, -4.8470, -4.9152, -3.7980, -4.5030, -4.5224, -4.5499,\n",
      "         -4.6618, -4.6629, -4.5790, -4.3926, -5.0133, -4.8062, -4.7888, -4.4904,\n",
      "         -4.5832, -4.8137, -4.6366, -4.3946, -4.5766, -4.0948, -4.8195, -4.9098,\n",
      "         -4.5989, -4.9887, -4.6756, -4.3684, -4.3342, -4.7842, -4.4538, -5.0173,\n",
      "         -4.7057, -4.6838, -4.2616, -4.8642, -4.4264, -4.8586, -5.0989, -4.7572,\n",
      "         -4.6701, -4.4778, -4.7008, -4.4875, -4.5683, -4.4132, -4.4126, -4.8856,\n",
      "         -4.5565, -5.1447, -4.7891, -4.5967, -4.4875, -4.5021, -4.5961, -4.4730,\n",
      "         -4.2663, -4.3894, -4.4386, -4.5658, -4.5094, -4.5367, -4.8218, -4.3465,\n",
      "         -4.4791, -4.4046, -4.6455, -4.5798, -4.7075, -4.4282, -4.4495, -4.6381,\n",
      "         -4.9900, -4.8689, -4.6240, -4.8419, -4.9005, -4.4464, -4.6482, -4.4592,\n",
      "         -4.6367, -4.1076, -4.9009, -4.8065, -4.3292, -4.3097, -4.6051, -4.5654,\n",
      "         -4.8547, -4.4342, -4.6579, -4.2197, -4.7107, -4.3507, -4.5942, -4.5560,\n",
      "         -4.6164]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Will\n",
      "target index is: [36] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3948, -4.8125, -4.8204, -4.8696, -4.1052, -4.6190, -4.6417, -4.2921,\n",
      "         -4.5303, -4.7503, -4.6124, -4.6723, -4.5710, -4.8739, -4.9289, -4.2862,\n",
      "         -4.5043, -4.5683, -4.3782, -4.5342, -4.7941, -4.1605, -4.9006, -5.0566,\n",
      "         -4.0186, -5.0305, -4.4273, -4.4284, -4.2372, -4.4277, -4.5018, -4.9008,\n",
      "         -5.0330, -4.9126, -4.3681, -4.6646, -4.6008, -4.6607, -5.0934, -4.8032,\n",
      "         -4.9816, -4.5723, -4.4491, -4.6466, -4.6391, -4.4095, -4.6844, -4.6805,\n",
      "         -4.5819, -4.9035, -4.4306, -4.6161, -4.8994, -4.6001, -4.6386, -4.4606,\n",
      "         -4.1291, -4.2737, -4.3380, -4.5381, -4.9730, -4.7108, -4.4749, -4.4910,\n",
      "         -4.5116, -4.4418, -4.6742, -4.5991, -4.7369, -4.6661, -4.3102, -4.3525,\n",
      "         -4.7909, -4.8802, -4.7242, -4.7512, -4.3773, -4.3425, -4.5402, -4.7767,\n",
      "         -4.4551, -4.6800, -4.6419, -4.7366, -4.4355, -4.4710, -4.5631, -4.7994,\n",
      "         -4.6522, -4.3407, -4.6345, -4.5446, -4.8147, -4.5039, -4.8700, -4.3758,\n",
      "         -4.3201]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : be\n",
      "target index is: [24] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3459, -4.6879, -4.7955, -4.7483, -4.1759, -4.9923, -4.5548, -4.3624,\n",
      "         -4.7489, -4.7751, -4.6418, -4.3125, -4.6950, -5.0088, -5.0725, -4.3681,\n",
      "         -4.4038, -4.7430, -4.6773, -4.9813, -4.3738, -3.9748, -4.4512, -4.6895,\n",
      "         -4.0837, -5.0776, -4.3221, -4.7477, -4.4453, -4.5561, -4.3990, -5.2560,\n",
      "         -4.8231, -4.8229, -4.6096, -4.5486, -4.7033, -4.5608, -4.9545, -4.8387,\n",
      "         -5.0272, -4.7544, -4.6321, -4.6842, -4.3418, -4.5236, -4.4591, -4.7624,\n",
      "         -4.6177, -4.6276, -4.7334, -4.0837, -5.0323, -4.4199, -4.6446, -4.6631,\n",
      "         -4.5223, -4.4340, -4.3413, -4.7254, -4.8925, -4.5416, -4.5799, -4.0791,\n",
      "         -4.6651, -4.5144, -4.8773, -4.4262, -4.3146, -4.4181, -4.2026, -4.7010,\n",
      "         -4.9387, -4.7500, -5.0715, -5.1520, -4.4891, -4.3193, -4.6981, -4.8774,\n",
      "         -4.1563, -4.6077, -4.6722, -4.5021, -4.3103, -4.4600, -4.3926, -4.8810,\n",
      "         -5.0026, -4.5268, -4.1866, -4.7717, -4.5471, -4.4508, -4.5769, -4.5742,\n",
      "         -4.5368]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : a\n",
      "target index is: [46] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3585, -4.5246, -4.6602, -5.3651, -4.1573, -4.6996, -4.2669, -4.0527,\n",
      "         -4.7560, -4.5644, -4.8072, -4.9195, -4.3841, -4.7471, -4.6952, -4.3148,\n",
      "         -4.2066, -4.6279, -4.6830, -4.5704, -4.9775, -4.3629, -4.7625, -4.9510,\n",
      "         -4.2658, -5.2699, -4.2058, -4.4363, -4.3172, -4.6483, -4.4751, -4.7619,\n",
      "         -4.9089, -5.0775, -4.4399, -4.6627, -4.5337, -4.3518, -4.9358, -4.5825,\n",
      "         -4.8739, -4.6051, -4.9725, -4.3500, -4.9181, -4.2568, -4.8716, -4.7717,\n",
      "         -4.7207, -4.7894, -4.1816, -4.6424, -4.5622, -4.5331, -4.6584, -4.5530,\n",
      "         -4.3402, -4.5010, -4.4092, -4.7354, -4.8506, -4.7019, -4.4657, -4.3632,\n",
      "         -4.6259, -4.3577, -4.9905, -4.4092, -4.7641, -4.8021, -4.7494, -4.5351,\n",
      "         -4.8755, -4.8034, -4.6719, -4.8868, -4.4016, -4.3140, -4.1499, -4.7009,\n",
      "         -4.3623, -4.6308, -4.7167, -4.7179, -4.8499, -4.3320, -4.6254, -4.7334,\n",
      "         -4.7233, -4.3609, -4.5330, -4.3951, -5.0746, -4.3726, -4.8139, -4.3065,\n",
      "         -4.3421]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : totter'd\n",
      "target index is: [20] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6851, -4.6856, -4.9455, -4.8717, -4.3879, -4.7999, -4.6244, -4.0678,\n",
      "         -4.8677, -4.5981, -4.8268, -4.2871, -4.3184, -4.6819, -5.0051, -4.6067,\n",
      "         -4.7223, -4.4167, -4.3085, -4.7329, -4.5907, -4.3942, -4.6197, -4.8261,\n",
      "         -4.0220, -5.1511, -4.5202, -4.7619, -4.1895, -4.2601, -4.5217, -4.8004,\n",
      "         -4.8222, -4.9159, -4.8700, -5.1936, -4.6592, -4.5109, -4.7792, -4.5267,\n",
      "         -4.7304, -4.7703, -4.7138, -4.6766, -4.5988, -4.4562, -4.8165, -4.8305,\n",
      "         -4.8075, -4.6881, -4.3844, -4.4929, -4.8191, -4.5442, -4.5398, -4.4317,\n",
      "         -4.3983, -4.1910, -4.2726, -4.3926, -4.7900, -4.4731, -4.4860, -3.9645,\n",
      "         -4.5351, -4.6379, -4.4283, -4.7044, -4.6261, -4.0329, -4.4227, -4.3302,\n",
      "         -5.0667, -4.8353, -4.9979, -4.9970, -4.3107, -4.3566, -4.2407, -4.8969,\n",
      "         -4.6347, -4.6207, -5.0017, -4.6459, -4.8254, -4.5600, -4.6543, -4.7097,\n",
      "         -4.8100, -4.4296, -4.5536, -4.7181, -4.8320, -4.1403, -4.7159, -4.6924,\n",
      "         -4.3217]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : weed\n",
      "target index is: [29] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6031, -4.7444, -4.5377, -4.6604, -4.1489, -4.7645, -4.4977, -4.3217,\n",
      "         -4.6869, -4.8046, -4.6589, -4.6453, -4.6976, -4.8103, -5.0378, -4.8101,\n",
      "         -4.4275, -4.4124, -4.4382, -4.5930, -4.5537, -4.6573, -4.6660, -4.4705,\n",
      "         -4.1829, -4.8286, -4.5493, -4.7146, -4.5739, -4.4564, -4.3149, -4.5944,\n",
      "         -4.5434, -4.7678, -4.6347, -4.7248, -4.3954, -4.5883, -4.3798, -4.6021,\n",
      "         -4.6286, -4.7037, -4.8227, -4.6307, -4.5060, -4.2925, -4.2273, -4.5223,\n",
      "         -4.6510, -4.4898, -4.7380, -4.3237, -4.8633, -4.3962, -4.4448, -4.5423,\n",
      "         -4.4551, -4.2300, -4.3320, -4.6586, -5.0275, -4.5358, -4.5261, -4.2315,\n",
      "         -4.8451, -4.6888, -4.6484, -4.6206, -4.4747, -4.4955, -4.5626, -4.6771,\n",
      "         -4.8360, -4.9246, -4.8225, -4.7764, -4.5998, -4.2481, -4.7030, -4.8856,\n",
      "         -4.6796, -4.5520, -4.6549, -4.5780, -4.7215, -4.5267, -4.4491, -4.7899,\n",
      "         -4.9761, -4.1621, -4.6872, -4.5146, -4.6462, -4.5018, -4.5506, -4.7933,\n",
      "         -4.6264]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : of\n",
      "target index is: [57] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5189, -4.3974, -4.3765, -4.6334, -3.9010, -4.7273, -4.9699, -4.5030,\n",
      "         -4.7181, -4.6015, -4.6316, -4.2498, -4.8554, -4.7631, -4.6293, -4.5816,\n",
      "         -4.5706, -4.9465, -4.4831, -4.7789, -4.4434, -4.1933, -4.5422, -4.4660,\n",
      "         -4.3925, -4.7363, -4.4227, -4.6876, -4.4071, -4.6178, -4.4541, -5.2716,\n",
      "         -4.7160, -4.3311, -4.6615, -5.0187, -4.5876, -4.9135, -4.5089, -4.8638,\n",
      "         -4.7126, -4.8268, -4.7824, -4.6611, -4.4543, -4.4165, -4.4423, -4.9622,\n",
      "         -4.8391, -4.4553, -4.6394, -4.4545, -4.7903, -4.3146, -4.9868, -4.5181,\n",
      "         -4.6745, -4.3846, -4.4893, -4.4590, -4.7574, -4.7684, -4.7170, -3.8397,\n",
      "         -4.7992, -4.6566, -5.0468, -4.6627, -4.6341, -4.7548, -4.3182, -4.5714,\n",
      "         -4.9677, -4.6704, -4.6621, -4.7682, -4.6942, -4.4556, -4.5985, -4.8815,\n",
      "         -4.5858, -4.0876, -4.8143, -4.7666, -4.4357, -4.5721, -4.3909, -4.5839,\n",
      "         -4.9049, -4.1596, -4.5991, -4.7582, -4.5374, -4.4818, -4.0943, -4.8145,\n",
      "         -4.4607]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : small\n",
      "target index is: [38] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3555, -4.2937, -4.6279, -4.8665, -4.3320, -4.7536, -4.5264, -4.5338,\n",
      "         -4.7055, -4.9369, -4.8519, -4.5870, -4.7699, -4.4897, -4.2898, -4.7733,\n",
      "         -4.8349, -5.0309, -4.6097, -4.2426, -4.8109, -4.5574, -4.5930, -4.4130,\n",
      "         -4.7337, -5.0990, -4.7448, -4.4425, -4.0894, -4.6276, -4.4652, -5.0000,\n",
      "         -4.7719, -4.6910, -4.4663, -4.8705, -4.7510, -4.8354, -4.9093, -4.4373,\n",
      "         -4.6450, -4.5964, -4.8606, -4.1394, -4.8355, -4.1646, -5.0188, -4.4169,\n",
      "         -4.4369, -4.8615, -4.9110, -4.7075, -4.7483, -4.4816, -4.6415, -4.6554,\n",
      "         -4.2911, -4.1962, -4.6525, -4.6656, -4.6177, -4.7068, -4.8577, -4.2848,\n",
      "         -4.9913, -4.4837, -5.1374, -4.2503, -4.6836, -4.7761, -4.2239, -4.7006,\n",
      "         -4.7691, -4.6531, -4.8500, -4.7267, -5.0300, -4.2928, -4.4815, -4.2169,\n",
      "         -4.6843, -4.4002, -4.7631, -4.8449, -4.6523, -4.0666, -4.3318, -4.4261,\n",
      "         -5.0296, -4.2387, -4.5091, -4.2560, -4.6501, -4.6037, -4.2389, -4.4107,\n",
      "         -4.3542]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : worth\n",
      "target index is: [83] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6782, -4.6198, -4.7844, -5.0682, -4.2616, -4.8411, -4.3451, -4.5457,\n",
      "         -4.7055, -4.7440, -5.0417, -4.8429, -4.8937, -4.7584, -4.4403, -4.5437,\n",
      "         -4.5443, -4.8685, -4.6359, -4.2043, -4.7711, -3.9890, -5.0291, -4.7110,\n",
      "         -4.1665, -5.1283, -4.2324, -4.0871, -4.5593, -4.5984, -5.0035, -4.9162,\n",
      "         -5.0404, -4.9609, -4.5639, -4.2917, -4.8009, -4.9085, -5.1907, -4.6989,\n",
      "         -4.9939, -5.1867, -4.7435, -4.6149, -4.7017, -4.5177, -4.8098, -5.0012,\n",
      "         -4.3110, -4.8803, -3.9481, -4.7950, -4.1928, -3.9204, -4.9759, -4.0344,\n",
      "         -4.8774, -4.4326, -4.4963, -4.5819, -4.7702, -4.7003, -4.6055, -4.1896,\n",
      "         -4.8532, -4.1680, -5.0780, -4.5900, -4.8868, -4.5725, -4.2443, -4.7916,\n",
      "         -4.8815, -4.1871, -4.5232, -5.0371, -4.4140, -4.4626, -4.7403, -4.7244,\n",
      "         -4.2031, -4.3715, -4.7612, -4.4642, -4.2742, -4.2107, -5.0455, -5.2730,\n",
      "         -4.5289, -4.2729, -4.4820, -4.6882, -4.5435, -4.3596, -4.4501, -4.7972,\n",
      "         -4.2934]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : held:\n",
      "target index is: [19] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3505, -4.3936, -5.0610, -5.0667, -4.0541, -4.9000, -4.3435, -4.5728,\n",
      "         -4.6684, -4.1804, -5.0528, -4.6327, -4.8794, -4.7228, -4.4222, -4.6442,\n",
      "         -4.6201, -4.6804, -5.0096, -4.4513, -4.3652, -4.3903, -4.8475, -4.7413,\n",
      "         -4.8073, -5.2136, -4.4539, -4.4746, -4.6030, -4.6569, -4.7515, -4.6449,\n",
      "         -4.7078, -5.2302, -4.5922, -4.5816, -4.4855, -4.5977, -4.9894, -4.2612,\n",
      "         -4.5992, -4.5800, -4.4862, -4.2528, -4.2545, -4.6046, -4.6920, -4.5392,\n",
      "         -4.2374, -5.3256, -4.3694, -5.0149, -4.7082, -4.3860, -4.7533, -4.5636,\n",
      "         -4.6162, -4.5921, -4.4917, -4.5916, -4.6343, -4.3427, -4.4348, -4.4758,\n",
      "         -4.4503, -4.5977, -4.6741, -4.3195, -4.5845, -4.3537, -4.6167, -4.9981,\n",
      "         -4.8610, -4.5295, -4.8833, -5.3043, -4.1761, -4.7977, -4.5606, -4.7709,\n",
      "         -4.6367, -4.2478, -4.8160, -4.5440, -5.2979, -3.8950, -5.1151, -4.5759,\n",
      "         -4.7201, -4.0516, -4.5512, -4.8329, -4.8261, -4.1551, -4.6315, -4.2822,\n",
      "         -4.2647]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Then\n",
      "target index is: [65] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3820, -4.5185, -4.9038, -4.7416, -3.9566, -4.8554, -4.6022, -4.7559,\n",
      "         -4.8270, -4.6453, -4.7249, -4.6181, -4.8027, -4.6917, -4.7448, -4.5541,\n",
      "         -4.5487, -4.6763, -5.1222, -4.7102, -4.5992, -4.2113, -4.8420, -4.3443,\n",
      "         -4.4118, -4.7440, -4.7840, -4.2997, -4.3337, -4.4116, -4.6955, -4.5573,\n",
      "         -4.7477, -4.9130, -4.5400, -4.2399, -4.6574, -5.0023, -4.9924, -4.4477,\n",
      "         -4.8866, -4.3900, -4.5316, -4.3527, -4.2573, -4.3545, -4.5036, -4.7019,\n",
      "         -4.3351, -4.9780, -4.6786, -4.5466, -4.9474, -4.0410, -4.5709, -4.4147,\n",
      "         -4.3131, -4.4143, -4.7041, -4.3628, -4.7583, -4.6188, -4.5229, -4.3941,\n",
      "         -4.6778, -4.5557, -4.7656, -4.2785, -4.6230, -4.4721, -4.4401, -4.7513,\n",
      "         -4.8256, -4.7734, -4.9279, -4.9574, -4.4298, -4.5275, -4.9304, -4.9980,\n",
      "         -4.4828, -4.2293, -4.4384, -4.5114, -4.8218, -4.0388, -4.8064, -5.0299,\n",
      "         -4.8659, -4.1252, -4.6971, -4.9251, -4.5305, -4.4175, -4.5219, -4.8682,\n",
      "         -4.6938]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : being\n",
      "target index is: [32] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3489, -4.2700, -4.6259, -5.0544, -4.1756, -4.3694, -4.5095, -4.1394,\n",
      "         -4.9681, -4.4591, -4.8412, -4.3403, -4.6634, -4.3869, -5.0168, -4.4250,\n",
      "         -4.4433, -4.4852, -4.7145, -4.0573, -4.8249, -4.7818, -4.4558, -4.5005,\n",
      "         -4.8820, -4.5741, -4.6495, -4.5347, -4.4235, -4.7936, -4.2449, -4.8255,\n",
      "         -4.9086, -4.6017, -4.5214, -4.8050, -4.4835, -4.9791, -4.9217, -4.8213,\n",
      "         -4.7041, -4.7248, -4.4958, -4.1968, -4.4490, -4.1368, -4.7375, -4.7430,\n",
      "         -4.7710, -4.6975, -4.7160, -4.3921, -4.5209, -4.5411, -5.0071, -4.6981,\n",
      "         -4.5633, -4.5915, -4.5388, -4.5662, -4.9110, -4.8327, -4.7806, -4.2471,\n",
      "         -4.5992, -4.5343, -4.9498, -4.5200, -4.6540, -4.8888, -4.5444, -4.6934,\n",
      "         -4.6658, -5.0641, -4.3934, -4.5504, -4.5870, -4.4206, -4.4310, -4.6952,\n",
      "         -4.6232, -4.4062, -4.4249, -4.8791, -4.8132, -4.4616, -4.3662, -4.2155,\n",
      "         -5.0723, -4.4010, -4.6472, -4.4146, -4.9944, -4.5205, -4.4098, -4.4069,\n",
      "         -4.6977]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : asked,\n",
      "target index is: [23] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1979, -4.6007, -4.5004, -4.6500, -4.1006, -4.8321, -4.6610, -4.3765,\n",
      "         -4.6777, -4.5934, -4.6383, -4.3030, -4.6310, -4.6793, -4.6962, -4.8037,\n",
      "         -4.7395, -5.0865, -4.4400, -4.8200, -4.5421, -4.4978, -4.6985, -4.6032,\n",
      "         -4.4124, -4.8583, -4.5274, -4.4920, -4.3407, -4.5473, -4.5837, -4.8133,\n",
      "         -4.6715, -4.6008, -4.7295, -5.0568, -4.5845, -4.4614, -4.4874, -4.6408,\n",
      "         -4.7635, -4.4265, -4.6482, -4.5071, -4.3918, -4.1955, -4.6531, -4.8749,\n",
      "         -4.7778, -4.5101, -4.6061, -4.3321, -4.8898, -4.4678, -4.8182, -4.3858,\n",
      "         -4.5888, -4.2451, -4.3735, -4.6171, -4.7104, -4.5095, -4.6148, -3.9823,\n",
      "         -4.7901, -4.6311, -4.9503, -4.6880, -4.8675, -4.6371, -4.5352, -4.6275,\n",
      "         -4.9192, -4.5115, -4.6561, -4.9642, -4.7478, -4.2590, -4.4702, -4.9259,\n",
      "         -4.5419, -4.1954, -4.9088, -4.6219, -4.4143, -4.5230, -4.6388, -4.5485,\n",
      "         -5.0317, -4.4322, -4.5169, -4.5214, -4.6116, -4.6459, -4.2901, -4.7166,\n",
      "         -4.4622]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : where\n",
      "target index is: [51] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3590, -4.2977, -4.6690, -4.9598, -4.2815, -4.9446, -4.7313, -4.6701,\n",
      "         -4.8804, -4.6522, -4.9534, -4.6116, -4.8341, -4.6000, -4.6478, -4.9639,\n",
      "         -4.6936, -4.5886, -4.9335, -4.5152, -4.6578, -4.5716, -4.8090, -4.5239,\n",
      "         -4.5823, -4.7498, -4.3833, -4.3909, -4.2762, -4.6478, -4.3172, -4.9391,\n",
      "         -4.7375, -4.6838, -4.5152, -4.9896, -4.4742, -4.6570, -4.7773, -4.5671,\n",
      "         -4.6129, -4.7064, -4.6169, -4.5856, -4.5246, -4.1521, -4.7985, -4.5843,\n",
      "         -4.7625, -4.7882, -4.2427, -4.9087, -4.6502, -4.5052, -4.5071, -4.6877,\n",
      "         -4.5478, -4.3608, -4.5617, -4.5303, -4.5502, -4.4236, -4.5246, -4.4009,\n",
      "         -4.4867, -4.8004, -5.0162, -4.3062, -4.3960, -4.3304, -4.6645, -4.5145,\n",
      "         -5.0825, -4.9431, -4.8600, -4.9435, -4.5742, -4.2378, -4.3215, -4.5033,\n",
      "         -4.3949, -4.3892, -4.7328, -4.8838, -4.8363, -4.2349, -4.3251, -4.4928,\n",
      "         -4.7635, -4.4279, -4.2023, -4.7185, -4.6985, -4.3633, -4.2661, -4.5732,\n",
      "         -4.2130]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : all\n",
      "target index is: [52] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4732, -4.2771, -4.6659, -4.7936, -4.4456, -4.8221, -4.4365, -4.4570,\n",
      "         -4.5474, -4.8858, -4.9929, -4.6950, -4.4990, -4.6148, -4.5875, -4.6503,\n",
      "         -4.6419, -4.7334, -4.5888, -4.2132, -4.7877, -4.7589, -4.6818, -4.4851,\n",
      "         -4.3768, -4.8683, -4.5054, -4.4964, -4.2025, -4.8431, -4.4723, -4.7766,\n",
      "         -4.8682, -4.8520, -4.4914, -4.5538, -4.6226, -4.4823, -4.6666, -4.6161,\n",
      "         -4.7391, -4.6155, -4.7434, -4.5009, -4.7627, -4.2179, -4.8414, -4.6405,\n",
      "         -4.5664, -4.8288, -4.4493, -4.4646, -4.5967, -4.3260, -4.7210, -4.5416,\n",
      "         -4.3856, -4.3590, -4.6078, -4.7410, -4.7760, -4.7318, -4.5851, -4.5766,\n",
      "         -4.8027, -4.5322, -5.0749, -4.3668, -4.6394, -4.6422, -4.4477, -4.5165,\n",
      "         -4.5561, -4.8832, -4.6378, -4.6657, -4.5520, -4.2172, -4.3548, -4.6613,\n",
      "         -4.4819, -4.5736, -4.6130, -4.8058, -4.6492, -4.3042, -4.4610, -4.5709,\n",
      "         -4.7114, -4.3357, -4.6121, -4.6485, -4.6573, -4.5388, -4.3472, -4.4741,\n",
      "         -4.2349]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3525, -4.3633, -4.9416, -4.7772, -4.2766, -4.7755, -4.8547, -4.3931,\n",
      "         -5.0856, -4.2676, -5.0089, -4.3958, -4.5164, -4.6132, -4.6660, -4.8276,\n",
      "         -4.5543, -4.4321, -4.4832, -4.5005, -4.6506, -4.3870, -4.5157, -4.7962,\n",
      "         -4.4128, -5.0724, -4.3677, -4.5351, -4.4962, -4.4873, -4.6709, -4.6644,\n",
      "         -4.8460, -4.6792, -4.8954, -5.0964, -4.7026, -4.6358, -4.8772, -4.6059,\n",
      "         -4.6531, -4.7746, -4.6703, -4.6173, -4.5240, -4.1213, -4.8181, -4.7213,\n",
      "         -4.8995, -4.6466, -4.7517, -4.7666, -4.5531, -4.2917, -4.4714, -4.7801,\n",
      "         -4.3054, -4.3719, -4.4560, -4.5279, -4.7032, -4.5241, -4.2657, -4.3261,\n",
      "         -4.2371, -4.7515, -4.7089, -4.2449, -4.5903, -4.3758, -4.4512, -4.6188,\n",
      "         -4.8107, -4.5861, -4.7902, -4.7246, -4.2371, -4.4809, -4.2514, -4.7080,\n",
      "         -4.3534, -4.5697, -4.8053, -5.0598, -4.8573, -4.4443, -4.7399, -4.6400,\n",
      "         -4.8908, -4.4711, -4.5091, -4.7979, -4.8280, -4.3466, -4.0625, -4.8418,\n",
      "         -4.3935]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty\n",
      "target index is: [0] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3525, -4.6944, -4.7511, -4.9174, -4.2193, -4.6907, -4.3739, -4.2035,\n",
      "         -5.1196, -4.4885, -4.7892, -4.4100, -4.2713, -4.5932, -4.8566, -5.1035,\n",
      "         -4.7083, -4.5586, -4.6688, -4.5347, -4.7676, -4.7309, -4.8445, -4.6491,\n",
      "         -4.4435, -5.1962, -4.3812, -4.4498, -4.2196, -4.6754, -4.4903, -4.3505,\n",
      "         -4.7352, -4.9425, -4.6835, -5.1644, -4.3429, -4.5201, -4.3933, -4.3719,\n",
      "         -4.5547, -4.3853, -4.6473, -4.3478, -4.5371, -4.1000, -4.9199, -4.5999,\n",
      "         -4.8461, -4.7792, -4.5195, -4.6668, -4.8246, -4.5594, -4.5888, -4.5831,\n",
      "         -4.4379, -4.3411, -4.5205, -4.3886, -4.7212, -4.4354, -4.3699, -4.4474,\n",
      "         -4.3028, -5.0172, -4.7636, -4.4311, -4.7559, -4.0261, -4.5831, -4.5059,\n",
      "         -5.1173, -4.9180, -4.7606, -4.7408, -4.5876, -3.9141, -4.1974, -4.7658,\n",
      "         -4.5980, -4.7861, -4.8526, -4.9329, -5.1299, -4.3009, -4.5775, -4.4038,\n",
      "         -5.3369, -4.8568, -4.7551, -4.5962, -4.8745, -4.3683, -4.5317, -4.8008,\n",
      "         -4.2841]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : lies,\n",
      "target index is: [59] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3018, -4.6712, -4.6495, -4.6738, -4.2039, -4.8961, -4.3871, -4.2221,\n",
      "         -4.6776, -5.1482, -4.7582, -4.3813, -4.5357, -4.8153, -4.7566, -4.6502,\n",
      "         -4.4742, -4.9513, -4.7816, -4.9124, -4.4341, -4.4821, -4.6622, -4.5242,\n",
      "         -4.1484, -4.8803, -4.5067, -4.3789, -4.3737, -4.5931, -4.6269, -4.7073,\n",
      "         -4.5214, -5.1351, -4.5117, -4.6534, -4.9089, -4.3149, -4.6870, -4.3897,\n",
      "         -5.0498, -4.2558, -4.7678, -4.4278, -4.4574, -4.1851, -4.4818, -4.5824,\n",
      "         -4.5323, -4.5439, -4.5982, -4.1704, -5.0247, -4.3976, -4.6925, -4.3275,\n",
      "         -4.5821, -4.4490, -4.7653, -4.7708, -4.6624, -4.3129, -4.5387, -4.3702,\n",
      "         -4.6618, -4.6763, -4.7128, -4.3582, -4.6644, -4.4308, -4.4427, -4.6874,\n",
      "         -4.4781, -4.9629, -4.8518, -4.9260, -4.6260, -4.1277, -4.6444, -5.0410,\n",
      "         -4.3918, -4.7364, -4.6947, -4.7825, -4.4319, -4.4277, -4.4670, -5.0370,\n",
      "         -5.0056, -4.5269, -4.6856, -4.6896, -4.4283, -4.6409, -4.7316, -4.5795,\n",
      "         -4.4454]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Where\n",
      "target index is: [18] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5450, -4.4293, -4.3839, -4.5941, -4.2399, -4.9776, -4.7540, -4.5227,\n",
      "         -4.6635, -4.7725, -4.7056, -4.5034, -4.7143, -4.7536, -4.5521, -4.5542,\n",
      "         -4.8503, -4.5921, -4.5699, -4.6114, -4.3912, -4.3244, -4.7395, -4.6473,\n",
      "         -4.3771, -4.7678, -4.6530, -4.4730, -4.3475, -4.5657, -4.7162, -4.6611,\n",
      "         -4.8339, -4.5970, -4.6445, -4.9012, -4.5736, -4.9036, -4.4887, -4.5206,\n",
      "         -4.6567, -4.6672, -4.8372, -4.5200, -4.6207, -4.4136, -4.5508, -4.6780,\n",
      "         -4.5004, -4.8338, -4.4886, -4.8362, -4.5144, -4.6009, -4.7213, -4.7568,\n",
      "         -4.2945, -4.4289, -4.3798, -4.5126, -4.8154, -4.7713, -4.5152, -4.2200,\n",
      "         -4.9007, -4.4397, -4.9233, -4.3655, -4.5759, -4.7186, -4.3062, -4.4828,\n",
      "         -4.8599, -4.9118, -4.8291, -4.7686, -4.2632, -4.3280, -4.6989, -4.5539,\n",
      "         -4.4578, -4.2922, -4.6223, -4.7493, -4.6381, -4.4491, -4.3802, -4.7143,\n",
      "         -4.7738, -4.2495, -4.5337, -4.7251, -4.5492, -4.4299, -4.2576, -4.4979,\n",
      "         -4.5529]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : all\n",
      "target index is: [52] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2821, -4.2307, -4.6104, -4.9467, -4.3441, -4.6118, -4.5562, -4.4811,\n",
      "         -4.7961, -4.9751, -4.8372, -4.4806, -4.7234, -4.6442, -4.5038, -4.7686,\n",
      "         -4.7548, -5.0571, -4.4180, -4.1632, -4.7670, -4.4215, -4.6745, -4.4694,\n",
      "         -4.6080, -4.7487, -4.4058, -4.4742, -4.1872, -4.9998, -4.4376, -4.9408,\n",
      "         -4.8656, -4.6849, -4.3188, -4.7273, -4.5701, -4.7896, -4.7923, -4.7325,\n",
      "         -4.6838, -4.6520, -4.8115, -4.5814, -4.8657, -4.2666, -5.0312, -4.6399,\n",
      "         -4.6274, -4.8727, -4.4302, -4.6503, -4.3907, -4.5232, -5.0194, -4.6041,\n",
      "         -4.6397, -4.4385, -4.6175, -4.7871, -4.5707, -4.5912, -4.7175, -4.4220,\n",
      "         -4.9932, -4.4645, -5.1132, -4.6211, -4.7679, -4.6762, -4.3181, -4.5713,\n",
      "         -4.5767, -4.7872, -4.4145, -4.6306, -4.6176, -4.1745, -4.3215, -4.4116,\n",
      "         -4.4637, -4.4247, -4.7522, -4.8458, -4.4386, -4.4019, -4.3467, -4.5503,\n",
      "         -4.7299, -4.2843, -4.4450, -4.4247, -4.7356, -4.5447, -4.1508, -4.4287,\n",
      "         -4.3661]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : the\n",
      "target index is: [82] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1527, -4.4061, -4.5691, -4.8757, -4.1839, -4.6912, -4.6632, -4.3311,\n",
      "         -4.6341, -4.7174, -4.8765, -4.7197, -4.6297, -4.7996, -4.6975, -4.6604,\n",
      "         -4.4296, -4.5071, -4.4522, -4.6376, -4.8791, -4.5217, -4.8021, -4.6022,\n",
      "         -4.2001, -4.5009, -4.5429, -4.4975, -4.4578, -4.5003, -4.5576, -4.6702,\n",
      "         -4.5560, -4.6775, -4.8887, -4.7724, -4.8459, -4.5463, -4.8655, -4.8146,\n",
      "         -4.7149, -4.5529, -4.7665, -4.3595, -4.6018, -4.1719, -4.6309, -4.5204,\n",
      "         -4.5594, -4.4572, -4.5051, -4.5953, -4.9604, -4.4430, -4.5116, -4.6758,\n",
      "         -4.4436, -4.5189, -4.4227, -4.5764, -5.1462, -4.6833, -4.4088, -4.0382,\n",
      "         -4.8503, -4.7381, -4.7380, -4.5102, -4.6514, -4.7295, -4.7263, -4.6405,\n",
      "         -4.4850, -4.5307, -4.5336, -4.5309, -4.3925, -4.4669, -4.5542, -4.8064,\n",
      "         -4.2217, -4.3348, -4.8732, -4.7706, -4.5813, -4.5616, -4.7695, -4.8122,\n",
      "         -4.9135, -4.3590, -4.6032, -4.5146, -4.6381, -4.5391, -4.3377, -4.6134,\n",
      "         -4.6227]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : treasure\n",
      "target index is: [31] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3675, -4.3652, -4.7193, -4.9687, -4.1171, -4.7654, -4.6534, -4.5967,\n",
      "         -4.7603, -4.5724, -4.6177, -4.2795, -4.7946, -4.7788, -4.8316, -4.8277,\n",
      "         -4.4797, -4.7505, -4.6977, -4.5565, -4.5258, -4.4770, -4.8525, -4.6092,\n",
      "         -4.7224, -4.9819, -4.2916, -4.4459, -4.2804, -4.8958, -4.2497, -5.0276,\n",
      "         -4.6738, -4.5998, -4.4989, -5.0389, -4.3754, -4.6870, -4.7143, -4.7792,\n",
      "         -4.5756, -4.7638, -4.5080, -4.3755, -4.5356, -4.2870, -4.6551, -4.7122,\n",
      "         -4.7592, -4.9123, -4.3109, -4.7636, -4.7285, -4.8377, -4.7079, -4.3860,\n",
      "         -4.5669, -4.1854, -4.4929, -4.6080, -4.5128, -4.3326, -4.7799, -4.2426,\n",
      "         -4.4887, -4.6300, -5.0437, -4.7045, -4.2641, -4.3155, -4.7223, -4.7375,\n",
      "         -4.8583, -4.8297, -4.7590, -5.0158, -4.6556, -4.2883, -4.5185, -4.5528,\n",
      "         -4.6325, -4.1912, -4.8038, -4.9739, -4.6490, -4.4461, -4.3362, -4.2888,\n",
      "         -4.7315, -4.5369, -4.3099, -4.4810, -4.8534, -4.4855, -4.5162, -4.4551,\n",
      "         -4.2935]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : of\n",
      "target index is: [57] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4817, -4.1717, -4.3123, -4.5626, -4.1672, -4.8555, -4.8924, -4.4305,\n",
      "         -4.8220, -4.7651, -5.0725, -4.5460, -4.6017, -4.5593, -4.7822, -4.7721,\n",
      "         -4.6679, -4.5581, -4.5612, -4.5486, -4.6007, -4.3742, -4.6858, -4.3944,\n",
      "         -4.0684, -4.6807, -4.4976, -4.5409, -4.3012, -4.4896, -4.6556, -5.0489,\n",
      "         -5.0254, -4.5862, -4.8645, -4.9123, -4.8217, -4.7578, -4.5227, -4.7006,\n",
      "         -4.8383, -4.5117, -4.6523, -4.4939, -4.5233, -4.3192, -4.7489, -4.9395,\n",
      "         -4.6170, -4.5232, -4.4245, -4.4127, -4.8529, -4.2349, -4.6504, -4.6510,\n",
      "         -4.4515, -4.3977, -4.4669, -4.7006, -4.9030, -4.7174, -4.3849, -4.1655,\n",
      "         -4.7038, -4.7204, -5.0167, -4.5075, -4.7702, -4.6955, -4.5736, -4.4739,\n",
      "         -4.7085, -4.8606, -4.6742, -4.7854, -4.5945, -4.1655, -4.5050, -4.9115,\n",
      "         -4.1935, -4.3535, -4.7524, -4.8214, -4.6135, -4.4685, -4.5528, -4.6937,\n",
      "         -4.7690, -4.2057, -4.6470, -4.8180, -4.5902, -4.3932, -4.3139, -4.6590,\n",
      "         -4.3291]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1226, -4.2770, -4.8842, -5.0408, -4.2135, -4.7457, -4.7419, -4.2576,\n",
      "         -5.2600, -4.3819, -5.1308, -4.1517, -4.5664, -4.2804, -4.7265, -4.9886,\n",
      "         -4.5634, -4.5920, -4.7712, -4.1932, -4.7908, -4.7995, -4.4638, -4.4658,\n",
      "         -4.7298, -4.8545, -4.4049, -4.3524, -4.4106, -4.6916, -4.5890, -4.7625,\n",
      "         -5.0250, -4.8203, -4.8128, -5.2491, -4.6025, -4.5632, -4.9205, -4.4343,\n",
      "         -4.8944, -4.6538, -4.4809, -4.4073, -4.6499, -4.0064, -4.8735, -4.7216,\n",
      "         -4.8567, -4.7160, -4.6193, -4.7420, -4.4243, -4.3458, -4.8270, -4.8112,\n",
      "         -4.4524, -4.4698, -4.6829, -4.6481, -4.6226, -4.6152, -4.3042, -4.5343,\n",
      "         -4.3559, -4.7857, -5.1188, -4.3344, -4.5805, -4.6030, -4.2769, -4.7111,\n",
      "         -4.6944, -5.0266, -4.5636, -4.7049, -4.2946, -4.2157, -4.1755, -4.6112,\n",
      "         -4.4078, -4.5515, -4.6438, -5.0033, -5.1489, -4.2313, -4.6125, -4.3200,\n",
      "         -5.0821, -4.5565, -4.4046, -4.7888, -4.8785, -4.5098, -4.1878, -4.4739,\n",
      "         -4.3674]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : lusty\n",
      "target index is: [30] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2181, -4.6296, -4.3926, -4.9647, -4.2180, -4.7147, -4.5102, -4.1611,\n",
      "         -4.6966, -4.9706, -4.8855, -4.4525, -4.3881, -4.6586, -4.9086, -4.8435,\n",
      "         -4.4460, -4.7418, -4.3991, -4.8271, -4.7054, -5.0473, -4.7019, -4.6773,\n",
      "         -4.3847, -4.7175, -4.5361, -4.4797, -4.2091, -4.5161, -4.2090, -4.6935,\n",
      "         -4.5970, -4.9069, -4.7695, -4.8953, -4.3992, -4.4526, -4.4911, -4.5359,\n",
      "         -4.8234, -4.2833, -4.8115, -4.3358, -4.6544, -4.1714, -4.5339, -4.5850,\n",
      "         -4.6645, -4.5516, -4.6242, -4.3021, -5.0717, -4.5460, -4.8621, -4.7409,\n",
      "         -4.3556, -4.3119, -4.5388, -4.6269, -4.8593, -4.3841, -4.6182, -4.2060,\n",
      "         -4.6843, -4.8059, -4.8118, -4.8260, -4.7746, -4.4238, -4.6415, -4.4485,\n",
      "         -5.0328, -4.9648, -4.6905, -4.6938, -4.9038, -3.7928, -4.3615, -5.0004,\n",
      "         -4.4868, -4.5656, -4.6611, -4.8968, -4.8470, -4.4672, -4.4191, -4.4373,\n",
      "         -5.2569, -4.3981, -4.7914, -4.5059, -4.5165, -4.5918, -4.4099, -4.7693,\n",
      "         -4.4261]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : days;\n",
      "target index is: [48] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5425, -4.7382, -4.4178, -4.4733, -3.7365, -4.7671, -4.5511, -4.4475,\n",
      "         -4.5018, -4.9584, -4.4781, -4.5997, -5.0719, -4.9375, -4.6459, -4.5994,\n",
      "         -4.9328, -5.0908, -4.6220, -4.7332, -4.6305, -4.0609, -4.7134, -4.5304,\n",
      "         -4.4167, -4.8258, -4.4508, -4.5151, -4.5888, -4.5506, -4.6012, -4.6576,\n",
      "         -4.6940, -4.7679, -4.4027, -4.9554, -4.7229, -4.8831, -4.5372, -4.5770,\n",
      "         -4.8321, -4.6606, -5.0164, -4.4291, -4.8443, -4.7124, -4.3630, -4.4310,\n",
      "         -4.3064, -4.3460, -4.4583, -4.6610, -4.7482, -4.4964, -4.7034, -3.9078,\n",
      "         -4.6265, -4.1300, -4.4643, -4.5968, -4.6391, -4.7653, -5.0026, -3.9886,\n",
      "         -5.0510, -4.3848, -4.9426, -4.5529, -4.7443, -5.0625, -4.2337, -4.5589,\n",
      "         -4.8270, -4.9457, -4.4875, -5.0009, -4.6869, -4.5888, -4.5483, -4.6442,\n",
      "         -4.7570, -4.0539, -5.0170, -4.6453, -4.4632, -4.6510, -4.5634, -5.0234,\n",
      "         -4.8441, -4.2533, -4.6582, -4.4130, -4.4559, -4.5573, -4.4053, -4.4620,\n",
      "         -4.6103]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : To\n",
      "target index is: [26] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2548, -4.6600, -5.0241, -4.9586, -4.0881, -4.7793, -4.4642, -4.7209,\n",
      "         -4.5786, -4.6316, -4.9417, -4.4896, -4.8534, -4.4845, -4.8489, -4.6415,\n",
      "         -4.2255, -4.7071, -4.8786, -4.6220, -4.3472, -4.1954, -4.8678, -4.7100,\n",
      "         -4.5103, -4.8662, -4.4002, -4.4164, -4.3726, -4.8412, -4.6357, -4.9352,\n",
      "         -4.9206, -5.0018, -4.5638, -4.5501, -4.5753, -4.5252, -5.1353, -4.6933,\n",
      "         -4.7044, -4.6922, -4.3472, -4.7205, -4.1191, -4.4252, -4.5570, -4.8308,\n",
      "         -4.4502, -4.9915, -4.2537, -4.6042, -4.6056, -4.2553, -4.8045, -4.7302,\n",
      "         -4.6762, -4.5580, -4.5039, -4.6003, -4.6224, -4.3793, -4.5837, -4.3107,\n",
      "         -4.3537, -4.8177, -4.9581, -4.5146, -4.6125, -4.2829, -4.4004, -4.5593,\n",
      "         -4.9131, -4.4830, -4.8740, -4.9780, -4.5392, -4.3845, -4.7616, -4.6618,\n",
      "         -4.1471, -4.3606, -4.5633, -4.7152, -4.4296, -4.3423, -4.6485, -4.7370,\n",
      "         -4.8696, -4.5997, -4.4567, -4.9709, -4.5337, -4.2221, -4.4230, -4.7105,\n",
      "         -4.3014]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : say,\n",
      "target index is: [96] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7638, -4.3208, -4.6550, -4.9190, -3.9656, -4.7161, -4.6070, -4.2892,\n",
      "         -4.7477, -4.5087, -4.7758, -4.6346, -4.6817, -4.7458, -4.5978, -4.8512,\n",
      "         -4.8161, -4.3570, -4.7582, -4.2364, -4.6734, -4.5963, -4.6842, -4.7184,\n",
      "         -4.4578, -4.8146, -4.4117, -4.5411, -4.2817, -4.5214, -4.6141, -4.6365,\n",
      "         -4.8495, -4.7923, -4.4521, -4.8545, -4.4927, -4.8344, -4.5417, -4.4602,\n",
      "         -4.5853, -4.6664, -4.6738, -4.4366, -4.6637, -4.5037, -4.4162, -4.5143,\n",
      "         -4.5528, -4.6994, -4.3576, -4.8356, -4.6275, -4.5642, -4.7632, -4.3815,\n",
      "         -4.6733, -4.3782, -4.4794, -4.6774, -4.6783, -4.6298, -4.5624, -4.2388,\n",
      "         -4.5827, -4.4501, -4.5025, -4.6250, -4.5541, -4.8504, -4.6683, -4.5094,\n",
      "         -4.8117, -5.1409, -4.6783, -4.7357, -4.3630, -4.5508, -4.4326, -4.8681,\n",
      "         -4.7612, -4.4038, -4.7061, -4.6825, -4.9605, -4.2210, -4.4109, -4.7323,\n",
      "         -4.6115, -4.1636, -4.7152, -4.5917, -4.6323, -4.3067, -4.6899, -4.4022,\n",
      "         -4.5091]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : within\n",
      "target index is: [34] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1944, -4.3395, -4.7176, -4.8844, -4.5153, -4.8523, -4.4782, -4.0746,\n",
      "         -5.1540, -4.5723, -4.9950, -4.3903, -4.2815, -4.6230, -5.1811, -5.0651,\n",
      "         -4.5708, -4.5694, -4.7253, -4.6064, -4.5307, -4.7473, -4.7352, -4.9211,\n",
      "         -4.4635, -4.9379, -4.2394, -4.3619, -4.1268, -4.5145, -4.5218, -4.6663,\n",
      "         -4.9655, -4.8738, -4.8370, -5.0125, -4.7834, -4.3630, -4.5686, -4.5262,\n",
      "         -4.6896, -4.6643, -4.4239, -4.3653, -4.3326, -4.0092, -4.7051, -4.7771,\n",
      "         -4.6219, -4.7583, -4.6593, -4.1930, -4.6772, -4.6303, -4.5388, -4.6597,\n",
      "         -4.5606, -4.1818, -4.4388, -4.9361, -4.8416, -4.5957, -4.5068, -4.4387,\n",
      "         -4.3570, -4.9593, -4.9431, -4.5373, -4.4911, -4.1718, -4.4453, -4.6167,\n",
      "         -4.7677, -4.7721, -4.6837, -4.8865, -4.5382, -4.0367, -4.3197, -5.0578,\n",
      "         -4.2741, -4.7451, -4.6234, -4.9408, -4.9009, -4.6482, -4.6901, -4.3824,\n",
      "         -5.1329, -4.6187, -4.5031, -4.4393, -4.8188, -4.5628, -4.4272, -4.5550,\n",
      "         -4.4073]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thine\n",
      "target index is: [56] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1457, -4.9323, -4.1285, -4.5970, -4.0708, -4.7222, -4.8397, -4.3256,\n",
      "         -4.7129, -4.8726, -4.7575, -4.7805, -4.6934, -4.7054, -4.7800, -4.6850,\n",
      "         -4.6099, -4.7566, -4.5008, -4.9983, -4.8347, -4.6061, -4.8084, -4.4565,\n",
      "         -4.2966, -4.7556, -4.6518, -4.5212, -4.3173, -4.3822, -4.3584, -4.5436,\n",
      "         -4.6307, -4.5555, -4.6900, -4.8867, -4.3813, -4.8607, -4.6474, -4.7100,\n",
      "         -5.0139, -4.3084, -4.9556, -4.2519, -4.8429, -4.3029, -4.6167, -4.4759,\n",
      "         -4.7673, -4.3160, -4.5511, -4.6920, -5.1613, -4.5813, -4.9116, -4.6116,\n",
      "         -4.1971, -4.3026, -4.4130, -4.2962, -4.7347, -4.5749, -4.6213, -4.0682,\n",
      "         -4.7736, -4.4872, -5.0743, -4.7715, -4.9165, -5.0125, -4.4868, -4.4737,\n",
      "         -5.2587, -5.0149, -4.5930, -4.8038, -4.6362, -4.0821, -4.4244, -4.8341,\n",
      "         -4.4775, -4.0621, -4.6788, -4.8159, -4.6924, -4.6262, -4.4137, -4.5692,\n",
      "         -5.2757, -4.3004, -4.4041, -4.3940, -4.4262, -4.8041, -4.2345, -4.7146,\n",
      "         -4.4971]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : own\n",
      "target index is: [92] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4044, -4.4254, -4.4749, -4.9555, -3.7354, -4.4356, -4.7080, -4.6384,\n",
      "         -4.9214, -5.0520, -4.8448, -4.6165, -5.0841, -4.7867, -4.7929, -4.7289,\n",
      "         -4.6028, -5.1666, -4.5166, -4.3310, -4.4837, -4.0502, -4.7231, -4.5738,\n",
      "         -4.7631, -4.7723, -4.4957, -4.5894, -4.5666, -5.0694, -4.2010, -4.8348,\n",
      "         -4.6511, -4.4393, -4.2120, -4.8848, -4.5938, -5.1376, -4.8236, -4.8557,\n",
      "         -4.5057, -4.7717, -5.0150, -4.2595, -4.9032, -4.4066, -4.6123, -4.5125,\n",
      "         -4.7657, -4.7189, -4.6157, -4.7929, -4.6226, -4.6124, -4.9597, -4.2232,\n",
      "         -4.8606, -4.3679, -4.4869, -4.5985, -4.4840, -4.6774, -5.0837, -3.8394,\n",
      "         -4.7977, -4.5043, -5.1379, -4.6145, -4.6350, -4.9776, -4.4610, -4.5420,\n",
      "         -4.5589, -5.0628, -4.4236, -4.6235, -4.7462, -4.6044, -4.5084, -4.4309,\n",
      "         -4.7273, -4.1945, -4.8858, -4.8410, -4.2327, -4.5144, -4.1593, -4.6040,\n",
      "         -4.8295, -4.4028, -4.3618, -4.3631, -4.7225, -4.6562, -3.9342, -4.6724,\n",
      "         -4.3300]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : deep\n",
      "target index is: [76] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3205, -4.6638, -4.6783, -4.8118, -4.2744, -4.5414, -4.3710, -4.2474,\n",
      "         -4.6972, -4.9179, -5.0287, -4.3613, -4.4992, -4.4752, -4.6544, -4.4340,\n",
      "         -4.0979, -4.7455, -4.6410, -4.6065, -4.5817, -4.6136, -4.6133, -4.6380,\n",
      "         -4.4701, -4.6388, -4.5867, -4.5048, -4.4792, -4.6184, -4.6379, -4.8683,\n",
      "         -4.8898, -4.9083, -4.7303, -4.8179, -4.7902, -4.4454, -5.1278, -4.7531,\n",
      "         -4.7306, -4.5066, -4.8778, -4.3977, -4.5239, -4.3455, -4.6347, -4.7901,\n",
      "         -4.5182, -4.4411, -4.5893, -4.3228, -4.7879, -4.3506, -4.9001, -4.6645,\n",
      "         -4.4264, -4.6402, -4.7507, -4.6268, -4.8054, -4.6164, -4.4686, -3.9828,\n",
      "         -4.6015, -4.4785, -4.9139, -4.4516, -4.5812, -4.6341, -4.4368, -4.6689,\n",
      "         -4.5306, -4.4004, -4.4858, -4.6145, -4.6790, -4.5732, -4.5727, -4.7196,\n",
      "         -4.0455, -4.5224, -4.6783, -4.7251, -4.4744, -4.3966, -4.7908, -4.7398,\n",
      "         -5.0093, -4.4783, -4.5167, -4.7883, -4.6668, -4.6704, -4.2377, -4.5810,\n",
      "         -4.6100]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : sunken\n",
      "target index is: [91] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4109, -4.5284, -4.7146, -4.8643, -4.2131, -4.8847, -4.5922, -4.7783,\n",
      "         -4.7285, -4.4448, -4.9413, -4.4967, -4.8035, -4.6176, -4.6786, -4.8410,\n",
      "         -4.8998, -4.7965, -4.7615, -4.3067, -4.4887, -4.2332, -4.8906, -4.5526,\n",
      "         -4.5677, -4.8914, -4.3612, -4.6785, -4.3242, -4.6451, -4.8794, -4.6551,\n",
      "         -4.6465, -4.8217, -4.7366, -5.0143, -4.7214, -4.6787, -4.7738, -4.2466,\n",
      "         -4.8158, -4.7451, -4.8275, -4.3643, -4.4963, -4.5981, -4.7008, -4.5679,\n",
      "         -4.3564, -4.9048, -3.9239, -5.2427, -4.3425, -4.4742, -4.7670, -4.2375,\n",
      "         -4.8271, -4.4603, -4.3924, -4.5109, -4.5163, -4.3599, -4.6594, -4.0110,\n",
      "         -4.5181, -4.6104, -4.9803, -4.5869, -4.6479, -4.5422, -4.4576, -4.6539,\n",
      "         -4.8492, -4.7512, -4.5829, -5.0161, -4.1847, -4.6073, -4.4795, -4.5514,\n",
      "         -4.6196, -4.1939, -4.9241, -4.5903, -4.7908, -4.2653, -4.7844, -4.8655,\n",
      "         -4.7762, -4.3060, -4.3928, -4.7157, -4.5242, -4.3706, -4.5205, -4.2573,\n",
      "         -4.3772]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : eyes,\n",
      "target index is: [58] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2607, -4.5124, -5.0697, -5.3289, -3.8945, -4.6407, -4.3435, -4.5034,\n",
      "         -4.7238, -4.6204, -5.1114, -4.6496, -4.7890, -4.5868, -4.6283, -4.6649,\n",
      "         -4.5960, -4.7027, -5.0095, -4.5298, -4.7237, -4.3159, -4.9653, -4.6387,\n",
      "         -4.5145, -4.8597, -4.4562, -4.3839, -4.3211, -4.7100, -4.7627, -4.5593,\n",
      "         -4.6436, -5.1053, -4.5989, -4.7065, -4.5042, -4.4731, -5.1179, -4.3188,\n",
      "         -4.5821, -4.3503, -4.7865, -4.4380, -4.5837, -4.3439, -4.8749, -4.4578,\n",
      "         -4.4901, -5.0357, -4.3213, -4.9918, -4.5027, -4.2899, -4.4938, -4.6675,\n",
      "         -4.5777, -4.7313, -4.6310, -4.3996, -4.5857, -4.2897, -4.1257, -4.4821,\n",
      "         -4.2473, -4.6634, -4.6695, -4.5679, -4.6286, -4.2537, -4.5211, -4.6408,\n",
      "         -4.9004, -4.7681, -4.7781, -4.7791, -4.4060, -4.5129, -4.5503, -4.7278,\n",
      "         -4.4063, -4.5108, -4.9350, -4.9037, -4.9021, -4.0144, -4.6555, -4.6680,\n",
      "         -4.6969, -4.4782, -4.7812, -4.6618, -4.8573, -4.1954, -4.7055, -4.5931,\n",
      "         -4.2452]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Were\n",
      "target index is: [37] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2536, -4.5254, -4.6894, -4.6427, -4.2318, -4.6962, -4.3863, -4.2692,\n",
      "         -4.7957, -4.9077, -4.5972, -4.4383, -4.5307, -4.8467, -4.9917, -4.6707,\n",
      "         -4.7318, -4.5371, -4.6475, -4.7188, -4.3240, -4.4387, -4.8574, -5.0348,\n",
      "         -4.2699, -4.9255, -4.5849, -4.4050, -4.2183, -4.4058, -4.6291, -4.6595,\n",
      "         -4.5687, -4.8988, -4.3621, -4.8287, -4.8505, -4.3756, -4.7645, -4.3781,\n",
      "         -4.7022, -4.5361, -4.7022, -4.6876, -4.5614, -4.2253, -4.2435, -4.7906,\n",
      "         -4.4707, -4.8825, -4.7253, -4.3312, -4.8077, -4.5184, -4.4660, -4.4741,\n",
      "         -4.3826, -4.3383, -4.4694, -4.8797, -4.6312, -4.1523, -4.5565, -4.3542,\n",
      "         -4.4871, -4.6919, -4.5936, -4.3658, -4.6745, -4.1715, -4.5360, -4.6032,\n",
      "         -4.6764, -5.1197, -4.9162, -4.9226, -4.6322, -4.2706, -4.6214, -4.8856,\n",
      "         -4.5590, -4.7250, -4.7720, -4.7999, -4.6164, -4.3465, -4.4656, -4.8145,\n",
      "         -4.8874, -4.4181, -4.7955, -4.5012, -4.6342, -4.5520, -4.8576, -4.6957,\n",
      "         -4.6190]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : an\n",
      "target index is: [74] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4938, -4.6946, -4.6858, -4.4953, -4.1013, -4.9809, -4.6337, -4.5492,\n",
      "         -4.7302, -4.5035, -4.9833, -4.7231, -4.8439, -4.8966, -4.7858, -4.8558,\n",
      "         -4.8249, -4.5782, -4.6650, -4.7020, -4.3825, -4.0828, -4.7826, -4.8917,\n",
      "         -4.3995, -5.2029, -4.3482, -4.2101, -4.6418, -4.3720, -4.8379, -4.5578,\n",
      "         -4.8514, -4.9579, -4.3924, -4.7115, -4.7550, -4.5945, -4.7761, -4.4787,\n",
      "         -4.9127, -4.7422, -4.5787, -4.5287, -4.4112, -4.4327, -4.5375, -4.5676,\n",
      "         -4.3682, -4.9997, -4.4256, -4.4672, -4.6275, -4.4126, -4.4376, -4.3293,\n",
      "         -4.4621, -4.3032, -4.2045, -4.8296, -4.5370, -4.5389, -4.6001, -4.3634,\n",
      "         -4.5940, -4.3633, -4.8410, -4.2956, -4.7033, -4.5649, -4.4155, -4.6833,\n",
      "         -4.8491, -4.8159, -5.0250, -5.1037, -4.3272, -4.2654, -4.4285, -4.8820,\n",
      "         -4.3414, -4.6111, -4.4687, -4.8096, -4.5284, -4.2540, -4.6633, -5.0493,\n",
      "         -4.8131, -4.5959, -4.3527, -4.4562, -4.5610, -4.5706, -4.6248, -4.4818,\n",
      "         -4.3623]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : all-eating\n",
      "target index is: [60] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4712, -4.5713, -4.8541, -4.7431, -3.9411, -4.7088, -4.7159, -4.4237,\n",
      "         -4.8327, -4.4489, -5.0182, -4.6818, -4.8959, -4.6028, -4.7212, -4.6810,\n",
      "         -4.4718, -4.4363, -4.8419, -4.4945, -4.7338, -4.5819, -4.8266, -4.8912,\n",
      "         -4.6732, -4.9176, -4.6957, -4.2813, -4.2573, -4.4251, -4.5370, -4.5472,\n",
      "         -4.8265, -4.9536, -4.3539, -4.7264, -4.2850, -4.9173, -4.8374, -4.6302,\n",
      "         -4.7554, -4.4507, -4.4763, -4.5592, -4.3489, -4.4558, -4.5526, -4.6491,\n",
      "         -4.6721, -4.8540, -4.5171, -4.8405, -4.8322, -4.2555, -4.6735, -4.7669,\n",
      "         -4.3318, -4.3916, -4.6466, -4.4825, -4.6566, -4.6087, -4.4828, -4.4723,\n",
      "         -4.4414, -4.3862, -4.5650, -4.3003, -4.7442, -4.5910, -4.4227, -4.2941,\n",
      "         -5.0657, -4.8836, -4.7641, -4.8152, -4.3309, -4.3625, -4.4312, -5.0329,\n",
      "         -4.4116, -4.3337, -4.3201, -4.9206, -5.0062, -4.0313, -4.7426, -4.5694,\n",
      "         -4.8649, -4.2555, -4.5113, -4.6735, -4.7374, -4.4802, -4.6067, -4.5471,\n",
      "         -4.5597]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : shame,\n",
      "target index is: [41] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6959, -4.7323, -4.8786, -4.5265, -4.1433, -4.5958, -4.6336, -4.4690,\n",
      "         -4.5958, -4.6388, -4.5651, -4.5062, -4.8706, -4.7310, -4.7787, -4.4815,\n",
      "         -4.4636, -4.9124, -4.5730, -4.4867, -4.5772, -4.2179, -4.6911, -4.6038,\n",
      "         -4.5227, -4.9749, -4.3633, -4.4995, -4.4995, -4.6132, -4.4373, -5.0262,\n",
      "         -5.0874, -4.8207, -4.5561, -4.7025, -4.4880, -5.0464, -4.8055, -4.7343,\n",
      "         -4.8018, -4.3782, -4.4860, -4.5699, -4.4626, -4.4894, -4.6160, -4.6513,\n",
      "         -4.4250, -4.6418, -4.8679, -4.2363, -4.8136, -4.3333, -4.8833, -4.1739,\n",
      "         -4.4912, -4.2702, -4.4369, -4.5082, -4.6433, -5.0184, -4.7191, -4.2234,\n",
      "         -4.7964, -4.2553, -5.0335, -4.5238, -4.6512, -4.6779, -3.9977, -4.4794,\n",
      "         -4.7494, -4.5928, -4.6224, -4.8694, -4.8382, -4.3396, -4.8399, -4.8325,\n",
      "         -4.6571, -4.4749, -4.4426, -4.5718, -4.3409, -4.4922, -4.3797, -4.7544,\n",
      "         -4.7719, -4.1985, -4.6758, -4.4168, -4.7313, -4.6534, -4.5166, -4.7278,\n",
      "         -4.4513]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : and\n",
      "target index is: [44] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6866, -4.4812, -4.5734, -4.6423, -4.2048, -4.7435, -4.5120, -4.4221,\n",
      "         -4.7124, -4.8052, -4.4692, -4.4741, -4.8450, -4.8264, -4.4818, -4.5199,\n",
      "         -4.6190, -4.9143, -4.6457, -4.5305, -4.3628, -4.3238, -4.4512, -4.4670,\n",
      "         -4.5441, -4.7052, -4.3528, -4.4447, -4.6297, -4.5700, -4.6452, -4.8407,\n",
      "         -4.7983, -4.7723, -4.4011, -4.4985, -4.7770, -4.9227, -4.5995, -4.5459,\n",
      "         -4.7974, -4.6835, -4.7937, -4.5271, -4.5439, -4.6136, -4.3774, -4.5783,\n",
      "         -4.2938, -4.5356, -4.5983, -4.5862, -4.5873, -4.3896, -4.9000, -4.4852,\n",
      "         -4.7706, -4.6520, -4.6145, -4.6978, -4.8118, -4.7212, -4.8200, -4.2033,\n",
      "         -4.9308, -4.4362, -4.8762, -4.3986, -4.6600, -4.8480, -4.3181, -4.8265,\n",
      "         -4.6105, -4.6153, -4.4105, -4.7393, -4.5654, -4.4827, -4.7066, -4.4234,\n",
      "         -4.4499, -4.3581, -4.6552, -4.6464, -4.6124, -4.3248, -4.6007, -4.8177,\n",
      "         -4.8684, -4.1519, -4.7827, -4.7548, -4.3197, -4.3692, -4.4426, -4.4067,\n",
      "         -4.5704]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thriftless\n",
      "target index is: [43] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3631, -4.4327, -4.5487, -4.7382, -4.1175, -4.5553, -4.6622, -4.4890,\n",
      "         -4.7418, -4.5309, -4.9610, -4.3784, -4.7596, -4.5972, -4.6391, -4.9240,\n",
      "         -4.8730, -4.5539, -4.8996, -4.2030, -4.6961, -4.8217, -4.6151, -4.5849,\n",
      "         -4.8397, -4.7514, -4.5464, -4.4950, -4.1693, -4.7521, -4.6494, -4.5075,\n",
      "         -4.7373, -4.5944, -4.6321, -5.0446, -4.6320, -4.9046, -4.5362, -4.4841,\n",
      "         -4.5581, -4.5807, -4.7067, -4.1990, -4.4807, -4.2860, -4.4979, -4.1530,\n",
      "         -4.5546, -4.7081, -4.8429, -4.9457, -4.6089, -4.6630, -4.9389, -4.7650,\n",
      "         -4.4060, -4.4317, -4.5274, -4.6918, -4.5644, -4.6790, -4.5918, -4.4069,\n",
      "         -4.6786, -4.8228, -4.8699, -4.4193, -4.4511, -4.7453, -4.2190, -4.7022,\n",
      "         -4.7759, -5.0601, -4.5869, -4.5744, -4.4367, -4.4835, -4.4281, -4.3880,\n",
      "         -4.7060, -4.2962, -4.5164, -4.7667, -5.0580, -4.2987, -4.5024, -4.5381,\n",
      "         -5.2550, -4.4646, -4.7226, -4.4632, -4.4998, -4.5422, -4.1299, -4.2833,\n",
      "         -4.6208]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : praise.\n",
      "target index is: [94] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-3.9321, -5.0554, -4.7025, -5.1440, -3.7601, -4.7152, -4.8391, -4.4053,\n",
      "         -4.6707, -5.0116, -4.6371, -4.2691, -4.4274, -4.5392, -4.8379, -4.5801,\n",
      "         -4.9010, -5.0801, -4.7068, -4.5342, -4.7752, -4.0822, -5.1674, -4.9735,\n",
      "         -4.3612, -4.8691, -4.4863, -4.1267, -3.9182, -4.8727, -4.5735, -4.8096,\n",
      "         -4.8895, -4.8269, -4.4568, -5.2927, -4.6721, -4.6311, -4.9852, -4.9481,\n",
      "         -4.6716, -4.3527, -4.8980, -4.6001, -4.7135, -4.4340, -4.8862, -4.6642,\n",
      "         -4.7158, -4.8462, -4.3197, -4.7937, -4.4539, -4.6555, -4.8902, -4.5230,\n",
      "         -3.9469, -4.3633, -4.5188, -4.6807, -4.4119, -4.3814, -4.3353, -4.3578,\n",
      "         -4.5695, -4.6686, -5.0175, -5.0134, -4.8737, -4.8131, -4.1978, -4.3180,\n",
      "         -4.8471, -5.0669, -4.5719, -4.5335, -4.7091, -4.0318, -4.3784, -4.4317,\n",
      "         -4.5320, -4.1995, -5.1935, -5.0389, -4.1118, -4.6357, -4.3102, -4.7871,\n",
      "         -5.2174, -4.9367, -5.0144, -4.2760, -4.7152, -4.3716, -4.5454, -4.4373,\n",
      "         -4.4901]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : How\n",
      "target index is: [12] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1674, -4.7145, -4.4764, -5.0283, -4.0340, -5.0038, -4.6108, -4.3555,\n",
      "         -5.1457, -4.9669, -5.0420, -5.0790, -4.7381, -4.5203, -5.3411, -5.1094,\n",
      "         -4.8519, -4.4039, -4.7788, -4.7425, -4.6280, -4.8712, -4.7909, -5.0143,\n",
      "         -4.3755, -5.0920, -4.5854, -4.1936, -4.2849, -4.5871, -4.3050, -3.9718,\n",
      "         -4.6588, -4.7559, -4.4492, -5.1975, -4.5679, -4.5064, -4.5355, -4.5345,\n",
      "         -4.3516, -4.8573, -4.8220, -4.2173, -4.6149, -4.0146, -4.5030, -4.1685,\n",
      "         -5.0173, -4.5455, -4.3721, -4.7856, -4.6615, -4.7773, -4.5359, -4.8135,\n",
      "         -4.4055, -4.3877, -4.2937, -4.6573, -4.6561, -4.2795, -4.2718, -4.2310,\n",
      "         -4.5246, -4.9177, -4.6259, -4.3672, -4.2525, -4.4633, -4.5594, -4.3651,\n",
      "         -5.2983, -5.2875, -4.9276, -4.7812, -4.5358, -4.1021, -4.2850, -4.5863,\n",
      "         -4.5757, -4.9779, -4.7018, -5.1459, -5.0006, -4.1276, -4.1879, -4.8330,\n",
      "         -5.5377, -4.4652, -4.4651, -4.1610, -4.8121, -4.8649, -4.3837, -4.7934,\n",
      "         -4.5820]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : much\n",
      "target index is: [68] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4342, -4.9938, -4.6254, -4.4569, -3.4099, -4.4739, -4.7282, -4.2726,\n",
      "         -4.9972, -4.5553, -4.4689, -4.4725, -4.8162, -4.7386, -5.0096, -4.8002,\n",
      "         -4.8179, -4.8953, -4.1268, -4.8480, -4.7553, -4.1103, -4.9833, -4.8182,\n",
      "         -4.4738, -5.1240, -4.4869, -4.3833, -4.6028, -4.6026, -4.2317, -4.9814,\n",
      "         -4.6865, -4.5634, -4.4447, -5.3172, -4.4422, -5.0854, -4.6576, -4.9703,\n",
      "         -4.8644, -4.5771, -4.9281, -4.6484, -4.8275, -4.4141, -4.6793, -5.1407,\n",
      "         -4.9804, -4.5957, -4.9364, -4.4014, -5.0420, -4.1683, -4.6210, -4.0143,\n",
      "         -4.2636, -3.9345, -4.2547, -4.1670, -4.5369, -4.7897, -4.5578, -3.8866,\n",
      "         -4.6636, -4.4074, -4.6594, -4.5534, -5.1132, -4.7348, -4.4745, -4.3509,\n",
      "         -5.4752, -5.0283, -4.6035, -5.0669, -4.8742, -4.1720, -4.3298, -5.1331,\n",
      "         -4.8109, -4.1544, -4.9681, -4.8789, -4.3666, -4.5677, -4.5972, -4.8700,\n",
      "         -5.3058, -4.4967, -4.8791, -4.1576, -4.6457, -4.6393, -4.3477, -5.1633,\n",
      "         -4.4190]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : more\n",
      "target index is: [4] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3112, -4.8071, -4.7176, -4.4062, -4.1517, -4.6030, -4.8432, -4.4393,\n",
      "         -4.8901, -4.4806, -4.8645, -4.2991, -4.7166, -4.3664, -4.8348, -4.8000,\n",
      "         -4.6045, -4.7890, -4.7011, -4.6460, -4.4671, -4.4828, -4.6491, -4.6290,\n",
      "         -4.5604, -4.8171, -4.5825, -4.4557, -4.4084, -4.5712, -4.7521, -4.6844,\n",
      "         -4.8718, -4.5937, -4.9323, -5.0118, -4.8976, -4.6968, -4.7395, -4.6439,\n",
      "         -4.6119, -4.5528, -4.5771, -4.5111, -4.0699, -4.2826, -4.5284, -4.7189,\n",
      "         -4.7060, -4.5224, -4.9134, -4.3038, -4.7601, -4.3813, -4.8045, -4.4278,\n",
      "         -4.4757, -4.1938, -4.4776, -4.6829, -4.6058, -4.5860, -4.6082, -3.9014,\n",
      "         -4.5124, -4.6322, -4.8536, -4.6155, -4.6437, -4.6201, -4.0531, -4.6014,\n",
      "         -4.6928, -4.4623, -4.5069, -4.8347, -4.6710, -4.4853, -4.5805, -4.8098,\n",
      "         -4.4484, -4.2601, -4.6727, -4.7713, -4.5478, -4.5581, -4.7659, -4.7435,\n",
      "         -5.2320, -4.4870, -4.7110, -4.6776, -4.6300, -4.5615, -4.0985, -4.9461,\n",
      "         -4.5239]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : praise\n",
      "target index is: [45] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3963, -4.5151, -4.6936, -5.1962, -4.0362, -4.5992, -4.4715, -4.2836,\n",
      "         -5.2183, -4.6207, -4.8314, -4.3315, -4.7431, -4.5229, -5.1174, -4.8282,\n",
      "         -4.6813, -4.5002, -4.7939, -4.2314, -4.6903, -4.7059, -4.8780, -4.7240,\n",
      "         -4.8693, -4.9150, -4.5338, -4.2682, -4.2833, -4.6297, -4.2788, -4.4485,\n",
      "         -4.8768, -4.8899, -4.4706, -5.1797, -4.3219, -5.0061, -4.5349, -4.6114,\n",
      "         -4.4860, -4.5854, -4.7097, -4.2098, -4.6306, -4.1568, -4.7737, -4.4182,\n",
      "         -4.8056, -5.1278, -4.2505, -5.0988, -4.4189, -4.7817, -4.6124, -4.6446,\n",
      "         -4.3674, -4.4119, -4.4520, -4.4934, -4.5421, -4.2927, -4.6102, -4.4371,\n",
      "         -4.3299, -4.6199, -5.0694, -4.6020, -4.5338, -4.3286, -4.6952, -4.6808,\n",
      "         -5.2124, -5.2236, -4.6851, -4.9095, -4.4919, -4.1089, -4.2012, -4.4526,\n",
      "         -4.8323, -4.6460, -4.7221, -5.0027, -4.9872, -4.2415, -4.2375, -4.3082,\n",
      "         -5.1075, -4.7208, -4.5515, -4.0679, -5.0403, -4.5223, -4.6510, -4.3696,\n",
      "         -4.4019]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : deserv'd\n",
      "target index is: [66] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4234, -4.7241, -4.5278, -4.3387, -4.0402, -4.7369, -4.5734, -4.3474,\n",
      "         -4.8631, -4.8382, -4.4436, -4.7237, -4.7812, -4.7452, -4.9009, -4.8291,\n",
      "         -4.8513, -4.8461, -4.4822, -4.9369, -4.4278, -4.4609, -4.7494, -4.6541,\n",
      "         -4.2338, -5.1014, -4.6918, -4.5006, -4.3394, -4.6452, -4.2304, -4.7166,\n",
      "         -4.8106, -4.7889, -4.5623, -5.2364, -4.5079, -4.6819, -4.5385, -4.6115,\n",
      "         -4.7954, -4.6204, -4.8566, -4.5652, -4.7830, -4.2953, -4.7418, -4.5739,\n",
      "         -4.7720, -4.4789, -4.8482, -4.3052, -5.1216, -4.4580, -4.5814, -4.4897,\n",
      "         -4.0731, -4.0771, -4.2850, -4.4122, -4.6433, -4.4946, -4.5928, -4.2489,\n",
      "         -4.6413, -4.4588, -4.6253, -4.2951, -4.5234, -4.3420, -4.5450, -4.5099,\n",
      "         -5.2637, -4.9266, -4.8620, -4.9686, -4.9396, -3.9876, -4.5473, -4.8710,\n",
      "         -4.5709, -4.5040, -4.8833, -4.8558, -4.6659, -4.2951, -4.1992, -4.6446,\n",
      "         -5.1954, -4.3226, -4.4409, -4.5295, -4.7376, -4.7243, -4.2818, -4.8485,\n",
      "         -4.4267]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2691, -4.2406, -4.9305, -4.6765, -4.2319, -4.7477, -4.8603, -4.2137,\n",
      "         -5.0420, -4.7881, -5.3200, -4.5303, -4.4087, -4.6346, -4.6065, -4.7932,\n",
      "         -4.5011, -4.5388, -4.4022, -4.4302, -4.6423, -4.2859, -4.7002, -4.7194,\n",
      "         -4.3269, -5.0190, -4.3336, -4.4667, -4.5750, -4.6480, -4.7227, -4.7941,\n",
      "         -5.2425, -4.7360, -4.6342, -5.0875, -4.7323, -4.7966, -5.0136, -4.8213,\n",
      "         -4.8838, -4.7232, -4.7993, -4.6084, -4.7515, -4.0227, -4.8584, -4.9283,\n",
      "         -4.8661, -4.4929, -4.8456, -4.3357, -4.5236, -4.2233, -4.4845, -4.7727,\n",
      "         -4.3074, -4.1869, -4.5914, -4.5798, -4.7530, -4.6650, -4.1215, -4.4401,\n",
      "         -4.4666, -4.7357, -4.8881, -4.2390, -4.8196, -4.7728, -4.3435, -4.5445,\n",
      "         -4.7935, -4.8190, -4.7318, -4.6381, -4.3339, -4.3429, -4.2142, -4.7359,\n",
      "         -3.9337, -4.6671, -4.7677, -5.1008, -4.6401, -4.3978, -4.7092, -4.9044,\n",
      "         -4.7715, -4.4227, -4.5719, -4.7610, -4.9658, -4.3296, -3.8590, -4.9562,\n",
      "         -4.1806]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty's\n",
      "target index is: [80] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2951, -4.4853, -4.7154, -4.5461, -4.2202, -4.9413, -4.5067, -4.2991,\n",
      "         -4.4230, -5.1491, -4.9687, -4.1080, -4.6245, -4.7434, -4.6160, -4.7536,\n",
      "         -4.9053, -5.1707, -4.5235, -4.4189, -4.9461, -4.7582, -4.5623, -4.5004,\n",
      "         -4.2139, -4.6599, -4.6635, -4.4621, -3.8623, -4.5879, -4.8081, -4.5863,\n",
      "         -4.7160, -4.6169, -4.6709, -5.1495, -4.8590, -4.6219, -4.6652, -4.5358,\n",
      "         -4.6960, -4.2596, -4.9909, -4.0742, -4.5005, -4.1015, -4.4717, -4.4830,\n",
      "         -4.5045, -4.8974, -4.7697, -4.4547, -4.7522, -4.3915, -4.6273, -4.4177,\n",
      "         -4.3241, -4.2580, -4.7423, -5.0332, -4.8442, -4.1954, -4.5017, -4.1246,\n",
      "         -5.0428, -4.8152, -5.0707, -4.6880, -4.8093, -4.6144, -4.3264, -4.7813,\n",
      "         -4.5066, -4.8572, -4.7967, -4.9207, -5.1398, -4.0938, -4.3745, -4.4632,\n",
      "         -4.7557, -4.3218, -5.2008, -4.7388, -4.8794, -4.1043, -4.6173, -5.0089,\n",
      "         -5.0556, -4.5929, -5.1846, -4.4858, -4.5631, -4.5177, -4.2746, -4.3511,\n",
      "         -4.5743]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : use,\n",
      "target index is: [11] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1216, -4.6026, -5.0295, -5.2983, -3.7674, -5.0944, -4.7014, -4.6793,\n",
      "         -4.6920, -4.6179, -4.9318, -4.7978, -5.2374, -4.7363, -4.6844, -4.8661,\n",
      "         -5.0240, -4.4903, -4.7847, -4.3042, -4.8405, -4.1926, -5.1453, -4.6792,\n",
      "         -4.3089, -4.8814, -4.2224, -4.2403, -4.0637, -5.0417, -4.7133, -4.5724,\n",
      "         -4.8096, -4.7138, -4.9716, -5.1946, -5.0804, -4.7454, -5.0962, -4.7414,\n",
      "         -4.6988, -5.3402, -4.8596, -4.6247, -4.7103, -4.4511, -4.8218, -4.3557,\n",
      "         -4.4718, -4.8380, -3.9491, -5.5158, -4.2528, -4.5315, -4.8860, -4.3310,\n",
      "         -4.5447, -4.3699, -4.3063, -4.2494, -4.6551, -4.2633, -4.3833, -3.6963,\n",
      "         -4.5710, -4.8419, -4.8981, -4.9423, -4.3636, -4.4935, -4.2500, -4.6638,\n",
      "         -5.0899, -4.4953, -4.7333, -4.8160, -4.0404, -4.6744, -4.5445, -4.5077,\n",
      "         -4.5332, -4.0419, -5.4882, -5.0913, -4.5908, -4.5917, -4.6615, -5.0313,\n",
      "         -4.7743, -4.3652, -4.2753, -4.4413, -4.6262, -4.0642, -4.2814, -4.6063,\n",
      "         -4.6174]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : If\n",
      "target index is: [61] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7090, -4.3204, -4.8792, -4.9807, -4.4869, -4.7893, -4.7250, -4.3001,\n",
      "         -4.6228, -4.7870, -4.8010, -4.1658, -4.7396, -4.4691, -4.8575, -4.8435,\n",
      "         -4.4109, -4.6292, -4.9136, -4.4710, -4.5139, -4.9240, -4.7264, -4.5969,\n",
      "         -4.5484, -4.8132, -4.5364, -4.2828, -4.3259, -4.4590, -4.4099, -4.7906,\n",
      "         -5.1990, -4.7358, -4.9541, -5.3610, -4.4133, -4.9211, -4.4670, -4.4875,\n",
      "         -4.2570, -4.8446, -4.2765, -4.4822, -4.1678, -4.3770, -4.5240, -4.8023,\n",
      "         -4.5586, -4.7896, -4.2890, -4.3902, -4.5858, -4.3830, -4.5413, -4.5215,\n",
      "         -4.6049, -4.3343, -4.8492, -4.6117, -4.6247, -4.2928, -4.4703, -3.7609,\n",
      "         -4.4225, -4.4110, -4.7264, -4.6628, -4.3057, -4.0012, -4.5067, -4.5816,\n",
      "         -4.8891, -4.8335, -5.0806, -5.0263, -4.8096, -4.0619, -4.6348, -4.7791,\n",
      "         -4.9996, -4.5786, -4.9189, -5.1343, -5.0020, -4.3198, -4.4251, -4.5740,\n",
      "         -5.0529, -4.1865, -4.6845, -4.8717, -4.9555, -4.2852, -4.6685, -4.7960,\n",
      "         -4.6379]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thou\n",
      "target index is: [22] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5350, -4.4339, -4.9584, -4.6300, -4.4216, -4.8894, -4.4257, -4.3880,\n",
      "         -4.4456, -4.7332, -4.6059, -4.4392, -4.7482, -4.8991, -4.5731, -4.5626,\n",
      "         -4.7549, -5.0830, -4.5213, -4.3843, -4.5683, -4.4494, -4.8112, -4.3570,\n",
      "         -4.2498, -4.5943, -4.4717, -4.6824, -4.5157, -4.7281, -4.8993, -4.9382,\n",
      "         -4.6779, -4.7733, -4.3714, -4.5040, -4.5434, -4.6626, -4.7182, -4.5240,\n",
      "         -5.0670, -4.1865, -4.8190, -4.7373, -4.4529, -4.4032, -4.3636, -4.5122,\n",
      "         -4.1499, -5.1316, -4.8672, -4.2856, -4.7280, -4.3877, -4.6896, -4.4541,\n",
      "         -4.5656, -4.4391, -4.5024, -4.7120, -4.7495, -4.4643, -4.3168, -4.4479,\n",
      "         -4.9247, -4.6354, -4.5575, -4.4769, -4.6143, -4.4416, -4.2029, -4.9651,\n",
      "         -4.5296, -4.7153, -4.6763, -4.8714, -4.4953, -4.3801, -4.6158, -4.4092,\n",
      "         -4.6124, -4.5846, -4.8504, -4.4557, -4.5415, -4.5644, -4.7152, -4.7268,\n",
      "         -4.7985, -4.3137, -4.9583, -4.4198, -4.5571, -4.5292, -4.6638, -4.5158,\n",
      "         -4.4915]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : couldst\n",
      "target index is: [47] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4748, -4.3618, -4.5042, -4.7876, -4.2301, -4.8021, -4.7769, -4.4069,\n",
      "         -4.5959, -4.7761, -4.6282, -4.5247, -4.6110, -4.8486, -4.6904, -4.3070,\n",
      "         -4.5646, -4.5241, -4.4627, -4.5764, -4.5229, -4.3321, -4.6904, -4.7774,\n",
      "         -4.2337, -4.5732, -4.4465, -4.6156, -4.3090, -4.6821, -4.5633, -4.8168,\n",
      "         -4.8156, -4.5240, -4.6386, -4.8315, -4.5862, -4.8007, -4.7449, -4.8469,\n",
      "         -4.5915, -4.7482, -4.7657, -4.6872, -4.5888, -4.5877, -4.6427, -4.7828,\n",
      "         -4.6017, -4.6142, -4.4966, -4.6525, -4.5759, -4.4974, -4.7436, -4.6558,\n",
      "         -4.4624, -4.4712, -4.4314, -4.5010, -4.7974, -4.5822, -4.4309, -4.1852,\n",
      "         -4.7488, -4.4819, -4.7951, -4.7238, -4.5047, -4.6033, -4.3733, -4.4323,\n",
      "         -4.7534, -4.7908, -4.7240, -4.6982, -4.3291, -4.4096, -4.6742, -4.6478,\n",
      "         -4.4574, -4.4152, -4.7872, -4.8230, -4.4985, -4.6198, -4.3779, -4.6807,\n",
      "         -4.6052, -4.3266, -4.5232, -4.7677, -4.6435, -4.2752, -4.4436, -4.5930,\n",
      "         -4.5894]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : answer\n",
      "target index is: [53] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3795, -4.7562, -4.7371, -4.7912, -4.2286, -4.5572, -4.6639, -4.2989,\n",
      "         -4.7892, -4.7600, -4.7245, -4.4351, -4.5218, -4.6909, -4.8189, -4.6962,\n",
      "         -4.2657, -4.6266, -4.3715, -4.7032, -4.5798, -4.3932, -4.5956, -4.5291,\n",
      "         -4.2662, -5.0278, -4.3363, -4.7816, -4.5836, -4.5011, -4.5455, -4.7515,\n",
      "         -4.8070, -4.7603, -4.3996, -4.9031, -4.5799, -4.3510, -4.7802, -4.7683,\n",
      "         -4.8000, -4.6557, -4.8016, -4.6654, -4.3791, -4.3340, -4.5315, -4.7189,\n",
      "         -4.7546, -4.3410, -4.7768, -4.4523, -4.8009, -4.3863, -4.5840, -4.5555,\n",
      "         -4.6172, -4.3960, -4.4260, -4.4388, -4.6198, -4.5733, -4.4486, -4.0272,\n",
      "         -4.5559, -4.6260, -4.8083, -4.6278, -4.6381, -4.5840, -4.4139, -4.6277,\n",
      "         -4.8014, -4.6589, -4.8298, -4.7514, -4.3810, -4.3289, -4.4599, -4.9093,\n",
      "         -4.3221, -4.6232, -4.6984, -4.8480, -4.6424, -4.7001, -4.5039, -4.5804,\n",
      "         -5.0909, -4.3211, -4.4248, -4.6890, -4.7494, -4.5312, -4.5138, -4.8158,\n",
      "         -4.3373]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : 'This\n",
      "target index is: [9] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4208, -4.7199, -4.8283, -4.7019, -3.7016, -4.6338, -4.3389, -4.3242,\n",
      "         -4.9234, -4.8387, -4.8968, -4.5865, -4.8817, -4.7689, -4.7604, -4.8061,\n",
      "         -4.4739, -4.8678, -4.6902, -4.5483, -4.4756, -4.3171, -4.7732, -4.4057,\n",
      "         -4.5467, -4.9918, -4.4479, -4.4490, -4.5511, -4.7809, -4.5472, -4.6947,\n",
      "         -4.5713, -4.9651, -4.3117, -4.6433, -4.5404, -4.7459, -4.8512, -4.3846,\n",
      "         -4.8253, -4.2141, -4.7375, -4.4046, -4.6857, -4.1913, -4.5264, -4.5460,\n",
      "         -4.5943, -4.8460, -4.9383, -4.5117, -4.9753, -4.0488, -4.4361, -4.2779,\n",
      "         -4.6369, -4.2951, -4.6734, -4.5648, -4.5081, -4.4669, -4.6759, -4.4764,\n",
      "         -4.4818, -4.6733, -4.4408, -4.2332, -4.6779, -4.7703, -4.4009, -4.6222,\n",
      "         -4.7812, -5.0647, -4.8790, -5.0207, -4.6763, -4.4120, -4.5475, -4.7833,\n",
      "         -4.7400, -4.4936, -4.7024, -4.7826, -4.6566, -4.1891, -4.4158, -4.8408,\n",
      "         -4.9398, -4.4191, -4.6743, -4.4980, -4.6007, -4.6909, -4.5407, -4.7028,\n",
      "         -4.3349]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : fair\n",
      "target index is: [21] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3691, -4.4523, -4.8918, -4.5850, -4.0892, -4.5671, -4.8254, -4.2994,\n",
      "         -4.6752, -4.4164, -4.8339, -4.4934, -4.6027, -4.6524, -4.7639, -4.5888,\n",
      "         -4.6429, -4.4719, -4.6234, -4.3624, -4.5669, -4.2714, -4.8704, -4.8935,\n",
      "         -4.4143, -4.7810, -4.4622, -4.4036, -4.3235, -4.6378, -4.6107, -4.7044,\n",
      "         -4.9739, -4.8238, -4.4863, -4.6592, -4.7733, -4.7910, -5.1378, -4.8272,\n",
      "         -4.7610, -4.5488, -4.4561, -4.7061, -4.4171, -4.2571, -4.5992, -4.8270,\n",
      "         -4.5695, -4.8722, -4.7313, -4.3155, -4.7010, -4.4014, -4.7107, -4.7012,\n",
      "         -4.2746, -4.3484, -4.5253, -4.5883, -4.6655, -4.5314, -4.5768, -4.4871,\n",
      "         -4.4644, -4.7175, -4.6786, -4.5617, -4.8112, -4.6366, -4.3704, -4.6374,\n",
      "         -4.5883, -4.8681, -4.5906, -4.6345, -4.4874, -4.5269, -4.5526, -4.7468,\n",
      "         -4.3131, -4.3445, -4.5319, -4.7213, -4.5779, -4.2620, -4.7698, -4.7550,\n",
      "         -4.7209, -4.3861, -4.8433, -4.8124, -4.7692, -4.2118, -4.3820, -4.6736,\n",
      "         -4.4109]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : child\n",
      "target index is: [5] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3767, -4.4507, -4.9630, -4.6439, -4.1231, -4.7650, -4.5607, -4.6840,\n",
      "         -4.7219, -4.4909, -4.9773, -4.5519, -4.8805, -4.7612, -4.7831, -4.8709,\n",
      "         -4.5954, -4.6720, -4.7934, -4.4891, -4.5518, -4.3584, -4.8471, -4.6366,\n",
      "         -4.7052, -5.2416, -4.5771, -4.4869, -4.1575, -4.7168, -4.4921, -4.8016,\n",
      "         -4.6911, -4.7258, -4.5621, -4.8049, -4.4546, -4.6521, -4.7120, -4.5280,\n",
      "         -4.6506, -4.4627, -4.5149, -4.4229, -4.5436, -4.2675, -4.7237, -4.5904,\n",
      "         -4.6017, -4.9048, -4.7720, -4.6132, -5.0204, -4.3855, -4.4191, -4.2427,\n",
      "         -4.3484, -4.1388, -4.5888, -4.7356, -4.5237, -4.4145, -4.7755, -4.4446,\n",
      "         -4.4419, -4.5669, -4.7501, -4.3199, -4.4496, -4.4005, -4.4242, -4.5704,\n",
      "         -4.8045, -4.9751, -4.9988, -5.2150, -4.7911, -4.2682, -4.5232, -4.7780,\n",
      "         -4.6056, -4.3861, -4.6617, -4.9772, -4.7209, -4.1516, -4.4015, -4.3032,\n",
      "         -4.8709, -4.4512, -4.4269, -4.3952, -4.6407, -4.5362, -4.6318, -4.5809,\n",
      "         -4.1841]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : of\n",
      "target index is: [57] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6030, -4.0736, -4.5754, -4.7152, -4.1117, -4.8084, -4.8047, -4.5457,\n",
      "         -4.7536, -4.8643, -5.1015, -4.5005, -4.5825, -4.5347, -4.6557, -4.5848,\n",
      "         -4.7660, -4.5541, -4.6797, -4.3896, -4.5108, -4.2135, -4.7739, -4.4438,\n",
      "         -4.2484, -4.6057, -4.4891, -4.4570, -4.2495, -4.7611, -4.7076, -4.9762,\n",
      "         -5.0601, -4.5828, -4.7082, -4.7244, -4.8651, -4.8820, -4.8248, -4.7475,\n",
      "         -4.7001, -4.4404, -4.5939, -4.5714, -4.4997, -4.2910, -4.8408, -4.9303,\n",
      "         -4.5269, -4.7583, -4.4938, -4.4801, -4.5727, -4.3097, -4.7763, -4.7284,\n",
      "         -4.4114, -4.4484, -4.4954, -4.5767, -4.8622, -4.8094, -4.4232, -4.2945,\n",
      "         -4.6282, -4.7391, -5.0550, -4.4475, -4.7875, -4.7035, -4.5331, -4.5542,\n",
      "         -4.6361, -4.9269, -4.6180, -4.7147, -4.5166, -4.3979, -4.5715, -4.7940,\n",
      "         -4.1008, -4.3763, -4.6089, -4.6573, -4.4640, -4.3325, -4.5531, -4.8303,\n",
      "         -4.5078, -4.2818, -4.8325, -4.8495, -4.6287, -4.2294, -4.1946, -4.7856,\n",
      "         -4.3392]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : mine\n",
      "target index is: [86] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.0998, -4.3466, -4.6075, -5.0265, -4.1489, -4.6386, -4.7985, -4.5035,\n",
      "         -4.6949, -4.7813, -5.0124, -4.2969, -4.9015, -4.5261, -4.5940, -4.7998,\n",
      "         -4.6677, -4.8646, -4.5788, -4.1909, -4.9346, -4.7303, -4.5682, -4.1190,\n",
      "         -4.5105, -4.4906, -4.6823, -4.4774, -4.2009, -4.6400, -4.5705, -4.9950,\n",
      "         -4.7742, -4.5304, -4.6536, -4.7013, -4.6488, -4.7394, -4.8099, -4.7400,\n",
      "         -4.9065, -4.4828, -4.7721, -4.5434, -4.7781, -4.1743, -4.8838, -4.6205,\n",
      "         -4.5581, -4.5994, -4.6558, -4.8741, -4.6067, -4.3632, -4.8199, -4.6720,\n",
      "         -4.3412, -4.4130, -4.6825, -4.5614, -4.6089, -4.5893, -4.4431, -4.3740,\n",
      "         -4.7644, -4.6353, -5.1629, -4.8170, -4.6423, -4.7836, -4.2798, -4.5842,\n",
      "         -4.5862, -4.8945, -4.6191, -4.6059, -4.5541, -4.2212, -4.5040, -4.4912,\n",
      "         -4.6187, -4.2693, -4.6994, -4.7822, -4.6792, -4.4519, -4.4149, -4.4238,\n",
      "         -4.9010, -4.2555, -4.4919, -4.6138, -4.5025, -4.5185, -4.3150, -4.6057,\n",
      "         -4.4026]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Shall\n",
      "target index is: [81] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2458, -4.3939, -4.5747, -5.0853, -4.0582, -4.7237, -4.6711, -4.5611,\n",
      "         -4.7117, -4.9447, -4.7639, -4.3026, -4.6521, -4.7630, -4.7162, -4.6222,\n",
      "         -4.3399, -4.7099, -4.5063, -4.6354, -4.5924, -4.5223, -4.6806, -4.4068,\n",
      "         -4.3820, -4.5361, -4.3778, -4.4528, -4.4083, -4.8540, -4.1568, -5.0095,\n",
      "         -4.5713, -4.6545, -4.5727, -4.9944, -4.4530, -4.6382, -4.8542, -4.9664,\n",
      "         -4.6478, -4.7813, -4.7566, -4.6290, -4.6127, -4.2043, -4.5151, -4.7103,\n",
      "         -4.7594, -4.6571, -4.5595, -4.6106, -4.6544, -4.4382, -4.5811, -4.9964,\n",
      "         -4.6045, -4.6057, -4.5412, -4.4964, -4.7026, -4.5343, -4.6401, -4.1671,\n",
      "         -4.7889, -4.7586, -4.7971, -4.5675, -4.5133, -4.3772, -4.7226, -4.6510,\n",
      "         -4.8231, -4.8044, -4.7218, -4.5325, -4.5958, -4.1892, -4.4502, -4.5090,\n",
      "         -4.4894, -4.3667, -4.7642, -5.0688, -4.5316, -4.5576, -4.1822, -4.5863,\n",
      "         -4.9072, -4.3969, -4.5259, -4.7778, -4.7847, -4.3855, -4.1474, -4.6857,\n",
      "         -4.4646]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : sum\n",
      "target index is: [70] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3066, -4.3886, -4.6915, -4.8299, -4.1950, -4.8777, -4.5174, -4.3697,\n",
      "         -4.6590, -4.7678, -4.7099, -4.3135, -4.5682, -4.9690, -4.7973, -4.6919,\n",
      "         -4.5270, -5.1682, -4.7032, -4.6358, -4.5983, -4.3119, -4.7021, -4.5883,\n",
      "         -4.3070, -4.9758, -4.3080, -4.4578, -4.4755, -4.6389, -4.5738, -4.8940,\n",
      "         -4.8694, -4.9505, -4.3277, -4.4820, -4.7264, -4.4681, -4.6861, -4.5944,\n",
      "         -5.0668, -4.4150, -4.5913, -4.5215, -4.4016, -4.2350, -4.4014, -4.6172,\n",
      "         -4.3328, -4.7989, -4.6096, -4.1282, -4.9527, -4.4495, -4.6884, -4.5535,\n",
      "         -4.6225, -4.4303, -4.5993, -4.9428, -4.8049, -4.5943, -4.6896, -4.3370,\n",
      "         -4.9301, -4.6072, -4.8497, -4.3894, -4.5800, -4.6099, -4.3411, -4.8190,\n",
      "         -4.5524, -4.8297, -4.6591, -4.7965, -4.5535, -4.1694, -4.5625, -4.8203,\n",
      "         -4.3129, -4.6685, -4.5450, -4.6459, -4.2636, -4.5760, -4.4911, -4.6850,\n",
      "         -5.0267, -4.4452, -4.6247, -4.5547, -4.5555, -4.7109, -4.4954, -4.4241,\n",
      "         -4.4165]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : my\n",
      "target index is: [90] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3945, -4.3797, -4.6044, -5.1581, -4.2406, -5.1514, -4.4837, -4.4902,\n",
      "         -4.7333, -4.6388, -5.1239, -4.5809, -4.7311, -4.7579, -4.3866, -4.6285,\n",
      "         -4.6295, -4.6839, -4.9540, -4.3261, -4.7955, -4.3115, -4.7375, -4.6113,\n",
      "         -4.3845, -5.0000, -4.2327, -4.4827, -4.1408, -4.6010, -4.6692, -4.8772,\n",
      "         -4.7900, -4.9245, -4.7364, -4.5691, -4.6828, -4.4080, -4.8767, -4.5315,\n",
      "         -4.9481, -4.7850, -4.8699, -4.3980, -4.8354, -4.3557, -4.8168, -4.6601,\n",
      "         -4.5507, -5.1772, -4.1253, -5.0980, -4.4344, -4.5628, -4.7299, -4.4221,\n",
      "         -4.5449, -4.4250, -4.3095, -5.0248, -4.5975, -4.3545, -4.4901, -4.2973,\n",
      "         -4.6028, -4.3610, -5.0585, -4.6041, -4.4088, -4.5292, -4.6128, -4.6243,\n",
      "         -4.7442, -4.7125, -4.7438, -5.0142, -4.3706, -4.3390, -4.3248, -4.6523,\n",
      "         -4.4146, -4.5067, -4.8256, -4.4450, -4.6405, -4.1690, -4.5216, -4.8571,\n",
      "         -4.4875, -4.6156, -4.3572, -4.5680, -4.7170, -4.3497, -4.6517, -4.3087,\n",
      "         -4.1791]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : count,\n",
      "target index is: [55] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5858, -4.2598, -4.7169, -4.9571, -4.5105, -4.9556, -4.6187, -4.4615,\n",
      "         -4.6211, -4.8846, -4.9647, -4.6614, -4.6995, -4.7587, -4.7325, -4.6528,\n",
      "         -4.5846, -4.5849, -4.8599, -4.6408, -4.6111, -4.6806, -4.8581, -4.4057,\n",
      "         -4.3893, -4.7029, -4.5304, -4.2190, -4.2923, -4.6164, -4.2281, -4.8829,\n",
      "         -5.0088, -4.8033, -4.8505, -4.6437, -4.5752, -4.8066, -4.7285, -4.5192,\n",
      "         -4.6160, -4.6573, -4.3917, -4.5855, -4.4422, -4.2471, -4.9861, -4.6696,\n",
      "         -4.6495, -4.9374, -4.2751, -4.6701, -4.7529, -4.3274, -4.6256, -4.4417,\n",
      "         -4.2245, -4.2229, -4.6540, -4.4569, -4.6064, -4.5307, -4.3262, -4.1676,\n",
      "         -4.5882, -4.4992, -4.9579, -4.4121, -4.2210, -4.1723, -4.4699, -4.5560,\n",
      "         -4.8183, -4.7880, -5.0119, -5.1162, -4.3370, -4.2421, -4.6408, -4.9125,\n",
      "         -4.6823, -4.7334, -4.8496, -4.8499, -4.7585, -4.2902, -4.1956, -4.5607,\n",
      "         -4.7777, -4.3492, -4.3207, -4.9382, -4.7901, -4.3024, -4.5753, -4.7266,\n",
      "         -4.3992]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : and\n",
      "target index is: [44] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6591, -4.4729, -4.7141, -4.6793, -4.2108, -4.9030, -4.4036, -4.2691,\n",
      "         -4.7487, -4.9915, -4.6539, -4.4964, -4.6564, -4.8877, -4.6795, -4.4067,\n",
      "         -4.3165, -4.8198, -4.5486, -4.6650, -4.4909, -4.2918, -4.4169, -4.5451,\n",
      "         -4.2036, -4.8333, -4.4588, -4.5077, -4.7715, -4.4595, -4.6213, -4.8436,\n",
      "         -4.8013, -4.8624, -4.3643, -4.2757, -4.9273, -4.7991, -4.8256, -4.6667,\n",
      "         -4.9826, -4.6314, -4.8578, -4.5501, -4.4382, -4.5397, -4.3118, -4.7849,\n",
      "         -4.2524, -4.5713, -4.6447, -4.3423, -4.7975, -4.2023, -4.5495, -4.6045,\n",
      "         -4.5497, -4.6089, -4.6894, -4.8047, -4.9778, -4.6959, -4.4037, -4.1538,\n",
      "         -4.9437, -4.4654, -4.7241, -4.1394, -4.6773, -4.8387, -4.5583, -4.8957,\n",
      "         -4.3693, -4.6449, -4.7759, -4.8400, -4.2985, -4.4783, -4.6694, -4.4697,\n",
      "         -4.3058, -4.5394, -4.7730, -4.7965, -4.6425, -4.4880, -4.6923, -4.8000,\n",
      "         -4.9657, -4.1438, -4.8524, -4.9324, -4.3451, -4.4464, -4.4939, -4.4534,\n",
      "         -4.5639]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : make\n",
      "target index is: [14] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4460, -4.2540, -4.7374, -5.1444, -4.3565, -4.6433, -4.5831, -4.4333,\n",
      "         -4.6756, -4.6961, -4.7712, -4.5615, -4.8243, -4.6414, -4.4226, -4.5921,\n",
      "         -4.6177, -4.7425, -4.7616, -4.1539, -4.8555, -4.6892, -4.8591, -4.4114,\n",
      "         -4.6936, -4.6938, -4.4282, -4.3707, -4.2804, -4.6761, -4.5705, -4.7961,\n",
      "         -4.8840, -4.7889, -4.4456, -4.4354, -4.5203, -4.9589, -4.8048, -4.6328,\n",
      "         -4.7174, -4.6476, -4.6191, -4.4631, -4.7266, -4.3667, -5.0807, -4.5206,\n",
      "         -4.4210, -4.9731, -4.2340, -4.8881, -4.2383, -4.5687, -5.0000, -4.2603,\n",
      "         -4.5345, -4.3524, -4.8203, -4.4732, -4.5903, -4.5878, -4.4076, -4.4533,\n",
      "         -4.6322, -4.4455, -5.2107, -4.8972, -4.4562, -4.5470, -4.2318, -4.6992,\n",
      "         -4.5776, -4.8053, -4.5203, -4.7825, -4.4405, -4.2844, -4.6592, -4.7221,\n",
      "         -4.6582, -4.6081, -4.6795, -4.7497, -4.6024, -4.4320, -4.4714, -4.5650,\n",
      "         -4.5124, -4.1860, -4.5111, -4.4112, -4.7852, -4.4375, -4.6369, -4.5206,\n",
      "         -4.3774]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : my\n",
      "target index is: [90] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3249, -4.2438, -4.8792, -5.0341, -4.2183, -5.0002, -4.3382, -4.4139,\n",
      "         -4.8166, -4.6812, -4.6793, -4.4037, -4.6189, -4.9795, -4.7721, -4.4842,\n",
      "         -4.3977, -4.8053, -4.7746, -4.6135, -4.7937, -4.1625, -4.6990, -4.9207,\n",
      "         -4.2433, -5.0281, -4.1868, -4.5431, -4.1735, -4.6907, -4.3665, -4.8973,\n",
      "         -4.6015, -4.7347, -4.7453, -4.6634, -4.8515, -4.3476, -5.0142, -4.8304,\n",
      "         -4.7127, -4.9224, -4.6365, -4.5799, -4.5294, -4.3169, -4.5719, -4.8844,\n",
      "         -4.6487, -4.7910, -4.5407, -4.6042, -4.6748, -4.6331, -4.5180, -4.7140,\n",
      "         -4.7579, -4.4870, -4.5094, -4.8712, -4.8139, -4.1505, -4.5015, -4.0453,\n",
      "         -4.7146, -4.8611, -4.8171, -4.5436, -4.4877, -4.0425, -4.7045, -4.7583,\n",
      "         -4.5959, -4.5611, -4.7777, -4.9151, -4.4460, -4.4797, -4.3059, -4.5588,\n",
      "         -4.4411, -4.4976, -4.9957, -4.7491, -4.5907, -4.6293, -4.6563, -4.5783,\n",
      "         -4.6118, -4.2740, -4.4940, -4.7646, -4.8250, -4.2498, -4.3614, -4.4664,\n",
      "         -4.3146]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : old\n",
      "target index is: [84] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.0869, -4.3581, -4.4122, -5.0279, -4.2873, -5.2513, -4.3888, -4.4172,\n",
      "         -4.5112, -4.9282, -4.9684, -4.7991, -4.2560, -4.8151, -4.9297, -4.4199,\n",
      "         -4.5252, -4.5695, -4.8634, -4.7475, -4.7089, -4.2758, -5.0609, -4.7588,\n",
      "         -4.0089, -4.8612, -4.3505, -4.5137, -3.9591, -4.7161, -4.6085, -4.6835,\n",
      "         -4.6427, -4.9961, -4.8765, -4.5989, -4.7940, -4.3228, -4.7377, -4.5638,\n",
      "         -4.8539, -4.5053, -4.7919, -4.2933, -4.5130, -4.4242, -4.8265, -4.5604,\n",
      "         -4.6158, -4.9131, -4.0792, -4.7336, -4.9129, -4.6774, -4.7126, -4.5646,\n",
      "         -4.2542, -4.5313, -4.4107, -4.8262, -4.9499, -4.3568, -4.3938, -4.3021,\n",
      "         -4.6805, -4.7420, -4.8834, -4.5790, -4.4840, -4.3793, -4.5869, -4.4440,\n",
      "         -4.7681, -4.8729, -4.7386, -4.9497, -4.3200, -4.3583, -4.6210, -4.8778,\n",
      "         -4.1171, -4.5728, -4.8341, -4.7528, -4.4979, -4.4981, -4.6148, -4.7818,\n",
      "         -4.8682, -4.5532, -4.5354, -4.6180, -4.6074, -4.4398, -4.8454, -4.3753,\n",
      "         -4.4246]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : excuse,'\n",
      "target index is: [64] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4790, -4.4315, -4.5221, -4.7950, -4.1818, -4.9207, -4.6148, -4.3578,\n",
      "         -4.7505, -4.8138, -4.7414, -4.6528, -4.4956, -4.4959, -4.8288, -4.6318,\n",
      "         -4.7198, -4.2817, -4.6468, -4.6094, -4.4050, -4.7032, -4.4587, -4.7683,\n",
      "         -4.2610, -4.7250, -4.5864, -4.5648, -4.3866, -4.2389, -4.6453, -4.6866,\n",
      "         -4.8923, -4.7636, -4.6573, -5.2324, -4.8174, -4.6744, -4.6027, -4.5262,\n",
      "         -4.3648, -4.7970, -4.8100, -4.6401, -4.5672, -4.6100, -4.5461, -4.4725,\n",
      "         -4.5041, -4.4602, -4.2976, -4.5165, -4.4770, -4.4938, -4.5711, -4.4252,\n",
      "         -4.6236, -4.4408, -4.3790, -4.6201, -4.9402, -4.5192, -4.5402, -3.7684,\n",
      "         -4.6868, -4.4259, -4.6720, -4.3639, -4.4934, -4.6492, -4.6160, -4.6083,\n",
      "         -4.9432, -4.8482, -4.8460, -4.6480, -4.6321, -4.5073, -4.3972, -4.5794,\n",
      "         -4.7287, -4.7123, -4.9498, -4.9314, -4.6744, -4.2281, -4.4278, -4.9613,\n",
      "         -4.8804, -4.1703, -4.4975, -4.7095, -4.5901, -4.5203, -4.6734, -4.5577,\n",
      "         -4.8791]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Proving\n",
      "target index is: [25] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4498, -4.6006, -4.9584, -4.7447, -4.4805, -4.6959, -4.6173, -4.4777,\n",
      "         -4.6079, -4.5691, -4.9407, -4.4109, -4.4454, -4.5010, -4.5439, -4.8660,\n",
      "         -4.5967, -4.8677, -4.3970, -4.5777, -4.5137, -4.4884, -4.6976, -4.5167,\n",
      "         -4.4188, -4.7160, -4.2308, -4.5972, -4.4467, -4.4620, -5.0667, -4.8182,\n",
      "         -4.8170, -4.8382, -4.9904, -5.0140, -4.4734, -4.7161, -4.6213, -4.3664,\n",
      "         -4.7760, -4.5868, -4.6236, -4.6891, -4.3225, -4.3798, -4.7506, -4.8132,\n",
      "         -4.4520, -4.9107, -4.2829, -4.5372, -4.5216, -4.1579, -4.5479, -4.2745,\n",
      "         -4.7049, -4.3723, -4.5445, -4.3665, -4.4916, -4.3280, -4.3903, -4.0442,\n",
      "         -4.4361, -4.5887, -4.7137, -4.7170, -4.9576, -4.1924, -4.0597, -4.5832,\n",
      "         -5.1109, -4.3286, -4.8262, -4.9745, -4.3655, -4.4595, -4.4241, -4.6087,\n",
      "         -4.6637, -4.6231, -4.9288, -4.8929, -4.8919, -4.5380, -5.1198, -5.0122,\n",
      "         -4.8481, -4.4175, -4.6135, -4.6860, -4.7286, -4.2187, -4.6328, -4.8326,\n",
      "         -4.3625]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : his\n",
      "target index is: [49] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6419, -4.3195, -4.9151, -5.0979, -4.2692, -4.5986, -4.2201, -4.3866,\n",
      "         -4.9880, -4.4647, -4.7318, -4.3098, -4.7350, -4.6787, -4.9001, -4.5354,\n",
      "         -4.5108, -4.4790, -4.7044, -4.3331, -4.4642, -4.3914, -4.4677, -4.6388,\n",
      "         -4.6330, -4.7841, -4.4247, -4.5741, -4.7354, -4.5545, -4.7098, -4.5858,\n",
      "         -4.7584, -4.7943, -4.5076, -4.6729, -4.4926, -4.8143, -4.7417, -4.3447,\n",
      "         -4.4175, -4.5063, -4.4746, -4.3167, -4.4761, -4.6987, -4.4719, -4.3808,\n",
      "         -4.3611, -5.1795, -4.4570, -4.7806, -4.3791, -4.3710, -4.6234, -4.5514,\n",
      "         -4.9133, -4.6963, -4.2555, -4.7026, -4.9187, -4.4854, -4.5221, -4.3715,\n",
      "         -4.4706, -4.6485, -4.5177, -4.3944, -4.6730, -4.3049, -4.7706, -4.9085,\n",
      "         -4.7426, -4.7824, -4.6934, -4.9213, -4.3821, -4.5268, -4.3344, -4.4982,\n",
      "         -4.8018, -4.6852, -4.8433, -4.5747, -4.9917, -4.3381, -4.7383, -4.6073,\n",
      "         -4.8341, -4.3010, -4.6149, -4.3107, -4.9355, -4.5508, -4.7025, -4.5846,\n",
      "         -4.5328]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty\n",
      "target index is: [0] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5529, -4.4864, -4.8456, -4.6790, -4.3935, -4.7174, -4.7140, -4.0914,\n",
      "         -4.7747, -4.4614, -4.6196, -4.3448, -4.3977, -4.7359, -4.7813, -4.7205,\n",
      "         -4.7047, -4.4841, -4.3322, -4.4815, -4.5874, -4.4683, -4.7162, -4.9289,\n",
      "         -4.2370, -5.2807, -4.3117, -4.7607, -4.0461, -4.4311, -4.6223, -4.6288,\n",
      "         -4.9967, -4.7099, -4.5288, -5.0332, -4.4662, -4.6010, -4.6429, -4.7789,\n",
      "         -4.7283, -4.6531, -4.7379, -4.7473, -4.6037, -4.4575, -4.7703, -5.0243,\n",
      "         -4.8637, -4.8045, -4.6805, -4.4532, -4.8366, -4.5912, -4.6678, -4.5770,\n",
      "         -4.2508, -4.0876, -4.4326, -4.3601, -4.6698, -4.5466, -4.4573, -4.4158,\n",
      "         -4.4288, -4.6917, -4.6006, -4.7356, -4.6594, -4.3418, -4.4801, -4.5038,\n",
      "         -5.1509, -4.6145, -4.9171, -4.8898, -4.4324, -4.2564, -4.2589, -4.8915,\n",
      "         -4.3937, -4.4419, -4.6983, -4.8272, -4.7781, -4.5109, -4.7058, -4.2899,\n",
      "         -4.7560, -4.5600, -4.6079, -4.5896, -4.8534, -4.3141, -4.6389, -4.6209,\n",
      "         -4.2429]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : by\n",
      "target index is: [62] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.0234, -4.6825, -4.6660, -4.6749, -3.8801, -4.7130, -4.4171, -4.0902,\n",
      "         -4.9026, -4.9249, -4.7023, -4.4696, -4.4082, -4.6948, -4.7652, -4.8013,\n",
      "         -4.4205, -4.6791, -4.5441, -4.8117, -4.7286, -4.4077, -4.8767, -4.7365,\n",
      "         -4.1412, -4.7880, -4.4960, -4.3934, -4.5352, -4.7233, -4.5482, -4.4523,\n",
      "         -4.5551, -4.9740, -4.5861, -5.1401, -4.8106, -4.2376, -4.7211, -4.3757,\n",
      "         -4.6988, -4.4586, -4.8517, -4.3561, -4.5225, -3.9206, -4.5239, -4.7587,\n",
      "         -4.8772, -4.5170, -4.7495, -4.3726, -4.8947, -4.3088, -4.4010, -4.4789,\n",
      "         -4.3167, -4.3689, -4.6928, -4.7729, -4.8420, -4.2456, -4.3585, -4.3746,\n",
      "         -4.5486, -4.8319, -4.5776, -4.2089, -4.9646, -4.6480, -4.7336, -4.7789,\n",
      "         -4.5011, -5.0334, -4.7255, -4.8091, -4.6550, -4.3003, -4.4768, -5.0190,\n",
      "         -4.3143, -4.5110, -5.0278, -5.0104, -4.6830, -4.3035, -4.7642, -5.1080,\n",
      "         -5.1557, -4.6068, -4.8860, -4.7170, -4.5092, -4.5260, -4.6246, -4.8203,\n",
      "         -4.5372]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : succession\n",
      "target index is: [7] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6361, -4.4100, -4.6554, -4.6810, -4.1912, -4.6705, -4.6885, -4.4375,\n",
      "         -4.7045, -4.5750, -4.7159, -4.2475, -4.7696, -4.5034, -4.9705, -4.6652,\n",
      "         -4.6477, -4.4969, -4.8516, -4.5118, -4.3518, -4.5868, -4.7750, -4.8775,\n",
      "         -4.5098, -4.6984, -4.4991, -4.2707, -4.1942, -4.4435, -4.4795, -4.7724,\n",
      "         -4.9348, -4.5591, -4.8819, -5.1975, -4.5421, -4.9382, -4.5292, -4.5219,\n",
      "         -4.2789, -4.6788, -4.4417, -4.7298, -4.2725, -4.5389, -4.3279, -4.8287,\n",
      "         -4.4103, -4.8495, -4.5175, -4.5346, -4.5409, -4.4072, -4.6773, -4.5308,\n",
      "         -4.5812, -4.3326, -4.6054, -4.7183, -4.5039, -4.4092, -4.4176, -3.9167,\n",
      "         -4.3958, -4.5394, -4.5857, -4.5491, -4.4025, -4.1185, -4.3824, -4.4450,\n",
      "         -4.9855, -4.8007, -4.7995, -4.9173, -4.7654, -4.3392, -4.5493, -4.8694,\n",
      "         -4.9634, -4.5444, -4.7168, -4.8900, -4.7412, -4.4179, -4.4562, -4.6001,\n",
      "         -4.9842, -4.4854, -4.7612, -4.6622, -4.8004, -4.6996, -4.5906, -4.9873,\n",
      "         -4.7057]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thine!\n",
      "target index is: [40] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6119, -4.3050, -4.6885, -4.4825, -4.2132, -4.7538, -4.5905, -4.2911,\n",
      "         -4.7177, -4.6537, -4.6325, -4.3926, -4.7004, -4.7054, -4.4844, -4.8399,\n",
      "         -4.8872, -5.0606, -4.6435, -4.5630, -4.5474, -4.5855, -4.6146, -4.5326,\n",
      "         -4.5321, -4.5994, -4.1921, -4.4090, -4.3985, -4.6745, -4.8532, -4.8547,\n",
      "         -4.9233, -4.5794, -4.5127, -4.8833, -4.7747, -4.7726, -4.5670, -4.4358,\n",
      "         -4.7345, -4.6287, -4.5984, -4.5726, -4.6165, -4.4762, -4.5892, -4.5492,\n",
      "         -4.3353, -4.7162, -4.3870, -4.4493, -4.5034, -4.5368, -4.9855, -4.1526,\n",
      "         -4.7770, -4.2966, -4.6908, -4.7663, -4.5159, -4.4707, -4.6319, -4.2032,\n",
      "         -4.8841, -4.5338, -4.7240, -4.6336, -4.7927, -4.6473, -4.2028, -4.8163,\n",
      "         -4.7907, -4.5192, -4.3483, -4.9364, -4.6826, -4.4234, -4.4201, -4.4419,\n",
      "         -4.6654, -4.3576, -4.9227, -4.8229, -4.7375, -4.4183, -4.8838, -4.8079,\n",
      "         -4.7172, -4.3967, -4.7555, -4.3493, -4.5717, -4.3036, -4.5438, -4.2711,\n",
      "         -4.6869]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : This\n",
      "target index is: [1] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4656, -4.3543, -4.7532, -4.7832, -4.2057, -4.5649, -4.7543, -4.4812,\n",
      "         -4.5400, -4.5638, -4.7826, -4.6972, -4.8216, -4.6818, -4.4497, -4.7182,\n",
      "         -4.6174, -4.6091, -4.8416, -4.3941, -4.6918, -4.6252, -5.0451, -4.5105,\n",
      "         -4.5199, -4.6792, -4.5196, -4.4297, -4.2627, -4.7292, -4.5749, -4.7632,\n",
      "         -4.7687, -4.7144, -4.6275, -4.8575, -4.4418, -4.8477, -4.6928, -4.6613,\n",
      "         -4.6123, -4.4095, -4.6394, -4.6503, -4.5666, -4.2483, -4.7591, -4.5641,\n",
      "         -4.3128, -4.7344, -4.4702, -4.7293, -4.6420, -4.5524, -4.7984, -4.4566,\n",
      "         -4.3165, -4.1912, -4.7218, -4.3128, -4.6138, -4.6707, -4.3803, -4.3031,\n",
      "         -4.5590, -4.7593, -4.9011, -4.7746, -4.4752, -4.3592, -4.1834, -4.3600,\n",
      "         -4.9563, -4.8512, -4.6606, -4.7998, -4.4070, -4.3761, -4.6565, -4.6701,\n",
      "         -4.5473, -4.4252, -4.6016, -4.8162, -4.7656, -4.5413, -4.5570, -4.5075,\n",
      "         -4.7498, -4.2975, -4.5521, -4.5683, -4.8781, -4.3944, -4.4867, -4.7535,\n",
      "         -4.5004]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : were\n",
      "target index is: [93] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2637, -4.4735, -4.7743, -4.8965, -3.8274, -4.5395, -4.4112, -4.2800,\n",
      "         -4.6368, -4.8793, -4.6151, -4.4544, -4.6134, -4.9261, -4.7610, -4.5368,\n",
      "         -4.4994, -4.9858, -4.5926, -4.4255, -4.8558, -4.1600, -4.7181, -4.9431,\n",
      "         -4.3430, -4.6835, -4.3974, -4.3540, -4.2874, -4.8679, -4.3978, -4.9216,\n",
      "         -4.6627, -4.6322, -4.3066, -4.8339, -4.8985, -4.5586, -5.1097, -4.7874,\n",
      "         -4.6849, -4.6939, -4.7560, -4.5947, -4.8013, -4.2537, -4.2572, -4.7273,\n",
      "         -4.4763, -4.7697, -4.8456, -4.3405, -4.7752, -4.6289, -4.6153, -4.4475,\n",
      "         -4.3993, -4.3712, -4.4431, -4.7672, -4.6362, -4.4694, -4.8497, -4.0749,\n",
      "         -4.7485, -4.6979, -4.7354, -4.6096, -4.7809, -4.5110, -4.5858, -4.6371,\n",
      "         -4.2975, -4.7985, -4.6580, -4.5183, -4.7081, -4.7037, -4.5469, -4.4399,\n",
      "         -4.6766, -4.5271, -5.0383, -4.7754, -4.2226, -4.6247, -4.4572, -4.7610,\n",
      "         -4.7328, -4.4384, -4.7621, -4.5588, -4.8060, -4.4785, -4.5092, -4.5205,\n",
      "         -4.5452]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : to\n",
      "target index is: [72] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5537, -4.5701, -4.7163, -4.4745, -4.4856, -4.7641, -4.9738, -4.2634,\n",
      "         -4.7075, -4.7027, -4.6226, -4.6487, -4.5310, -4.7215, -4.8152, -4.5639,\n",
      "         -4.7810, -4.2086, -4.6234, -4.6084, -4.3747, -4.5103, -5.0545, -4.8524,\n",
      "         -4.2957, -4.9909, -4.5467, -4.2986, -4.1972, -4.7170, -4.6398, -4.2714,\n",
      "         -5.1053, -4.7989, -4.5731, -5.1739, -4.5298, -4.7115, -4.6240, -4.7410,\n",
      "         -4.4804, -4.5388, -4.6023, -4.6099, -4.4975, -4.3315, -4.7137, -4.7474,\n",
      "         -4.7639, -4.6694, -4.3727, -4.5876, -4.6572, -4.7944, -4.8417, -4.6838,\n",
      "         -3.9757, -4.0962, -4.5051, -4.3184, -4.5470, -4.4387, -4.2796, -4.1767,\n",
      "         -4.4474, -4.5439, -4.8498, -4.9543, -4.4564, -4.4319, -4.1775, -4.2070,\n",
      "         -5.2013, -4.9834, -4.8881, -4.9017, -4.2783, -4.2763, -4.5617, -4.6803,\n",
      "         -4.4471, -4.5735, -4.5805, -4.9941, -4.7844, -4.5814, -4.5456, -4.5357,\n",
      "         -5.0503, -4.5049, -4.6418, -4.6841, -5.0925, -4.2529, -4.5301, -4.8798,\n",
      "         -4.6177]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : be\n",
      "target index is: [24] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2010, -4.8510, -4.8172, -5.0745, -4.0373, -4.8163, -4.5812, -4.2359,\n",
      "         -4.8928, -5.0809, -4.9420, -4.3215, -4.6750, -4.9117, -4.9772, -4.5769,\n",
      "         -3.9835, -5.0268, -4.5718, -5.0283, -4.3720, -4.2092, -4.6198, -4.4786,\n",
      "         -4.2692, -5.0132, -4.0624, -4.6163, -4.5931, -4.7282, -4.2027, -5.3542,\n",
      "         -4.8504, -5.1227, -4.3419, -4.7220, -4.8336, -4.4647, -5.0371, -4.9707,\n",
      "         -5.0730, -4.4388, -4.6632, -4.4896, -4.2177, -4.1091, -4.4470, -4.6887,\n",
      "         -4.5807, -4.4756, -4.4701, -4.1091, -5.2230, -4.3814, -4.7036, -4.6946,\n",
      "         -4.8222, -4.4334, -4.5693, -4.9031, -4.9624, -4.5870, -4.7050, -3.9537,\n",
      "         -4.6357, -4.7639, -4.9852, -4.4533, -4.3998, -4.5228, -4.3308, -4.7697,\n",
      "         -4.6885, -4.8289, -4.6863, -4.8606, -4.7352, -4.0715, -4.5588, -4.9976,\n",
      "         -4.1053, -4.8328, -4.6986, -4.6701, -4.3272, -4.8131, -4.3057, -4.9183,\n",
      "         -4.9981, -4.4618, -4.3156, -4.6757, -4.7715, -4.6137, -4.3523, -4.6406,\n",
      "         -4.3064]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : new\n",
      "target index is: [27] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5461, -4.4771, -4.3626, -4.7250, -4.1798, -4.7283, -4.6525, -4.3873,\n",
      "         -4.6055, -4.6481, -4.8529, -4.5209, -4.6253, -4.7284, -4.5834, -4.6456,\n",
      "         -4.5111, -4.5630, -4.4812, -4.6079, -4.7664, -4.6281, -4.5318, -4.4792,\n",
      "         -4.3937, -4.6377, -4.4620, -4.6512, -4.4787, -4.4196, -4.5051, -4.6471,\n",
      "         -4.8427, -4.7301, -4.5530, -4.7144, -4.6552, -4.6847, -4.5689, -4.7038,\n",
      "         -4.6647, -4.5453, -4.9743, -4.6338, -4.7097, -4.6127, -4.6613, -4.5614,\n",
      "         -4.5421, -4.3683, -4.3142, -4.5396, -4.6557, -4.3371, -4.7264, -4.4779,\n",
      "         -4.5425, -4.6042, -4.5217, -4.6635, -4.7281, -4.5979, -4.5667, -4.1056,\n",
      "         -4.9833, -4.4613, -4.8764, -4.4378, -4.6978, -5.0030, -4.5882, -4.6198,\n",
      "         -4.7192, -4.7470, -4.6609, -4.6951, -4.4744, -4.4428, -4.3929, -4.8287,\n",
      "         -4.4261, -4.3452, -4.6034, -4.7760, -4.6977, -4.3220, -4.5713, -4.7756,\n",
      "         -4.7747, -4.1806, -4.5913, -4.8245, -4.3779, -4.5654, -4.3777, -4.4142,\n",
      "         -4.7089]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : made\n",
      "target index is: [16] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3448, -4.6336, -4.7504, -4.8554, -4.2474, -4.6844, -4.4061, -4.5289,\n",
      "         -4.6875, -4.3982, -4.8778, -4.4702, -4.6663, -4.5424, -4.6953, -4.8188,\n",
      "         -4.4644, -4.7083, -4.5963, -4.5990, -4.3486, -4.3796, -4.6862, -4.5669,\n",
      "         -4.6476, -5.1496, -4.1498, -4.6860, -4.6094, -4.7368, -4.5297, -4.8911,\n",
      "         -4.5604, -4.9438, -4.5204, -4.9714, -4.5328, -4.3564, -4.6408, -4.4065,\n",
      "         -4.6468, -4.5349, -4.5385, -4.4206, -4.4674, -4.4687, -4.7018, -4.5304,\n",
      "         -4.5877, -4.8464, -4.3724, -4.7994, -4.8119, -4.5010, -4.6170, -4.4285,\n",
      "         -4.7846, -4.5317, -4.4001, -4.5871, -4.5582, -4.5013, -4.5855, -4.2524,\n",
      "         -4.3366, -4.8624, -4.7952, -4.3723, -4.6121, -4.3978, -4.5709, -4.6855,\n",
      "         -4.8240, -4.6907, -4.7665, -4.8724, -4.4913, -4.3868, -4.2867, -4.6035,\n",
      "         -4.4409, -4.5944, -4.7435, -4.7475, -4.7836, -4.3888, -4.7457, -4.5283,\n",
      "         -4.9549, -4.6602, -4.3390, -4.5972, -4.6635, -4.5400, -4.5325, -4.4585,\n",
      "         -4.3249]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : when\n",
      "target index is: [85] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4425, -4.5718, -4.8302, -4.7595, -4.2428, -4.6468, -4.2605, -4.3704,\n",
      "         -4.8891, -4.5527, -4.9162, -4.4742, -4.7338, -4.6041, -4.4800, -4.5228,\n",
      "         -4.2680, -4.6679, -4.7362, -4.4255, -4.4563, -4.3386, -4.6680, -4.7489,\n",
      "         -4.6235, -5.0875, -4.5306, -4.2723, -4.7668, -4.7748, -4.6968, -4.5920,\n",
      "         -4.7050, -5.0521, -4.4761, -4.7509, -4.3654, -4.5686, -4.8813, -4.3704,\n",
      "         -4.6040, -4.6771, -4.6766, -4.3800, -4.5754, -4.1819, -4.7611, -4.8899,\n",
      "         -4.7334, -4.9405, -4.5975, -4.6787, -4.5232, -3.8500, -4.3957, -4.5756,\n",
      "         -4.6042, -4.5414, -4.5825, -4.6133, -4.5874, -4.5048, -4.4308, -4.5767,\n",
      "         -4.4616, -4.4141, -4.8810, -4.1845, -4.7687, -4.5167, -4.6245, -4.9054,\n",
      "         -4.8509, -4.7749, -4.8895, -5.0029, -4.4654, -4.4316, -4.3561, -4.8746,\n",
      "         -4.4814, -4.4571, -4.6373, -4.7257, -4.9202, -4.0461, -4.9626, -4.9380,\n",
      "         -4.8259, -4.4172, -4.4229, -4.6605, -4.7451, -4.5092, -4.4977, -4.7121,\n",
      "         -4.2763]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thou\n",
      "target index is: [22] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6246, -4.6049, -4.9573, -4.6534, -4.1940, -4.7577, -4.4732, -4.7143,\n",
      "         -4.6480, -4.5493, -4.6907, -4.2375, -4.7962, -4.7003, -4.7254, -4.2366,\n",
      "         -4.7282, -4.6511, -4.8179, -4.4843, -4.7713, -4.1735, -4.7774, -4.6093,\n",
      "         -4.2003, -4.7156, -4.7674, -4.3880, -4.3077, -4.3554, -4.7289, -4.5732,\n",
      "         -4.7197, -4.8468, -4.5999, -4.4629, -4.5939, -4.8126, -4.9616, -4.3546,\n",
      "         -4.8910, -4.1847, -4.6540, -4.5508, -4.3747, -4.5075, -4.5722, -4.8016,\n",
      "         -4.3758, -5.1449, -4.7315, -4.6986, -4.6393, -4.2492, -4.6149, -4.4291,\n",
      "         -4.2723, -4.4742, -4.6334, -4.4212, -4.6664, -4.5406, -4.3456, -4.5702,\n",
      "         -4.7318, -4.4540, -4.5785, -4.4477, -4.7892, -4.2507, -4.3142, -4.6570,\n",
      "         -4.8902, -4.8866, -4.7957, -4.9179, -4.4940, -4.6110, -4.6614, -4.6570,\n",
      "         -4.6343, -4.4160, -4.5568, -4.3859, -4.7142, -4.1667, -4.7336, -4.8820,\n",
      "         -4.8341, -4.4428, -4.7858, -4.6654, -4.5770, -4.5948, -4.6414, -4.6173,\n",
      "         -4.6873]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : art\n",
      "target index is: [15] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3528, -4.4761, -4.7712, -4.9296, -4.2593, -4.7757, -4.5865, -4.3968,\n",
      "         -4.6225, -4.8057, -4.6696, -4.4594, -4.4225, -4.7553, -4.7555, -4.2573,\n",
      "         -4.4967, -4.4781, -4.2827, -4.5597, -4.5917, -4.2637, -4.8066, -4.8862,\n",
      "         -4.1700, -4.7090, -4.4262, -4.5444, -4.2018, -4.5766, -4.5416, -4.8494,\n",
      "         -4.8794, -4.6310, -4.5764, -4.9348, -4.6253, -4.6080, -4.9319, -4.9302,\n",
      "         -4.8287, -4.8595, -4.7459, -4.8012, -4.6065, -4.5057, -4.6452, -4.9679,\n",
      "         -4.6072, -4.6629, -4.4475, -4.7858, -4.4888, -4.5131, -4.7602, -4.6676,\n",
      "         -4.3805, -4.4183, -4.4793, -4.4294, -4.7025, -4.3609, -4.3855, -4.1577,\n",
      "         -4.6255, -4.4635, -4.8241, -4.8431, -4.6340, -4.4496, -4.5128, -4.5473,\n",
      "         -4.8925, -4.7113, -4.6224, -4.7895, -4.3688, -4.4404, -4.6052, -4.6510,\n",
      "         -4.4203, -4.4625, -4.9452, -4.8682, -4.4413, -4.6727, -4.5626, -4.6628,\n",
      "         -4.5185, -4.3617, -4.5204, -4.7150, -4.5943, -4.1769, -4.7022, -4.5200,\n",
      "         -4.4836]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : old,\n",
      "target index is: [8] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4288, -4.5592, -4.9770, -4.6879, -4.3350, -4.7151, -4.5118, -4.3367,\n",
      "         -4.7197, -4.5857, -4.7950, -4.3883, -4.5832, -4.9579, -5.0379, -4.9578,\n",
      "         -4.7077, -4.7374, -4.5661, -4.6757, -4.3365, -4.2943, -4.7487, -4.6150,\n",
      "         -4.3597, -5.1330, -4.3034, -4.6998, -4.6501, -4.5846, -4.6944, -4.7882,\n",
      "         -4.6823, -4.8920, -4.4858, -4.8644, -4.7486, -4.3872, -4.5937, -4.3316,\n",
      "         -4.6414, -4.5952, -4.6455, -4.5793, -4.2576, -4.3159, -4.4464, -4.3777,\n",
      "         -4.4833, -4.9143, -4.7724, -4.2663, -4.8753, -4.3867, -4.3315, -4.4089,\n",
      "         -4.5803, -4.1916, -4.2782, -4.7362, -4.7553, -4.4033, -4.4541, -4.2251,\n",
      "         -4.5079, -4.7463, -4.6817, -4.4013, -4.3705, -4.1737, -4.4000, -4.7526,\n",
      "         -4.6549, -4.8690, -4.9234, -4.9303, -4.4495, -4.3549, -4.6005, -4.8085,\n",
      "         -4.5829, -4.7680, -4.8763, -4.7385, -4.5862, -4.5645, -4.6010, -4.8538,\n",
      "         -5.0275, -4.3382, -4.7434, -4.7125, -4.6914, -4.2996, -4.6736, -4.7030,\n",
      "         -4.2889]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : And\n",
      "target index is: [6] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4872, -4.3661, -4.4998, -4.5592, -4.3644, -5.0145, -4.5055, -4.4510,\n",
      "         -4.6497, -4.8022, -4.8437, -4.3677, -4.5561, -4.6336, -4.6379, -4.7093,\n",
      "         -4.6653, -4.6240, -4.9471, -4.5667, -4.4855, -4.5124, -4.5836, -4.5961,\n",
      "         -4.2057, -4.7040, -4.6226, -4.4246, -4.3027, -4.5391, -4.7168, -4.7850,\n",
      "         -4.6482, -4.7345, -4.6184, -4.5425, -4.7880, -4.5914, -4.5539, -4.4104,\n",
      "         -4.8587, -4.3871, -4.7155, -4.4268, -4.4827, -4.3877, -4.4407, -4.6163,\n",
      "         -4.5287, -4.7876, -4.5332, -4.4622, -4.8961, -4.3409, -4.5880, -4.5348,\n",
      "         -4.4391, -4.5610, -4.5682, -4.8053, -4.6852, -4.4976, -4.5333, -4.4151,\n",
      "         -4.7060, -4.6637, -4.7559, -4.2468, -4.7044, -4.6176, -4.6122, -4.6984,\n",
      "         -4.5412, -4.9677, -4.7852, -4.7932, -4.5713, -4.2957, -4.6047, -4.7654,\n",
      "         -4.2746, -4.4589, -4.5942, -4.7151, -4.5516, -4.3095, -4.5990, -4.7678,\n",
      "         -4.8727, -4.5095, -4.7811, -4.7722, -4.2866, -4.5543, -4.5410, -4.5416,\n",
      "         -4.5211]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : see\n",
      "target index is: [67] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4244, -4.5588, -4.7722, -4.9992, -4.4478, -4.7339, -4.5504, -4.4574,\n",
      "         -4.7909, -4.6244, -5.0313, -4.8834, -4.6635, -4.7192, -4.6926, -4.7349,\n",
      "         -4.5415, -4.5443, -4.7219, -4.3723, -4.7556, -4.7284, -4.9224, -4.7269,\n",
      "         -4.6168, -4.9256, -4.5821, -4.3244, -4.3543, -4.7736, -4.5122, -4.7194,\n",
      "         -5.0380, -4.9355, -4.2859, -4.5916, -4.2463, -4.5503, -4.7459, -4.7657,\n",
      "         -4.7744, -4.6112, -4.5713, -4.6262, -4.4738, -4.1182, -4.8069, -4.7205,\n",
      "         -4.7963, -4.8496, -4.2620, -4.6034, -4.5896, -4.3725, -4.7373, -4.7615,\n",
      "         -4.4168, -4.3026, -4.6468, -4.4414, -4.7546, -4.5722, -4.4567, -4.6194,\n",
      "         -4.5593, -4.4618, -5.0762, -4.4491, -4.5309, -4.6832, -4.2601, -4.1688,\n",
      "         -5.0436, -4.9147, -4.7965, -4.8827, -4.3228, -4.1232, -4.3349, -4.7536,\n",
      "         -4.2643, -4.7132, -4.3419, -4.9413, -4.7630, -4.3108, -4.4814, -4.5246,\n",
      "         -4.7254, -4.3334, -4.2312, -4.5466, -4.9428, -4.3829, -4.4460, -4.5543,\n",
      "         -4.1553]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5887, -4.4072, -4.9622, -4.5640, -4.1764, -4.6495, -4.6323, -4.2226,\n",
      "         -5.1294, -4.3790, -4.7447, -4.2047, -4.3197, -4.5853, -4.7752, -4.8596,\n",
      "         -4.3727, -4.5322, -4.3840, -4.5738, -4.6450, -4.4017, -4.3420, -4.7368,\n",
      "         -4.3693, -5.1606, -4.2807, -4.9266, -4.5846, -4.4677, -4.6374, -4.5854,\n",
      "         -4.8370, -4.6501, -4.5979, -5.1128, -4.6011, -4.5346, -4.6023, -4.6899,\n",
      "         -4.4641, -4.7987, -4.8639, -4.6385, -4.4094, -4.1585, -4.5846, -5.0528,\n",
      "         -5.0301, -4.4651, -4.8365, -4.4143, -4.4212, -4.3272, -4.4357, -4.5060,\n",
      "         -4.6436, -4.2494, -4.3200, -4.5259, -4.7371, -4.7287, -4.4255, -4.0384,\n",
      "         -4.4561, -4.6944, -4.7012, -4.4244, -4.8202, -4.5182, -4.6693, -4.6829,\n",
      "         -4.8751, -4.5557, -4.8434, -4.8518, -4.3589, -4.5351, -4.3186, -4.9082,\n",
      "         -4.4838, -4.4766, -4.7698, -4.8317, -4.8293, -4.5752, -4.7748, -4.7373,\n",
      "         -4.9804, -4.4602, -4.6424, -4.7941, -4.8804, -4.3491, -4.2796, -4.9112,\n",
      "         -4.4575]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : blood\n",
      "target index is: [39] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5529, -4.4920, -4.7878, -4.5086, -4.3767, -4.7745, -4.3354, -4.3593,\n",
      "         -4.8497, -4.7650, -4.9593, -4.3628, -4.6842, -4.4651, -4.5270, -4.8811,\n",
      "         -4.6695, -4.8078, -4.3470, -4.4230, -4.7907, -4.8201, -4.5986, -4.4562,\n",
      "         -4.6372, -5.1425, -4.8001, -4.5157, -4.1522, -4.7221, -4.4726, -4.5479,\n",
      "         -4.7262, -4.7087, -4.7089, -5.3133, -4.3780, -4.7032, -4.4581, -4.2764,\n",
      "         -4.4834, -4.4339, -4.7042, -4.1892, -4.7782, -4.1675, -5.0391, -4.6570,\n",
      "         -4.6654, -4.8613, -4.7867, -4.7466, -4.7069, -4.3046, -4.4005, -4.5143,\n",
      "         -4.2746, -4.0690, -4.7284, -4.6454, -4.6503, -4.2349, -4.5890, -4.3651,\n",
      "         -4.5678, -4.5964, -4.6810, -4.2431, -4.6791, -4.1244, -4.5026, -4.6342,\n",
      "         -5.0403, -5.0387, -4.8852, -5.2995, -5.0517, -3.9534, -4.2310, -4.5643,\n",
      "         -5.0364, -4.6182, -5.0031, -5.0448, -5.2702, -4.0434, -4.4560, -4.4985,\n",
      "         -5.2332, -4.3819, -4.8228, -4.5946, -4.7635, -4.5180, -4.4282, -4.5333,\n",
      "         -4.3452]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : warm\n",
      "target index is: [2] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5398, -4.3882, -4.6755, -4.8269, -4.5928, -4.6449, -4.4105, -4.4800,\n",
      "         -4.7747, -5.0666, -4.9512, -4.7877, -4.7270, -4.7960, -4.6070, -4.5063,\n",
      "         -4.7126, -4.9796, -4.5446, -4.1917, -4.8472, -4.2863, -5.0849, -4.4850,\n",
      "         -4.1323, -4.7279, -4.4014, -4.2819, -4.3502, -4.7259, -4.7328, -4.7729,\n",
      "         -4.9322, -4.8641, -4.5982, -4.4237, -4.8114, -4.9444, -4.8876, -4.7313,\n",
      "         -4.8385, -4.5841, -4.6721, -4.5503, -4.6767, -4.3223, -4.8550, -4.8244,\n",
      "         -4.2471, -4.8642, -4.4676, -4.4044, -4.4109, -4.1639, -4.6965, -4.1925,\n",
      "         -4.4904, -4.1291, -4.6904, -4.6867, -4.7823, -4.7401, -4.3768, -4.4114,\n",
      "         -4.8043, -4.4589, -5.1401, -4.5479, -4.6920, -4.3280, -4.1222, -4.7131,\n",
      "         -4.3899, -4.5023, -4.5771, -4.7971, -4.4227, -4.3263, -4.5595, -4.8085,\n",
      "         -4.4305, -4.8385, -4.7416, -4.5620, -4.3502, -4.5431, -4.7792, -5.0703,\n",
      "         -4.5671, -4.1266, -4.6141, -4.5570, -4.7337, -4.7658, -4.3546, -4.7012,\n",
      "         -4.2585]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : when\n",
      "target index is: [85] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4669, -4.3380, -4.7580, -4.9812, -4.2609, -4.7535, -4.3342, -4.4263,\n",
      "         -4.7194, -4.3738, -4.6491, -4.6807, -4.8394, -4.6198, -4.4452, -4.5014,\n",
      "         -4.3059, -4.6409, -4.8136, -4.5626, -4.4823, -4.4450, -4.6075, -4.6840,\n",
      "         -4.5295, -5.0643, -4.4179, -4.3720, -4.8375, -4.6183, -4.6615, -4.5768,\n",
      "         -4.7336, -4.9622, -4.5978, -4.6965, -4.5247, -4.3964, -4.9176, -4.5373,\n",
      "         -4.5630, -4.9237, -4.6596, -4.3617, -4.3909, -4.3912, -4.6890, -4.7948,\n",
      "         -4.5590, -4.6880, -4.4465, -4.8496, -4.6815, -4.2740, -4.6352, -4.6309,\n",
      "         -4.6501, -4.7291, -4.5159, -4.5006, -4.8054, -4.4327, -4.5395, -4.1212,\n",
      "         -4.5234, -4.4240, -4.7380, -4.3291, -4.5757, -4.6373, -4.7776, -5.0893,\n",
      "         -4.9917, -4.2115, -4.7265, -4.9553, -4.4834, -4.7379, -4.5533, -4.6896,\n",
      "         -4.3139, -4.3396, -4.8793, -4.5684, -4.9132, -4.1809, -5.1019, -4.5730,\n",
      "         -4.6162, -4.2275, -4.3011, -4.7246, -4.7775, -4.2336, -4.5252, -4.5742,\n",
      "         -4.6781]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thou\n",
      "target index is: [22] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6255, -4.6064, -4.9516, -4.6540, -4.1951, -4.7581, -4.4682, -4.7148,\n",
      "         -4.6427, -4.5500, -4.6907, -4.2379, -4.7972, -4.7005, -4.7258, -4.2188,\n",
      "         -4.7284, -4.6518, -4.8187, -4.4858, -4.7721, -4.1739, -4.7700, -4.6100,\n",
      "         -4.2012, -4.7161, -4.7689, -4.3891, -4.3087, -4.3559, -4.7297, -4.5742,\n",
      "         -4.7205, -4.8473, -4.6009, -4.4632, -4.5947, -4.8135, -4.9629, -4.3506,\n",
      "         -4.8919, -4.1845, -4.6547, -4.5515, -4.3759, -4.5086, -4.5735, -4.8024,\n",
      "         -4.3767, -5.1457, -4.7325, -4.6997, -4.6404, -4.2504, -4.6164, -4.4304,\n",
      "         -4.2726, -4.4758, -4.6344, -4.4220, -4.6676, -4.5415, -4.3463, -4.5711,\n",
      "         -4.7321, -4.4540, -4.5788, -4.4428, -4.7905, -4.2517, -4.3151, -4.6580,\n",
      "         -4.8909, -4.8879, -4.7964, -4.9191, -4.4948, -4.6121, -4.6578, -4.6574,\n",
      "         -4.6350, -4.4169, -4.5579, -4.3869, -4.7151, -4.1569, -4.7345, -4.8830,\n",
      "         -4.8359, -4.4437, -4.7874, -4.6660, -4.5778, -4.5962, -4.6424, -4.6177,\n",
      "         -4.6887]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : feel'st\n",
      "target index is: [35] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4753, -4.2225, -4.7301, -4.8613, -4.1390, -4.7349, -4.7187, -4.2032,\n",
      "         -4.7778, -4.4886, -4.7135, -4.6416, -4.7656, -4.8308, -4.6877, -4.5609,\n",
      "         -4.6181, -4.3325, -4.6173, -4.4941, -4.5788, -4.5088, -4.4945, -4.8768,\n",
      "         -4.5435, -4.7953, -4.4300, -4.5308, -4.5615, -4.5183, -4.4865, -4.6584,\n",
      "         -4.8653, -4.6531, -4.3064, -4.9228, -4.5162, -4.8156, -4.7602, -4.7771,\n",
      "         -4.5880, -4.8626, -4.5758, -4.6833, -4.4215, -4.4140, -4.4760, -4.6222,\n",
      "         -4.7126, -4.5622, -4.5888, -4.7022, -4.6005, -4.6230, -4.6819, -4.6245,\n",
      "         -4.5760, -4.3494, -4.3990, -4.5187, -4.9254, -4.5945, -4.5346, -4.1992,\n",
      "         -4.5455, -4.5054, -4.5207, -4.5824, -4.5078, -4.6751, -4.6731, -4.5673,\n",
      "         -4.8582, -4.9179, -4.7373, -4.7228, -4.3257, -4.4989, -4.4181, -4.7453,\n",
      "         -4.4738, -4.5081, -4.7228, -4.9047, -4.7592, -4.4157, -4.3913, -4.5629,\n",
      "         -4.5805, -4.1263, -4.4171, -4.5651, -4.8810, -4.3997, -4.5567, -4.6457,\n",
      "         -4.5172]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : it\n",
      "target index is: [88] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5466, -4.4010, -4.7832, -4.7140, -4.1253, -4.8802, -4.5732, -4.2271,\n",
      "         -4.6338, -4.6324, -4.6626, -4.3402, -4.4640, -4.8295, -4.6887, -4.6228,\n",
      "         -4.5440, -5.0273, -4.5435, -4.6516, -4.6830, -4.3811, -4.9779, -4.6391,\n",
      "         -4.1446, -4.8310, -4.1471, -4.6162, -4.1109, -4.6877, -4.6467, -5.2913,\n",
      "         -5.0672, -4.7641, -4.9073, -5.1112, -4.5056, -4.7103, -4.7274, -4.7395,\n",
      "         -4.9476, -4.4393, -4.6286, -4.6295, -4.4771, -4.3147, -4.6766, -4.8573,\n",
      "         -4.4650, -4.7582, -4.7095, -4.1063, -4.8922, -4.3600, -4.8200, -4.4426,\n",
      "         -4.5390, -4.1123, -4.6810, -4.6780, -4.6486, -4.5867, -4.3060, -4.1749,\n",
      "         -4.7335, -4.8502, -4.7542, -4.6689, -4.5382, -4.2393, -4.1581, -4.3578,\n",
      "         -4.8733, -4.7447, -4.7129, -4.7173, -4.7831, -3.9749, -4.5580, -4.7640,\n",
      "         -4.5151, -4.5726, -4.8681, -4.8166, -4.5058, -4.7087, -4.3759, -4.6207,\n",
      "         -4.7928, -4.6308, -4.8599, -4.7668, -4.7457, -4.3038, -4.5763, -4.6508,\n",
      "         -4.2228]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : cold.\n",
      "target index is: [79] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3496, -4.1263, -4.7900, -4.7957, -4.1173, -5.0193, -4.4794, -4.4984,\n",
      "         -4.8333, -4.4920, -4.8036, -4.5610, -4.6886, -4.7623, -5.0661, -4.7171,\n",
      "         -4.6188, -4.1577, -4.8442, -4.4157, -4.7335, -4.3612, -4.6304, -4.8518,\n",
      "         -4.3343, -4.7583, -4.4723, -4.2626, -4.2451, -4.4627, -4.3712, -4.5880,\n",
      "         -4.6820, -4.7524, -4.5306, -4.5090, -4.6838, -4.7464, -4.7262, -4.6922,\n",
      "         -4.6808, -4.5242, -4.5278, -4.4034, -4.4314, -4.3071, -4.4562, -4.7294,\n",
      "         -4.7469, -5.0615, -4.5764, -4.6046, -4.6612, -4.5615, -4.3820, -4.7832,\n",
      "         -4.4315, -4.4230, -4.3279, -4.6753, -4.8609, -4.4208, -4.5989, -4.5119,\n",
      "         -4.5463, -4.9842, -4.5825, -4.2628, -4.5336, -4.4191, -4.6835, -4.7016,\n",
      "         -4.9141, -5.0192, -4.9202, -4.8124, -4.4993, -4.5899, -4.4352, -4.7465,\n",
      "         -4.2445, -4.4997, -4.6325, -4.6686, -4.8813, -4.2701, -4.7984, -4.5706,\n",
      "         -4.7968, -4.4706, -4.6058, -4.5416, -4.7498, -4.5291, -4.4359, -4.6563,\n",
      "         -4.6144]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : winters\n",
      "target index is: [3] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2848, -4.6752, -4.3737, -4.6918, -4.1894, -4.6017, -4.4991, -4.2547,\n",
      "         -4.7507, -4.9123, -4.7977, -4.7940, -4.5311, -4.2506, -4.5787, -4.3879,\n",
      "         -4.1243, -4.6973, -4.6367, -4.8088, -4.8168, -4.6408, -4.5974, -4.6001,\n",
      "         -4.3718, -4.9012, -4.4669, -4.4854, -4.4008, -4.5748, -4.2699, -5.0565,\n",
      "         -4.8982, -4.6630, -4.9486, -4.8992, -4.5783, -4.7025, -5.0237, -4.6913,\n",
      "         -4.9605, -4.3871, -4.8645, -4.3937, -5.0606, -4.3821, -5.1423, -5.2084,\n",
      "         -4.8937, -4.2376, -4.6447, -4.3871, -4.8215, -4.1710, -4.9593, -4.1489,\n",
      "         -4.2942, -4.1252, -4.8715, -4.3920, -4.2974, -4.6525, -4.4698, -4.1154,\n",
      "         -4.5706, -3.9861, -5.3835, -4.5242, -4.8618, -4.6430, -4.6040, -4.3142,\n",
      "         -4.9446, -4.8487, -4.6185, -5.1866, -4.8277, -4.1571, -4.3987, -4.7938,\n",
      "         -4.3032, -4.5751, -4.6863, -5.0480, -4.7583, -4.3639, -4.6999, -4.6547,\n",
      "         -5.1124, -4.3939, -4.3713, -4.6749, -4.6269, -4.7028, -4.4771, -4.7921,\n",
      "         -4.3942]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : shall\n",
      "target index is: [10] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4836, -4.3637, -5.1129, -4.8428, -4.2663, -4.7429, -4.3756, -4.7052,\n",
      "         -4.7574, -4.4432, -4.7439, -4.4197, -4.8019, -4.6768, -5.0381, -4.5013,\n",
      "         -4.7556, -4.5650, -4.6890, -4.4757, -4.5262, -4.0062, -4.5931, -4.5348,\n",
      "         -4.1724, -4.7834, -4.6069, -4.6112, -4.4439, -4.6041, -4.8829, -4.6759,\n",
      "         -4.5957, -4.8480, -4.7023, -4.4272, -4.9380, -4.4875, -5.0137, -4.3837,\n",
      "         -4.9386, -4.7297, -4.6867, -4.7412, -4.3878, -4.4895, -4.6263, -4.6171,\n",
      "         -4.4465, -5.0681, -4.4710, -4.7748, -4.5726, -4.3256, -4.5011, -4.5322,\n",
      "         -4.6775, -4.5149, -4.2155, -4.5755, -4.7905, -4.3794, -4.2620, -4.1696,\n",
      "         -4.4490, -4.7495, -4.6549, -4.5774, -4.6719, -4.1883, -4.4087, -4.7630,\n",
      "         -4.5410, -4.6488, -4.9257, -4.6972, -4.0581, -4.7796, -4.6814, -4.6930,\n",
      "         -4.3588, -4.5345, -4.9396, -4.6435, -4.5813, -4.4184, -4.8514, -4.9767,\n",
      "         -4.7854, -4.3191, -4.6468, -4.9258, -4.6112, -4.2407, -4.6409, -4.7744,\n",
      "         -4.3785]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : besiege\n",
      "target index is: [75] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3712, -4.5359, -4.3916, -4.7736, -4.1219, -4.7818, -4.5331, -4.2635,\n",
      "         -4.6934, -4.7182, -4.9505, -4.6566, -4.6602, -4.5609, -5.0289, -4.6905,\n",
      "         -4.5723, -4.4342, -4.8283, -4.6137, -4.5677, -4.8864, -4.5256, -4.5599,\n",
      "         -4.3796, -4.6980, -4.6767, -4.6003, -4.3041, -4.3745, -4.4978, -4.5998,\n",
      "         -4.7383, -4.7299, -4.8557, -4.7909, -4.6377, -4.6688, -4.6800, -4.5026,\n",
      "         -4.4619, -4.6840, -4.7722, -4.1663, -4.4938, -4.4849, -4.3498, -4.4054,\n",
      "         -4.5283, -4.6079, -4.5560, -4.3390, -4.7566, -4.3928, -4.7278, -4.5646,\n",
      "         -4.5378, -4.4325, -4.4678, -4.6995, -5.0640, -4.4593, -4.6151, -3.8086,\n",
      "         -4.6827, -4.4733, -4.8232, -4.6557, -4.4957, -4.7953, -4.5858, -4.5926,\n",
      "         -4.7923, -4.9297, -4.7639, -4.7375, -4.7186, -4.2287, -4.4855, -4.8881,\n",
      "         -4.6796, -4.5213, -4.6296, -4.9157, -4.7247, -4.2779, -4.3606, -4.7906,\n",
      "         -5.3052, -4.1939, -4.6812, -4.6730, -4.4887, -4.6081, -4.3225, -4.5893,\n",
      "         -4.8389]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1653, -4.4953, -4.7511, -4.9607, -3.9909, -4.6797, -4.8145, -4.4207,\n",
      "         -5.2612, -4.3436, -4.8767, -4.1718, -4.8163, -4.4196, -4.7313, -5.0507,\n",
      "         -4.9199, -4.6436, -4.5541, -4.4550, -4.5007, -4.5648, -4.7155, -4.5002,\n",
      "         -4.8749, -4.8480, -4.0862, -4.6175, -4.5589, -4.5791, -4.5936, -4.9076,\n",
      "         -4.9143, -4.6362, -4.5420, -5.2095, -4.5727, -4.9945, -4.7850, -4.6521,\n",
      "         -4.8804, -4.9722, -4.7224, -4.5786, -4.6523, -4.3338, -4.8915, -4.8433,\n",
      "         -4.8251, -4.6795, -4.3577, -5.0505, -4.3043, -4.4451, -5.0691, -4.2347,\n",
      "         -4.8260, -4.4386, -4.4386, -4.2272, -4.2995, -4.3235, -4.6530, -3.9884,\n",
      "         -4.3755, -4.7048, -5.0409, -4.6621, -4.6924, -4.7427, -4.3406, -4.8421,\n",
      "         -5.2166, -4.6197, -4.5093, -4.9433, -4.3034, -4.3096, -4.2277, -4.5551,\n",
      "         -4.5203, -4.2877, -4.9536, -4.9824, -4.6711, -4.3900, -4.4512, -4.5555,\n",
      "         -4.8290, -4.5968, -4.0410, -4.4330, -4.5905, -4.4843, -4.1549, -4.6467,\n",
      "         -4.6024]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : brow,\n",
      "target index is: [13] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4318, -4.3180, -4.5877, -4.6504, -4.2943, -4.8811, -4.6235, -4.4275,\n",
      "         -4.7386, -4.7824, -4.8319, -4.4590, -4.8151, -4.4037, -4.7581, -4.8934,\n",
      "         -4.6962, -4.7428, -4.4929, -4.4838, -4.8071, -4.9156, -4.6390, -4.3305,\n",
      "         -4.6145, -4.8217, -4.7452, -4.2766, -4.0937, -4.3819, -4.2456, -4.7460,\n",
      "         -4.8743, -4.6070, -4.9412, -5.0304, -4.5450, -4.9045, -4.3425, -4.3799,\n",
      "         -4.7181, -4.6070, -4.4830, -4.1548, -4.5317, -4.1581, -4.7565, -4.8247,\n",
      "         -4.5607, -4.7979, -4.8717, -4.4783, -4.8756, -4.1722, -4.6243, -4.4323,\n",
      "         -4.4089, -4.0170, -4.7518, -4.6227, -4.8923, -4.4508, -4.5821, -4.1519,\n",
      "         -4.7816, -4.6000, -5.0629, -4.5592, -4.5885, -4.4367, -4.4032, -4.5772,\n",
      "         -4.8520, -4.9066, -4.8224, -5.0509, -5.0380, -3.8460, -4.5222, -4.9838,\n",
      "         -4.9619, -4.5465, -4.7305, -5.0129, -5.0357, -4.3599, -4.3760, -4.5330,\n",
      "         -4.9366, -4.0303, -4.8246, -4.6048, -4.6577, -4.5760, -4.3263, -4.8542,\n",
      "         -4.3356]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : And\n",
      "target index is: [6] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3842, -4.3071, -4.6487, -4.8131, -4.2006, -4.8299, -4.7206, -4.5394,\n",
      "         -4.8410, -4.5898, -4.4816, -4.3465, -4.8670, -4.8802, -4.3686, -4.8891,\n",
      "         -4.8811, -5.0052, -4.5280, -4.3774, -4.4294, -4.4105, -4.6564, -4.6176,\n",
      "         -4.6508, -4.7111, -4.2818, -4.4334, -4.3189, -4.9684, -4.5420, -5.2365,\n",
      "         -4.7627, -4.6883, -4.4730, -4.8388, -4.6462, -4.9106, -4.7442, -4.6374,\n",
      "         -4.8327, -4.9819, -4.7319, -4.6962, -4.6811, -4.4946, -4.5378, -4.5982,\n",
      "         -4.5052, -4.9964, -4.5263, -4.6780, -4.3763, -4.7252, -5.1910, -4.5858,\n",
      "         -4.5912, -4.4535, -4.4545, -4.6213, -4.6165, -4.4982, -4.9122, -4.2546,\n",
      "         -4.9782, -4.6701, -4.9532, -4.6297, -4.6602, -4.6766, -4.1013, -4.8668,\n",
      "         -5.0487, -4.5114, -4.2835, -4.8098, -4.6376, -4.3624, -4.5909, -4.2187,\n",
      "         -4.5423, -4.0298, -4.8787, -4.6592, -4.3773, -4.4043, -4.5225, -4.5511,\n",
      "         -4.7819, -4.3247, -4.5396, -4.5401, -4.2708, -4.1190, -4.1314, -4.4000,\n",
      "         -4.5031]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : dig\n",
      "target index is: [42] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4141, -4.6396, -4.6923, -4.9446, -4.2538, -4.8274, -4.6680, -4.5420,\n",
      "         -4.5238, -4.6791, -4.8387, -4.9887, -4.7146, -4.8212, -4.5565, -4.7208,\n",
      "         -4.6857, -4.7336, -4.7052, -4.4041, -4.8309, -4.4921, -5.0182, -4.6991,\n",
      "         -4.4110, -4.9657, -4.5027, -4.5022, -4.1313, -4.7877, -4.5224, -4.8282,\n",
      "         -4.8842, -4.8309, -4.2468, -4.5084, -4.3693, -4.6591, -4.8423, -4.7399,\n",
      "         -4.8150, -4.4331, -4.7368, -4.6490, -4.6206, -4.2849, -4.9126, -4.4976,\n",
      "         -4.6519, -4.8572, -4.3841, -4.7639, -4.6020, -4.5276, -4.7380, -4.5830,\n",
      "         -4.2396, -4.2099, -4.6330, -4.4164, -4.5718, -4.6586, -4.6804, -4.6390,\n",
      "         -4.6575, -4.3740, -4.9640, -4.5806, -4.6197, -4.7750, -4.2385, -4.2128,\n",
      "         -5.0127, -4.8286, -4.7536, -4.7833, -4.5563, -4.1932, -4.5284, -4.4797,\n",
      "         -4.4060, -4.4749, -4.4758, -4.9537, -4.5114, -4.3364, -4.3168, -4.4435,\n",
      "         -4.6960, -4.2187, -4.4245, -4.4433, -4.7570, -4.4232, -4.5877, -4.4186,\n",
      "         -4.2827]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : deep\n",
      "target index is: [76] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5635, -4.9078, -4.7062, -4.6277, -4.2631, -4.8155, -4.3633, -4.1796,\n",
      "         -4.7134, -4.9980, -4.8004, -4.4422, -4.5773, -4.8881, -4.7807, -4.3053,\n",
      "         -4.2430, -4.8073, -4.4466, -4.9100, -4.4912, -4.2423, -4.5624, -4.7290,\n",
      "         -4.1340, -4.8997, -4.4462, -4.6963, -4.6920, -4.4671, -4.7385, -4.6634,\n",
      "         -4.8942, -4.9378, -4.4197, -4.6232, -4.9803, -4.5239, -5.0086, -4.7237,\n",
      "         -4.8427, -4.6742, -4.8790, -4.5402, -4.3899, -4.3412, -4.5056, -4.6188,\n",
      "         -4.4773, -4.3141, -4.4989, -4.1766, -4.7315, -4.4320, -4.5638, -4.4709,\n",
      "         -4.5378, -4.5515, -4.5101, -4.6724, -5.0282, -4.6775, -4.5584, -3.9454,\n",
      "         -4.6854, -4.4664, -4.8971, -4.4194, -4.6926, -4.5877, -4.4025, -4.7347,\n",
      "         -4.5957, -4.5099, -4.6178, -4.9082, -4.4917, -4.5906, -4.7034, -4.7160,\n",
      "         -4.1184, -4.7961, -4.7012, -4.6390, -4.3467, -4.5271, -4.6682, -5.0703,\n",
      "         -4.9454, -4.3698, -4.4835, -4.6966, -4.6887, -4.4446, -4.4869, -4.4550,\n",
      "         -4.5687]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : trenches\n",
      "target index is: [54] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4128, -4.5434, -4.9395, -5.3989, -4.1004, -4.6675, -4.4207, -4.4424,\n",
      "         -4.8156, -4.4168, -4.9030, -4.4306, -4.8016, -4.7672, -4.9676, -4.7110,\n",
      "         -4.4816, -4.6458, -4.7022, -4.6255, -4.5428, -4.2778, -4.7730, -4.5667,\n",
      "         -4.4315, -4.8840, -4.1860, -4.5650, -4.5723, -4.7045, -4.4960, -5.0621,\n",
      "         -4.9193, -4.9463, -4.5017, -4.5735, -4.3578, -4.7277, -5.0272, -4.6957,\n",
      "         -4.8530, -4.8027, -4.5695, -4.5424, -4.4021, -4.4940, -4.5228, -4.7436,\n",
      "         -4.4217, -5.1619, -4.1575, -4.7862, -4.5979, -4.3980, -4.4930, -4.6695,\n",
      "         -4.9329, -4.6023, -4.2838, -4.4744, -4.6785, -4.3594, -4.5064, -4.1656,\n",
      "         -4.5137, -4.6308, -4.6894, -4.5225, -4.4584, -4.3607, -4.6450, -4.7592,\n",
      "         -5.2097, -4.5632, -4.8661, -5.0480, -4.2421, -4.2518, -4.2272, -4.5435,\n",
      "         -4.5326, -4.5585, -4.6424, -4.5413, -4.6710, -4.3898, -4.5557, -4.7135,\n",
      "         -4.6821, -4.6693, -4.0571, -4.5794, -4.7274, -4.2858, -4.6022, -4.6439,\n",
      "         -4.4911]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : in\n",
      "target index is: [95] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7183, -4.4323, -4.5670, -4.5242, -4.1103, -4.6681, -4.6662, -4.1872,\n",
      "         -4.7408, -4.5670, -4.6502, -4.2528, -4.4563, -4.6683, -4.8360, -4.6702,\n",
      "         -4.5769, -4.7366, -4.2197, -4.5373, -4.5216, -4.5796, -4.5412, -4.6497,\n",
      "         -4.2323, -4.9338, -4.4182, -4.8151, -4.4099, -4.4564, -4.7190, -4.7176,\n",
      "         -4.9246, -4.7186, -4.5920, -5.0927, -4.5069, -4.6748, -4.2949, -4.6629,\n",
      "         -4.5081, -4.6108, -4.9579, -4.7144, -4.5173, -4.4108, -4.4750, -4.9153,\n",
      "         -4.8321, -4.5096, -4.6321, -4.1554, -4.6261, -4.2834, -4.7344, -4.4410,\n",
      "         -4.5422, -4.2270, -4.3407, -4.7163, -4.8238, -4.6745, -4.4822, -4.1175,\n",
      "         -4.8021, -4.4605, -4.7186, -4.6156, -4.7901, -4.8532, -4.4723, -4.5577,\n",
      "         -5.0091, -4.8242, -4.8444, -4.8244, -4.6682, -4.3503, -4.3540, -5.0050,\n",
      "         -4.7131, -4.2559, -4.6942, -4.7137, -4.7400, -4.4364, -4.6555, -4.6924,\n",
      "         -4.8446, -4.2439, -4.9024, -4.7676, -4.6044, -4.3596, -4.5015, -4.6242,\n",
      "         -4.5848]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1744, -4.5203, -5.1070, -4.8455, -4.2826, -4.7153, -4.7254, -4.3532,\n",
      "         -5.2765, -4.2320, -4.9053, -4.2257, -4.4633, -4.3050, -5.0153, -5.1304,\n",
      "         -4.6584, -4.5990, -4.6401, -4.4364, -4.5416, -4.5531, -4.5258, -4.6062,\n",
      "         -4.5388, -5.0561, -4.3033, -4.5265, -4.5931, -4.7377, -4.6848, -4.5131,\n",
      "         -4.9971, -4.8476, -4.8408, -5.4126, -4.7206, -4.5555, -4.6381, -4.2970,\n",
      "         -4.5616, -4.6828, -4.3803, -4.4684, -4.2081, -4.1481, -4.7258, -4.7163,\n",
      "         -4.9679, -4.7648, -4.6011, -4.6849, -4.4062, -4.4109, -4.5233, -4.5687,\n",
      "         -4.5639, -4.2904, -4.4392, -4.5825, -4.6898, -4.4128, -4.3295, -4.2806,\n",
      "         -4.0556, -4.8352, -4.8127, -4.5326, -4.5928, -4.2433, -4.3673, -4.7042,\n",
      "         -4.7866, -4.7264, -4.8053, -4.7196, -4.2796, -4.2090, -4.2448, -4.6957,\n",
      "         -4.5811, -4.7736, -4.8451, -5.0465, -5.0846, -4.4249, -4.7006, -4.5203,\n",
      "         -5.1529, -4.6294, -4.4212, -4.7958, -4.9377, -4.4221, -4.2673, -4.8699,\n",
      "         -4.4896]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty's\n",
      "target index is: [80] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2938, -4.4785, -4.7001, -4.5446, -4.2284, -4.9388, -4.4845, -4.2873,\n",
      "         -4.4247, -5.1504, -4.9626, -4.0730, -4.6298, -4.7412, -4.6113, -4.7477,\n",
      "         -4.9030, -5.1766, -4.5302, -4.4253, -4.9510, -4.7525, -4.5450, -4.5065,\n",
      "         -4.2136, -4.6569, -4.6712, -4.4617, -3.8685, -4.5937, -4.8132, -4.5922,\n",
      "         -4.7206, -4.6214, -4.6765, -5.1455, -4.8645, -4.6278, -4.6701, -4.5362,\n",
      "         -4.6928, -4.2657, -4.9864, -4.0807, -4.4990, -4.1087, -4.4779, -4.4756,\n",
      "         -4.5119, -4.8921, -4.7760, -4.4614, -4.7570, -4.3956, -4.6246, -4.4135,\n",
      "         -4.3316, -4.2557, -4.7476, -5.0401, -4.8490, -4.1903, -4.5027, -4.1332,\n",
      "         -5.0368, -4.8207, -5.0750, -4.6832, -4.8150, -4.6198, -4.3267, -4.7867,\n",
      "         -4.4989, -4.8635, -4.8013, -4.9196, -5.1384, -4.1024, -4.3504, -4.4563,\n",
      "         -4.7516, -4.3130, -5.2075, -4.7426, -4.8753, -4.0935, -4.6136, -5.0126,\n",
      "         -5.0582, -4.6006, -5.1711, -4.4921, -4.5678, -4.5179, -4.2805, -4.3547,\n",
      "         -4.5815]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : field,\n",
      "target index is: [77] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-3.9734, -4.1728, -4.7916, -5.6681, -4.1003, -5.1099, -4.5345, -4.5011,\n",
      "         -4.8698, -4.8482, -4.6856, -5.1658, -5.0406, -4.7885, -4.6949, -4.8345,\n",
      "         -4.9336, -4.7186, -4.8659, -4.5055, -4.7426, -4.3862, -4.9333, -4.6751,\n",
      "         -4.5512, -4.8619, -4.3235, -4.0863, -4.1777, -4.9316, -4.2868, -4.7734,\n",
      "         -4.8087, -4.7706, -4.5087, -4.9588, -4.7020, -4.9765, -4.9767, -4.8808,\n",
      "         -4.5765, -5.1679, -4.8139, -4.6708, -4.5094, -4.1121, -5.1205, -4.4386,\n",
      "         -4.6546, -5.0000, -3.8334, -5.2574, -4.3313, -4.8216, -4.8270, -4.4914,\n",
      "         -4.5831, -4.3235, -4.4744, -4.2883, -4.7598, -4.3041, -4.4554, -3.8390,\n",
      "         -4.4868, -4.5259, -4.9372, -4.7688, -4.4389, -4.4597, -4.6204, -4.5376,\n",
      "         -5.3886, -4.6240, -4.8603, -4.8762, -4.2863, -4.2014, -4.2625, -4.5155,\n",
      "         -4.4855, -4.3952, -5.2011, -5.2230, -4.5119, -4.4167, -4.3016, -4.8709,\n",
      "         -4.6054, -4.2811, -4.0616, -4.3612, -4.9455, -4.1665, -4.4992, -4.8602,\n",
      "         -4.4886]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Thy\n",
      "target index is: [73] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2984, -4.6036, -4.7327, -4.6706, -4.2255, -4.9302, -4.6317, -4.1456,\n",
      "         -4.7070, -4.8945, -4.6395, -4.2239, -4.2996, -4.7098, -4.6401, -4.3812,\n",
      "         -4.6797, -4.8220, -4.1459, -4.7069, -4.5391, -4.2857, -4.7685, -4.8256,\n",
      "         -4.0936, -4.8550, -4.5749, -4.7274, -4.0826, -4.4279, -4.7824, -4.7041,\n",
      "         -4.8881, -4.6271, -4.7260, -5.1231, -4.9196, -4.5696, -4.7685, -4.9293,\n",
      "         -4.7708, -4.4564, -4.9610, -4.6793, -4.4974, -4.4311, -4.6190, -5.0999,\n",
      "         -4.6993, -4.4974, -4.6202, -4.2864, -4.7657, -4.4996, -4.7786, -4.5050,\n",
      "         -4.2474, -4.1284, -4.5709, -4.4343, -4.8644, -4.3828, -4.4740, -3.9483,\n",
      "         -4.8195, -4.6622, -4.8100, -4.9089, -4.9074, -4.6640, -4.3652, -4.4657,\n",
      "         -4.8480, -4.6944, -4.7710, -4.8980, -4.5678, -4.3579, -4.5539, -4.7087,\n",
      "         -4.4132, -4.3093, -5.1184, -4.7071, -4.3487, -4.7578, -4.7137, -4.6841,\n",
      "         -4.6866, -4.5581, -4.7239, -4.6429, -4.6852, -4.1661, -4.5087, -4.6201,\n",
      "         -4.5072]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : youth's\n",
      "target index is: [89] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1909, -4.7572, -4.7355, -4.8873, -4.1893, -4.7604, -4.8246, -4.5548,\n",
      "         -4.8245, -5.0004, -4.8909, -4.4145, -4.7222, -4.3594, -5.0290, -4.8691,\n",
      "         -4.6837, -4.6761, -4.6593, -4.6520, -4.4076, -4.5146, -4.4585, -4.5517,\n",
      "         -4.2940, -4.6866, -4.6734, -4.7868, -4.4853, -4.3929, -4.9984, -4.3772,\n",
      "         -4.9359, -4.6931, -4.6799, -5.2176, -4.7936, -4.7523, -4.8134, -4.3150,\n",
      "         -4.6377, -4.6766, -4.9018, -4.3551, -4.2972, -4.4923, -4.4864, -4.4197,\n",
      "         -4.5491, -4.4170, -4.2399, -4.8704, -4.4225, -4.2560, -4.3879, -4.4495,\n",
      "         -4.5051, -4.5035, -4.5428, -4.4959, -4.7491, -4.3474, -4.5272, -3.6915,\n",
      "         -4.3089, -4.3640, -4.8738, -4.6442, -4.7070, -4.6350, -4.3634, -4.7187,\n",
      "         -4.9323, -4.7701, -4.8734, -4.6221, -4.4026, -4.3115, -4.5935, -4.3150,\n",
      "         -4.6508, -4.7469, -4.9835, -5.1828, -4.5954, -4.2893, -4.5057, -5.0600,\n",
      "         -5.2553, -4.2083, -4.4404, -4.7243, -4.6313, -4.5084, -4.4346, -4.7113,\n",
      "         -4.8846]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : proud\n",
      "target index is: [50] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4447, -4.3366, -4.9147, -5.1043, -4.4025, -4.6719, -4.3472, -4.5723,\n",
      "         -5.3805, -4.5337, -4.9032, -4.4405, -4.8794, -4.5025, -4.6249, -5.1545,\n",
      "         -4.9839, -4.7197, -4.5610, -4.0308, -4.4098, -4.3924, -4.7720, -4.4827,\n",
      "         -4.9138, -4.9458, -4.4769, -4.4027, -4.6188, -4.8926, -4.7176, -4.6356,\n",
      "         -4.8837, -4.8820, -4.3627, -5.1421, -4.6101, -4.9956, -4.6753, -4.2125,\n",
      "         -4.3951, -4.6414, -4.5963, -4.4595, -4.5747, -4.2701, -4.9054, -4.2926,\n",
      "         -4.4926, -5.3725, -4.2877, -5.1382, -4.2342, -4.5514, -4.5542, -4.5482,\n",
      "         -4.8470, -4.3750, -4.3904, -4.7464, -4.6609, -4.2303, -4.6667, -4.4162,\n",
      "         -4.3958, -4.8548, -4.8414, -4.2934, -4.6429, -4.2681, -4.4530, -4.9130,\n",
      "         -4.9592, -4.8625, -4.6309, -4.8039, -4.4524, -4.2897, -4.0947, -4.1514,\n",
      "         -4.7908, -4.8172, -5.0909, -4.7955, -5.0188, -4.2552, -4.5654, -4.5808,\n",
      "         -4.7217, -4.3565, -4.3249, -4.2009, -4.8997, -4.5269, -4.2350, -4.6017,\n",
      "         -4.2839]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : livery\n",
      "target index is: [28] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6348, -4.4224, -4.9868, -4.7588, -4.0835, -5.1106, -4.4060, -4.3747,\n",
      "         -4.5728, -4.5021, -4.8556, -4.5801, -4.6829, -4.8404, -4.3266, -4.5759,\n",
      "         -4.8294, -5.0176, -4.7801, -4.3649, -4.7718, -4.1120, -4.9755, -4.8182,\n",
      "         -4.1728, -4.9366, -4.1941, -4.4638, -4.1308, -4.8457, -4.9297, -5.1603,\n",
      "         -4.9262, -4.8158, -4.6682, -4.7863, -4.5882, -4.6824, -5.0571, -4.5190,\n",
      "         -4.9588, -4.5575, -4.7660, -4.7765, -4.7538, -4.3381, -4.6801, -4.8793,\n",
      "         -4.4240, -5.0312, -4.4378, -4.6612, -4.5161, -4.3120, -4.6968, -4.3184,\n",
      "         -4.3442, -4.1486, -4.7184, -4.8815, -4.5316, -4.4181, -4.2293, -4.5459,\n",
      "         -4.5737, -4.5602, -4.7246, -4.7599, -4.7380, -4.2568, -4.2838, -4.4891,\n",
      "         -4.8074, -4.8691, -4.6738, -4.9056, -4.5661, -4.1779, -4.4143, -4.4757,\n",
      "         -4.4896, -4.6500, -4.8858, -4.6805, -4.4810, -4.3293, -4.4557, -4.8458,\n",
      "         -4.4605, -4.5292, -4.8723, -4.5982, -4.7812, -4.3252, -4.5564, -4.5147,\n",
      "         -4.0109]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : so\n",
      "target index is: [69] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3722, -4.3411, -4.9292, -4.7820, -4.3035, -5.0105, -4.5861, -4.4089,\n",
      "         -4.5501, -4.6558, -4.8116, -4.8509, -4.4660, -5.0292, -4.8472, -4.6187,\n",
      "         -4.7486, -4.3181, -4.5637, -4.5859, -4.4142, -4.2882, -4.9894, -4.8386,\n",
      "         -4.2468, -4.9240, -4.4087, -4.5084, -4.2439, -4.6628, -4.8408, -4.7779,\n",
      "         -4.9530, -5.0246, -4.6075, -4.7875, -4.8932, -4.4113, -4.8520, -4.7025,\n",
      "         -4.6484, -4.6749, -4.6526, -4.6190, -4.3468, -4.3168, -4.4904, -4.5439,\n",
      "         -4.5183, -4.8921, -4.5920, -4.5041, -4.8022, -4.3693, -4.4704, -4.7007,\n",
      "         -4.2179, -4.2911, -4.3240, -4.6463, -4.8836, -4.4871, -4.2009, -4.2087,\n",
      "         -4.3972, -4.8425, -4.4787, -4.4609, -4.2785, -4.4425, -4.3280, -4.5347,\n",
      "         -4.8098, -4.8477, -4.9755, -4.8169, -4.2530, -4.5335, -4.7943, -4.8076,\n",
      "         -4.2910, -4.6460, -4.8830, -4.7684, -4.7144, -4.3908, -4.5618, -4.6570,\n",
      "         -4.7385, -4.2748, -4.7309, -4.8763, -4.7626, -4.1641, -4.7105, -4.6633,\n",
      "         -4.3297]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : gazed\n",
      "target index is: [17] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4638, -4.3469, -4.6786, -4.7893, -4.3266, -4.6378, -4.4842, -4.3525,\n",
      "         -4.5790, -4.7478, -4.6877, -4.5594, -4.5893, -4.7201, -4.7672, -4.6325,\n",
      "         -4.4551, -4.6607, -4.6405, -4.5150, -4.6742, -4.6117, -4.6723, -4.6070,\n",
      "         -4.3713, -4.8729, -4.4432, -4.5478, -4.3555, -4.6159, -4.4109, -4.8428,\n",
      "         -4.8712, -4.7703, -4.5870, -4.6803, -4.5919, -4.6150, -4.7004, -4.6030,\n",
      "         -4.6972, -4.6036, -4.4466, -4.4433, -4.5289, -4.3029, -4.6788, -4.5721,\n",
      "         -4.4399, -4.6090, -4.5626, -4.3057, -4.8540, -4.5096, -4.6609, -4.3903,\n",
      "         -4.5744, -4.2480, -4.5768, -4.7141, -4.7476, -4.6360, -4.6862, -4.3486,\n",
      "         -4.6424, -4.6279, -4.8136, -4.4768, -4.5645, -4.5141, -4.4795, -4.4892,\n",
      "         -4.4960, -4.8244, -4.7046, -4.8427, -4.6091, -4.1906, -4.6470, -4.8397,\n",
      "         -4.5905, -4.6320, -4.6843, -4.8165, -4.5134, -4.4779, -4.3111, -4.6510,\n",
      "         -4.6811, -4.3222, -4.6362, -4.5630, -4.8118, -4.5115, -4.6043, -4.5552,\n",
      "         -4.5199]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : on\n",
      "target index is: [87] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4799, -4.6622, -4.6099, -4.6318, -4.2347, -4.6161, -4.3558, -4.2701,\n",
      "         -4.6919, -4.7155, -4.5831, -4.7783, -4.7719, -4.5899, -4.6536, -4.4696,\n",
      "         -4.3108, -4.6371, -4.6837, -4.7157, -4.8017, -4.6660, -4.5867, -4.5138,\n",
      "         -4.4340, -4.7600, -4.5933, -4.5228, -4.6465, -4.4337, -4.4723, -4.6572,\n",
      "         -4.7132, -4.7551, -4.7667, -4.6248, -4.7095, -4.6667, -4.9515, -4.6145,\n",
      "         -4.7247, -4.5316, -4.8189, -4.2969, -4.6457, -4.3847, -4.6167, -4.5772,\n",
      "         -4.4488, -4.3428, -4.7607, -4.4293, -5.1053, -4.3028, -4.6308, -4.3231,\n",
      "         -4.2935, -4.2928, -4.6529, -4.5302, -4.7405, -4.7082, -4.4930, -3.9934,\n",
      "         -4.8192, -4.2786, -4.8222, -4.5504, -4.5835, -4.5805, -4.5346, -4.6836,\n",
      "         -4.6736, -4.4080, -4.5943, -4.8164, -4.6349, -4.5416, -4.7743, -4.8051,\n",
      "         -4.4115, -4.4745, -4.7775, -4.6619, -4.6634, -4.4555, -4.6375, -4.7678,\n",
      "         -4.9323, -4.2610, -4.4912, -4.3272, -4.7387, -4.6541, -4.5331, -4.6879,\n",
      "         -4.8062]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : now,\n",
      "target index is: [63] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4328, -4.6264, -4.8472, -4.9148, -3.7937, -4.5007, -4.5207, -4.5536,\n",
      "         -4.6607, -4.6663, -4.5786, -4.3935, -5.0034, -4.8015, -4.7916, -4.4854,\n",
      "         -4.5883, -4.8165, -4.6420, -4.3911, -4.5775, -4.0961, -4.8004, -4.9103,\n",
      "         -4.5893, -4.9922, -4.6742, -4.3757, -4.3339, -4.7875, -4.4594, -5.0194,\n",
      "         -4.7037, -4.6915, -4.2638, -4.8578, -4.4094, -4.8559, -5.0993, -4.7615,\n",
      "         -4.6697, -4.4758, -4.6929, -4.4893, -4.5627, -4.4182, -4.4165, -4.8852,\n",
      "         -4.5592, -5.1475, -4.7929, -4.5996, -4.4857, -4.5078, -4.6023, -4.4769,\n",
      "         -4.2738, -4.3754, -4.4417, -4.5705, -4.5106, -4.5290, -4.8241, -4.3531,\n",
      "         -4.4833, -4.4016, -4.6382, -4.5876, -4.7104, -4.4281, -4.4520, -4.6479,\n",
      "         -4.9822, -4.8590, -4.6236, -4.8408, -4.8817, -4.4492, -4.6304, -4.4610,\n",
      "         -4.6387, -4.1126, -4.9007, -4.8045, -4.3300, -4.3076, -4.6112, -4.5695,\n",
      "         -4.8548, -4.4373, -4.6556, -4.2226, -4.7111, -4.3519, -4.5969, -4.5538,\n",
      "         -4.6180]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Will\n",
      "target index is: [36] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3933, -4.8185, -4.8227, -4.8694, -4.1053, -4.6152, -4.6392, -4.2944,\n",
      "         -4.5278, -4.7527, -4.6108, -4.6761, -4.5655, -4.8774, -4.9303, -4.2825,\n",
      "         -4.5090, -4.5652, -4.3806, -4.5301, -4.7894, -4.1628, -4.8893, -5.0583,\n",
      "         -3.9995, -5.0322, -4.4289, -4.4288, -4.2430, -4.4248, -4.5081, -4.9017,\n",
      "         -5.0326, -4.9197, -4.3695, -4.6620, -4.5968, -4.6612, -5.0960, -4.8074,\n",
      "         -4.9821, -4.5725, -4.4509, -4.6508, -4.6312, -4.4178, -4.6835, -4.6799,\n",
      "         -4.5839, -4.9051, -4.4360, -4.6206, -4.8986, -4.6030, -4.6381, -4.4625,\n",
      "         -4.1329, -4.2664, -4.3439, -4.5405, -4.9726, -4.7077, -4.4747, -4.4972,\n",
      "         -4.5096, -4.4426, -4.6716, -4.6057, -4.7372, -4.6627, -4.3151, -4.3618,\n",
      "         -4.7868, -4.8730, -4.7234, -4.7485, -4.3676, -4.3488, -4.5100, -4.7740,\n",
      "         -4.4519, -4.6861, -4.6433, -4.7398, -4.4359, -4.4671, -4.5666, -4.8006,\n",
      "         -4.6516, -4.3428, -4.6291, -4.5483, -4.8164, -4.5066, -4.8776, -4.3749,\n",
      "         -4.3232]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : be\n",
      "target index is: [24] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3447, -4.6927, -4.8007, -4.7464, -4.1794, -4.9927, -4.5470, -4.3671,\n",
      "         -4.7475, -4.7718, -4.6428, -4.3172, -4.6988, -5.0091, -5.0691, -4.3685,\n",
      "         -4.4063, -4.7397, -4.6754, -4.9807, -4.3754, -3.9779, -4.4408, -4.6935,\n",
      "         -4.0787, -5.0754, -4.3218, -4.7376, -4.4543, -4.5519, -4.4041, -5.2598,\n",
      "         -4.8204, -4.8294, -4.6113, -4.5496, -4.7055, -4.5663, -4.9486, -4.8373,\n",
      "         -5.0270, -4.7599, -4.6318, -4.6857, -4.3343, -4.5276, -4.4428, -4.7637,\n",
      "         -4.6209, -4.6308, -4.7352, -4.0850, -5.0233, -4.4188, -4.6382, -4.6651,\n",
      "         -4.5239, -4.4233, -4.3428, -4.7299, -4.8901, -4.5427, -4.5805, -4.0863,\n",
      "         -4.6625, -4.5168, -4.8809, -4.4283, -4.3155, -4.4211, -4.2053, -4.7101,\n",
      "         -4.9377, -4.7493, -5.0699, -5.1459, -4.4875, -4.3271, -4.6619, -4.8742,\n",
      "         -4.1512, -4.6151, -4.6751, -4.5070, -4.3063, -4.4585, -4.3934, -4.8823,\n",
      "         -5.0019, -4.5260, -4.1825, -4.7742, -4.5468, -4.4576, -4.5842, -4.5704,\n",
      "         -4.5365]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : a\n",
      "target index is: [46] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3525, -4.5264, -4.6604, -5.3650, -4.1605, -4.6998, -4.2665, -4.0532,\n",
      "         -4.7524, -4.5663, -4.8011, -4.9222, -4.3810, -4.7462, -4.6966, -4.3171,\n",
      "         -4.2076, -4.6290, -4.6852, -4.5662, -4.9602, -4.3673, -4.7400, -4.9503,\n",
      "         -4.2576, -5.2679, -4.2092, -4.4392, -4.3229, -4.6476, -4.4757, -4.7644,\n",
      "         -4.9129, -5.0864, -4.4391, -4.6646, -4.5349, -4.3470, -4.9411, -4.5843,\n",
      "         -4.8795, -4.6058, -4.9735, -4.3572, -4.9149, -4.2685, -4.8735, -4.7753,\n",
      "         -4.7205, -4.7923, -4.1887, -4.6452, -4.5627, -4.5391, -4.6612, -4.5476,\n",
      "         -4.3441, -4.4941, -4.4131, -4.7353, -4.8507, -4.7004, -4.4659, -4.3696,\n",
      "         -4.6229, -4.3544, -4.9835, -4.4166, -4.7624, -4.7992, -4.7548, -4.5461,\n",
      "         -4.8730, -4.7939, -4.6732, -4.8882, -4.3941, -4.3216, -4.1078, -4.7017,\n",
      "         -4.3552, -4.6350, -4.7153, -4.7179, -4.8471, -4.3287, -4.6302, -4.7358,\n",
      "         -4.7215, -4.3650, -4.5242, -4.3987, -5.0757, -4.3803, -4.8212, -4.3051,\n",
      "         -4.3497]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : totter'd\n",
      "target index is: [20] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6762, -4.6923, -4.9449, -4.8711, -4.3882, -4.8006, -4.6160, -4.0695,\n",
      "         -4.8658, -4.5977, -4.8249, -4.2917, -4.3183, -4.6817, -5.0090, -4.6064,\n",
      "         -4.7276, -4.4132, -4.3086, -4.7357, -4.5895, -4.3988, -4.6027, -4.8320,\n",
      "         -4.0082, -5.1492, -4.5251, -4.7623, -4.1950, -4.2450, -4.5264, -4.8038,\n",
      "         -4.8233, -4.9234, -4.8697, -5.1949, -4.6626, -4.5116, -4.7794, -4.5226,\n",
      "         -4.7293, -4.7751, -4.7200, -4.6857, -4.5949, -4.4630, -4.8124, -4.8341,\n",
      "         -4.8078, -4.6845, -4.3864, -4.4932, -4.8163, -4.5468, -4.5384, -4.4337,\n",
      "         -4.3995, -4.1787, -4.2748, -4.3889, -4.7935, -4.4739, -4.4795, -3.9740,\n",
      "         -4.5339, -4.6378, -4.4262, -4.7106, -4.6255, -4.0327, -4.4272, -4.3409,\n",
      "         -5.0687, -4.8337, -4.9965, -4.9923, -4.3130, -4.3634, -4.2035, -4.8933,\n",
      "         -4.6239, -4.6287, -5.0078, -4.6525, -4.8229, -4.5604, -4.6592, -4.7141,\n",
      "         -4.8092, -4.4260, -4.5549, -4.7224, -4.8332, -4.1461, -4.7247, -4.6912,\n",
      "         -4.3265]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : weed\n",
      "target index is: [29] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6000, -4.7492, -4.5370, -4.6587, -4.1498, -4.7663, -4.4871, -4.3202,\n",
      "         -4.6881, -4.8042, -4.6606, -4.6448, -4.7010, -4.8134, -5.0366, -4.8107,\n",
      "         -4.4291, -4.4102, -4.4370, -4.5980, -4.5533, -4.6573, -4.6559, -4.4709,\n",
      "         -4.1772, -4.8281, -4.5494, -4.7143, -4.5784, -4.4532, -4.3188, -4.5945,\n",
      "         -4.5416, -4.7744, -4.6347, -4.7252, -4.3971, -4.5914, -4.3793, -4.6013,\n",
      "         -4.6295, -4.7083, -4.8273, -4.6350, -4.5028, -4.2974, -4.2245, -4.5211,\n",
      "         -4.6487, -4.4916, -4.7395, -4.3245, -4.8609, -4.3993, -4.4435, -4.5460,\n",
      "         -4.4570, -4.2139, -4.3358, -4.6584, -5.0292, -4.5393, -4.5268, -4.2356,\n",
      "         -4.8454, -4.6918, -4.6475, -4.6235, -4.4687, -4.4994, -4.5650, -4.6851,\n",
      "         -4.8377, -4.9250, -4.8208, -4.7749, -4.5967, -4.2496, -4.6610, -4.8858,\n",
      "         -4.6747, -4.5559, -4.6580, -4.5800, -4.7223, -4.5271, -4.4520, -4.7911,\n",
      "         -4.9752, -4.1625, -4.6841, -4.5198, -4.6422, -4.5051, -4.5531, -4.7958,\n",
      "         -4.6324]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : of\n",
      "target index is: [57] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5153, -4.3962, -4.3796, -4.6357, -3.8982, -4.7269, -4.9623, -4.5080,\n",
      "         -4.7183, -4.6005, -4.6316, -4.2516, -4.8541, -4.7523, -4.6292, -4.5867,\n",
      "         -4.5716, -4.9489, -4.4880, -4.7772, -4.4481, -4.1996, -4.5347, -4.4663,\n",
      "         -4.3922, -4.7367, -4.4179, -4.6842, -4.4119, -4.6192, -4.4537, -5.2726,\n",
      "         -4.7161, -4.3393, -4.6624, -5.0222, -4.5883, -4.9190, -4.4933, -4.8602,\n",
      "         -4.7131, -4.8339, -4.7749, -4.6603, -4.4478, -4.4160, -4.4387, -4.9662,\n",
      "         -4.8435, -4.4573, -4.6405, -4.4520, -4.7796, -4.3172, -4.9884, -4.5223,\n",
      "         -4.6805, -4.3759, -4.4898, -4.4628, -4.7601, -4.7619, -4.7185, -3.8484,\n",
      "         -4.8046, -4.6618, -5.0506, -4.6681, -4.6376, -4.7565, -4.3201, -4.5806,\n",
      "         -4.9662, -4.6664, -4.6663, -4.7685, -4.6850, -4.4592, -4.5558, -4.8780,\n",
      "         -4.5733, -4.0906, -4.8125, -4.7684, -4.4363, -4.5719, -4.3884, -4.5863,\n",
      "         -4.9036, -4.1568, -4.5955, -4.7622, -4.5338, -4.4877, -4.0993, -4.8170,\n",
      "         -4.4657]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : small\n",
      "target index is: [38] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3562, -4.2938, -4.6213, -4.8715, -4.3391, -4.7560, -4.5160, -4.5366,\n",
      "         -4.7099, -4.9404, -4.8484, -4.5770, -4.7688, -4.4895, -4.2878, -4.7778,\n",
      "         -4.8398, -5.0349, -4.6119, -4.2393, -4.8121, -4.5582, -4.5738, -4.4112,\n",
      "         -4.7355, -5.1011, -4.7485, -4.4471, -4.0866, -4.6350, -4.4649, -5.0012,\n",
      "         -4.7717, -4.6989, -4.4716, -4.8729, -4.7490, -4.8347, -4.9116, -4.4455,\n",
      "         -4.6497, -4.6001, -4.8536, -4.1405, -4.8269, -4.1678, -5.0248, -4.4185,\n",
      "         -4.4368, -4.8638, -4.9114, -4.7111, -4.7426, -4.4904, -4.6458, -4.6578,\n",
      "         -4.2976, -4.1836, -4.6567, -4.6692, -4.6211, -4.7067, -4.8662, -4.2876,\n",
      "         -4.9976, -4.4850, -5.1349, -4.2550, -4.6837, -4.7779, -4.2273, -4.7102,\n",
      "         -4.7671, -4.6485, -4.8536, -4.7326, -5.0112, -4.2856, -4.4423, -4.2199,\n",
      "         -4.6831, -4.3971, -4.7556, -4.8228, -4.6566, -4.0606, -4.3343, -4.4273,\n",
      "         -5.0309, -4.2449, -4.4994, -4.2557, -4.6484, -4.6062, -4.2385, -4.4168,\n",
      "         -4.3590]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : worth\n",
      "target index is: [83] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6725, -4.6182, -4.7912, -5.0743, -4.2668, -4.8424, -4.3433, -4.5545,\n",
      "         -4.7075, -4.7514, -5.0359, -4.8500, -4.8922, -4.7478, -4.4386, -4.5456,\n",
      "         -4.5484, -4.8732, -4.6436, -4.1675, -4.7689, -4.0007, -4.9947, -4.7158,\n",
      "         -4.1652, -5.1320, -4.2337, -4.0929, -4.5575, -4.6041, -5.0048, -4.9158,\n",
      "         -5.0369, -4.9730, -4.5690, -4.2904, -4.7997, -4.9085, -5.1915, -4.7066,\n",
      "         -5.0013, -5.1870, -4.7325, -4.6122, -4.6889, -4.5236, -4.8137, -5.0019,\n",
      "         -4.3188, -4.8735, -3.9532, -4.8010, -4.1893, -3.9295, -4.9744, -4.0311,\n",
      "         -4.8876, -4.4359, -4.4938, -4.5918, -4.7668, -4.6815, -4.6176, -4.1972,\n",
      "         -4.8548, -4.1636, -5.0803, -4.6012, -4.8959, -4.5667, -4.2538, -4.8065,\n",
      "         -4.8818, -4.1673, -4.5339, -5.0346, -4.4023, -4.4712, -4.7042, -4.7254,\n",
      "         -4.1942, -4.3783, -4.7546, -4.4622, -4.2750, -4.1912, -5.0446, -5.2785,\n",
      "         -4.5324, -4.2801, -4.4659, -4.6844, -4.5481, -4.3666, -4.4613, -4.7938,\n",
      "         -4.2896]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : held:\n",
      "target index is: [19] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3394, -4.3963, -5.0609, -5.0656, -4.0623, -4.8998, -4.3379, -4.5772,\n",
      "         -4.6723, -4.1853, -5.0553, -4.6370, -4.8814, -4.7180, -4.4224, -4.6411,\n",
      "         -4.6228, -4.6790, -5.0154, -4.4435, -4.3631, -4.3933, -4.8107, -4.7453,\n",
      "         -4.8049, -5.2151, -4.4572, -4.4835, -4.6028, -4.6572, -4.7519, -4.6467,\n",
      "         -4.7002, -5.2382, -4.5924, -4.5771, -4.4841, -4.5891, -4.9949, -4.2642,\n",
      "         -4.6022, -4.5765, -4.4877, -4.2537, -4.2501, -4.6107, -4.6957, -4.5384,\n",
      "         -4.2446, -5.3225, -4.3725, -5.0221, -4.7029, -4.3943, -4.7568, -4.5609,\n",
      "         -4.6216, -4.5832, -4.4875, -4.5942, -4.6316, -4.3345, -4.4372, -4.4801,\n",
      "         -4.4510, -4.5768, -4.6697, -4.3248, -4.5872, -4.3548, -4.6263, -5.0091,\n",
      "         -4.8635, -4.5207, -4.8859, -5.2993, -4.1709, -4.8037, -4.5367, -4.7760,\n",
      "         -4.6334, -4.2521, -4.8198, -4.5446, -5.2960, -3.8896, -5.1212, -4.5816,\n",
      "         -4.7215, -4.0597, -4.5463, -4.8341, -4.8303, -4.1594, -4.6339, -4.2782,\n",
      "         -4.2659]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Then\n",
      "target index is: [65] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3791, -4.5232, -4.9055, -4.7404, -3.9582, -4.8528, -4.5910, -4.7605,\n",
      "         -4.8307, -4.6478, -4.7262, -4.6198, -4.8079, -4.6931, -4.7414, -4.5468,\n",
      "         -4.5516, -4.6751, -5.1227, -4.7051, -4.6017, -4.2086, -4.8195, -4.3479,\n",
      "         -4.4103, -4.7461, -4.7845, -4.3040, -4.3372, -4.4154, -4.7007, -4.5579,\n",
      "         -4.7290, -4.9208, -4.5411, -4.2328, -4.6555, -4.9998, -4.9915, -4.4510,\n",
      "         -4.8863, -4.3867, -4.5342, -4.3519, -4.2466, -4.3562, -4.5021, -4.6991,\n",
      "         -4.3370, -4.9757, -4.6789, -4.5506, -4.9416, -4.0464, -4.5709, -4.4191,\n",
      "         -4.3201, -4.4061, -4.7030, -4.3687, -4.7577, -4.6198, -4.5303, -4.3957,\n",
      "         -4.6792, -4.5508, -4.7675, -4.2797, -4.6272, -4.4756, -4.4477, -4.7613,\n",
      "         -4.8274, -4.7730, -4.9284, -4.9523, -4.4226, -4.5303, -4.8971, -4.9974,\n",
      "         -4.4814, -4.2332, -4.4419, -4.5115, -4.8261, -4.0338, -4.8052, -5.0325,\n",
      "         -4.8689, -4.1304, -4.6917, -4.9267, -4.5284, -4.4195, -4.5260, -4.8672,\n",
      "         -4.6924]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : being\n",
      "target index is: [32] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3406, -4.2724, -4.6282, -5.0523, -4.1775, -4.3662, -4.5076, -4.1450,\n",
      "         -4.9670, -4.4618, -4.8435, -4.3405, -4.6640, -4.3797, -5.0170, -4.4290,\n",
      "         -4.4443, -4.4883, -4.7207, -4.0578, -4.8238, -4.7864, -4.4413, -4.4840,\n",
      "         -4.8786, -4.5739, -4.6533, -4.5360, -4.4258, -4.7980, -4.2403, -4.8255,\n",
      "         -4.9105, -4.6097, -4.5217, -4.8073, -4.4815, -4.9797, -4.9212, -4.8227,\n",
      "         -4.7064, -4.7250, -4.4914, -4.1996, -4.4459, -4.1388, -4.7410, -4.7464,\n",
      "         -4.7717, -4.7023, -4.7194, -4.3965, -4.5177, -4.5451, -5.0109, -4.7027,\n",
      "         -4.5638, -4.5838, -4.5449, -4.5675, -4.9131, -4.8309, -4.7831, -4.2529,\n",
      "         -4.6065, -4.5369, -4.9416, -4.5267, -4.6519, -4.8941, -4.5436, -4.7021,\n",
      "         -4.6625, -5.0576, -4.3965, -4.5527, -4.5755, -4.4244, -4.3945, -4.6982,\n",
      "         -4.6139, -4.4047, -4.4204, -4.8746, -4.8149, -4.4620, -4.3678, -4.2177,\n",
      "         -5.0689, -4.4075, -4.6413, -4.4166, -4.9938, -4.5252, -4.4069, -4.4086,\n",
      "         -4.7035]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : asked,\n",
      "target index is: [23] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1956, -4.5990, -4.4986, -4.6528, -4.0945, -4.8337, -4.6527, -4.3762,\n",
      "         -4.6816, -4.5942, -4.6343, -4.2969, -4.6264, -4.6732, -4.7015, -4.8083,\n",
      "         -4.7424, -5.0916, -4.4407, -4.8227, -4.5448, -4.5016, -4.6913, -4.6058,\n",
      "         -4.4121, -4.8607, -4.5258, -4.4915, -4.3461, -4.5470, -4.5822, -4.8141,\n",
      "         -4.6736, -4.6082, -4.7327, -5.0594, -4.5872, -4.4651, -4.4812, -4.6390,\n",
      "         -4.7668, -4.4317, -4.6468, -4.5115, -4.3901, -4.1961, -4.6547, -4.8771,\n",
      "         -4.7763, -4.5107, -4.6096, -4.3232, -4.8886, -4.4751, -4.8205, -4.3883,\n",
      "         -4.5904, -4.2357, -4.3752, -4.6137, -4.7108, -4.5094, -4.6144, -3.9886,\n",
      "         -4.7922, -4.6347, -4.9516, -4.6928, -4.8686, -4.6372, -4.5408, -4.6359,\n",
      "         -4.9202, -4.5114, -4.6587, -4.9667, -4.7448, -4.2550, -4.4304, -4.9232,\n",
      "         -4.5315, -4.1980, -4.9090, -4.6222, -4.4155, -4.5220, -4.6412, -4.5501,\n",
      "         -5.0349, -4.4297, -4.5132, -4.5245, -4.6044, -4.6512, -4.2949, -4.7208,\n",
      "         -4.4683]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : where\n",
      "target index is: [51] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3555, -4.3013, -4.6681, -4.9602, -4.2876, -4.9467, -4.7253, -4.6760,\n",
      "         -4.8815, -4.6540, -4.9536, -4.6159, -4.8344, -4.5928, -4.6504, -4.9674,\n",
      "         -4.6977, -4.5887, -4.9366, -4.5135, -4.6598, -4.5751, -4.7960, -4.5263,\n",
      "         -4.5809, -4.7505, -4.3876, -4.3922, -4.2728, -4.6506, -4.3153, -4.9421,\n",
      "         -4.7383, -4.6908, -4.5158, -4.9927, -4.4765, -4.6551, -4.7763, -4.5702,\n",
      "         -4.6136, -4.7080, -4.6139, -4.5899, -4.5169, -4.1575, -4.8013, -4.5891,\n",
      "         -4.7658, -4.7886, -4.2436, -4.9110, -4.6350, -4.5077, -4.5123, -4.6871,\n",
      "         -4.5504, -4.3505, -4.5609, -4.5285, -4.5509, -4.4189, -4.5273, -4.4105,\n",
      "         -4.4885, -4.8010, -5.0124, -4.3093, -4.3962, -4.3306, -4.6639, -4.5220,\n",
      "         -5.0851, -4.9329, -4.8640, -4.9440, -4.5641, -4.2436, -4.2906, -4.5031,\n",
      "         -4.3867, -4.3906, -4.7304, -4.8814, -4.8366, -4.2311, -4.3251, -4.4957,\n",
      "         -4.7624, -4.4342, -4.1973, -4.7226, -4.6992, -4.3656, -4.2683, -4.5715,\n",
      "         -4.2134]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : all\n",
      "target index is: [52] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4725, -4.2785, -4.6631, -4.7949, -4.4515, -4.8220, -4.4301, -4.4581,\n",
      "         -4.5491, -4.8884, -4.9901, -4.6920, -4.4993, -4.6165, -4.5862, -4.6534,\n",
      "         -4.6435, -4.7342, -4.5889, -4.2108, -4.7835, -4.7606, -4.6686, -4.4841,\n",
      "         -4.3753, -4.8698, -4.5105, -4.4974, -4.2041, -4.8479, -4.4705, -4.7780,\n",
      "         -4.8694, -4.8585, -4.4926, -4.5565, -4.6261, -4.4821, -4.6694, -4.6185,\n",
      "         -4.7430, -4.6183, -4.7440, -4.5043, -4.7558, -4.2255, -4.8463, -4.6417,\n",
      "         -4.5668, -4.8316, -4.4534, -4.4679, -4.5932, -4.3316, -4.7238, -4.5401,\n",
      "         -4.3878, -4.3529, -4.6129, -4.7403, -4.7770, -4.7351, -4.5898, -4.5828,\n",
      "         -4.8039, -4.5334, -5.0733, -4.3680, -4.6397, -4.6398, -4.4507, -4.5240,\n",
      "         -4.5575, -4.8803, -4.6401, -4.6689, -4.5419, -4.2166, -4.3097, -4.6610,\n",
      "         -4.4738, -4.5722, -4.6057, -4.7997, -4.6511, -4.2981, -4.4588, -4.5689,\n",
      "         -4.7119, -4.3411, -4.5992, -4.6502, -4.6586, -4.5439, -4.3506, -4.4791,\n",
      "         -4.2405]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3358, -4.3654, -4.9416, -4.7757, -4.2783, -4.7741, -4.8495, -4.3947,\n",
      "         -5.0858, -4.2680, -5.0098, -4.4014, -4.5161, -4.6019, -4.6688, -4.8338,\n",
      "         -4.5571, -4.4295, -4.4898, -4.5013, -4.6525, -4.3957, -4.5035, -4.7986,\n",
      "         -4.4066, -5.0720, -4.3732, -4.5380, -4.4990, -4.4846, -4.6621, -4.6646,\n",
      "         -4.8490, -4.6889, -4.8970, -5.1011, -4.7084, -4.6361, -4.8749, -4.5992,\n",
      "         -4.6569, -4.7789, -4.6704, -4.6225, -4.5255, -4.1236, -4.8207, -4.7250,\n",
      "         -4.9052, -4.6431, -4.7519, -4.7668, -4.5473, -4.2974, -4.4739, -4.7821,\n",
      "         -4.3042, -4.3671, -4.4574, -4.5236, -4.7028, -4.5156, -4.2629, -4.3366,\n",
      "         -4.2410, -4.7525, -4.7088, -4.2496, -4.5872, -4.3772, -4.4569, -4.6285,\n",
      "         -4.8130, -4.5809, -4.7933, -4.7214, -4.2398, -4.4883, -4.2159, -4.7090,\n",
      "         -4.3229, -4.5733, -4.8074, -5.0641, -4.8554, -4.4422, -4.7394, -4.6445,\n",
      "         -4.8903, -4.4723, -4.5081, -4.8020, -4.8296, -4.3523, -4.0650, -4.8441,\n",
      "         -4.3996]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty\n",
      "target index is: [0] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3420, -4.7008, -4.7395, -4.9178, -4.2200, -4.6930, -4.3612, -4.2010,\n",
      "         -5.1227, -4.4890, -4.7855, -4.4116, -4.2638, -4.5885, -4.8629, -5.1086,\n",
      "         -4.7156, -4.5582, -4.6689, -4.5439, -4.7675, -4.7326, -4.8303, -4.6526,\n",
      "         -4.4357, -5.1988, -4.3905, -4.4542, -4.2192, -4.6716, -4.4847, -4.3549,\n",
      "         -4.7406, -4.9520, -4.6863, -5.1687, -4.3483, -4.5160, -4.3966, -4.3689,\n",
      "         -4.5579, -4.3890, -4.6525, -4.3596, -4.5377, -4.1091, -4.9273, -4.6030,\n",
      "         -4.8403, -4.7761, -4.5240, -4.6647, -4.8224, -4.5688, -4.5958, -4.5875,\n",
      "         -4.4348, -4.3264, -4.5261, -4.3679, -4.7246, -4.4382, -4.3671, -4.4606,\n",
      "         -4.3037, -5.0186, -4.7521, -4.4361, -4.7513, -4.0255, -4.5874, -4.5166,\n",
      "         -5.1227, -4.9167, -4.7602, -4.7405, -4.5864, -3.9163, -4.1529, -4.7617,\n",
      "         -4.5750, -4.7898, -4.8558, -4.9349, -5.1308, -4.2988, -4.5830, -4.4087,\n",
      "         -5.3401, -4.8609, -4.7524, -4.6045, -4.8720, -4.3725, -4.5362, -4.8024,\n",
      "         -4.2907]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : lies,\n",
      "target index is: [59] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3043, -4.6762, -4.6472, -4.6759, -4.2071, -4.8999, -4.3727, -4.2175,\n",
      "         -4.6812, -5.1474, -4.7552, -4.3755, -4.5356, -4.8206, -4.7528, -4.6506,\n",
      "         -4.4778, -4.9514, -4.7696, -4.9131, -4.4343, -4.4776, -4.6517, -4.5288,\n",
      "         -4.1472, -4.8826, -4.5081, -4.3733, -4.3802, -4.5933, -4.6298, -4.7095,\n",
      "         -4.5194, -5.1422, -4.5160, -4.6556, -4.9125, -4.3154, -4.6892, -4.3935,\n",
      "         -5.0524, -4.2596, -4.7718, -4.4309, -4.4530, -4.1893, -4.4801, -4.5809,\n",
      "         -4.5281, -4.5441, -4.5990, -4.1708, -5.0226, -4.4045, -4.6879, -4.3309,\n",
      "         -4.5835, -4.4401, -4.7693, -4.7694, -4.6614, -4.3194, -4.5433, -4.3756,\n",
      "         -4.6577, -4.6799, -4.7146, -4.3567, -4.6632, -4.4308, -4.4471, -4.6964,\n",
      "         -4.4785, -4.9653, -4.8474, -4.9267, -4.6235, -4.1249, -4.6077, -5.0369,\n",
      "         -4.3901, -4.7406, -4.6971, -4.7809, -4.4339, -4.4219, -4.4687, -5.0370,\n",
      "         -5.0088, -4.5293, -4.6767, -4.6892, -4.4286, -4.6457, -4.7372, -4.5816,\n",
      "         -4.4474]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Where\n",
      "target index is: [18] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5418, -4.4325, -4.3864, -4.5950, -4.2444, -4.9781, -4.7494, -4.5284,\n",
      "         -4.6624, -4.7742, -4.7076, -4.5069, -4.7147, -4.7485, -4.5499, -4.5547,\n",
      "         -4.8494, -4.5911, -4.5725, -4.6106, -4.3947, -4.3284, -4.7319, -4.6497,\n",
      "         -4.3724, -4.7654, -4.6503, -4.4755, -4.3488, -4.5685, -4.7184, -4.6623,\n",
      "         -4.8317, -4.6037, -4.6422, -4.9022, -4.5750, -4.9062, -4.4857, -4.5228,\n",
      "         -4.6556, -4.6692, -4.8334, -4.5189, -4.6147, -4.4169, -4.5494, -4.6794,\n",
      "         -4.5043, -4.8343, -4.4852, -4.8390, -4.4979, -4.5994, -4.7214, -4.7589,\n",
      "         -4.2995, -4.4245, -4.3759, -4.5165, -4.8137, -4.7652, -4.5187, -4.2272,\n",
      "         -4.9015, -4.4413, -4.9238, -4.3669, -4.5756, -4.7233, -4.3082, -4.4907,\n",
      "         -4.8624, -4.9064, -4.8313, -4.7666, -4.2547, -4.3326, -4.6646, -4.5551,\n",
      "         -4.4539, -4.2945, -4.6221, -4.7496, -4.6414, -4.4487, -4.3784, -4.7191,\n",
      "         -4.7731, -4.2519, -4.5288, -4.7287, -4.5461, -4.4325, -4.2571, -4.4969,\n",
      "         -4.5559]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : all\n",
      "target index is: [52] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2797, -4.2301, -4.6092, -4.9523, -4.3499, -4.6143, -4.5524, -4.4867,\n",
      "         -4.7975, -4.9783, -4.8343, -4.4782, -4.7186, -4.6389, -4.5049, -4.7763,\n",
      "         -4.7576, -5.0624, -4.4223, -4.1573, -4.7673, -4.4263, -4.6633, -4.4666,\n",
      "         -4.6083, -4.7519, -4.4082, -4.4742, -4.1822, -5.0055, -4.4348, -4.9421,\n",
      "         -4.8703, -4.6943, -4.3216, -4.7318, -4.5709, -4.7896, -4.7923, -4.7374,\n",
      "         -4.6904, -4.6573, -4.8031, -4.5838, -4.8583, -4.2736, -5.0367, -4.6412,\n",
      "         -4.6298, -4.8744, -4.4322, -4.6529, -4.3840, -4.5291, -5.0237, -4.6038,\n",
      "         -4.6450, -4.4323, -4.6205, -4.7885, -4.5745, -4.5871, -4.7244, -4.4312,\n",
      "         -4.9990, -4.4694, -5.1099, -4.6280, -4.7698, -4.6740, -4.3178, -4.5812,\n",
      "         -4.5760, -4.7766, -4.4206, -4.6338, -4.5985, -4.1740, -4.2822, -4.4130,\n",
      "         -4.4553, -4.4223, -4.7390, -4.8365, -4.4404, -4.3933, -4.3467, -4.5513,\n",
      "         -4.7306, -4.2899, -4.4304, -4.4275, -4.7368, -4.5491, -4.1546, -4.4320,\n",
      "         -4.3707]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : the\n",
      "target index is: [82] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1483, -4.4076, -4.5719, -4.8754, -4.1854, -4.6910, -4.6606, -4.3304,\n",
      "         -4.6356, -4.7209, -4.8759, -4.7167, -4.6282, -4.7987, -4.6965, -4.6629,\n",
      "         -4.4302, -4.5066, -4.4555, -4.6342, -4.8792, -4.5275, -4.7937, -4.6025,\n",
      "         -4.1957, -4.5014, -4.5432, -4.5012, -4.4630, -4.5027, -4.5578, -4.6609,\n",
      "         -4.5550, -4.6852, -4.8917, -4.7727, -4.8480, -4.5464, -4.8654, -4.8177,\n",
      "         -4.7190, -4.5539, -4.7666, -4.3617, -4.6017, -4.1731, -4.6345, -4.5203,\n",
      "         -4.5590, -4.4568, -4.5059, -4.5959, -4.9597, -4.4475, -4.5110, -4.6782,\n",
      "         -4.4468, -4.5162, -4.4253, -4.5796, -5.1472, -4.6734, -4.4139, -4.0402,\n",
      "         -4.8488, -4.7402, -4.7390, -4.5147, -4.6488, -4.7323, -4.7304, -4.6486,\n",
      "         -4.4832, -4.5235, -4.5372, -4.5303, -4.3874, -4.4648, -4.5227, -4.8087,\n",
      "         -4.2139, -4.3348, -4.8743, -4.7699, -4.5825, -4.5592, -4.7712, -4.8156,\n",
      "         -4.9136, -4.3599, -4.5995, -4.5133, -4.6343, -4.5394, -4.3380, -4.6159,\n",
      "         -4.6280]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : treasure\n",
      "target index is: [31] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3632, -4.3678, -4.7179, -4.9696, -4.1177, -4.7665, -4.6486, -4.6017,\n",
      "         -4.7599, -4.5745, -4.6175, -4.2814, -4.7887, -4.7712, -4.8366, -4.8309,\n",
      "         -4.4845, -4.7522, -4.7008, -4.5585, -4.5265, -4.4810, -4.8403, -4.6088,\n",
      "         -4.7158, -4.9837, -4.2930, -4.4475, -4.2789, -4.8969, -4.2500, -5.0318,\n",
      "         -4.6764, -4.6075, -4.4993, -5.0402, -4.3713, -4.6870, -4.7114, -4.7812,\n",
      "         -4.5759, -4.7673, -4.5029, -4.3813, -4.5307, -4.2932, -4.6557, -4.7172,\n",
      "         -4.7619, -4.9155, -4.3151, -4.7630, -4.7211, -4.8413, -4.7137, -4.3863,\n",
      "         -4.5689, -4.1645, -4.4951, -4.6065, -4.5136, -4.3280, -4.7792, -4.2522,\n",
      "         -4.4920, -4.6300, -5.0347, -4.7113, -4.2651, -4.3156, -4.7226, -4.7455,\n",
      "         -4.8552, -4.8209, -4.7605, -5.0159, -4.6434, -4.2922, -4.4939, -4.5523,\n",
      "         -4.6269, -4.1939, -4.8022, -4.9723, -4.6467, -4.4460, -4.3405, -4.2903,\n",
      "         -4.7299, -4.5402, -4.3054, -4.4868, -4.8531, -4.4872, -4.5202, -4.4541,\n",
      "         -4.2964]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : of\n",
      "target index is: [57] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4794, -4.1742, -4.3137, -4.5624, -4.1693, -4.8555, -4.8818, -4.4312,\n",
      "         -4.8231, -4.7655, -5.0720, -4.5466, -4.6047, -4.5561, -4.7809, -4.7762,\n",
      "         -4.6687, -4.5565, -4.5631, -4.5479, -4.6032, -4.3795, -4.6784, -4.3974,\n",
      "         -4.0658, -4.6813, -4.5003, -4.5386, -4.3071, -4.4926, -4.6536, -5.0479,\n",
      "         -5.0246, -4.5946, -4.8645, -4.9166, -4.8272, -4.7617, -4.5165, -4.6991,\n",
      "         -4.8391, -4.5180, -4.6536, -4.4970, -4.5173, -4.3210, -4.7482, -4.9414,\n",
      "         -4.6194, -4.5239, -4.4244, -4.4130, -4.8428, -4.2382, -4.6505, -4.6523,\n",
      "         -4.4536, -4.3924, -4.4693, -4.7017, -4.9036, -4.7173, -4.3880, -4.1747,\n",
      "         -4.7042, -4.7263, -5.0200, -4.5068, -4.7703, -4.6961, -4.5771, -4.4817,\n",
      "         -4.7118, -4.8603, -4.6770, -4.7855, -4.5913, -4.1667, -4.4488, -4.9084,\n",
      "         -4.1779, -4.3543, -4.7514, -4.8232, -4.6158, -4.4660, -4.5460, -4.6946,\n",
      "         -4.7697, -4.2057, -4.6398, -4.8206, -4.5886, -4.3992, -4.3176, -4.6636,\n",
      "         -4.3339]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1100, -4.2771, -4.8823, -5.0438, -4.2198, -4.7454, -4.7375, -4.2591,\n",
      "         -5.2617, -4.3835, -5.1289, -4.1547, -4.5637, -4.2673, -4.7296, -4.9983,\n",
      "         -4.5649, -4.5940, -4.7778, -4.1939, -4.7919, -4.8069, -4.4486, -4.4620,\n",
      "         -4.7294, -4.8549, -4.4110, -4.3561, -4.4098, -4.6957, -4.5724, -4.7656,\n",
      "         -5.0304, -4.8316, -4.8150, -5.2558, -4.6077, -4.5610, -4.9227, -4.4344,\n",
      "         -4.9017, -4.6565, -4.4770, -4.4128, -4.6501, -4.0090, -4.8807, -4.7277,\n",
      "         -4.8606, -4.7144, -4.6212, -4.7432, -4.4184, -4.3550, -4.8342, -4.8134,\n",
      "         -4.4506, -4.4651, -4.6849, -4.6413, -4.6243, -4.6087, -4.3077, -4.5461,\n",
      "         -4.3628, -4.7868, -5.1141, -4.3401, -4.5785, -4.6063, -4.2813, -4.7222,\n",
      "         -4.6971, -5.0209, -4.5685, -4.7077, -4.2904, -4.2206, -4.1338, -4.6143,\n",
      "         -4.3791, -4.5490, -4.6397, -5.0012, -5.1505, -4.2284, -4.6135, -4.3237,\n",
      "         -5.0832, -4.5631, -4.3972, -4.7917, -4.8804, -4.5163, -4.1872, -4.4776,\n",
      "         -4.3732]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : lusty\n",
      "target index is: [30] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2176, -4.6354, -4.3846, -4.9670, -4.2208, -4.7184, -4.4973, -4.1599,\n",
      "         -4.6985, -4.9715, -4.8804, -4.4466, -4.3802, -4.6617, -4.9103, -4.8473,\n",
      "         -4.4504, -4.7436, -4.3952, -4.8325, -4.7043, -5.0488, -4.6934, -4.6786,\n",
      "         -4.3798, -4.7189, -4.5419, -4.4806, -4.2135, -4.5146, -4.2103, -4.6939,\n",
      "         -4.5999, -4.9146, -4.7743, -4.8986, -4.4015, -4.4534, -4.4934, -4.5398,\n",
      "         -4.8242, -4.2857, -4.8157, -4.3427, -4.6527, -4.1767, -4.5384, -4.5862,\n",
      "         -4.6496, -4.5496, -4.6243, -4.3011, -5.0715, -4.5539, -4.8638, -4.7467,\n",
      "         -4.3545, -4.3005, -4.5454, -4.6200, -4.8644, -4.3885, -4.6217, -4.2129,\n",
      "         -4.6834, -4.8126, -4.8055, -4.8301, -4.7678, -4.4267, -4.6438, -4.4595,\n",
      "         -5.0345, -4.9649, -4.6884, -4.6971, -4.8997, -3.7884, -4.3150, -4.9963,\n",
      "         -4.4805, -4.5671, -4.6641, -4.8933, -4.8509, -4.4661, -4.4236, -4.4396,\n",
      "         -5.2605, -4.4003, -4.7864, -4.5070, -4.5100, -4.5946, -4.4135, -4.7708,\n",
      "         -4.4319]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : days;\n",
      "target index is: [48] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5411, -4.7330, -4.4219, -4.4783, -3.7303, -4.7687, -4.5471, -4.4509,\n",
      "         -4.5017, -4.9605, -4.4780, -4.5993, -5.0669, -4.9283, -4.6451, -4.6031,\n",
      "         -4.9315, -5.0951, -4.6249, -4.7289, -4.6324, -4.0629, -4.7053, -4.5331,\n",
      "         -4.4158, -4.8256, -4.4326, -4.5180, -4.5908, -4.5550, -4.6030, -4.6594,\n",
      "         -4.6924, -4.7785, -4.4008, -4.9566, -4.7200, -4.8877, -4.5306, -4.5800,\n",
      "         -4.8364, -4.6622, -5.0074, -4.4263, -4.8397, -4.7157, -4.3635, -4.4315,\n",
      "         -4.3115, -4.3478, -4.4570, -4.6603, -4.7406, -4.5007, -4.7042, -3.9104,\n",
      "         -4.6366, -4.1207, -4.4601, -4.6050, -4.6365, -4.7533, -5.0099, -3.9934,\n",
      "         -5.0545, -4.3875, -4.9439, -4.5607, -4.7456, -5.0660, -4.2399, -4.5709,\n",
      "         -4.8225, -4.9379, -4.4919, -5.0020, -4.6716, -4.5916, -4.5118, -4.6461,\n",
      "         -4.7545, -4.0590, -5.0161, -4.6449, -4.4682, -4.6483, -4.5681, -5.0268,\n",
      "         -4.8437, -4.2542, -4.6527, -4.4190, -4.4494, -4.5613, -4.4075, -4.4636,\n",
      "         -4.6164]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : To\n",
      "target index is: [26] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2526, -4.6649, -5.0281, -4.9603, -4.0959, -4.7784, -4.4598, -4.7270,\n",
      "         -4.5775, -4.6326, -4.9417, -4.4948, -4.8514, -4.4816, -4.8488, -4.6411,\n",
      "         -4.2312, -4.7066, -4.8799, -4.6127, -4.3505, -4.1980, -4.8500, -4.7138,\n",
      "         -4.5062, -4.8693, -4.4052, -4.4138, -4.3724, -4.8428, -4.6380, -4.9376,\n",
      "         -4.9164, -5.0089, -4.5698, -4.5501, -4.5737, -4.5217, -5.1362, -4.6987,\n",
      "         -4.7045, -4.6921, -4.3428, -4.7217, -4.1116, -4.4279, -4.5557, -4.8319,\n",
      "         -4.4525, -4.9884, -4.2549, -4.6097, -4.5980, -4.2587, -4.8030, -4.7324,\n",
      "         -4.6788, -4.5508, -4.5035, -4.6032, -4.6211, -4.3719, -4.5880, -4.3184,\n",
      "         -4.3528, -4.8154, -4.9576, -4.5191, -4.6168, -4.2835, -4.4034, -4.5683,\n",
      "         -4.9122, -4.4760, -4.8761, -4.9731, -4.5311, -4.3912, -4.7422, -4.6608,\n",
      "         -4.1450, -4.3643, -4.5647, -4.7170, -4.4298, -4.3350, -4.6498, -4.7393,\n",
      "         -4.8724, -4.6035, -4.4517, -4.9688, -4.5366, -4.2234, -4.4278, -4.7049,\n",
      "         -4.2898]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : say,\n",
      "target index is: [96] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7576, -4.3196, -4.6558, -4.9184, -3.9653, -4.7150, -4.6036, -4.2917,\n",
      "         -4.7458, -4.5116, -4.7785, -4.6390, -4.6821, -4.7393, -4.5999, -4.8527,\n",
      "         -4.8148, -4.3565, -4.7636, -4.2375, -4.6703, -4.5984, -4.6685, -4.7180,\n",
      "         -4.4538, -4.8096, -4.4090, -4.5465, -4.2849, -4.5220, -4.6135, -4.6401,\n",
      "         -4.8487, -4.8003, -4.4420, -4.8559, -4.4929, -4.8334, -4.5415, -4.4599,\n",
      "         -4.5857, -4.6636, -4.6739, -4.4398, -4.6611, -4.5116, -4.4199, -4.5176,\n",
      "         -4.5571, -4.7017, -4.3588, -4.8386, -4.6193, -4.5669, -4.7676, -4.3800,\n",
      "         -4.6780, -4.3707, -4.4784, -4.6790, -4.6769, -4.6252, -4.5628, -4.2464,\n",
      "         -4.5855, -4.4479, -4.4972, -4.6287, -4.5516, -4.8525, -4.6736, -4.5186,\n",
      "         -4.8114, -5.1366, -4.6802, -4.7348, -4.3553, -4.5578, -4.3930, -4.8697,\n",
      "         -4.7539, -4.4079, -4.7065, -4.6849, -4.9640, -4.2227, -4.4128, -4.7343,\n",
      "         -4.6074, -4.1687, -4.7111, -4.5992, -4.6321, -4.3118, -4.6903, -4.4015,\n",
      "         -4.5165]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : within\n",
      "target index is: [34] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1867, -4.3416, -4.7153, -4.8829, -4.5202, -4.8516, -4.4672, -4.0742,\n",
      "         -5.1569, -4.5739, -4.9967, -4.3913, -4.2801, -4.6221, -5.1845, -5.0716,\n",
      "         -4.5755, -4.5676, -4.7247, -4.6106, -4.5308, -4.7533, -4.7270, -4.9205,\n",
      "         -4.4585, -4.9378, -4.2478, -4.3605, -4.1303, -4.5144, -4.5166, -4.6681,\n",
      "         -4.9698, -4.8817, -4.8409, -5.0172, -4.7885, -4.3663, -4.5710, -4.5245,\n",
      "         -4.6900, -4.6673, -4.4272, -4.3724, -4.3323, -4.0102, -4.7060, -4.7793,\n",
      "         -4.6186, -4.7578, -4.6623, -4.1929, -4.6771, -4.6380, -4.5402, -4.6649,\n",
      "         -4.5487, -4.1722, -4.4452, -4.9292, -4.8407, -4.5968, -4.5064, -4.4483,\n",
      "         -4.3572, -4.9630, -4.9387, -4.5402, -4.4845, -4.1746, -4.4500, -4.6251,\n",
      "         -4.7705, -4.7720, -4.6817, -4.8873, -4.5406, -4.0386, -4.2805, -5.0545,\n",
      "         -4.2538, -4.7488, -4.6253, -4.9419, -4.9013, -4.6454, -4.6921, -4.3826,\n",
      "         -5.1342, -4.6228, -4.4970, -4.4424, -4.8205, -4.5673, -4.4273, -4.5584,\n",
      "         -4.4105]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thine\n",
      "target index is: [56] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1460, -4.9361, -4.1278, -4.6002, -4.0674, -4.7248, -4.8338, -4.3274,\n",
      "         -4.7143, -4.8735, -4.7516, -4.7761, -4.6867, -4.6996, -4.7834, -4.6873,\n",
      "         -4.6088, -4.7596, -4.5026, -5.0023, -4.8363, -4.6091, -4.8023, -4.4571,\n",
      "         -4.2894, -4.7569, -4.6477, -4.5246, -4.3229, -4.3852, -4.3604, -4.5418,\n",
      "         -4.6293, -4.5645, -4.6917, -4.8886, -4.3829, -4.8642, -4.6438, -4.7134,\n",
      "         -5.0180, -4.3109, -4.9558, -4.2572, -4.8407, -4.3063, -4.6191, -4.4778,\n",
      "         -4.7625, -4.3160, -4.5508, -4.6889, -5.1537, -4.5851, -4.9135, -4.6162,\n",
      "         -4.2031, -4.2917, -4.4139, -4.2961, -4.7366, -4.5716, -4.6247, -4.0736,\n",
      "         -4.7754, -4.4938, -5.0720, -4.7765, -4.9126, -5.0187, -4.4906, -4.4863,\n",
      "         -5.2601, -5.0124, -4.5977, -4.8067, -4.6247, -4.0814, -4.3737, -4.8356,\n",
      "         -4.4729, -4.0606, -4.6816, -4.8142, -4.6994, -4.6269, -4.4180, -4.5751,\n",
      "         -5.2788, -4.2994, -4.4003, -4.3969, -4.4067, -4.8056, -4.2349, -4.7168,\n",
      "         -4.5054]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : own\n",
      "target index is: [92] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4030, -4.4268, -4.4771, -4.9600, -3.7355, -4.4363, -4.7042, -4.6434,\n",
      "         -4.9228, -5.0534, -4.8435, -4.6163, -5.0761, -4.7783, -4.7946, -4.7342,\n",
      "         -4.6069, -5.1728, -4.5221, -4.3273, -4.4880, -4.0510, -4.7111, -4.5704,\n",
      "         -4.7610, -4.7753, -4.4890, -4.5885, -4.5623, -5.0760, -4.2028, -4.8350,\n",
      "         -4.6521, -4.4508, -4.2140, -4.8873, -4.5867, -5.1394, -4.8168, -4.8601,\n",
      "         -4.5106, -4.7759, -5.0044, -4.2604, -4.8954, -4.4098, -4.6149, -4.5153,\n",
      "         -4.7711, -4.7241, -4.6150, -4.7945, -4.6126, -4.6183, -4.9635, -4.2282,\n",
      "         -4.8700, -4.3526, -4.4886, -4.6049, -4.4866, -4.6685, -5.0927, -3.8475,\n",
      "         -4.8049, -4.5099, -5.1332, -4.6234, -4.6363, -4.9824, -4.4593, -4.5527,\n",
      "         -4.5504, -5.0516, -4.4284, -4.6236, -4.7134, -4.6058, -4.4740, -4.4348,\n",
      "         -4.7221, -4.1949, -4.8770, -4.8343, -4.2349, -4.5076, -4.1604, -4.6063,\n",
      "         -4.8292, -4.4070, -4.3540, -4.3662, -4.7193, -4.6594, -3.9364, -4.6740,\n",
      "         -4.3340]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : deep\n",
      "target index is: [76] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3193, -4.6660, -4.6806, -4.8149, -4.2803, -4.5421, -4.3690, -4.2480,\n",
      "         -4.6984, -4.9182, -5.0230, -4.3592, -4.4976, -4.4747, -4.6505, -4.4373,\n",
      "         -4.0991, -4.7482, -4.6410, -4.5991, -4.5820, -4.6179, -4.5980, -4.6373,\n",
      "         -4.4695, -4.6390, -4.5896, -4.5040, -4.4839, -4.6205, -4.6368, -4.8658,\n",
      "         -4.8882, -4.9154, -4.7358, -4.8191, -4.7899, -4.4452, -5.1285, -4.7570,\n",
      "         -4.7340, -4.5080, -4.8757, -4.3977, -4.5217, -4.3440, -4.6362, -4.7913,\n",
      "         -4.5169, -4.4396, -4.5868, -4.3248, -4.7871, -4.3569, -4.8951, -4.6675,\n",
      "         -4.4295, -4.6397, -4.7522, -4.6310, -4.8079, -4.6131, -4.4748, -3.9844,\n",
      "         -4.6018, -4.4802, -4.9156, -4.4551, -4.5834, -4.6377, -4.4401, -4.6766,\n",
      "         -4.5286, -4.3980, -4.4878, -4.6150, -4.6745, -4.5714, -4.5459, -4.7213,\n",
      "         -4.0402, -4.5232, -4.6768, -4.7210, -4.4753, -4.3911, -4.7916, -4.7428,\n",
      "         -5.0118, -4.4789, -4.5122, -4.7779, -4.6666, -4.6741, -4.2400, -4.5824,\n",
      "         -4.6078]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : sunken\n",
      "target index is: [91] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4036, -4.5278, -4.7189, -4.8677, -4.2189, -4.8877, -4.5890, -4.7849,\n",
      "         -4.7290, -4.4470, -4.9435, -4.5002, -4.8001, -4.6047, -4.6806, -4.8427,\n",
      "         -4.9001, -4.7985, -4.7661, -4.2991, -4.4909, -4.2398, -4.8737, -4.5580,\n",
      "         -4.5679, -4.8892, -4.3582, -4.6837, -4.3226, -4.6451, -4.8788, -4.6579,\n",
      "         -4.6444, -4.8309, -4.7359, -5.0143, -4.7229, -4.6772, -4.7730, -4.2484,\n",
      "         -4.8190, -4.7467, -4.8219, -4.3637, -4.4947, -4.6018, -4.7026, -4.5700,\n",
      "         -4.3636, -4.9003, -3.9186, -5.2460, -4.3314, -4.4783, -4.7688, -4.2353,\n",
      "         -4.8334, -4.4565, -4.3801, -4.5153, -4.5142, -4.3455, -4.6649, -4.0213,\n",
      "         -4.5185, -4.6050, -4.9791, -4.5919, -4.6517, -4.5451, -4.4647, -4.6660,\n",
      "         -4.8521, -4.7421, -4.5882, -5.0124, -4.1790, -4.6124, -4.4547, -4.5552,\n",
      "         -4.6130, -4.1978, -4.9249, -4.5925, -4.7917, -4.2604, -4.7870, -4.8721,\n",
      "         -4.7787, -4.3093, -4.3872, -4.7180, -4.5234, -4.3758, -4.5225, -4.2540,\n",
      "         -4.3782]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : eyes,\n",
      "target index is: [58] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2529, -4.5184, -5.0663, -5.3299, -3.9023, -4.6410, -4.3377, -4.5050,\n",
      "         -4.7234, -4.6232, -5.1097, -4.6519, -4.7824, -4.5863, -4.6306, -4.6623,\n",
      "         -4.6018, -4.6998, -5.0116, -4.5277, -4.7204, -4.3153, -4.9423, -4.6433,\n",
      "         -4.5079, -4.8620, -4.4616, -4.3915, -4.3197, -4.7114, -4.7626, -4.5609,\n",
      "         -4.6408, -5.1135, -4.6007, -4.7047, -4.5032, -4.4581, -5.1231, -4.3241,\n",
      "         -4.5836, -4.3492, -4.7894, -4.4447, -4.5796, -4.3534, -4.8812, -4.4584,\n",
      "         -4.4918, -5.0325, -4.3242, -4.9975, -4.4992, -4.2962, -4.4991, -4.6672,\n",
      "         -4.5829, -4.7225, -4.6319, -4.3955, -4.5884, -4.2817, -4.1287, -4.4899,\n",
      "         -4.2452, -4.6554, -4.6614, -4.5731, -4.6294, -4.2504, -4.5252, -4.6506,\n",
      "         -4.9011, -4.7586, -4.7792, -4.7744, -4.3956, -4.5174, -4.5242, -4.7282,\n",
      "         -4.4007, -4.5134, -4.9374, -4.9037, -4.9017, -4.0112, -4.6610, -4.6730,\n",
      "         -4.6992, -4.4844, -4.7760, -4.6652, -4.8591, -4.1965, -4.7093, -4.5902,\n",
      "         -4.2461]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Were\n",
      "target index is: [37] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2529, -4.5314, -4.6873, -4.6407, -4.2352, -4.6949, -4.3768, -4.2658,\n",
      "         -4.7954, -4.9072, -4.5983, -4.4379, -4.5283, -4.8512, -4.9914, -4.6703,\n",
      "         -4.7369, -4.5331, -4.6422, -4.7232, -4.3226, -4.4376, -4.8470, -5.0376,\n",
      "         -4.2633, -4.9248, -4.5875, -4.4047, -4.2248, -4.4024, -4.6324, -4.6622,\n",
      "         -4.5683, -4.9046, -4.3633, -4.8288, -4.8494, -4.3755, -4.7664, -4.3794,\n",
      "         -4.7006, -4.5380, -4.7057, -4.6922, -4.5606, -4.2305, -4.2410, -4.7910,\n",
      "         -4.4680, -4.8850, -4.7267, -4.3347, -4.8061, -4.5224, -4.4655, -4.4770,\n",
      "         -4.3823, -4.3234, -4.4746, -4.8777, -4.6297, -4.1559, -4.5554, -4.3602,\n",
      "         -4.4851, -4.6922, -4.5912, -4.3676, -4.6688, -4.1738, -4.5385, -4.6106,\n",
      "         -4.6738, -5.1221, -4.9052, -4.9210, -4.6305, -4.2715, -4.5912, -4.8846,\n",
      "         -4.5565, -4.7316, -4.7754, -4.8007, -4.6155, -4.3481, -4.4686, -4.8143,\n",
      "         -4.8870, -4.4195, -4.7948, -4.5035, -4.6358, -4.5561, -4.8615, -4.6983,\n",
      "         -4.6213]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : an\n",
      "target index is: [74] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4895, -4.6961, -4.6879, -4.4948, -4.1025, -4.9801, -4.6274, -4.5520,\n",
      "         -4.7339, -4.5075, -4.9859, -4.7248, -4.8439, -4.8918, -4.7881, -4.8572,\n",
      "         -4.8279, -4.5783, -4.6649, -4.6950, -4.3833, -4.0862, -4.7669, -4.8962,\n",
      "         -4.3938, -5.2037, -4.3474, -4.2118, -4.6451, -4.3743, -4.8391, -4.5603,\n",
      "         -4.8495, -4.9656, -4.3933, -4.7120, -4.7563, -4.5975, -4.7783, -4.4812,\n",
      "         -4.9144, -4.7405, -4.5777, -4.5309, -4.4079, -4.4357, -4.5369, -4.5696,\n",
      "         -4.3730, -5.0002, -4.4268, -4.4705, -4.6204, -4.4187, -4.4376, -4.3277,\n",
      "         -4.4641, -4.2950, -4.2030, -4.8329, -4.5245, -4.5334, -4.6027, -4.3712,\n",
      "         -4.5926, -4.3605, -4.8408, -4.2976, -4.7003, -4.5655, -4.4241, -4.6923,\n",
      "         -4.8512, -4.8123, -5.0255, -5.1024, -4.3231, -4.2694, -4.3952, -4.8839,\n",
      "         -4.3348, -4.6178, -4.4717, -4.8111, -4.5313, -4.2483, -4.6646, -5.0525,\n",
      "         -4.8147, -4.6019, -4.3463, -4.4595, -4.5600, -4.5771, -4.6261, -4.4810,\n",
      "         -4.3634]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : all-eating\n",
      "target index is: [60] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4687, -4.5741, -4.8538, -4.7430, -3.9406, -4.7065, -4.7115, -4.4265,\n",
      "         -4.8345, -4.4544, -5.0157, -4.6850, -4.8962, -4.6013, -4.7236, -4.6780,\n",
      "         -4.4742, -4.4356, -4.8460, -4.4895, -4.7319, -4.5807, -4.8047, -4.8913,\n",
      "         -4.6666, -4.9178, -4.6968, -4.2868, -4.2598, -4.4290, -4.5372, -4.5479,\n",
      "         -4.8207, -4.9613, -4.3526, -4.7230, -4.2832, -4.9138, -4.8417, -4.6349,\n",
      "         -4.7537, -4.4389, -4.4777, -4.5620, -4.3424, -4.4599, -4.5570, -4.6523,\n",
      "         -4.6726, -4.8536, -4.5202, -4.8457, -4.8271, -4.2618, -4.6780, -4.7682,\n",
      "         -4.3363, -4.3848, -4.6478, -4.4840, -4.6538, -4.6049, -4.4863, -4.4764,\n",
      "         -4.4428, -4.3814, -4.5603, -4.3043, -4.7409, -4.5928, -4.4289, -4.3041,\n",
      "         -5.0660, -4.8775, -4.7659, -4.8166, -4.3223, -4.3684, -4.3986, -5.0353,\n",
      "         -4.4094, -4.3378, -4.3218, -4.9187, -5.0121, -4.0290, -4.7458, -4.5722,\n",
      "         -4.8631, -4.2635, -4.5089, -4.6766, -4.7358, -4.4814, -4.6078, -4.5461,\n",
      "         -4.5612]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : shame,\n",
      "target index is: [41] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6962, -4.7338, -4.8808, -4.5309, -4.1403, -4.5954, -4.6247, -4.4753,\n",
      "         -4.5970, -4.6402, -4.5609, -4.5089, -4.8722, -4.7299, -4.7787, -4.4799,\n",
      "         -4.4672, -4.9142, -4.5746, -4.4804, -4.5802, -4.2157, -4.6760, -4.6047,\n",
      "         -4.5183, -4.9769, -4.3607, -4.4970, -4.5014, -4.6166, -4.4411, -5.0304,\n",
      "         -5.0817, -4.8273, -4.5567, -4.7006, -4.4842, -5.0492, -4.8019, -4.7377,\n",
      "         -4.8009, -4.3786, -4.4827, -4.5686, -4.4438, -4.4915, -4.6136, -4.6510,\n",
      "         -4.4269, -4.6402, -4.8705, -4.2383, -4.8078, -4.3356, -4.8821, -4.1790,\n",
      "         -4.4964, -4.2623, -4.4397, -4.5133, -4.6435, -5.0192, -4.7241, -4.2273,\n",
      "         -4.8008, -4.2578, -5.0337, -4.5286, -4.6556, -4.6791, -4.0029, -4.4882,\n",
      "         -4.7484, -4.5901, -4.6261, -4.8709, -4.8247, -4.3443, -4.8077, -4.8285,\n",
      "         -4.6556, -4.4785, -4.4411, -4.5698, -4.3460, -4.4850, -4.3794, -4.7547,\n",
      "         -4.7738, -4.2028, -4.6681, -4.4191, -4.7300, -4.6548, -4.5235, -4.7271,\n",
      "         -4.4513]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : and\n",
      "target index is: [44] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6823, -4.4785, -4.5769, -4.6462, -4.2074, -4.7442, -4.5082, -4.4277,\n",
      "         -4.7129, -4.8068, -4.4697, -4.4762, -4.8460, -4.8200, -4.4733, -4.5230,\n",
      "         -4.6188, -4.9167, -4.6486, -4.5208, -4.3647, -4.3280, -4.4374, -4.4668,\n",
      "         -4.5480, -4.7049, -4.3479, -4.4456, -4.6309, -4.5756, -4.6456, -4.8423,\n",
      "         -4.7956, -4.7803, -4.4010, -4.5000, -4.7763, -4.9247, -4.5960, -4.5486,\n",
      "         -4.8005, -4.6845, -4.7831, -4.5188, -4.5380, -4.6150, -4.3769, -4.5764,\n",
      "         -4.2969, -4.5348, -4.5967, -4.5902, -4.5796, -4.3937, -4.8987, -4.4877,\n",
      "         -4.7776, -4.6512, -4.6130, -4.7049, -4.8114, -4.7148, -4.8275, -4.2089,\n",
      "         -4.9335, -4.4358, -4.8779, -4.4022, -4.6642, -4.8507, -4.3227, -4.8359,\n",
      "         -4.6098, -4.6108, -4.4134, -4.7390, -4.5569, -4.4858, -4.6791, -4.4238,\n",
      "         -4.4468, -4.3609, -4.6516, -4.6435, -4.6157, -4.3198, -4.6009, -4.8210,\n",
      "         -4.8680, -4.1552, -4.7760, -4.7549, -4.3205, -4.3748, -4.4451, -4.4053,\n",
      "         -4.5716]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thriftless\n",
      "target index is: [43] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3563, -4.4316, -4.5492, -4.7378, -4.1224, -4.5548, -4.6597, -4.4924,\n",
      "         -4.7442, -4.5342, -4.9662, -4.3748, -4.7539, -4.5895, -4.6400, -4.9280,\n",
      "         -4.8733, -4.5552, -4.9043, -4.2060, -4.6988, -4.8258, -4.6073, -4.5803,\n",
      "         -4.8380, -4.7520, -4.5456, -4.5033, -4.1685, -4.7589, -4.6449, -4.5067,\n",
      "         -4.7378, -4.6027, -4.6325, -5.0474, -4.6316, -4.9045, -4.5377, -4.4874,\n",
      "         -4.5608, -4.5796, -4.7001, -4.2007, -4.4838, -4.2865, -4.5036, -4.1541,\n",
      "         -4.5555, -4.7105, -4.8427, -4.9493, -4.6015, -4.6688, -4.9446, -4.7701,\n",
      "         -4.4071, -4.4236, -4.5265, -4.6925, -4.5633, -4.6696, -4.5967, -4.4137,\n",
      "         -4.6832, -4.8232, -4.8627, -4.4240, -4.4459, -4.7516, -4.2234, -4.7112,\n",
      "         -4.7759, -5.0538, -4.5891, -4.5754, -4.4270, -4.4828, -4.3984, -4.3930,\n",
      "         -4.6981, -4.2937, -4.5158, -4.7610, -5.0625, -4.2995, -4.5062, -4.5427,\n",
      "         -5.2554, -4.4703, -4.7187, -4.4672, -4.4937, -4.5423, -4.1176, -4.2857,\n",
      "         -4.6259]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : praise.\n",
      "target index is: [94] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-3.9307, -5.0580, -4.7003, -5.1496, -3.7579, -4.7148, -4.8380, -4.4079,\n",
      "         -4.6692, -5.0139, -4.6323, -4.2632, -4.3940, -4.5317, -4.8461, -4.5855,\n",
      "         -4.9066, -5.0842, -4.7085, -4.5362, -4.7743, -4.0899, -5.1672, -4.9769,\n",
      "         -4.3459, -4.8732, -4.4872, -4.1337, -3.9226, -4.8753, -4.5727, -4.8119,\n",
      "         -4.8973, -4.8374, -4.4619, -5.2940, -4.6667, -4.6286, -4.9855, -4.9539,\n",
      "         -4.6749, -4.3586, -4.8913, -4.6091, -4.7154, -4.4402, -4.8948, -4.6686,\n",
      "         -4.7141, -4.8490, -4.3219, -4.7917, -4.4531, -4.6627, -4.8977, -4.5238,\n",
      "         -3.9513, -4.3513, -4.5206, -4.6752, -4.4143, -4.3680, -4.3374, -4.3724,\n",
      "         -4.5695, -4.6761, -5.0083, -5.0217, -4.8736, -4.8075, -4.2021, -4.3299,\n",
      "         -4.8405, -5.0580, -4.5735, -4.5351, -4.6919, -4.0281, -4.3421, -4.4285,\n",
      "         -4.5204, -4.2001, -5.1909, -5.0374, -4.1136, -4.6360, -4.3159, -4.7921,\n",
      "         -5.2209, -4.9339, -5.0069, -4.2797, -4.7091, -4.3733, -4.5490, -4.4417,\n",
      "         -4.4950]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : How\n",
      "target index is: [12] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1612, -4.7229, -4.4707, -5.0244, -4.0393, -5.0073, -4.6019, -4.3524,\n",
      "         -5.1474, -4.9724, -5.0447, -5.0775, -4.7347, -4.5207, -5.3448, -5.1167,\n",
      "         -4.8539, -4.4010, -4.7781, -4.7494, -4.6272, -4.8756, -4.7778, -5.0143,\n",
      "         -4.3631, -5.0857, -4.5883, -4.1964, -4.2901, -4.5855, -4.3045, -3.9709,\n",
      "         -4.6647, -4.7657, -4.4512, -5.2018, -4.5742, -4.5068, -4.5400, -4.5382,\n",
      "         -4.3511, -4.8561, -4.8274, -4.2264, -4.6170, -4.0206, -4.5057, -4.1744,\n",
      "         -5.0118, -4.5480, -4.3664, -4.7881, -4.6559, -4.7852, -4.5395, -4.8185,\n",
      "         -4.4041, -4.3706, -4.2990, -4.6535, -4.6534, -4.2733, -4.2751, -4.2397,\n",
      "         -4.5240, -4.9238, -4.6158, -4.3741, -4.2220, -4.4719, -4.5620, -4.3776,\n",
      "         -5.2992, -5.2767, -4.9252, -4.7838, -4.5305, -4.1045, -4.2300, -4.5906,\n",
      "         -4.5602, -4.9830, -4.7057, -5.1441, -5.0037, -4.1309, -4.1975, -4.8357,\n",
      "         -5.5344, -4.4752, -4.4654, -4.1678, -4.8076, -4.8705, -4.3821, -4.7970,\n",
      "         -4.5904]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : much\n",
      "target index is: [68] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4271, -4.9929, -4.6228, -4.4609, -3.3818, -4.4719, -4.7208, -4.2740,\n",
      "         -4.9995, -4.5610, -4.4632, -4.4733, -4.8067, -4.7244, -5.0171, -4.8032,\n",
      "         -4.8237, -4.9035, -4.1327, -4.8450, -4.7577, -4.1114, -4.9698, -4.8193,\n",
      "         -4.4623, -5.1300, -4.4800, -4.3891, -4.6078, -4.6028, -4.2339, -4.9833,\n",
      "         -4.6892, -4.5767, -4.4458, -5.3178, -4.4370, -5.0918, -4.6497, -4.9680,\n",
      "         -4.8655, -4.5764, -4.9233, -4.6540, -4.8223, -4.4185, -4.6868, -5.1465,\n",
      "         -4.9813, -4.5955, -4.9440, -4.3962, -5.0395, -4.1791, -4.6281, -4.0215,\n",
      "         -4.2723, -3.9204, -4.2609, -4.1643, -4.5362, -4.7836, -4.5574, -3.8980,\n",
      "         -4.6730, -4.4157, -4.6566, -4.5666, -5.1129, -4.7350, -4.4821, -4.3659,\n",
      "         -5.4730, -5.0222, -4.6092, -5.0708, -4.8623, -4.1760, -4.2745, -5.1293,\n",
      "         -4.7945, -4.1631, -4.9703, -4.8829, -4.3748, -4.5649, -4.6031, -4.8751,\n",
      "         -5.3076, -4.4983, -4.8795, -4.1674, -4.6391, -4.6453, -4.3562, -5.1651,\n",
      "         -4.4298]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : more\n",
      "target index is: [4] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3063, -4.8055, -4.7193, -4.4101, -4.1509, -4.6005, -4.8361, -4.4404,\n",
      "         -4.8936, -4.4806, -4.8626, -4.2964, -4.7124, -4.3611, -4.8356, -4.8053,\n",
      "         -4.6076, -4.7916, -4.7043, -4.6446, -4.4733, -4.4881, -4.6413, -4.6303,\n",
      "         -4.5577, -4.8187, -4.5814, -4.4572, -4.4137, -4.5727, -4.7499, -4.6847,\n",
      "         -4.8704, -4.6015, -4.9378, -5.0143, -4.8977, -4.7004, -4.7357, -4.6433,\n",
      "         -4.6129, -4.5543, -4.5726, -4.5127, -4.0677, -4.2721, -4.5292, -4.7222,\n",
      "         -4.7068, -4.5187, -4.9105, -4.3028, -4.7583, -4.3892, -4.8038, -4.4355,\n",
      "         -4.4764, -4.1874, -4.4788, -4.6857, -4.6056, -4.5791, -4.6117, -3.9058,\n",
      "         -4.5162, -4.6366, -4.8567, -4.6199, -4.6438, -4.6254, -4.0599, -4.6102,\n",
      "         -4.6921, -4.4609, -4.5090, -4.8360, -4.6670, -4.4835, -4.5496, -4.8095,\n",
      "         -4.4327, -4.2613, -4.6746, -4.7698, -4.5516, -4.5555, -4.7658, -4.7469,\n",
      "         -5.2343, -4.4859, -4.7096, -4.6759, -4.6280, -4.5645, -4.0975, -4.9510,\n",
      "         -4.5245]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : praise\n",
      "target index is: [45] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3850, -4.5208, -4.6873, -5.1960, -4.0377, -4.6014, -4.4669, -4.2885,\n",
      "         -5.2174, -4.6266, -4.8310, -4.3313, -4.7330, -4.5147, -5.1241, -4.8310,\n",
      "         -4.6874, -4.5032, -4.7977, -4.2364, -4.6863, -4.7091, -4.8603, -4.7187,\n",
      "         -4.8576, -4.9154, -4.5388, -4.2745, -4.2774, -4.6312, -4.2757, -4.4533,\n",
      "         -4.8825, -4.9001, -4.4698, -5.1803, -4.3188, -5.0004, -4.5395, -4.6157,\n",
      "         -4.4860, -4.5852, -4.7063, -4.2199, -4.6274, -4.1677, -4.7810, -4.4230,\n",
      "         -4.8035, -5.1294, -4.2524, -5.1018, -4.4132, -4.7892, -4.6217, -4.6451,\n",
      "         -4.3682, -4.3933, -4.4557, -4.4852, -4.5416, -4.2875, -4.6103, -4.4502,\n",
      "         -4.3339, -4.6194, -5.0475, -4.6107, -4.5261, -4.3291, -4.6963, -4.6921,\n",
      "         -5.2123, -5.2096, -4.6864, -4.9108, -4.4785, -4.1127, -4.1655, -4.4550,\n",
      "         -4.8219, -4.6480, -4.7207, -4.9991, -4.9881, -4.2416, -4.2470, -4.3125,\n",
      "         -5.1059, -4.7306, -4.5452, -4.0765, -5.0381, -4.5242, -4.6510, -4.3675,\n",
      "         -4.4089]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : deserv'd\n",
      "target index is: [66] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4221, -4.7284, -4.5196, -4.3382, -4.0351, -4.7388, -4.5584, -4.3466,\n",
      "         -4.8664, -4.8400, -4.4402, -4.7213, -4.7798, -4.7455, -4.9032, -4.8330,\n",
      "         -4.8581, -4.8464, -4.4797, -4.9437, -4.4280, -4.4598, -4.7370, -4.6578,\n",
      "         -4.2242, -5.1032, -4.6937, -4.5001, -4.3439, -4.6434, -4.2335, -4.7193,\n",
      "         -4.8111, -4.7972, -4.5634, -5.2394, -4.5079, -4.6862, -4.5368, -4.6119,\n",
      "         -4.7955, -4.6259, -4.8613, -4.5733, -4.7754, -4.3020, -4.7411, -4.5772,\n",
      "         -4.7688, -4.4825, -4.8528, -4.3033, -5.1163, -4.4641, -4.5838, -4.4947,\n",
      "         -4.0756, -4.0576, -4.2924, -4.4063, -4.6427, -4.4997, -4.5916, -4.2569,\n",
      "         -4.6434, -4.4643, -4.6223, -4.2987, -4.5174, -4.3424, -4.5488, -4.5200,\n",
      "         -5.2665, -4.9250, -4.8609, -4.9717, -4.9328, -3.9883, -4.4899, -4.8666,\n",
      "         -4.5620, -4.5105, -4.8843, -4.8539, -4.6684, -4.2956, -4.2030, -4.6452,\n",
      "         -5.1951, -4.3253, -4.4380, -4.5369, -4.7336, -4.7303, -4.2876, -4.8540,\n",
      "         -4.4362]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2559, -4.2430, -4.9338, -4.6774, -4.2304, -4.7442, -4.8566, -4.2144,\n",
      "         -5.0429, -4.7898, -5.3180, -4.5372, -4.4078, -4.6243, -4.6082, -4.8029,\n",
      "         -4.5037, -4.5384, -4.4102, -4.4266, -4.6440, -4.2950, -4.6896, -4.7197,\n",
      "         -4.3191, -5.0211, -4.3395, -4.4671, -4.5801, -4.6500, -4.7137, -4.7936,\n",
      "         -5.2485, -4.7482, -4.6363, -5.0944, -4.7391, -4.7995, -5.0126, -4.8146,\n",
      "         -4.8907, -4.7273, -4.7997, -4.6138, -4.7511, -4.0251, -4.8631, -4.9338,\n",
      "         -4.8727, -4.4915, -4.8480, -4.3374, -4.5180, -4.2311, -4.4853, -4.7759,\n",
      "         -4.3075, -4.1848, -4.5976, -4.5769, -4.7530, -4.6594, -4.1215, -4.4530,\n",
      "         -4.4721, -4.7422, -4.8902, -4.2442, -4.8178, -4.7726, -4.3496, -4.5558,\n",
      "         -4.7963, -4.8149, -4.7379, -4.6375, -4.3319, -4.3506, -4.1629, -4.7354,\n",
      "         -3.8956, -4.6704, -4.7649, -5.1052, -4.6413, -4.3915, -4.7033, -4.9073,\n",
      "         -4.7714, -4.4253, -4.5657, -4.7637, -4.9689, -4.3384, -3.8631, -4.9618,\n",
      "         -4.1883]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty's\n",
      "target index is: [80] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2953, -4.4852, -4.7064, -4.5498, -4.2248, -4.9445, -4.4919, -4.2951,\n",
      "         -4.4304, -5.1556, -4.9677, -4.0807, -4.6149, -4.7473, -4.6172, -4.7551,\n",
      "         -4.9106, -5.1759, -4.5210, -4.4236, -4.9485, -4.7613, -4.5504, -4.5043,\n",
      "         -4.2159, -4.6617, -4.6667, -4.4695, -3.8658, -4.5928, -4.8099, -4.5846,\n",
      "         -4.7162, -4.6275, -4.6789, -5.1511, -4.8608, -4.6236, -4.6665, -4.5416,\n",
      "         -4.6996, -4.2657, -4.9911, -4.0796, -4.4995, -4.1050, -4.4798, -4.4822,\n",
      "         -4.4989, -4.8980, -4.7696, -4.4528, -4.7529, -4.4029, -4.6303, -4.4203,\n",
      "         -4.3289, -4.2465, -4.7461, -5.0325, -4.8479, -4.1974, -4.5092, -4.1323,\n",
      "         -5.0439, -4.8194, -5.0686, -4.6914, -4.8081, -4.6123, -4.3339, -4.7931,\n",
      "         -4.5045, -4.8587, -4.7975, -4.9244, -5.1322, -4.0698, -4.3225, -4.4622,\n",
      "         -4.7519, -4.3211, -5.1995, -4.7265, -4.8819, -4.1026, -4.6186, -5.0098,\n",
      "         -5.0614, -4.5953, -5.1764, -4.4870, -4.5578, -4.5234, -4.2756, -4.3610,\n",
      "         -4.5842]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : use,\n",
      "target index is: [11] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1097, -4.6020, -5.0386, -5.3034, -3.7731, -5.0964, -4.7041, -4.6901,\n",
      "         -4.6887, -4.6254, -4.9359, -4.8038, -5.2252, -4.7148, -4.6908, -4.8728,\n",
      "         -5.0266, -4.4921, -4.7978, -4.2894, -4.8443, -4.2091, -5.1284, -4.6850,\n",
      "         -4.2986, -4.8821, -4.2188, -4.2522, -4.0624, -5.0459, -4.7105, -4.5680,\n",
      "         -4.8132, -4.7292, -4.9750, -5.1968, -5.0778, -4.7401, -5.0940, -4.7511,\n",
      "         -4.7036, -5.3455, -4.8437, -4.6283, -4.7091, -4.4561, -4.8292, -4.3591,\n",
      "         -4.4840, -4.8332, -3.9458, -5.5210, -4.2414, -4.5362, -4.8924, -4.3308,\n",
      "         -4.5545, -4.3668, -4.3004, -4.2569, -4.6534, -4.2176, -4.3920, -3.7110,\n",
      "         -4.5727, -4.8407, -4.8955, -4.9569, -4.3628, -4.4940, -4.2575, -4.6813,\n",
      "         -5.0872, -4.4615, -4.7440, -4.8117, -4.0252, -4.6834, -4.5144, -4.5138,\n",
      "         -4.5179, -4.0441, -5.4885, -5.0963, -4.5902, -4.5866, -4.6683, -5.0413,\n",
      "         -4.7741, -4.3700, -4.2675, -4.4454, -4.6268, -4.0642, -4.2819, -4.6043,\n",
      "         -4.6190]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : If\n",
      "target index is: [61] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7041, -4.3233, -4.8729, -4.9853, -4.4942, -4.7931, -4.7109, -4.3045,\n",
      "         -4.6234, -4.7893, -4.7978, -4.1667, -4.7402, -4.4673, -4.8588, -4.8449,\n",
      "         -4.4157, -4.6292, -4.9153, -4.4708, -4.5168, -4.9285, -4.6944, -4.5986,\n",
      "         -4.5438, -4.8079, -4.5433, -4.2860, -4.3257, -4.4548, -4.4110, -4.7946,\n",
      "         -5.1965, -4.7428, -4.9536, -5.3623, -4.4154, -4.9200, -4.4670, -4.4900,\n",
      "         -4.2507, -4.8465, -4.2801, -4.4867, -4.1550, -4.3812, -4.5254, -4.8064,\n",
      "         -4.5580, -4.7823, -4.2836, -4.3931, -4.5797, -4.3872, -4.5444, -4.5239,\n",
      "         -4.6063, -4.3232, -4.8505, -4.6104, -4.6286, -4.2924, -4.4730, -3.7684,\n",
      "         -4.4262, -4.4108, -4.7208, -4.6672, -4.3031, -4.0042, -4.5085, -4.5899,\n",
      "         -4.8913, -4.8255, -5.0819, -5.0272, -4.8072, -4.0642, -4.6000, -4.7765,\n",
      "         -4.9918, -4.5830, -4.9213, -5.1336, -5.0019, -4.3186, -4.4277, -4.5755,\n",
      "         -5.0515, -4.1917, -4.6813, -4.8735, -4.9587, -4.2883, -4.6754, -4.7951,\n",
      "         -4.6392]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thou\n",
      "target index is: [22] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5310, -4.4339, -4.9580, -4.6310, -4.4258, -4.8918, -4.4154, -4.3904,\n",
      "         -4.4481, -4.7337, -4.6075, -4.4348, -4.7461, -4.9000, -4.5680, -4.5602,\n",
      "         -4.7578, -5.0808, -4.5211, -4.3830, -4.5703, -4.4497, -4.8019, -4.3612,\n",
      "         -4.2482, -4.5987, -4.4715, -4.6847, -4.5164, -4.7306, -4.9020, -4.9381,\n",
      "         -4.6750, -4.7806, -4.3752, -4.5012, -4.5445, -4.6617, -4.7203, -4.5283,\n",
      "         -5.0713, -4.1910, -4.8157, -4.7373, -4.4481, -4.4085, -4.3654, -4.4994,\n",
      "         -4.1503, -5.1282, -4.8694, -4.2891, -4.7258, -4.3935, -4.6898, -4.4582,\n",
      "         -4.5707, -4.4342, -4.5030, -4.7126, -4.7508, -4.4612, -4.3218, -4.4534,\n",
      "         -4.9228, -4.6343, -4.5577, -4.4792, -4.6183, -4.4385, -4.2091, -4.9741,\n",
      "         -4.5309, -4.7116, -4.6772, -4.8675, -4.4873, -4.3778, -4.5861, -4.4061,\n",
      "         -4.6097, -4.5862, -4.8488, -4.4540, -4.5438, -4.5568, -4.7186, -4.7304,\n",
      "         -4.8021, -4.3161, -4.9467, -4.4235, -4.5564, -4.5301, -4.6662, -4.5155,\n",
      "         -4.4959]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : couldst\n",
      "target index is: [47] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4726, -4.3651, -4.5083, -4.7886, -4.2339, -4.8012, -4.7757, -4.4127,\n",
      "         -4.5908, -4.7760, -4.6296, -4.5283, -4.6092, -4.8456, -4.6897, -4.3080,\n",
      "         -4.5648, -4.5207, -4.4659, -4.5754, -4.5232, -4.3364, -4.6845, -4.7785,\n",
      "         -4.2248, -4.5709, -4.4463, -4.6159, -4.3131, -4.6822, -4.5664, -4.8174,\n",
      "         -4.8162, -4.5304, -4.6376, -4.8335, -4.5865, -4.8018, -4.7415, -4.8487,\n",
      "         -4.5906, -4.7515, -4.7626, -4.6891, -4.5819, -4.5932, -4.6400, -4.7853,\n",
      "         -4.6053, -4.6159, -4.4971, -4.6564, -4.5654, -4.4923, -4.7431, -4.6574,\n",
      "         -4.4671, -4.4659, -4.4319, -4.5044, -4.7996, -4.5745, -4.4323, -4.1921,\n",
      "         -4.7485, -4.4850, -4.7951, -4.7281, -4.5060, -4.6043, -4.3731, -4.4408,\n",
      "         -4.7513, -4.7829, -4.7260, -4.6954, -4.3202, -4.4159, -4.6447, -4.6473,\n",
      "         -4.4531, -4.4170, -4.7866, -4.8259, -4.4983, -4.6206, -4.3779, -4.6828,\n",
      "         -4.6021, -4.3263, -4.5198, -4.7712, -4.6422, -4.2755, -4.4472, -4.5927,\n",
      "         -4.5914]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : answer\n",
      "target index is: [53] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3749, -4.7607, -4.7384, -4.7933, -4.2313, -4.5577, -4.6569, -4.2994,\n",
      "         -4.7870, -4.7515, -4.7230, -4.4396, -4.5196, -4.6862, -4.8174, -4.7015,\n",
      "         -4.2674, -4.6248, -4.3709, -4.7081, -4.5807, -4.3951, -4.5885, -4.5315,\n",
      "         -4.2611, -5.0282, -4.3378, -4.7768, -4.5884, -4.4989, -4.5449, -4.7543,\n",
      "         -4.8097, -4.7679, -4.4022, -4.9080, -4.5828, -4.3514, -4.7777, -4.7640,\n",
      "         -4.8035, -4.6613, -4.8018, -4.6693, -4.3782, -4.3363, -4.5288, -4.7200,\n",
      "         -4.7538, -4.3404, -4.7750, -4.4536, -4.7961, -4.3886, -4.5830, -4.5609,\n",
      "         -4.6185, -4.3877, -4.4276, -4.4361, -4.6222, -4.5732, -4.4474, -4.0347,\n",
      "         -4.5572, -4.6300, -4.8087, -4.6308, -4.6379, -4.5881, -4.4143, -4.6361,\n",
      "         -4.8016, -4.6581, -4.8287, -4.7491, -4.3764, -4.3348, -4.4280, -4.9077,\n",
      "         -4.3088, -4.6251, -4.6994, -4.8507, -4.6441, -4.6987, -4.5066, -4.5830,\n",
      "         -5.0903, -4.3190, -4.4217, -4.6914, -4.7477, -4.5351, -4.5173, -4.8161,\n",
      "         -4.3397]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : 'This\n",
      "target index is: [9] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4199, -4.7239, -4.8226, -4.7029, -3.6994, -4.6340, -4.3249, -4.3214,\n",
      "         -4.9277, -4.8389, -4.8944, -4.5863, -4.8835, -4.7703, -4.7575, -4.8050,\n",
      "         -4.4801, -4.8694, -4.6863, -4.5508, -4.4757, -4.3039, -4.7557, -4.4074,\n",
      "         -4.5457, -4.9957, -4.4470, -4.4489, -4.5510, -4.7857, -4.5507, -4.6978,\n",
      "         -4.5655, -4.9739, -4.3125, -4.6425, -4.5383, -4.7430, -4.8535, -4.3869,\n",
      "         -4.8278, -4.2127, -4.7401, -4.4076, -4.6791, -4.1982, -4.5291, -4.5446,\n",
      "         -4.5930, -4.8483, -4.9417, -4.5155, -4.9711, -4.0569, -4.4387, -4.2836,\n",
      "         -4.6436, -4.2795, -4.6776, -4.5642, -4.5091, -4.4732, -4.6823, -4.4811,\n",
      "         -4.4846, -4.6730, -4.4376, -4.2359, -4.6789, -4.7731, -4.4040, -4.6319,\n",
      "         -4.7804, -5.0654, -4.8764, -5.0215, -4.6612, -4.4141, -4.5092, -4.7826,\n",
      "         -4.7391, -4.4980, -4.7023, -4.7781, -4.6613, -4.1843, -4.4191, -4.8419,\n",
      "         -4.9411, -4.4266, -4.6691, -4.5028, -4.5999, -4.6957, -4.5451, -4.7038,\n",
      "         -4.3381]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : fair\n",
      "target index is: [21] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3633, -4.4551, -4.8950, -4.5827, -4.0876, -4.5565, -4.8242, -4.3008,\n",
      "         -4.6740, -4.4182, -4.8351, -4.4972, -4.5986, -4.6491, -4.7650, -4.5883,\n",
      "         -4.6462, -4.4697, -4.6288, -4.3606, -4.5673, -4.2748, -4.8604, -4.8918,\n",
      "         -4.4036, -4.7830, -4.4654, -4.4072, -4.3298, -4.6384, -4.6104, -4.7053,\n",
      "         -4.9719, -4.8311, -4.4864, -4.6584, -4.7706, -4.7914, -5.1372, -4.8258,\n",
      "         -4.7623, -4.5474, -4.4551, -4.7097, -4.4157, -4.2579, -4.6008, -4.8294,\n",
      "         -4.5737, -4.8739, -4.7364, -4.3184, -4.6999, -4.4047, -4.7125, -4.7037,\n",
      "         -4.2762, -4.3417, -4.5296, -4.5899, -4.6642, -4.5275, -4.5761, -4.4943,\n",
      "         -4.4667, -4.7168, -4.6772, -4.5658, -4.8135, -4.6358, -4.3752, -4.6457,\n",
      "         -4.5837, -4.8665, -4.5907, -4.6312, -4.4816, -4.5319, -4.5246, -4.7464,\n",
      "         -4.2992, -4.3484, -4.5329, -4.7243, -4.5779, -4.2611, -4.7674, -4.7575,\n",
      "         -4.7197, -4.3872, -4.8411, -4.8144, -4.7719, -4.2158, -4.3837, -4.6757,\n",
      "         -4.4129]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : child\n",
      "target index is: [5] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3762, -4.4552, -4.9564, -4.6436, -4.1253, -4.7644, -4.5493, -4.6842,\n",
      "         -4.7254, -4.4927, -4.9746, -4.5521, -4.8789, -4.7614, -4.7867, -4.8716,\n",
      "         -4.6014, -4.6701, -4.7929, -4.4933, -4.5525, -4.3552, -4.8321, -4.6382,\n",
      "         -4.6995, -5.2446, -4.5805, -4.4899, -4.1586, -4.7180, -4.4936, -4.8046,\n",
      "         -4.6893, -4.7324, -4.5641, -4.8055, -4.4526, -4.6497, -4.7135, -4.5308,\n",
      "         -4.6514, -4.4630, -4.5173, -4.4288, -4.5365, -4.2713, -4.7254, -4.5925,\n",
      "         -4.6021, -4.9062, -4.7768, -4.6145, -5.0164, -4.3906, -4.4238, -4.2445,\n",
      "         -4.3507, -4.1158, -4.5932, -4.7315, -4.5232, -4.4173, -4.7768, -4.4502,\n",
      "         -4.4422, -4.5650, -4.7451, -4.3228, -4.4477, -4.4007, -4.4279, -4.5780,\n",
      "         -4.8048, -4.9743, -4.9966, -5.2166, -4.7803, -4.2689, -4.4906, -4.7782,\n",
      "         -4.6019, -4.3884, -4.6625, -4.9726, -4.7226, -4.1505, -4.4046, -4.3037,\n",
      "         -4.8723, -4.4559, -4.4228, -4.4005, -4.6401, -4.5377, -4.6345, -4.5847,\n",
      "         -4.1864]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : of\n",
      "target index is: [57] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6002, -4.0773, -4.5785, -4.7147, -4.1154, -4.8047, -4.7977, -4.5498,\n",
      "         -4.7540, -4.8663, -5.1027, -4.5025, -4.5841, -4.5318, -4.6534, -4.5863,\n",
      "         -4.7684, -4.5528, -4.6831, -4.3849, -4.5133, -4.2186, -4.7643, -4.4438,\n",
      "         -4.2452, -4.6073, -4.4928, -4.4567, -4.2530, -4.7654, -4.7075, -4.9768,\n",
      "         -5.0565, -4.5906, -4.7079, -4.7257, -4.8687, -4.8837, -4.8194, -4.7474,\n",
      "         -4.7005, -4.4439, -4.5933, -4.5735, -4.4914, -4.2924, -4.8413, -4.9333,\n",
      "         -4.5316, -4.7595, -4.4953, -4.4837, -4.5618, -4.3116, -4.7769, -4.7297,\n",
      "         -4.4162, -4.4453, -4.4975, -4.5802, -4.8618, -4.8081, -4.4280, -4.3039,\n",
      "         -4.6297, -4.7435, -5.0576, -4.4479, -4.7908, -4.7032, -4.5360, -4.5634,\n",
      "         -4.6367, -4.9246, -4.6216, -4.7131, -4.5096, -4.4004, -4.5248, -4.7920,\n",
      "         -4.0866, -4.3770, -4.6058, -4.6580, -4.4663, -4.3273, -4.5419, -4.8320,\n",
      "         -4.5080, -4.2830, -4.8248, -4.8501, -4.6295, -4.2346, -4.1981, -4.7886,\n",
      "         -4.3405]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : mine\n",
      "target index is: [86] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.0976, -4.3477, -4.6071, -5.0300, -4.1554, -4.6399, -4.7942, -4.5074,\n",
      "         -4.6949, -4.7811, -5.0091, -4.2936, -4.8954, -4.5218, -4.5951, -4.8058,\n",
      "         -4.6679, -4.8665, -4.5821, -4.1911, -4.9355, -4.7347, -4.5619, -4.1169,\n",
      "         -4.5085, -4.4937, -4.6847, -4.4813, -4.2014, -4.6462, -4.5655, -4.9939,\n",
      "         -4.7758, -4.5400, -4.6571, -4.7059, -4.6495, -4.7372, -4.8095, -4.7450,\n",
      "         -4.9137, -4.4881, -4.7676, -4.5477, -4.7738, -4.1763, -4.8898, -4.6217,\n",
      "         -4.5582, -4.6003, -4.6555, -4.8761, -4.6012, -4.3674, -4.8238, -4.6742,\n",
      "         -4.3456, -4.4053, -4.6835, -4.5617, -4.6134, -4.5827, -4.4502, -4.3802,\n",
      "         -4.7685, -4.6393, -5.1604, -4.8202, -4.6439, -4.7857, -4.2814, -4.5937,\n",
      "         -4.5868, -4.8868, -4.6248, -4.6082, -4.5396, -4.2196, -4.4662, -4.4938,\n",
      "         -4.6097, -4.2594, -4.6941, -4.7755, -4.6834, -4.4490, -4.4143, -4.4259,\n",
      "         -4.9028, -4.2576, -4.4801, -4.6157, -4.4976, -4.5185, -4.3136, -4.6093,\n",
      "         -4.4063]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Shall\n",
      "target index is: [81] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2414, -4.3994, -4.5732, -5.0858, -4.0631, -4.7250, -4.6666, -4.5650,\n",
      "         -4.7086, -4.9440, -4.7638, -4.3048, -4.6479, -4.7596, -4.7151, -4.6259,\n",
      "         -4.3436, -4.7108, -4.5084, -4.6373, -4.5938, -4.5251, -4.6712, -4.4054,\n",
      "         -4.3782, -4.5360, -4.3818, -4.4508, -4.4080, -4.8551, -4.1568, -5.0100,\n",
      "         -4.5742, -4.6618, -4.5750, -4.9976, -4.4526, -4.6367, -4.8512, -4.9679,\n",
      "         -4.6487, -4.7857, -4.7540, -4.6328, -4.6082, -4.2103, -4.5168, -4.7126,\n",
      "         -4.7578, -4.6587, -4.5589, -4.6142, -4.6443, -4.4392, -4.5839, -5.0007,\n",
      "         -4.6077, -4.5972, -4.5448, -4.4951, -4.7081, -4.5304, -4.6428, -4.1764,\n",
      "         -4.7918, -4.7638, -4.7931, -4.5726, -4.5124, -4.3790, -4.7146, -4.6585,\n",
      "         -4.8207, -4.7966, -4.7235, -4.5310, -4.5833, -4.1923, -4.4191, -4.5072,\n",
      "         -4.4814, -4.3666, -4.7603, -5.0675, -4.5302, -4.5565, -4.1839, -4.5893,\n",
      "         -4.9052, -4.3997, -4.5221, -4.7807, -4.7841, -4.3872, -4.1513, -4.6840,\n",
      "         -4.4666]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : sum\n",
      "target index is: [70] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3051, -4.3897, -4.6935, -4.8316, -4.2000, -4.8789, -4.5072, -4.3699,\n",
      "         -4.6617, -4.7671, -4.7114, -4.3114, -4.5690, -4.9707, -4.7934, -4.6951,\n",
      "         -4.5288, -5.1693, -4.6983, -4.6347, -4.5976, -4.3125, -4.6950, -4.5896,\n",
      "         -4.3081, -4.9776, -4.3092, -4.4501, -4.4793, -4.6422, -4.5748, -4.8962,\n",
      "         -4.8697, -4.9577, -4.3304, -4.4848, -4.7295, -4.4711, -4.6863, -4.5959,\n",
      "         -5.0709, -4.4203, -4.5901, -4.5229, -4.3979, -4.2390, -4.3972, -4.6153,\n",
      "         -4.3322, -4.8021, -4.6120, -4.1282, -4.9484, -4.4553, -4.6858, -4.5554,\n",
      "         -4.6217, -4.4232, -4.6032, -4.9435, -4.8024, -4.5981, -4.6943, -4.3448,\n",
      "         -4.9284, -4.6104, -4.8512, -4.3898, -4.5802, -4.6098, -4.3449, -4.8270,\n",
      "         -4.5536, -4.8312, -4.6588, -4.7960, -4.5484, -4.1698, -4.5236, -4.8162,\n",
      "         -4.3067, -4.6719, -4.5427, -4.6453, -4.2641, -4.5696, -4.4908, -4.6843,\n",
      "         -5.0288, -4.4489, -4.6094, -4.5563, -4.5562, -4.7173, -4.4989, -4.4246,\n",
      "         -4.4191]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : my\n",
      "target index is: [90] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3905, -4.3814, -4.6054, -5.1593, -4.2475, -5.1522, -4.4825, -4.4956,\n",
      "         -4.7328, -4.6437, -5.1221, -4.5831, -4.7260, -4.7521, -4.3915, -4.6307,\n",
      "         -4.6313, -4.6836, -4.9581, -4.3171, -4.7882, -4.3197, -4.7201, -4.6151,\n",
      "         -4.3811, -4.9983, -4.2362, -4.4866, -4.1442, -4.6026, -4.6676, -4.8807,\n",
      "         -4.7925, -4.9328, -4.7360, -4.5695, -4.6851, -4.4048, -4.8792, -4.5346,\n",
      "         -4.9518, -4.7877, -4.8671, -4.4029, -4.8309, -4.3660, -4.8182, -4.6641,\n",
      "         -4.5558, -5.1796, -4.1313, -5.1001, -4.4282, -4.5662, -4.7338, -4.4091,\n",
      "         -4.5492, -4.4170, -4.3076, -5.0251, -4.5942, -4.3465, -4.4925, -4.3078,\n",
      "         -4.5982, -4.3562, -5.0534, -4.6080, -4.4107, -4.5216, -4.6189, -4.6334,\n",
      "         -4.7445, -4.7032, -4.7475, -5.0135, -4.3640, -4.3433, -4.2918, -4.6530,\n",
      "         -4.4087, -4.5112, -4.8228, -4.4442, -4.6362, -4.1651, -4.5226, -4.8603,\n",
      "         -4.4876, -4.6208, -4.3468, -4.5714, -4.7198, -4.3572, -4.6572, -4.3090,\n",
      "         -4.1824]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : count,\n",
      "target index is: [55] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5828, -4.2652, -4.7139, -4.9601, -4.5186, -4.9589, -4.6065, -4.4680,\n",
      "         -4.6225, -4.8867, -4.9605, -4.6645, -4.7006, -4.7604, -4.7327, -4.6519,\n",
      "         -4.5894, -4.5815, -4.8608, -4.6374, -4.6090, -4.6818, -4.8337, -4.4114,\n",
      "         -4.3831, -4.7031, -4.5380, -4.2208, -4.2928, -4.6159, -4.2304, -4.8858,\n",
      "         -5.0049, -4.8095, -4.8529, -4.6444, -4.5793, -4.8046, -4.7311, -4.5242,\n",
      "         -4.6152, -4.6598, -4.3953, -4.5909, -4.4230, -4.2543, -4.9870, -4.6710,\n",
      "         -4.6507, -4.9342, -4.2767, -4.6751, -4.7445, -4.3295, -4.6276, -4.4416,\n",
      "         -4.2288, -4.2135, -4.6546, -4.4563, -4.6086, -4.5289, -4.3312, -4.1731,\n",
      "         -4.5849, -4.4972, -4.9547, -4.4139, -4.2218, -4.1702, -4.4749, -4.5657,\n",
      "         -4.8230, -4.7776, -5.0147, -5.1169, -4.3302, -4.2467, -4.6005, -4.9083,\n",
      "         -4.6785, -4.7345, -4.8496, -4.8476, -4.7591, -4.2842, -4.1967, -4.5622,\n",
      "         -4.7781, -4.3550, -4.3111, -4.9408, -4.7924, -4.3029, -4.5829, -4.7278,\n",
      "         -4.4017]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : and\n",
      "target index is: [44] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6550, -4.4748, -4.7168, -4.6804, -4.2173, -4.9036, -4.3966, -4.2703,\n",
      "         -4.7487, -4.9915, -4.6546, -4.4962, -4.6605, -4.8894, -4.6629, -4.4081,\n",
      "         -4.3166, -4.8186, -4.5475, -4.6582, -4.4917, -4.2939, -4.4007, -4.5471,\n",
      "         -4.2055, -4.8339, -4.4587, -4.5058, -4.7764, -4.4638, -4.6235, -4.8418,\n",
      "         -4.7971, -4.8704, -4.3663, -4.2764, -4.9306, -4.8002, -4.8242, -4.6686,\n",
      "         -4.9864, -4.6346, -4.8541, -4.5440, -4.4339, -4.5441, -4.3093, -4.7794,\n",
      "         -4.2543, -4.5706, -4.6434, -4.3478, -4.7915, -4.2070, -4.5443, -4.6080,\n",
      "         -4.5561, -4.6080, -4.6914, -4.8114, -4.9775, -4.6955, -4.4106, -4.1583,\n",
      "         -4.9442, -4.4645, -4.7278, -4.1395, -4.6810, -4.8410, -4.5626, -4.9048,\n",
      "         -4.3684, -4.6438, -4.7770, -4.8364, -4.2944, -4.4793, -4.6327, -4.4690,\n",
      "         -4.3006, -4.5426, -4.7720, -4.7940, -4.6430, -4.4827, -4.6908, -4.8027,\n",
      "         -4.9662, -4.1474, -4.8445, -4.9305, -4.3476, -4.4532, -4.4980, -4.4541,\n",
      "         -4.5658]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : make\n",
      "target index is: [14] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4402, -4.2545, -4.7387, -5.1497, -4.3630, -4.6452, -4.5791, -4.4412,\n",
      "         -4.6754, -4.7003, -4.7679, -4.5647, -4.8209, -4.6368, -4.4258, -4.5926,\n",
      "         -4.6189, -4.7444, -4.7670, -4.1465, -4.8526, -4.6938, -4.8408, -4.4122,\n",
      "         -4.6870, -4.6970, -4.4312, -4.3760, -4.2762, -4.6804, -4.5702, -4.7971,\n",
      "         -4.8835, -4.7977, -4.4460, -4.4345, -4.5192, -4.9541, -4.8078, -4.6397,\n",
      "         -4.7212, -4.6507, -4.6146, -4.4661, -4.7153, -4.3745, -5.0862, -4.5205,\n",
      "         -4.4247, -4.9701, -4.2374, -4.8931, -4.2324, -4.5727, -5.0036, -4.2590,\n",
      "         -4.5400, -4.3456, -4.8198, -4.4761, -4.5928, -4.5773, -4.4129, -4.4603,\n",
      "         -4.6343, -4.4421, -5.2047, -4.9036, -4.4602, -4.5443, -4.2372, -4.7093,\n",
      "         -4.5801, -4.7888, -4.5283, -4.7823, -4.4252, -4.2891, -4.6312, -4.7236,\n",
      "         -4.6543, -4.6056, -4.6744, -4.7479, -4.6046, -4.4235, -4.4736, -4.5670,\n",
      "         -4.5135, -4.1926, -4.4926, -4.4149, -4.7864, -4.4353, -4.6401, -4.5199,\n",
      "         -4.3803]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : my\n",
      "target index is: [90] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3169, -4.2459, -4.8803, -5.0319, -4.2249, -4.9987, -4.3340, -4.4178,\n",
      "         -4.8141, -4.6811, -4.6808, -4.4052, -4.6167, -4.9775, -4.7716, -4.4868,\n",
      "         -4.4025, -4.8036, -4.7772, -4.6105, -4.7904, -4.1688, -4.6841, -4.9238,\n",
      "         -4.2408, -5.0273, -4.1918, -4.5422, -4.1772, -4.6886, -4.3675, -4.8988,\n",
      "         -4.6038, -4.7424, -4.7482, -4.6647, -4.8523, -4.3461, -5.0121, -4.8287,\n",
      "         -4.7158, -4.9294, -4.6344, -4.5848, -4.5286, -4.3242, -4.5680, -4.8859,\n",
      "         -4.6530, -4.7936, -4.5465, -4.6066, -4.6716, -4.6360, -4.5189, -4.7108,\n",
      "         -4.7589, -4.4775, -4.5115, -4.8716, -4.8161, -4.1454, -4.5018, -4.0540,\n",
      "         -4.7132, -4.8586, -4.8156, -4.5497, -4.4903, -4.0384, -4.7053, -4.7669,\n",
      "         -4.5912, -4.5553, -4.7770, -4.9088, -4.4423, -4.4836, -4.2802, -4.5559,\n",
      "         -4.4301, -4.5036, -4.9938, -4.7501, -4.5784, -4.6274, -4.6572, -4.5805,\n",
      "         -4.6099, -4.2738, -4.4886, -4.7662, -4.8298, -4.2569, -4.3681, -4.4666,\n",
      "         -4.3173]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : old\n",
      "target index is: [84] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.0868, -4.3647, -4.4135, -5.0271, -4.2971, -5.2514, -4.3829, -4.4171,\n",
      "         -4.5109, -4.9288, -4.9681, -4.7999, -4.2509, -4.8185, -4.9304, -4.4198,\n",
      "         -4.5283, -4.5621, -4.8611, -4.7462, -4.7041, -4.2802, -5.0518, -4.7642,\n",
      "         -3.9994, -4.8618, -4.3551, -4.5145, -3.9672, -4.7155, -4.6112, -4.6826,\n",
      "         -4.6428, -5.0025, -4.8803, -4.5997, -4.7984, -4.3191, -4.7409, -4.5683,\n",
      "         -4.8555, -4.5090, -4.7947, -4.2993, -4.5095, -4.4316, -4.8253, -4.5603,\n",
      "         -4.6148, -4.9142, -4.0819, -4.7367, -4.9075, -4.6792, -4.7113, -4.5619,\n",
      "         -4.2563, -4.5232, -4.4118, -4.8242, -4.9502, -4.3506, -4.3965, -4.3090,\n",
      "         -4.6663, -4.7419, -4.8813, -4.5801, -4.4806, -4.3767, -4.5921, -4.4523,\n",
      "         -4.7700, -4.8686, -4.7366, -4.9464, -4.3167, -4.3601, -4.5834, -4.8750,\n",
      "         -4.1139, -4.5761, -4.8377, -4.7558, -4.4963, -4.4958, -4.6166, -4.7841,\n",
      "         -4.8699, -4.5540, -4.5274, -4.6199, -4.6068, -4.4405, -4.8501, -4.3765,\n",
      "         -4.4277]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : excuse,'\n",
      "target index is: [64] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4758, -4.4317, -4.5222, -4.7958, -4.1869, -4.9230, -4.6097, -4.3586,\n",
      "         -4.7486, -4.8160, -4.7402, -4.6530, -4.4960, -4.4923, -4.8283, -4.6353,\n",
      "         -4.7176, -4.2809, -4.6487, -4.6103, -4.4032, -4.7092, -4.4427, -4.7699,\n",
      "         -4.2585, -4.7129, -4.5854, -4.5671, -4.3918, -4.2367, -4.6462, -4.6882,\n",
      "         -4.8931, -4.7714, -4.6537, -5.2359, -4.8232, -4.6767, -4.6023, -4.5265,\n",
      "         -4.3627, -4.7979, -4.8120, -4.6429, -4.5643, -4.6153, -4.5459, -4.4783,\n",
      "         -4.5051, -4.4604, -4.2905, -4.5181, -4.4704, -4.4954, -4.5707, -4.4249,\n",
      "         -4.6268, -4.4365, -4.3784, -4.6226, -4.9391, -4.5156, -4.5429, -3.7735,\n",
      "         -4.6874, -4.4272, -4.6715, -4.3674, -4.4861, -4.6549, -4.6198, -4.6175,\n",
      "         -4.9430, -4.8437, -4.8458, -4.6489, -4.6325, -4.5101, -4.3576, -4.5821,\n",
      "         -4.7222, -4.7173, -4.9521, -4.9319, -4.6762, -4.2311, -4.4312, -4.9632,\n",
      "         -4.8768, -4.1722, -4.4973, -4.7113, -4.5901, -4.5267, -4.6769, -4.5592,\n",
      "         -4.8850]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Proving\n",
      "target index is: [25] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4395, -4.6005, -4.9571, -4.7507, -4.4823, -4.6982, -4.6072, -4.4826,\n",
      "         -4.6091, -4.5702, -4.9351, -4.4131, -4.4448, -4.4932, -4.5449, -4.8672,\n",
      "         -4.6009, -4.8693, -4.4000, -4.5694, -4.5181, -4.4937, -4.6744, -4.5238,\n",
      "         -4.4154, -4.7184, -4.2356, -4.6026, -4.4442, -4.4581, -5.0649, -4.8181,\n",
      "         -4.8153, -4.8467, -4.9954, -5.0144, -4.4780, -4.7146, -4.6225, -4.3679,\n",
      "         -4.7776, -4.5886, -4.6231, -4.6903, -4.3154, -4.3804, -4.7563, -4.8123,\n",
      "         -4.4517, -4.8905, -4.2775, -4.5400, -4.5199, -4.1641, -4.5480, -4.2781,\n",
      "         -4.7089, -4.3721, -4.5397, -4.3650, -4.4944, -4.3202, -4.3939, -4.0503,\n",
      "         -4.4398, -4.5868, -4.7142, -4.7230, -4.9621, -4.1944, -4.0687, -4.5943,\n",
      "         -5.1151, -4.3190, -4.8313, -4.9730, -4.3659, -4.4632, -4.3980, -4.6061,\n",
      "         -4.6485, -4.6251, -4.9316, -4.8938, -4.8956, -4.5288, -5.1230, -5.0187,\n",
      "         -4.8529, -4.4194, -4.6095, -4.6866, -4.7283, -4.2195, -4.6396, -4.8302,\n",
      "         -4.3630]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : his\n",
      "target index is: [49] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6242, -4.3206, -4.9139, -5.0956, -4.2725, -4.6004, -4.2137, -4.3920,\n",
      "         -4.9904, -4.4689, -4.7359, -4.3115, -4.7365, -4.6751, -4.8999, -4.5325,\n",
      "         -4.5148, -4.4811, -4.7098, -4.3299, -4.4621, -4.3933, -4.4435, -4.6364,\n",
      "         -4.6309, -4.7848, -4.4278, -4.5793, -4.7281, -4.5541, -4.7110, -4.5876,\n",
      "         -4.7558, -4.8018, -4.5077, -4.6689, -4.4900, -4.8097, -4.7455, -4.3462,\n",
      "         -4.4179, -4.5065, -4.4748, -4.3188, -4.4738, -4.7066, -4.4758, -4.3780,\n",
      "         -4.3631, -5.1771, -4.4590, -4.7866, -4.3773, -4.3781, -4.6280, -4.5530,\n",
      "         -4.9162, -4.6891, -4.2573, -4.7025, -4.9191, -4.4825, -4.5238, -4.3788,\n",
      "         -4.4740, -4.6418, -4.5094, -4.4014, -4.6736, -4.3068, -4.7732, -4.9172,\n",
      "         -4.7435, -4.7729, -4.6949, -4.9162, -4.3763, -4.5308, -4.3135, -4.4997,\n",
      "         -4.7977, -4.6901, -4.8440, -4.5758, -4.9901, -4.3332, -4.7439, -4.6110,\n",
      "         -4.8335, -4.3093, -4.6089, -4.3155, -4.9380, -4.5550, -4.7051, -4.5775,\n",
      "         -4.5368]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty\n",
      "target index is: [0] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5441, -4.4903, -4.8441, -4.6772, -4.3916, -4.7157, -4.7095, -4.0930,\n",
      "         -4.7718, -4.4603, -4.6183, -4.3505, -4.3948, -4.7297, -4.7854, -4.7226,\n",
      "         -4.7093, -4.4807, -4.3357, -4.4871, -4.5862, -4.4736, -4.7057, -4.9318,\n",
      "         -4.2237, -5.2815, -4.3171, -4.7642, -4.0522, -4.4231, -4.6220, -4.6332,\n",
      "         -5.0004, -4.7165, -4.5282, -5.0351, -4.4678, -4.6020, -4.6425, -4.7727,\n",
      "         -4.7298, -4.6570, -4.7399, -4.7549, -4.6047, -4.4636, -4.7704, -5.0272,\n",
      "         -4.8653, -4.8039, -4.6860, -4.4522, -4.8335, -4.5942, -4.6699, -4.5785,\n",
      "         -4.2507, -4.0756, -4.4358, -4.3531, -4.6714, -4.5462, -4.4456, -4.4248,\n",
      "         -4.4301, -4.6921, -4.5970, -4.7404, -4.6599, -4.3417, -4.4856, -4.5124,\n",
      "         -5.1521, -4.6141, -4.9163, -4.8871, -4.4330, -4.2629, -4.2246, -4.8884,\n",
      "         -4.3775, -4.4483, -4.7021, -4.8326, -4.7769, -4.5125, -4.7097, -4.2946,\n",
      "         -4.7543, -4.5560, -4.6087, -4.5950, -4.8524, -4.3179, -4.6438, -4.6215,\n",
      "         -4.2482]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : by\n",
      "target index is: [62] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.0213, -4.6865, -4.6604, -4.6763, -3.8791, -4.7119, -4.4068, -4.0760,\n",
      "         -4.9064, -4.9263, -4.6986, -4.4637, -4.4040, -4.6966, -4.7647, -4.8047,\n",
      "         -4.4233, -4.6793, -4.5392, -4.8167, -4.7283, -4.4044, -4.8621, -4.7413,\n",
      "         -4.1368, -4.7888, -4.4969, -4.3960, -4.5427, -4.7232, -4.5474, -4.4517,\n",
      "         -4.5552, -4.9838, -4.5883, -5.1434, -4.8148, -4.2370, -4.7253, -4.3741,\n",
      "         -4.7027, -4.4597, -4.8587, -4.3623, -4.5265, -3.9249, -4.5292, -4.7610,\n",
      "         -4.8746, -4.5178, -4.7510, -4.3716, -4.8965, -4.3193, -4.4012, -4.4831,\n",
      "         -4.3191, -4.3582, -4.6980, -4.7687, -4.8438, -4.2487, -4.3617, -4.3808,\n",
      "         -4.5473, -4.8352, -4.5771, -4.2100, -4.9600, -4.6505, -4.7397, -4.7899,\n",
      "         -4.4979, -5.0366, -4.7218, -4.8105, -4.6528, -4.2961, -4.4314, -5.0187,\n",
      "         -4.3007, -4.5154, -5.0318, -5.0106, -4.6856, -4.3023, -4.7672, -5.1112,\n",
      "         -5.1587, -4.6081, -4.8850, -4.7186, -4.5088, -4.5335, -4.6282, -4.8264,\n",
      "         -4.5446]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : succession\n",
      "target index is: [7] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6319, -4.4132, -4.6524, -4.6815, -4.1914, -4.6706, -4.6802, -4.4412,\n",
      "         -4.7049, -4.5796, -4.7165, -4.2473, -4.7673, -4.5022, -4.9727, -4.6647,\n",
      "         -4.6514, -4.4976, -4.8542, -4.5128, -4.3548, -4.5906, -4.7594, -4.8789,\n",
      "         -4.5031, -4.6947, -4.5025, -4.2739, -4.1966, -4.4424, -4.4827, -4.7754,\n",
      "         -4.9330, -4.5656, -4.8814, -5.1963, -4.5415, -4.9381, -4.5271, -4.5235,\n",
      "         -4.2679, -4.6775, -4.4435, -4.7345, -4.2653, -4.5403, -4.3288, -4.8324,\n",
      "         -4.4094, -4.8470, -4.5155, -4.5368, -4.5347, -4.4096, -4.6801, -4.5356,\n",
      "         -4.5814, -4.3234, -4.6075, -4.7176, -4.5047, -4.4057, -4.4188, -3.9250,\n",
      "         -4.3981, -4.5417, -4.5809, -4.5531, -4.3990, -4.1195, -4.3850, -4.4526,\n",
      "         -4.9861, -4.7953, -4.7983, -4.9163, -4.7627, -4.3406, -4.5202, -4.8662,\n",
      "         -4.9585, -4.5497, -4.7196, -4.8908, -4.7427, -4.4186, -4.4586, -4.6032,\n",
      "         -4.9833, -4.4897, -4.7614, -4.6666, -4.8017, -4.7000, -4.5934, -4.9858,\n",
      "         -4.7067]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thine!\n",
      "target index is: [40] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6051, -4.2936, -4.6882, -4.4875, -4.2116, -4.7543, -4.5861, -4.2940,\n",
      "         -4.7196, -4.6585, -4.6327, -4.3898, -4.6964, -4.6948, -4.4855, -4.8460,\n",
      "         -4.8877, -5.0658, -4.6482, -4.5564, -4.5492, -4.5919, -4.6021, -4.5336,\n",
      "         -4.5346, -4.5993, -4.1868, -4.4144, -4.3980, -4.6782, -4.8499, -4.8562,\n",
      "         -4.9258, -4.5880, -4.5133, -4.8867, -4.7761, -4.7749, -4.5645, -4.4376,\n",
      "         -4.7380, -4.6305, -4.5895, -4.5709, -4.6136, -4.4775, -4.5950, -4.5497,\n",
      "         -4.3395, -4.7126, -4.3885, -4.4482, -4.5009, -4.5440, -4.9890, -4.1540,\n",
      "         -4.7811, -4.2938, -4.6897, -4.7682, -4.5147, -4.4604, -4.6361, -4.2099,\n",
      "         -4.8889, -4.5341, -4.7244, -4.6405, -4.7956, -4.6462, -4.2104, -4.8257,\n",
      "         -4.7892, -4.5119, -4.3533, -4.9390, -4.6769, -4.4227, -4.3888, -4.4408,\n",
      "         -4.6552, -4.3605, -4.9195, -4.8208, -4.7406, -4.4143, -4.8865, -4.8104,\n",
      "         -4.7175, -4.3987, -4.7470, -4.3534, -4.5724, -4.3082, -4.5447, -4.2738,\n",
      "         -4.6925]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : This\n",
      "target index is: [1] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4626, -4.3575, -4.7534, -4.7865, -4.2083, -4.5650, -4.7493, -4.4872,\n",
      "         -4.5398, -4.5666, -4.7811, -4.7000, -4.8159, -4.6800, -4.4536, -4.7175,\n",
      "         -4.6211, -4.6071, -4.8453, -4.3936, -4.6935, -4.6276, -5.0344, -4.5137,\n",
      "         -4.5075, -4.6844, -4.5221, -4.4355, -4.2614, -4.7327, -4.5765, -4.7613,\n",
      "         -4.7656, -4.7224, -4.6301, -4.8563, -4.4402, -4.8440, -4.6941, -4.6681,\n",
      "         -4.6125, -4.4101, -4.6375, -4.6546, -4.5571, -4.2513, -4.7645, -4.5641,\n",
      "         -4.3141, -4.7304, -4.4716, -4.7334, -4.6361, -4.5545, -4.8021, -4.4611,\n",
      "         -4.3207, -4.1812, -4.7231, -4.3126, -4.6163, -4.6589, -4.3834, -4.3078,\n",
      "         -4.5598, -4.7586, -4.8964, -4.7801, -4.4765, -4.3586, -4.1883, -4.3692,\n",
      "         -4.9572, -4.8386, -4.6649, -4.7987, -4.3937, -4.3791, -4.6302, -4.6692,\n",
      "         -4.5424, -4.4230, -4.6032, -4.8155, -4.7698, -4.5380, -4.5612, -4.5112,\n",
      "         -4.7505, -4.3009, -4.5433, -4.5730, -4.8754, -4.3851, -4.4880, -4.7542,\n",
      "         -4.5026]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : were\n",
      "target index is: [93] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2623, -4.4734, -4.7757, -4.8981, -3.8277, -4.5352, -4.4101, -4.2798,\n",
      "         -4.6347, -4.8800, -4.6148, -4.4508, -4.6037, -4.9256, -4.7603, -4.5406,\n",
      "         -4.5029, -4.9872, -4.5948, -4.4254, -4.8544, -4.1621, -4.7102, -4.9411,\n",
      "         -4.3384, -4.6835, -4.3948, -4.3550, -4.2931, -4.8702, -4.3990, -4.9220,\n",
      "         -4.6647, -4.6407, -4.3090, -4.8347, -4.8926, -4.5590, -5.1079, -4.7898,\n",
      "         -4.6879, -4.6970, -4.7504, -4.5971, -4.8005, -4.2583, -4.2583, -4.7286,\n",
      "         -4.4779, -4.7747, -4.8494, -4.3428, -4.7763, -4.6326, -4.6175, -4.4505,\n",
      "         -4.4043, -4.3619, -4.4493, -4.7708, -4.6388, -4.4640, -4.8524, -4.0807,\n",
      "         -4.7510, -4.7016, -4.7330, -4.6158, -4.7815, -4.5096, -4.5873, -4.6464,\n",
      "         -4.2817, -4.7943, -4.6550, -4.5180, -4.6940, -4.7028, -4.5222, -4.4392,\n",
      "         -4.6711, -4.5305, -5.0351, -4.7712, -4.2194, -4.6247, -4.4599, -4.7617,\n",
      "         -4.7308, -4.4376, -4.7595, -4.5599, -4.8070, -4.4835, -4.5128, -4.5248,\n",
      "         -4.5490]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : to\n",
      "target index is: [72] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5491, -4.5776, -4.7156, -4.4748, -4.4875, -4.7628, -4.9704, -4.2659,\n",
      "         -4.7050, -4.7042, -4.6207, -4.6540, -4.5229, -4.7203, -4.8203, -4.5665,\n",
      "         -4.7869, -4.2018, -4.6259, -4.6139, -4.3766, -4.5165, -5.0463, -4.8565,\n",
      "         -4.2706, -4.9913, -4.5527, -4.3052, -4.2019, -4.7135, -4.6423, -4.2722,\n",
      "         -5.1074, -4.8075, -4.5733, -5.1761, -4.5312, -4.7119, -4.6254, -4.7423,\n",
      "         -4.4790, -4.5414, -4.6054, -4.6181, -4.4930, -4.3356, -4.7162, -4.7525,\n",
      "         -4.7647, -4.6676, -4.3718, -4.5898, -4.6502, -4.7943, -4.8438, -4.6871,\n",
      "         -3.9766, -4.0821, -4.5087, -4.3137, -4.5479, -4.4307, -4.2762, -4.1864,\n",
      "         -4.4474, -4.5470, -4.8441, -4.9588, -4.4505, -4.4340, -4.1825, -4.2168,\n",
      "         -5.2049, -4.9769, -4.8884, -4.9003, -4.2722, -4.2825, -4.5222, -4.6803,\n",
      "         -4.4334, -4.5763, -4.5862, -4.9977, -4.7880, -4.5844, -4.5492, -4.5407,\n",
      "         -5.0481, -4.5037, -4.6406, -4.6895, -5.0890, -4.2492, -4.5323, -4.8839,\n",
      "         -4.6232]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : be\n",
      "target index is: [24] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2009, -4.8559, -4.8211, -5.0765, -4.0416, -4.8186, -4.5686, -4.2393,\n",
      "         -4.8937, -5.0765, -4.9406, -4.3250, -4.6770, -4.9123, -4.9735, -4.5813,\n",
      "         -3.9878, -5.0282, -4.5663, -5.0265, -4.3730, -4.2092, -4.6102, -4.4797,\n",
      "         -4.2670, -5.0150, -4.0650, -4.5973, -4.5979, -4.7273, -4.2056, -5.3567,\n",
      "         -4.8511, -5.1314, -4.3466, -4.7266, -4.8372, -4.4690, -5.0322, -4.9713,\n",
      "         -5.0755, -4.4454, -4.6635, -4.4927, -4.2078, -4.1128, -4.4373, -4.6906,\n",
      "         -4.5789, -4.4789, -4.4721, -4.1102, -5.2153, -4.3854, -4.6978, -4.7005,\n",
      "         -4.8211, -4.4229, -4.5749, -4.9044, -4.9630, -4.5914, -4.7103, -3.9637,\n",
      "         -4.6353, -4.7714, -4.9878, -4.4556, -4.3993, -4.5245, -4.3301, -4.7797,\n",
      "         -4.6889, -4.8280, -4.6868, -4.8597, -4.7273, -4.0784, -4.5141, -4.9906,\n",
      "         -4.0965, -4.8382, -4.6968, -4.6714, -4.3260, -4.8049, -4.3056, -4.9176,\n",
      "         -4.9991, -4.4638, -4.3034, -4.6758, -4.7726, -4.6209, -4.3603, -4.6381,\n",
      "         -4.3054]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : new\n",
      "target index is: [27] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5437, -4.4766, -4.3645, -4.7272, -4.1826, -4.7292, -4.6504, -4.3883,\n",
      "         -4.6048, -4.6487, -4.8512, -4.5207, -4.6255, -4.7219, -4.5817, -4.6487,\n",
      "         -4.5035, -4.5645, -4.4840, -4.6070, -4.7636, -4.6335, -4.5226, -4.4792,\n",
      "         -4.3955, -4.6337, -4.4586, -4.6533, -4.4845, -4.4229, -4.5027, -4.6476,\n",
      "         -4.8430, -4.7376, -4.5502, -4.7174, -4.6599, -4.6863, -4.5669, -4.7047,\n",
      "         -4.6670, -4.5476, -4.9723, -4.6342, -4.7085, -4.6167, -4.6625, -4.5638,\n",
      "         -4.5432, -4.3703, -4.3131, -4.5405, -4.6482, -4.3388, -4.7268, -4.4781,\n",
      "         -4.5479, -4.6027, -4.5201, -4.6673, -4.7285, -4.5935, -4.5704, -4.1098,\n",
      "         -4.9839, -4.4631, -4.8775, -4.4394, -4.6969, -5.0066, -4.5926, -4.6285,\n",
      "         -4.7197, -4.7442, -4.6640, -4.6961, -4.4704, -4.4449, -4.3522, -4.8305,\n",
      "         -4.4207, -4.3457, -4.6024, -4.7767, -4.7012, -4.3228, -4.5718, -4.7788,\n",
      "         -4.7750, -4.1809, -4.5859, -4.8265, -4.3741, -4.5704, -4.3784, -4.4141,\n",
      "         -4.7152]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : made\n",
      "target index is: [16] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3394, -4.6359, -4.7488, -4.8576, -4.2498, -4.6875, -4.3996, -4.5306,\n",
      "         -4.6893, -4.3969, -4.8768, -4.4726, -4.6663, -4.5368, -4.6961, -4.8214,\n",
      "         -4.4684, -4.7098, -4.5959, -4.5990, -4.3496, -4.3789, -4.6710, -4.5690,\n",
      "         -4.6478, -5.1511, -4.1528, -4.6855, -4.6061, -4.7367, -4.5281, -4.8945,\n",
      "         -4.5615, -4.9496, -4.5228, -4.9734, -4.5332, -4.3542, -4.6421, -4.4075,\n",
      "         -4.6498, -4.5359, -4.5365, -4.4230, -4.4657, -4.4724, -4.7029, -4.5318,\n",
      "         -4.5888, -4.8438, -4.3725, -4.8011, -4.8067, -4.5069, -4.6191, -4.4299,\n",
      "         -4.7852, -4.5233, -4.3987, -4.5838, -4.5578, -4.5005, -4.5864, -4.2593,\n",
      "         -4.3384, -4.8597, -4.7912, -4.3754, -4.6131, -4.4005, -4.5728, -4.6923,\n",
      "         -4.8264, -4.6883, -4.7673, -4.8716, -4.4867, -4.3910, -4.2703, -4.6046,\n",
      "         -4.4340, -4.5971, -4.7441, -4.7463, -4.7841, -4.3824, -4.7494, -4.5310,\n",
      "         -4.9564, -4.6644, -4.3359, -4.5979, -4.6632, -4.5436, -4.5348, -4.4553,\n",
      "         -4.3238]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : when\n",
      "target index is: [85] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4363, -4.5754, -4.8258, -4.7594, -4.2433, -4.6475, -4.2523, -4.3690,\n",
      "         -4.8948, -4.5558, -4.9101, -4.4770, -4.7374, -4.6032, -4.4800, -4.5208,\n",
      "         -4.2718, -4.6703, -4.7376, -4.4161, -4.4533, -4.3357, -4.6295, -4.7507,\n",
      "         -4.6232, -5.0896, -4.5352, -4.2770, -4.7651, -4.7780, -4.6963, -4.5955,\n",
      "         -4.6994, -5.0592, -4.4783, -4.7487, -4.3650, -4.5662, -4.8868, -4.3708,\n",
      "         -4.6081, -4.6736, -4.6798, -4.3822, -4.5696, -4.1894, -4.7646, -4.8924,\n",
      "         -4.7365, -4.9382, -4.6026, -4.6838, -4.5218, -3.8603, -4.3980, -4.5745,\n",
      "         -4.6094, -4.5334, -4.5842, -4.6141, -4.5848, -4.5090, -4.4355, -4.5790,\n",
      "         -4.4650, -4.4055, -4.8781, -4.1880, -4.7717, -4.5174, -4.6306, -4.9141,\n",
      "         -4.8525, -4.7730, -4.8908, -5.0026, -4.4574, -4.4373, -4.3236, -4.8775,\n",
      "         -4.4760, -4.4626, -4.6368, -4.7229, -4.9220, -4.0372, -4.9643, -4.9413,\n",
      "         -4.8285, -4.4254, -4.4167, -4.6600, -4.7475, -4.5168, -4.5039, -4.7108,\n",
      "         -4.2789]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thou\n",
      "target index is: [22] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6201, -4.6109, -4.9578, -4.6512, -4.1948, -4.7552, -4.4675, -4.7178,\n",
      "         -4.6505, -4.5531, -4.6909, -4.2360, -4.7948, -4.7026, -4.7243, -4.2247,\n",
      "         -4.7306, -4.6513, -4.8195, -4.4808, -4.7725, -4.1735, -4.7609, -4.6131,\n",
      "         -4.1930, -4.7192, -4.7700, -4.3940, -4.3110, -4.3548, -4.7347, -4.5738,\n",
      "         -4.7101, -4.8529, -4.6025, -4.4512, -4.5891, -4.8098, -4.9642, -4.3582,\n",
      "         -4.8901, -4.1817, -4.6563, -4.5524, -4.3680, -4.5119, -4.5738, -4.7987,\n",
      "         -4.3773, -5.1436, -4.7351, -4.7023, -4.6380, -4.2537, -4.6169, -4.4323,\n",
      "         -4.2784, -4.4695, -4.6342, -4.4240, -4.6665, -4.5399, -4.3495, -4.5741,\n",
      "         -4.7307, -4.4484, -4.5767, -4.4500, -4.7938, -4.2492, -4.3205, -4.6649,\n",
      "         -4.8912, -4.8847, -4.7954, -4.9133, -4.4889, -4.6104, -4.6410, -4.6563,\n",
      "         -4.6354, -4.4206, -4.5596, -4.3874, -4.7157, -4.1631, -4.7365, -4.8860,\n",
      "         -4.8381, -4.4462, -4.7818, -4.6670, -4.5774, -4.5962, -4.6454, -4.6154,\n",
      "         -4.6889]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : art\n",
      "target index is: [15] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3501, -4.4797, -4.7755, -4.9318, -4.2636, -4.7747, -4.5871, -4.4013,\n",
      "         -4.6134, -4.8048, -4.6678, -4.4650, -4.4161, -4.7515, -4.7554, -4.2582,\n",
      "         -4.4977, -4.4755, -4.2866, -4.5559, -4.5891, -4.2703, -4.7960, -4.8886,\n",
      "         -4.1587, -4.7070, -4.4279, -4.5463, -4.2073, -4.5748, -4.5442, -4.8511,\n",
      "         -4.8820, -4.6383, -4.5774, -4.9363, -4.6235, -4.6061, -4.9308, -4.9319,\n",
      "         -4.8293, -4.8623, -4.7426, -4.8040, -4.6016, -4.5123, -4.6443, -4.9697,\n",
      "         -4.6099, -4.6625, -4.4485, -4.7899, -4.4838, -4.5110, -4.7597, -4.6677,\n",
      "         -4.3851, -4.4145, -4.4799, -4.4319, -4.7056, -4.3515, -4.3846, -4.1653,\n",
      "         -4.6245, -4.4648, -4.8230, -4.8489, -4.6357, -4.4486, -4.5139, -4.5564,\n",
      "         -4.8897, -4.7031, -4.6238, -4.7864, -4.3623, -4.4477, -4.5803, -4.6498,\n",
      "         -4.4147, -4.4655, -4.9453, -4.8720, -4.4406, -4.6724, -4.5648, -4.6662,\n",
      "         -4.5160, -4.3591, -4.5172, -4.7165, -4.5961, -4.1791, -4.7081, -4.5195,\n",
      "         -4.4841]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : old,\n",
      "target index is: [8] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4218, -4.5635, -4.9765, -4.6864, -4.3401, -4.7157, -4.4952, -4.3368,\n",
      "         -4.7219, -4.5829, -4.7994, -4.3920, -4.5854, -4.9586, -5.0369, -4.9600,\n",
      "         -4.7129, -4.7320, -4.5637, -4.6795, -4.3390, -4.2946, -4.7365, -4.6204,\n",
      "         -4.3551, -5.1338, -4.3063, -4.6968, -4.6514, -4.5816, -4.6962, -4.7926,\n",
      "         -4.6813, -4.8994, -4.4877, -4.8667, -4.7519, -4.3877, -4.5936, -4.3284,\n",
      "         -4.6424, -4.6014, -4.6485, -4.5835, -4.2547, -4.3203, -4.4422, -4.3753,\n",
      "         -4.4847, -4.9136, -4.7724, -4.2690, -4.8698, -4.3925, -4.3306, -4.4130,\n",
      "         -4.5788, -4.1771, -4.2800, -4.7322, -4.7544, -4.4050, -4.4539, -4.2343,\n",
      "         -4.5076, -4.7453, -4.6810, -4.4026, -4.3688, -4.1747, -4.4038, -4.7605,\n",
      "         -4.6570, -4.8701, -4.9193, -4.9241, -4.4484, -4.3597, -4.5652, -4.8053,\n",
      "         -4.5702, -4.7746, -4.8791, -4.7416, -4.5858, -4.5610, -4.6034, -4.8555,\n",
      "         -5.0276, -4.3415, -4.7374, -4.7178, -4.6952, -4.3044, -4.6782, -4.7029,\n",
      "         -4.2916]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : And\n",
      "target index is: [6] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4877, -4.3685, -4.4989, -4.5584, -4.3698, -5.0142, -4.4964, -4.4496,\n",
      "         -4.6519, -4.8031, -4.8441, -4.3642, -4.5583, -4.6343, -4.6337, -4.7092,\n",
      "         -4.6665, -4.6234, -4.9432, -4.5669, -4.4867, -4.5127, -4.5752, -4.5990,\n",
      "         -4.2073, -4.7036, -4.6252, -4.4242, -4.3080, -4.5418, -4.7172, -4.7869,\n",
      "         -4.6455, -4.7400, -4.6194, -4.5430, -4.7913, -4.5918, -4.5536, -4.4114,\n",
      "         -4.8594, -4.3892, -4.7171, -4.4287, -4.4806, -4.3903, -4.4408, -4.6154,\n",
      "         -4.5282, -4.7889, -4.5332, -4.4630, -4.8896, -4.3449, -4.5872, -4.5349,\n",
      "         -4.4407, -4.5556, -4.5688, -4.8058, -4.6825, -4.5014, -4.5362, -4.4209,\n",
      "         -4.7039, -4.6648, -4.7574, -4.2416, -4.7045, -4.6187, -4.6151, -4.7040,\n",
      "         -4.5436, -4.9708, -4.7833, -4.7923, -4.5703, -4.2937, -4.5709, -4.7646,\n",
      "         -4.2707, -4.4608, -4.5948, -4.7139, -4.5539, -4.3071, -4.5970, -4.7683,\n",
      "         -4.8747, -4.5115, -4.7756, -4.7734, -4.2860, -4.5597, -4.5419, -4.5446,\n",
      "         -4.5227]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : see\n",
      "target index is: [67] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4209, -4.5631, -4.7721, -5.0016, -4.4522, -4.7356, -4.5462, -4.4627,\n",
      "         -4.7912, -4.6273, -5.0282, -4.8889, -4.6639, -4.7174, -4.6949, -4.7380,\n",
      "         -4.5441, -4.5436, -4.7248, -4.3679, -4.7517, -4.7305, -4.9066, -4.7263,\n",
      "         -4.6084, -4.9283, -4.5873, -4.3257, -4.3537, -4.7769, -4.5104, -4.7213,\n",
      "         -5.0391, -4.9425, -4.2870, -4.5941, -4.2488, -4.5478, -4.7500, -4.7710,\n",
      "         -4.7779, -4.6098, -4.5719, -4.6306, -4.4647, -4.1257, -4.8109, -4.7228,\n",
      "         -4.7969, -4.8496, -4.2654, -4.6082, -4.5815, -4.3771, -4.7398, -4.7610,\n",
      "         -4.4190, -4.2961, -4.6501, -4.4398, -4.7534, -4.5700, -4.4592, -4.6266,\n",
      "         -4.5604, -4.4616, -5.0712, -4.4537, -4.5279, -4.6830, -4.2637, -4.1775,\n",
      "         -5.0483, -4.9055, -4.8015, -4.8857, -4.3112, -4.1309, -4.2942, -4.7541,\n",
      "         -4.2561, -4.7126, -4.3395, -4.9397, -4.7673, -4.3044, -4.4833, -4.5262,\n",
      "         -4.7248, -4.3419, -4.2205, -4.5491, -4.9426, -4.3838, -4.4495, -4.5524,\n",
      "         -4.1570]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5759, -4.4080, -4.9612, -4.5627, -4.1721, -4.6473, -4.6250, -4.2198,\n",
      "         -5.1292, -4.3768, -4.7444, -4.2093, -4.3220, -4.5773, -4.7767, -4.8633,\n",
      "         -4.3737, -4.5317, -4.3885, -4.5797, -4.6455, -4.4057, -4.3284, -4.7387,\n",
      "         -4.3648, -5.1582, -4.2827, -4.9267, -4.5899, -4.4629, -4.6336, -4.5887,\n",
      "         -4.8390, -4.6579, -4.5957, -5.1162, -4.6057, -4.5385, -4.5989, -4.6764,\n",
      "         -4.4654, -4.8036, -4.8676, -4.6442, -4.4118, -4.1615, -4.5852, -5.0558,\n",
      "         -5.0340, -4.4636, -4.8383, -4.4120, -4.4181, -4.3323, -4.4365, -4.5099,\n",
      "         -4.6426, -4.2412, -4.3220, -4.5212, -4.7384, -4.7307, -4.4202, -4.0480,\n",
      "         -4.4611, -4.6959, -4.7017, -4.4278, -4.8197, -4.5213, -4.6750, -4.6926,\n",
      "         -4.8759, -4.5585, -4.8442, -4.8483, -4.3623, -4.5411, -4.2775, -4.9072,\n",
      "         -4.4586, -4.4834, -4.7727, -4.8384, -4.8282, -4.5757, -4.7749, -4.7406,\n",
      "         -4.9792, -4.4578, -4.6425, -4.7991, -4.8816, -4.3569, -4.2841, -4.9136,\n",
      "         -4.4659]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : blood\n",
      "target index is: [39] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5496, -4.4957, -4.7669, -4.5118, -4.3786, -4.7780, -4.3166, -4.3568,\n",
      "         -4.8550, -4.7696, -4.9535, -4.3539, -4.6793, -4.4659, -4.5297, -4.8838,\n",
      "         -4.6762, -4.8096, -4.3453, -4.4293, -4.7913, -4.8177, -4.5755, -4.4587,\n",
      "         -4.6347, -5.1443, -4.8076, -4.5231, -4.1496, -4.7225, -4.4710, -4.5518,\n",
      "         -4.7281, -4.7174, -4.7120, -5.3160, -4.3793, -4.7009, -4.4624, -4.2802,\n",
      "         -4.4844, -4.4367, -4.7080, -4.1976, -4.7731, -4.1759, -5.0484, -4.6603,\n",
      "         -4.6602, -4.8591, -4.7888, -4.7475, -4.7047, -4.3147, -4.4090, -4.5182,\n",
      "         -4.2772, -4.0515, -4.7341, -4.6342, -4.6535, -4.2418, -4.5922, -4.3737,\n",
      "         -4.5715, -4.5977, -4.6724, -4.2478, -4.6750, -4.1227, -4.5064, -4.6440,\n",
      "         -5.0424, -5.0365, -4.8847, -5.3041, -5.0437, -3.9467, -4.1836, -4.5630,\n",
      "         -5.0262, -4.6210, -5.0019, -5.0354, -5.2727, -4.0418, -4.4610, -4.5005,\n",
      "         -5.2368, -4.3891, -4.8188, -4.6021, -4.7630, -4.5234, -4.4330, -4.5383,\n",
      "         -4.3534]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : warm\n",
      "target index is: [2] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5373, -4.3894, -4.6771, -4.8308, -4.5973, -4.6466, -4.4017, -4.4855,\n",
      "         -4.7799, -5.0717, -4.9476, -4.7860, -4.7265, -4.7975, -4.6049, -4.5065,\n",
      "         -4.7163, -4.9818, -4.5464, -4.1751, -4.8480, -4.2909, -5.0654, -4.4884,\n",
      "         -4.1280, -4.7335, -4.4045, -4.2829, -4.3497, -4.7298, -4.7357, -4.7710,\n",
      "         -4.9293, -4.8737, -4.6038, -4.4220, -4.8129, -4.9462, -4.8900, -4.7380,\n",
      "         -4.8445, -4.5875, -4.6699, -4.5520, -4.6641, -4.3273, -4.8598, -4.8209,\n",
      "         -4.2507, -4.8607, -4.4704, -4.4088, -4.4081, -4.1720, -4.6948, -4.1946,\n",
      "         -4.4954, -4.1289, -4.6931, -4.6926, -4.7817, -4.7338, -4.3866, -4.4167,\n",
      "         -4.8044, -4.4599, -5.1427, -4.5535, -4.6962, -4.3230, -4.1294, -4.7234,\n",
      "         -4.3912, -4.4909, -4.5837, -4.7955, -4.4103, -4.3267, -4.5189, -4.8063,\n",
      "         -4.4215, -4.8410, -4.7343, -4.5583, -4.3526, -4.5229, -4.7764, -5.0726,\n",
      "         -4.5705, -4.1324, -4.5968, -4.5559, -4.7369, -4.7683, -4.3627, -4.7027,\n",
      "         -4.2602]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : when\n",
      "target index is: [85] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4583, -4.3392, -4.7585, -4.9798, -4.2665, -4.7543, -4.3317, -4.4284,\n",
      "         -4.7216, -4.3768, -4.6477, -4.6858, -4.8431, -4.6144, -4.4423, -4.5014,\n",
      "         -4.3084, -4.6409, -4.8190, -4.5531, -4.4777, -4.4501, -4.5694, -4.6849,\n",
      "         -4.5296, -5.0631, -4.4217, -4.3793, -4.8382, -4.6196, -4.6619, -4.5764,\n",
      "         -4.7298, -4.9689, -4.5991, -4.6945, -4.5230, -4.3931, -4.9194, -4.5390,\n",
      "         -4.5683, -4.9222, -4.6589, -4.3614, -4.3880, -4.3964, -4.6893, -4.7959,\n",
      "         -4.5653, -4.6870, -4.4505, -4.8534, -4.6804, -4.2812, -4.6370, -4.6300,\n",
      "         -4.6563, -4.7231, -4.5150, -4.5062, -4.8060, -4.4263, -4.5419, -4.1213,\n",
      "         -4.5250, -4.4119, -4.7367, -4.3344, -4.5781, -4.6408, -4.7828, -5.0984,\n",
      "         -4.9915, -4.2032, -4.7293, -4.9527, -4.4785, -4.7450, -4.5330, -4.6943,\n",
      "         -4.3100, -4.3453, -4.8815, -4.5663, -4.9095, -4.1770, -5.1060, -4.5778,\n",
      "         -4.6155, -4.2317, -4.2994, -4.7220, -4.7797, -4.2381, -4.5291, -4.5715,\n",
      "         -4.6799]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thou\n",
      "target index is: [22] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6210, -4.6125, -4.9521, -4.6518, -4.1959, -4.7555, -4.4625, -4.7183,\n",
      "         -4.6453, -4.5538, -4.6908, -4.2364, -4.7958, -4.7028, -4.7247, -4.2068,\n",
      "         -4.7308, -4.6520, -4.8203, -4.4823, -4.7733, -4.1739, -4.7535, -4.6138,\n",
      "         -4.1939, -4.7197, -4.7716, -4.3951, -4.3121, -4.3553, -4.7356, -4.5748,\n",
      "         -4.7109, -4.8535, -4.6035, -4.4516, -4.5898, -4.8107, -4.9655, -4.3542,\n",
      "         -4.8911, -4.1816, -4.6570, -4.5531, -4.3692, -4.5130, -4.5750, -4.7995,\n",
      "         -4.3782, -5.1444, -4.7362, -4.7034, -4.6392, -4.2549, -4.6184, -4.4336,\n",
      "         -4.2787, -4.4711, -4.6352, -4.4248, -4.6677, -4.5408, -4.3502, -4.5751,\n",
      "         -4.7310, -4.4483, -4.5771, -4.4452, -4.7951, -4.2501, -4.3214, -4.6658,\n",
      "         -4.8919, -4.8861, -4.7961, -4.9145, -4.4897, -4.6115, -4.6374, -4.6567,\n",
      "         -4.6362, -4.4215, -4.5606, -4.3884, -4.7167, -4.1532, -4.7374, -4.8870,\n",
      "         -4.8399, -4.4472, -4.7834, -4.6676, -4.5783, -4.5975, -4.6465, -4.6158,\n",
      "         -4.6903]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : feel'st\n",
      "target index is: [35] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4669, -4.2243, -4.7330, -4.8591, -4.1398, -4.7331, -4.7178, -4.2076,\n",
      "         -4.7751, -4.4901, -4.7172, -4.6471, -4.7681, -4.8253, -4.6879, -4.5644,\n",
      "         -4.6204, -4.3305, -4.6221, -4.4935, -4.5769, -4.5132, -4.4803, -4.8741,\n",
      "         -4.5363, -4.7918, -4.4308, -4.5329, -4.5646, -4.5173, -4.4865, -4.6588,\n",
      "         -4.8661, -4.6599, -4.3033, -4.9255, -4.5162, -4.8160, -4.7585, -4.7762,\n",
      "         -4.5887, -4.8624, -4.5747, -4.6860, -4.4176, -4.4194, -4.4759, -4.6262,\n",
      "         -4.7181, -4.5652, -4.5910, -4.7059, -4.5945, -4.6233, -4.6845, -4.6255,\n",
      "         -4.5791, -4.3421, -4.4021, -4.5214, -4.9251, -4.5884, -4.5329, -4.2052,\n",
      "         -4.5497, -4.5045, -4.5178, -4.5885, -4.5047, -4.6776, -4.6743, -4.5755,\n",
      "         -4.8566, -4.9081, -4.7391, -4.7220, -4.3196, -4.5067, -4.3879, -4.7477,\n",
      "         -4.4639, -4.5119, -4.7228, -4.9061, -4.7580, -4.4174, -4.3931, -4.5643,\n",
      "         -4.5721, -4.1301, -4.4144, -4.5694, -4.8827, -4.4027, -4.5590, -4.6465,\n",
      "         -4.5225]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : it\n",
      "target index is: [88] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5438, -4.4016, -4.7818, -4.7180, -4.1239, -4.8798, -4.5600, -4.2303,\n",
      "         -4.6342, -4.6327, -4.6605, -4.3404, -4.4581, -4.8272, -4.6900, -4.6248,\n",
      "         -4.5488, -5.0271, -4.5433, -4.6504, -4.6850, -4.3844, -4.9689, -4.6435,\n",
      "         -4.1396, -4.8354, -4.1515, -4.6133, -4.1163, -4.6870, -4.6472, -5.2944,\n",
      "         -5.0688, -4.7717, -4.9111, -5.1137, -4.5090, -4.7121, -4.7237, -4.7391,\n",
      "         -4.9467, -4.4454, -4.6279, -4.6342, -4.4685, -4.3190, -4.6777, -4.8561,\n",
      "         -4.4626, -4.7563, -4.7161, -4.1065, -4.8876, -4.3640, -4.8202, -4.4464,\n",
      "         -4.5388, -4.1037, -4.6865, -4.6725, -4.6534, -4.5865, -4.3071, -4.1864,\n",
      "         -4.7330, -4.8561, -4.7543, -4.6733, -4.5420, -4.2306, -4.1632, -4.3678,\n",
      "         -4.8731, -4.7432, -4.7154, -4.7170, -4.7782, -3.9759, -4.5139, -4.7477,\n",
      "         -4.5032, -4.5777, -4.8676, -4.8195, -4.5064, -4.7040, -4.3763, -4.6220,\n",
      "         -4.7951, -4.6303, -4.8509, -4.7713, -4.7468, -4.3059, -4.5840, -4.6513,\n",
      "         -4.2249]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : cold.\n",
      "target index is: [79] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3412, -4.1322, -4.7905, -4.7842, -4.1200, -5.0157, -4.4748, -4.5000,\n",
      "         -4.8347, -4.4958, -4.8090, -4.5627, -4.6898, -4.7622, -5.0666, -4.7153,\n",
      "         -4.6235, -4.1543, -4.8464, -4.4176, -4.7323, -4.3643, -4.6193, -4.8507,\n",
      "         -4.3265, -4.7582, -4.4769, -4.2664, -4.2486, -4.4614, -4.3732, -4.5872,\n",
      "         -4.6800, -4.7588, -4.5320, -4.5073, -4.6831, -4.7450, -4.7255, -4.6910,\n",
      "         -4.6797, -4.5236, -4.5304, -4.4088, -4.4318, -4.3116, -4.4550, -4.7300,\n",
      "         -4.7483, -5.0651, -4.5814, -4.6064, -4.6571, -4.5650, -4.3852, -4.7852,\n",
      "         -4.4322, -4.4121, -4.3311, -4.6749, -4.8591, -4.4186, -4.5981, -4.5192,\n",
      "         -4.5457, -4.9832, -4.5777, -4.2648, -4.5289, -4.4206, -4.6855, -4.7087,\n",
      "         -4.9145, -5.0149, -4.9182, -4.8071, -4.4980, -4.5929, -4.4051, -4.7483,\n",
      "         -4.2357, -4.5051, -4.6359, -4.6705, -4.8784, -4.2711, -4.7996, -4.5741,\n",
      "         -4.7954, -4.4753, -4.6055, -4.5463, -4.7494, -4.5330, -4.4361, -4.6550,\n",
      "         -4.6180]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : winters\n",
      "target index is: [3] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2874, -4.6763, -4.3701, -4.6987, -4.1869, -4.6041, -4.4932, -4.2554,\n",
      "         -4.7518, -4.9123, -4.7752, -4.7950, -4.5267, -4.2476, -4.5813, -4.3907,\n",
      "         -4.1264, -4.7027, -4.6364, -4.8029, -4.8136, -4.6414, -4.5760, -4.6031,\n",
      "         -4.3666, -4.9027, -4.4679, -4.4876, -4.4069, -4.5763, -4.2691, -5.0586,\n",
      "         -4.8983, -4.6710, -4.9533, -4.9013, -4.5797, -4.7027, -5.0230, -4.6946,\n",
      "         -4.9649, -4.3882, -4.8662, -4.3980, -5.0517, -4.3859, -5.1474, -5.2146,\n",
      "         -4.8917, -4.2335, -4.6473, -4.3864, -4.8200, -4.1784, -4.9602, -4.1485,\n",
      "         -4.3002, -4.1184, -4.8752, -4.3900, -4.3000, -4.6544, -4.4734, -4.1169,\n",
      "         -4.5734, -3.9900, -5.3841, -4.5299, -4.8639, -4.6415, -4.6102, -4.3250,\n",
      "         -4.9448, -4.8456, -4.6235, -5.1916, -4.8183, -4.1596, -4.3558, -4.7920,\n",
      "         -4.2948, -4.5766, -4.6846, -5.0443, -4.7619, -4.3586, -4.7023, -4.6575,\n",
      "         -5.1158, -4.3948, -4.3651, -4.6719, -4.6220, -4.7078, -4.4870, -4.7970,\n",
      "         -4.3987]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : shall\n",
      "target index is: [10] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4733, -4.3687, -5.1174, -4.8403, -4.2727, -4.7408, -4.3693, -4.7098,\n",
      "         -4.7571, -4.4428, -4.7489, -4.4244, -4.8002, -4.6755, -5.0362, -4.4986,\n",
      "         -4.7595, -4.5613, -4.6917, -4.4719, -4.5294, -4.0106, -4.5805, -4.5406,\n",
      "         -4.1655, -4.7843, -4.6098, -4.6133, -4.4455, -4.6025, -4.8870, -4.6769,\n",
      "         -4.5910, -4.8563, -4.7053, -4.4235, -4.9395, -4.4837, -5.0138, -4.3828,\n",
      "         -4.9406, -4.7339, -4.6868, -4.7439, -4.3864, -4.4940, -4.6241, -4.6147,\n",
      "         -4.4518, -5.0661, -4.4703, -4.7802, -4.5675, -4.3283, -4.5008, -4.5352,\n",
      "         -4.6813, -4.5092, -4.2132, -4.5775, -4.7902, -4.3705, -4.2647, -4.1781,\n",
      "         -4.4476, -4.7460, -4.6559, -4.5815, -4.6754, -4.1884, -4.4130, -4.7725,\n",
      "         -4.5408, -4.6442, -4.9262, -4.6823, -4.0556, -4.7838, -4.6574, -4.6934,\n",
      "         -4.3494, -4.5400, -4.9428, -4.6490, -4.5787, -4.4141, -4.8516, -4.9815,\n",
      "         -4.7869, -4.3211, -4.6418, -4.9289, -4.6138, -4.2437, -4.6460, -4.7714,\n",
      "         -4.3782]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : besiege\n",
      "target index is: [75] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3706, -4.5393, -4.3913, -4.7735, -4.1285, -4.7828, -4.5240, -4.2633,\n",
      "         -4.6952, -4.7210, -4.9520, -4.6503, -4.6613, -4.5628, -5.0282, -4.6927,\n",
      "         -4.5706, -4.4339, -4.8280, -4.6162, -4.5681, -4.8897, -4.5133, -4.5582,\n",
      "         -4.3786, -4.6925, -4.6772, -4.6029, -4.3110, -4.3771, -4.4999, -4.5985,\n",
      "         -4.7359, -4.7375, -4.8555, -4.7933, -4.6404, -4.6691, -4.6803, -4.5064,\n",
      "         -4.4594, -4.6849, -4.7746, -4.1691, -4.4913, -4.4863, -4.3497, -4.4076,\n",
      "         -4.5247, -4.6104, -4.5517, -4.3404, -4.7508, -4.3964, -4.7272, -4.5675,\n",
      "         -4.5400, -4.4227, -4.4687, -4.7027, -5.0652, -4.4585, -4.6211, -3.8123,\n",
      "         -4.6831, -4.4772, -4.8227, -4.6584, -4.4870, -4.8029, -4.5896, -4.6013,\n",
      "         -4.7931, -4.9287, -4.7633, -4.7382, -4.7154, -4.2252, -4.4368, -4.8911,\n",
      "         -4.6788, -4.5227, -4.6318, -4.9119, -4.7279, -4.2799, -4.3630, -4.7914,\n",
      "         -5.3051, -4.1980, -4.6780, -4.6730, -4.4838, -4.6117, -4.3212, -4.5912,\n",
      "         -4.8425]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1494, -4.4904, -4.7553, -4.9673, -3.9868, -4.6819, -4.8138, -4.4299,\n",
      "         -5.2614, -4.3474, -4.8780, -4.1785, -4.8108, -4.3871, -4.7388, -5.0620,\n",
      "         -4.9216, -4.6509, -4.5649, -4.4480, -4.5051, -4.5765, -4.7011, -4.4974,\n",
      "         -4.8745, -4.8479, -4.0831, -4.6235, -4.5550, -4.5820, -4.5824, -4.9107,\n",
      "         -4.9209, -4.6494, -4.5435, -5.2161, -4.5746, -4.9968, -4.7781, -4.6499,\n",
      "         -4.8867, -4.9758, -4.7071, -4.5809, -4.6529, -4.3369, -4.8993, -4.8510,\n",
      "         -4.8338, -4.6772, -4.3566, -5.0488, -4.2921, -4.4534, -5.0769, -4.2364,\n",
      "         -4.8313, -4.4326, -4.4334, -4.2269, -4.2981, -4.3022, -4.6547, -4.0050,\n",
      "         -4.3854, -4.7082, -5.0368, -4.6751, -4.6935, -4.7470, -4.3471, -4.8571,\n",
      "         -5.2208, -4.6031, -4.5202, -4.9466, -4.2956, -4.3192, -4.1923, -4.5588,\n",
      "         -4.4946, -4.2907, -4.9517, -4.9861, -4.6744, -4.3854, -4.4559, -4.5624,\n",
      "         -4.8287, -4.6021, -4.0355, -4.4388, -4.5883, -4.4905, -4.1564, -4.6448,\n",
      "         -4.6076]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : brow,\n",
      "target index is: [13] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4313, -4.3204, -4.5777, -4.6542, -4.2962, -4.8848, -4.6003, -4.4289,\n",
      "         -4.7451, -4.7869, -4.8272, -4.4487, -4.8162, -4.4053, -4.7585, -4.8949,\n",
      "         -4.7023, -4.7468, -4.4918, -4.4841, -4.8095, -4.9150, -4.6189, -4.3320,\n",
      "         -4.6163, -4.8238, -4.7502, -4.2798, -4.0930, -4.3854, -4.2467, -4.7467,\n",
      "         -4.8697, -4.6161, -4.9455, -5.0320, -4.5480, -4.9064, -4.3416, -4.3849,\n",
      "         -4.7167, -4.6089, -4.4860, -4.1582, -4.5192, -4.1606, -4.7626, -4.8257,\n",
      "         -4.5540, -4.7952, -4.8724, -4.4794, -4.8713, -4.1812, -4.6288, -4.4377,\n",
      "         -4.4117, -4.0047, -4.7561, -4.6216, -4.8959, -4.4555, -4.5891, -4.1567,\n",
      "         -4.7857, -4.6049, -5.0608, -4.5626, -4.5861, -4.4379, -4.4074, -4.5876,\n",
      "         -4.8561, -4.9038, -4.8244, -5.0553, -5.0310, -3.8384, -4.4686, -4.9803,\n",
      "         -4.9571, -4.5478, -4.7303, -5.0020, -5.0419, -4.3545, -4.3765, -4.5327,\n",
      "         -4.9400, -4.0379, -4.8166, -4.6089, -4.6545, -4.5785, -4.3315, -4.8580,\n",
      "         -4.3418]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : And\n",
      "target index is: [6] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3782, -4.3031, -4.6535, -4.8191, -4.2018, -4.8309, -4.7193, -4.5505,\n",
      "         -4.8414, -4.5921, -4.4846, -4.3482, -4.8612, -4.8623, -4.3676, -4.8955,\n",
      "         -4.8841, -5.0087, -4.5358, -4.3650, -4.4334, -4.4190, -4.6451, -4.6165,\n",
      "         -4.6524, -4.7137, -4.2785, -4.4369, -4.3145, -4.9748, -4.5396, -5.2389,\n",
      "         -4.7656, -4.6989, -4.4768, -4.8422, -4.6424, -4.9131, -4.7381, -4.6413,\n",
      "         -4.8376, -4.9863, -4.7086, -4.6921, -4.6766, -4.4970, -4.5413, -4.5980,\n",
      "         -4.5113, -4.9969, -4.5276, -4.6817, -4.3655, -4.7287, -5.1953, -4.5879,\n",
      "         -4.5981, -4.4493, -4.4518, -4.6281, -4.6173, -4.4811, -4.9185, -4.2667,\n",
      "         -4.9834, -4.6732, -4.9516, -4.6383, -4.6671, -4.6762, -4.1044, -4.8781,\n",
      "         -5.0450, -4.4974, -4.2901, -4.8108, -4.6211, -4.3672, -4.5649, -4.2197,\n",
      "         -4.5347, -4.0316, -4.8708, -4.6546, -4.3788, -4.3977, -4.5241, -4.5565,\n",
      "         -4.7820, -4.3279, -4.5309, -4.5428, -4.2708, -4.1237, -4.1320, -4.3982,\n",
      "         -4.5028]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : dig\n",
      "target index is: [42] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4150, -4.6436, -4.6897, -4.9472, -4.2589, -4.8280, -4.6638, -4.5463,\n",
      "         -4.5230, -4.6818, -4.8351, -4.9906, -4.7092, -4.8220, -4.5584, -4.7218,\n",
      "         -4.6888, -4.7314, -4.7072, -4.4018, -4.8263, -4.4918, -5.0064, -4.7013,\n",
      "         -4.3999, -4.9692, -4.5060, -4.5066, -4.1315, -4.7914, -4.5248, -4.8300,\n",
      "         -4.8847, -4.8374, -4.2475, -4.5092, -4.3672, -4.6551, -4.8462, -4.7477,\n",
      "         -4.8180, -4.4327, -4.7359, -4.6538, -4.6109, -4.2940, -4.9178, -4.4973,\n",
      "         -4.6526, -4.8580, -4.3883, -4.7688, -4.5949, -4.5311, -4.7422, -4.5823,\n",
      "         -4.2454, -4.1988, -4.6359, -4.4161, -4.5729, -4.6553, -4.6834, -4.6453,\n",
      "         -4.6574, -4.3733, -4.9588, -4.5850, -4.6191, -4.7720, -4.2415, -4.2219,\n",
      "         -5.0133, -4.8189, -4.7566, -4.7859, -4.5363, -4.1979, -4.4919, -4.4795,\n",
      "         -4.4048, -4.4737, -4.4727, -4.9484, -4.5152, -4.3328, -4.3205, -4.4446,\n",
      "         -4.6959, -4.2245, -4.4135, -4.4481, -4.7559, -4.4216, -4.5906, -4.4193,\n",
      "         -4.2859]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : deep\n",
      "target index is: [76] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5621, -4.9103, -4.7099, -4.6302, -4.2677, -4.8156, -4.3589, -4.1799,\n",
      "         -4.7131, -4.9959, -4.7992, -4.4441, -4.5795, -4.8908, -4.7733, -4.3079,\n",
      "         -4.2429, -4.8065, -4.4441, -4.9050, -4.4914, -4.2456, -4.5503, -4.7308,\n",
      "         -4.1309, -4.8986, -4.4440, -4.6908, -4.7001, -4.4662, -4.7419, -4.6641,\n",
      "         -4.8914, -4.9450, -4.4228, -4.6242, -4.9833, -4.5275, -5.0080, -4.7243,\n",
      "         -4.8463, -4.6771, -4.8793, -4.5393, -4.3867, -4.3424, -4.4997, -4.6176,\n",
      "         -4.4779, -4.3140, -4.4967, -4.1797, -4.7286, -4.4348, -4.5529, -4.4748,\n",
      "         -4.5410, -4.5501, -4.5108, -4.6787, -5.0267, -4.6775, -4.5630, -3.9479,\n",
      "         -4.6830, -4.4685, -4.9009, -4.4221, -4.6933, -4.5909, -4.4075, -4.7438,\n",
      "         -4.5937, -4.5093, -4.6177, -4.9040, -4.4898, -4.5936, -4.6725, -4.7151,\n",
      "         -4.1131, -4.8023, -4.7024, -4.6409, -4.3466, -4.5213, -4.6677, -5.0730,\n",
      "         -4.9460, -4.3691, -4.4771, -4.6921, -4.6893, -4.4507, -4.4925, -4.4546,\n",
      "         -4.5687]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : trenches\n",
      "target index is: [54] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4017, -4.5475, -4.9424, -5.3989, -4.1046, -4.6711, -4.4171, -4.4511,\n",
      "         -4.8141, -4.4194, -4.9056, -4.4370, -4.8021, -4.7589, -4.9686, -4.7094,\n",
      "         -4.4849, -4.6473, -4.7061, -4.6189, -4.5401, -4.2813, -4.7517, -4.5682,\n",
      "         -4.4277, -4.8848, -4.1898, -4.5652, -4.5693, -4.7039, -4.4982, -5.0662,\n",
      "         -4.9186, -4.9543, -4.5022, -4.5738, -4.3581, -4.7231, -5.0286, -4.6989,\n",
      "         -4.8528, -4.8028, -4.5667, -4.5457, -4.3969, -4.5037, -4.5213, -4.7447,\n",
      "         -4.4248, -5.1601, -4.1596, -4.7909, -4.5887, -4.4017, -4.4956, -4.6694,\n",
      "         -4.9370, -4.5961, -4.2824, -4.4752, -4.6775, -4.3516, -4.5080, -4.1770,\n",
      "         -4.5143, -4.6267, -4.6827, -4.5302, -4.4603, -4.3618, -4.6466, -4.7697,\n",
      "         -5.2117, -4.5502, -4.8709, -5.0435, -4.2355, -4.2622, -4.2010, -4.5428,\n",
      "         -4.5293, -4.5633, -4.6443, -4.5453, -4.6691, -4.3846, -4.5619, -4.7187,\n",
      "         -4.6822, -4.6767, -4.0504, -4.5840, -4.7278, -4.2899, -4.6078, -4.6296,\n",
      "         -4.4896]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : in\n",
      "target index is: [95] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7135, -4.4310, -4.5673, -4.5255, -4.1069, -4.6677, -4.6586, -4.1847,\n",
      "         -4.7396, -4.5657, -4.6498, -4.2530, -4.4575, -4.6629, -4.8365, -4.6736,\n",
      "         -4.5747, -4.7366, -4.2226, -4.5439, -4.5216, -4.5835, -4.5309, -4.6514,\n",
      "         -4.2294, -4.9299, -4.4156, -4.8162, -4.4177, -4.4538, -4.7185, -4.7209,\n",
      "         -4.9252, -4.7267, -4.5879, -5.0969, -4.5116, -4.6793, -4.2902, -4.6556,\n",
      "         -4.5091, -4.6159, -4.9601, -4.7185, -4.5180, -4.4143, -4.4747, -4.9167,\n",
      "         -4.8330, -4.5101, -4.6336, -4.1520, -4.6217, -4.2865, -4.7346, -4.4451,\n",
      "         -4.5447, -4.2177, -4.3415, -4.7157, -4.8269, -4.6774, -4.4792, -4.1252,\n",
      "         -4.8056, -4.4636, -4.7193, -4.6191, -4.7897, -4.8568, -4.4788, -4.5674,\n",
      "         -5.0098, -4.8283, -4.8444, -4.8236, -4.6686, -4.3528, -4.3014, -5.0028,\n",
      "         -4.7003, -4.2603, -4.6962, -4.7190, -4.7430, -4.4406, -4.6570, -4.6951,\n",
      "         -4.8436, -4.2387, -4.9018, -4.7738, -4.6003, -4.3661, -4.5042, -4.6278,\n",
      "         -4.5937]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1596, -4.5211, -5.1037, -4.8468, -4.2851, -4.7159, -4.7141, -4.3523,\n",
      "         -5.2794, -4.2310, -4.9056, -4.2296, -4.4611, -4.2955, -5.0199, -5.1383,\n",
      "         -4.6623, -4.5981, -4.6449, -4.4416, -4.5462, -4.5580, -4.5118, -4.6083,\n",
      "         -4.5343, -5.0558, -4.3092, -4.5282, -4.5918, -4.7351, -4.6746, -4.5168,\n",
      "         -5.0017, -4.8577, -4.8430, -5.4179, -4.7266, -4.5554, -4.6380, -4.2915,\n",
      "         -4.5647, -4.6874, -4.3821, -4.4764, -4.2086, -4.1484, -4.7301, -4.7212,\n",
      "         -4.9707, -4.7597, -4.5990, -4.6837, -4.4025, -4.4201, -4.5279, -4.5737,\n",
      "         -4.5595, -4.2813, -4.4416, -4.5726, -4.6913, -4.4085, -4.3291, -4.2930,\n",
      "         -4.0615, -4.8372, -4.8086, -4.5374, -4.5882, -4.2466, -4.3724, -4.7142,\n",
      "         -4.7906, -4.7234, -4.8073, -4.7187, -4.2809, -4.2141, -4.2069, -4.6956,\n",
      "         -4.5470, -4.7765, -4.8464, -5.0507, -5.0845, -4.4218, -4.7031, -4.5242,\n",
      "         -5.1533, -4.6332, -4.4189, -4.8010, -4.9408, -4.4279, -4.2702, -4.8735,\n",
      "         -4.4951]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty's\n",
      "target index is: [80] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2942, -4.4783, -4.6910, -4.5483, -4.2331, -4.9421, -4.4698, -4.2833,\n",
      "         -4.4322, -5.1570, -4.9617, -4.0457, -4.6202, -4.7451, -4.6126, -4.7493,\n",
      "         -4.9083, -5.1818, -4.5277, -4.4300, -4.9535, -4.7557, -4.5332, -4.5105,\n",
      "         -4.2156, -4.6588, -4.6743, -4.4689, -3.8720, -4.5985, -4.8149, -4.5905,\n",
      "         -4.7209, -4.6320, -4.6846, -5.1472, -4.8664, -4.6296, -4.6713, -4.5420,\n",
      "         -4.6964, -4.2719, -4.9867, -4.0860, -4.4980, -4.1123, -4.4861, -4.4749,\n",
      "         -4.5064, -4.8928, -4.7759, -4.4595, -4.7579, -4.4069, -4.6276, -4.4161,\n",
      "         -4.3364, -4.2443, -4.7514, -5.0395, -4.8528, -4.1923, -4.5101, -4.1408,\n",
      "         -5.0380, -4.8249, -5.0730, -4.6866, -4.8139, -4.6178, -4.3343, -4.7985,\n",
      "         -4.4967, -4.8651, -4.8022, -4.9234, -5.1310, -4.0783, -4.2986, -4.4555,\n",
      "         -4.7480, -4.3125, -5.2062, -4.7305, -4.8779, -4.0919, -4.6149, -5.0135,\n",
      "         -5.0642, -4.6029, -5.1630, -4.4935, -4.5625, -4.5235, -4.2815, -4.3646,\n",
      "         -4.5915]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : field,\n",
      "target index is: [77] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-3.9624, -4.1765, -4.7960, -5.6726, -4.1081, -5.1151, -4.5326, -4.5137,\n",
      "         -4.8680, -4.8576, -4.6864, -5.1718, -5.0357, -4.7755, -4.7010, -4.8394,\n",
      "         -4.9407, -4.7207, -4.8763, -4.4921, -4.7402, -4.3984, -4.9067, -4.6789,\n",
      "         -4.5388, -4.8625, -4.3263, -4.0945, -4.1709, -4.9362, -4.2885, -4.7722,\n",
      "         -4.8118, -4.7853, -4.5116, -4.9604, -4.7004, -4.9711, -4.9778, -4.8919,\n",
      "         -4.5792, -5.1716, -4.8044, -4.6778, -4.4974, -4.1246, -5.1269, -4.4422,\n",
      "         -4.6639, -4.9976, -3.8351, -5.2629, -4.3190, -4.8258, -4.8348, -4.4900,\n",
      "         -4.5919, -4.3154, -4.4754, -4.2941, -4.7611, -4.2739, -4.4629, -3.8531,\n",
      "         -4.4895, -4.5237, -4.9291, -4.7842, -4.4367, -4.4584, -4.6236, -4.5547,\n",
      "         -5.3889, -4.5819, -4.8715, -4.8746, -4.2676, -4.2117, -4.2249, -4.5198,\n",
      "         -4.4767, -4.3985, -5.1966, -5.2222, -4.5089, -4.4086, -4.3094, -4.8769,\n",
      "         -4.6014, -4.2915, -4.0486, -4.3678, -4.9470, -4.1653, -4.5056, -4.8558,\n",
      "         -4.4928]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Thy\n",
      "target index is: [73] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2973, -4.6057, -4.7345, -4.6729, -4.2256, -4.9293, -4.6294, -4.1449,\n",
      "         -4.7035, -4.8916, -4.6359, -4.2221, -4.2907, -4.7065, -4.6408, -4.3841,\n",
      "         -4.6802, -4.8195, -4.1476, -4.7096, -4.5413, -4.2924, -4.7630, -4.8298,\n",
      "         -4.0836, -4.8556, -4.5748, -4.7295, -4.0931, -4.4230, -4.7837, -4.7029,\n",
      "         -4.8896, -4.6353, -4.7296, -5.1250, -4.9215, -4.5721, -4.7640, -4.9262,\n",
      "         -4.7736, -4.4633, -4.9598, -4.6832, -4.4989, -4.4326, -4.6189, -5.1012,\n",
      "         -4.6995, -4.4957, -4.6209, -4.2846, -4.7646, -4.5011, -4.7754, -4.5090,\n",
      "         -4.2513, -4.1206, -4.5726, -4.4347, -4.8704, -4.3785, -4.4712, -3.9558,\n",
      "         -4.8189, -4.6669, -4.8126, -4.9134, -4.9119, -4.6636, -4.3703, -4.4760,\n",
      "         -4.8435, -4.6953, -4.7708, -4.8960, -4.5634, -4.3570, -4.5164, -4.7047,\n",
      "         -4.4022, -4.3102, -5.1197, -4.7106, -4.3492, -4.7596, -4.7149, -4.6887,\n",
      "         -4.6872, -4.5439, -4.7233, -4.6429, -4.6810, -4.1689, -4.5135, -4.6252,\n",
      "         -4.5124]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : youth's\n",
      "target index is: [89] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1850, -4.7602, -4.7350, -4.8925, -4.1992, -4.7657, -4.8148, -4.5567,\n",
      "         -4.8243, -4.9991, -4.8904, -4.4131, -4.7191, -4.3538, -5.0265, -4.8755,\n",
      "         -4.6845, -4.6773, -4.6611, -4.6531, -4.4133, -4.5204, -4.4424, -4.5546,\n",
      "         -4.2901, -4.6800, -4.6714, -4.7888, -4.4854, -4.3941, -4.9974, -4.3785,\n",
      "         -4.9340, -4.7032, -4.6818, -5.2220, -4.7975, -4.7521, -4.8128, -4.3170,\n",
      "         -4.6378, -4.6803, -4.9011, -4.3571, -4.2954, -4.4920, -4.4874, -4.4227,\n",
      "         -4.5500, -4.4108, -4.2193, -4.8755, -4.4128, -4.2622, -4.3865, -4.4550,\n",
      "         -4.5099, -4.4995, -4.5372, -4.4995, -4.7521, -4.3399, -4.5356, -3.6995,\n",
      "         -4.3129, -4.3685, -4.8734, -4.6484, -4.6992, -4.6442, -4.3663, -4.7301,\n",
      "         -4.9341, -4.7625, -4.8753, -4.6204, -4.3967, -4.3119, -4.5551, -4.3199,\n",
      "         -4.6379, -4.7476, -4.9850, -5.1806, -4.6004, -4.2880, -4.5084, -5.0655,\n",
      "         -5.2542, -4.2116, -4.4371, -4.7240, -4.6288, -4.5136, -4.4370, -4.7116,\n",
      "         -4.8875]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : proud\n",
      "target index is: [50] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4293, -4.3367, -4.9102, -5.1072, -4.4075, -4.6771, -4.3383, -4.5810,\n",
      "         -5.3849, -4.5393, -4.9071, -4.4414, -4.8775, -4.4906, -4.6285, -5.1584,\n",
      "         -4.9917, -4.7246, -4.5678, -4.0255, -4.4138, -4.3947, -4.7494, -4.4819,\n",
      "         -4.9139, -4.9504, -4.4812, -4.4078, -4.5988, -4.8968, -4.7130, -4.6400,\n",
      "         -4.8862, -4.8927, -4.3653, -5.1438, -4.6090, -4.9917, -4.6780, -4.2178,\n",
      "         -4.3995, -4.6446, -4.5870, -4.4637, -4.5707, -4.2783, -4.9148, -4.2933,\n",
      "         -4.4979, -5.3687, -4.2888, -5.1427, -4.2246, -4.5616, -4.5626, -4.5508,\n",
      "         -4.8508, -4.3629, -4.3904, -4.7437, -4.6624, -4.2216, -4.6731, -4.4299,\n",
      "         -4.4041, -4.8526, -4.8309, -4.3026, -4.6448, -4.2682, -4.4545, -4.9247,\n",
      "         -4.9622, -4.8463, -4.6376, -4.8022, -4.4360, -4.2933, -4.0665, -4.1551,\n",
      "         -4.7765, -4.8194, -5.0825, -4.7901, -5.0200, -4.2436, -4.5707, -4.5862,\n",
      "         -4.7224, -4.3683, -4.3148, -4.2086, -4.9035, -4.5302, -4.2369, -4.5976,\n",
      "         -4.2881]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : livery\n",
      "target index is: [28] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6309, -4.4228, -4.9848, -4.7623, -4.0841, -5.1080, -4.3997, -4.3792,\n",
      "         -4.5727, -4.5067, -4.8517, -4.5802, -4.6749, -4.8379, -4.3297, -4.5755,\n",
      "         -4.8347, -5.0171, -4.7833, -4.3555, -4.7680, -4.1164, -4.9599, -4.8242,\n",
      "         -4.1660, -4.9418, -4.1992, -4.4685, -4.1334, -4.8478, -4.9297, -5.1645,\n",
      "         -4.9292, -4.8244, -4.6704, -4.7862, -4.5890, -4.6793, -5.0585, -4.5215,\n",
      "         -4.9609, -4.5614, -4.7630, -4.7820, -4.7468, -4.3471, -4.6860, -4.8786,\n",
      "         -4.4283, -5.0296, -4.4476, -4.6637, -4.5136, -4.3176, -4.7008, -4.3136,\n",
      "         -4.3496, -4.1406, -4.7216, -4.8785, -4.5332, -4.4127, -4.2318, -4.5576,\n",
      "         -4.5716, -4.5585, -4.7223, -4.7652, -4.7441, -4.2405, -4.2917, -4.4998,\n",
      "         -4.8063, -4.8620, -4.6777, -4.9050, -4.5570, -4.1804, -4.3763, -4.4669,\n",
      "         -4.4776, -4.6551, -4.8812, -4.6804, -4.4790, -4.3211, -4.4564, -4.8488,\n",
      "         -4.4623, -4.5309, -4.8606, -4.6038, -4.7866, -4.3297, -4.5656, -4.5168,\n",
      "         -4.0145]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : so\n",
      "target index is: [69] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3669, -4.3481, -4.9303, -4.7791, -4.3118, -5.0073, -4.5774, -4.4103,\n",
      "         -4.5485, -4.6553, -4.8155, -4.8567, -4.4671, -5.0319, -4.8467, -4.6195,\n",
      "         -4.7537, -4.3044, -4.5656, -4.5878, -4.4147, -4.2915, -4.9762, -4.8437,\n",
      "         -4.2331, -4.9240, -4.4150, -4.5112, -4.2500, -4.6613, -4.8418, -4.7779,\n",
      "         -4.9504, -5.0328, -4.6078, -4.7895, -4.8971, -4.4081, -4.8541, -4.7043,\n",
      "         -4.6492, -4.6777, -4.6565, -4.6254, -4.3420, -4.3228, -4.4893, -4.5420,\n",
      "         -4.5225, -4.8919, -4.5938, -4.5103, -4.7970, -4.3709, -4.4698, -4.7026,\n",
      "         -4.2187, -4.2805, -4.3276, -4.6457, -4.8835, -4.4816, -4.2010, -4.2162,\n",
      "         -4.3922, -4.8406, -4.4772, -4.4625, -4.2746, -4.4416, -4.3338, -4.5439,\n",
      "         -4.8111, -4.8445, -4.9727, -4.8112, -4.2496, -4.5402, -4.7535, -4.8063,\n",
      "         -4.2788, -4.6495, -4.8873, -4.7718, -4.7144, -4.3899, -4.5622, -4.6588,\n",
      "         -4.7368, -4.2772, -4.7274, -4.8811, -4.7652, -4.1656, -4.7135, -4.6659,\n",
      "         -4.3327]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : gazed\n",
      "target index is: [17] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4640, -4.3490, -4.6770, -4.7905, -4.3294, -4.6377, -4.4750, -4.3535,\n",
      "         -4.5794, -4.7486, -4.6874, -4.5588, -4.5908, -4.7231, -4.7669, -4.6337,\n",
      "         -4.4579, -4.6595, -4.6392, -4.5156, -4.6736, -4.6112, -4.6624, -4.6068,\n",
      "         -4.3669, -4.8737, -4.4451, -4.5448, -4.3592, -4.6165, -4.4128, -4.8440,\n",
      "         -4.8695, -4.7756, -4.5877, -4.6820, -4.5930, -4.6154, -4.7003, -4.6044,\n",
      "         -4.6975, -4.6062, -4.4486, -4.4464, -4.5204, -4.3072, -4.6781, -4.5732,\n",
      "         -4.4392, -4.6111, -4.5650, -4.3084, -4.8519, -4.5123, -4.6611, -4.3922,\n",
      "         -4.5748, -4.2373, -4.5826, -4.7152, -4.7488, -4.6395, -4.6891, -4.3530,\n",
      "         -4.6430, -4.6300, -4.8131, -4.4792, -4.5635, -4.5134, -4.4817, -4.4956,\n",
      "         -4.4949, -4.8233, -4.7038, -4.8442, -4.6023, -4.1919, -4.6133, -4.8360,\n",
      "         -4.5870, -4.6340, -4.6831, -4.8150, -4.5145, -4.4754, -4.3110, -4.6468,\n",
      "         -4.6805, -4.3252, -4.6288, -4.5655, -4.8136, -4.5143, -4.6091, -4.5574,\n",
      "         -4.5223]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : on\n",
      "target index is: [87] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4800, -4.6628, -4.6106, -4.6341, -4.2348, -4.6167, -4.3502, -4.2706,\n",
      "         -4.6942, -4.7169, -4.5767, -4.7782, -4.7749, -4.5911, -4.6515, -4.4698,\n",
      "         -4.3114, -4.6376, -4.6858, -4.7114, -4.8004, -4.6675, -4.5672, -4.5139,\n",
      "         -4.4320, -4.7608, -4.5912, -4.5256, -4.6520, -4.4370, -4.4746, -4.6542,\n",
      "         -4.7078, -4.7615, -4.7705, -4.6230, -4.7087, -4.6675, -4.9519, -4.6186,\n",
      "         -4.7278, -4.5311, -4.8188, -4.2971, -4.6386, -4.3856, -4.6173, -4.5774,\n",
      "         -4.4488, -4.3419, -4.7627, -4.4311, -5.1058, -4.3082, -4.6295, -4.3268,\n",
      "         -4.2994, -4.2857, -4.6559, -4.5362, -4.7421, -4.7046, -4.4981, -3.9882,\n",
      "         -4.8206, -4.2778, -4.8236, -4.5554, -4.5830, -4.5849, -4.5401, -4.6919,\n",
      "         -4.6706, -4.4034, -4.5971, -4.8175, -4.6277, -4.5423, -4.7456, -4.8072,\n",
      "         -4.4106, -4.4767, -4.7794, -4.6570, -4.6668, -4.4521, -4.6411, -4.7697,\n",
      "         -4.9329, -4.2636, -4.4877, -4.3242, -4.7353, -4.6541, -4.5366, -4.6909,\n",
      "         -4.8097]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : now,\n",
      "target index is: [63] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4290, -4.6296, -4.8474, -4.9145, -3.7895, -4.4985, -4.5192, -4.5573,\n",
      "         -4.6596, -4.6696, -4.5782, -4.3946, -4.9935, -4.7969, -4.7944, -4.4804,\n",
      "         -4.5933, -4.8193, -4.6475, -4.3875, -4.5785, -4.0974, -4.7815, -4.9109,\n",
      "         -4.5798, -4.9956, -4.6728, -4.3830, -4.3335, -4.7909, -4.4651, -5.0216,\n",
      "         -4.7018, -4.6991, -4.2659, -4.8515, -4.3925, -4.8534, -5.0997, -4.7659,\n",
      "         -4.6693, -4.4738, -4.6852, -4.4911, -4.5571, -4.4232, -4.4203, -4.8850,\n",
      "         -4.5619, -5.1504, -4.7967, -4.6026, -4.4840, -4.5134, -4.6085, -4.4807,\n",
      "         -4.2811, -4.3615, -4.4448, -4.5753, -4.5119, -4.5213, -4.8264, -4.3596,\n",
      "         -4.4874, -4.3987, -4.6310, -4.5953, -4.7134, -4.4279, -4.4546, -4.6575,\n",
      "         -4.9746, -4.8494, -4.6232, -4.8399, -4.8631, -4.4519, -4.6130, -4.4629,\n",
      "         -4.6408, -4.1176, -4.9005, -4.8025, -4.3309, -4.3057, -4.6173, -4.5736,\n",
      "         -4.8550, -4.4405, -4.6533, -4.2255, -4.7116, -4.3532, -4.5996, -4.5516,\n",
      "         -4.6196]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Will\n",
      "target index is: [36] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3919, -4.8245, -4.8250, -4.8692, -4.1053, -4.6113, -4.6368, -4.2968,\n",
      "         -4.5253, -4.7551, -4.6093, -4.6798, -4.5600, -4.8811, -4.9316, -4.2788,\n",
      "         -4.5137, -4.5622, -4.3831, -4.5262, -4.7847, -4.1651, -4.8782, -5.0601,\n",
      "         -3.9804, -5.0340, -4.4306, -4.4291, -4.2489, -4.4219, -4.5144, -4.9025,\n",
      "         -5.0322, -4.9267, -4.3709, -4.6595, -4.5928, -4.6618, -5.0987, -4.8116,\n",
      "         -4.9827, -4.5726, -4.4527, -4.6551, -4.6236, -4.4260, -4.6825, -4.6794,\n",
      "         -4.5859, -4.9068, -4.4414, -4.6251, -4.8978, -4.6059, -4.6376, -4.4644,\n",
      "         -4.1367, -4.2593, -4.3498, -4.5429, -4.9722, -4.7047, -4.4744, -4.5034,\n",
      "         -4.5076, -4.4435, -4.6690, -4.6124, -4.7376, -4.6593, -4.3200, -4.3710,\n",
      "         -4.7827, -4.8659, -4.7225, -4.7459, -4.3582, -4.3551, -4.4803, -4.7714,\n",
      "         -4.4487, -4.6921, -4.6448, -4.7431, -4.4363, -4.4634, -4.5702, -4.8019,\n",
      "         -4.6511, -4.3448, -4.6239, -4.5519, -4.8181, -4.5092, -4.8851, -4.3741,\n",
      "         -4.3264]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : be\n",
      "target index is: [24] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3436, -4.6976, -4.8060, -4.7446, -4.1828, -4.9932, -4.5392, -4.3719,\n",
      "         -4.7461, -4.7686, -4.6439, -4.3220, -4.7026, -5.0095, -5.0658, -4.3690,\n",
      "         -4.4088, -4.7365, -4.6734, -4.9802, -4.3770, -3.9809, -4.4306, -4.6975,\n",
      "         -4.0738, -5.0733, -4.3214, -4.7276, -4.4634, -4.5477, -4.4094, -5.2636,\n",
      "         -4.8179, -4.8358, -4.6130, -4.5506, -4.7077, -4.5718, -4.9429, -4.8358,\n",
      "         -5.0269, -4.7655, -4.6316, -4.6873, -4.3269, -4.5316, -4.4266, -4.7650,\n",
      "         -4.6241, -4.6339, -4.7371, -4.0862, -5.0144, -4.4178, -4.6318, -4.6671,\n",
      "         -4.5256, -4.4127, -4.3444, -4.7344, -4.8878, -4.5438, -4.5811, -4.0934,\n",
      "         -4.6600, -4.5192, -4.8845, -4.4304, -4.3165, -4.4240, -4.2080, -4.7192,\n",
      "         -4.9369, -4.7487, -5.0683, -5.1399, -4.4860, -4.3348, -4.6262, -4.8711,\n",
      "         -4.1462, -4.6225, -4.6779, -4.5119, -4.3023, -4.4570, -4.3941, -4.8836,\n",
      "         -5.0014, -4.5252, -4.1785, -4.7768, -4.5465, -4.4644, -4.5916, -4.5667,\n",
      "         -4.5362]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : a\n",
      "target index is: [46] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3467, -4.5282, -4.6606, -5.3650, -4.1638, -4.7000, -4.2663, -4.0537,\n",
      "         -4.7488, -4.5682, -4.7952, -4.9250, -4.3780, -4.7454, -4.6979, -4.3194,\n",
      "         -4.2085, -4.6302, -4.6874, -4.5621, -4.9429, -4.3717, -4.7176, -4.9496,\n",
      "         -4.2496, -5.2659, -4.2125, -4.4420, -4.3288, -4.6470, -4.4763, -4.7670,\n",
      "         -4.9169, -5.0954, -4.4383, -4.6665, -4.5361, -4.3425, -4.9464, -4.5860,\n",
      "         -4.8850, -4.6066, -4.9746, -4.3643, -4.9118, -4.2802, -4.8755, -4.7789,\n",
      "         -4.7204, -4.7953, -4.1958, -4.6481, -4.5633, -4.5451, -4.6641, -4.5422,\n",
      "         -4.3480, -4.4873, -4.4171, -4.7352, -4.8509, -4.6991, -4.4660, -4.3760,\n",
      "         -4.6199, -4.3511, -4.9768, -4.4239, -4.7608, -4.7964, -4.7602, -4.5572,\n",
      "         -4.8705, -4.7845, -4.6745, -4.8896, -4.3867, -4.3291, -4.0663, -4.7025,\n",
      "         -4.3482, -4.6392, -4.7140, -4.7180, -4.8445, -4.3254, -4.6351, -4.7383,\n",
      "         -4.7197, -4.3691, -4.5155, -4.4023, -5.0769, -4.3880, -4.8286, -4.3037,\n",
      "         -4.3573]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : totter'd\n",
      "target index is: [20] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6674, -4.6990, -4.9445, -4.8706, -4.3885, -4.8015, -4.6078, -4.0712,\n",
      "         -4.8639, -4.5973, -4.8232, -4.2963, -4.3183, -4.6815, -5.0129, -4.6060,\n",
      "         -4.7329, -4.4098, -4.3088, -4.7385, -4.5883, -4.4033, -4.5858, -4.8378,\n",
      "         -3.9944, -5.1475, -4.5299, -4.7628, -4.2005, -4.2299, -4.5312, -4.8072,\n",
      "         -4.8245, -4.9310, -4.8694, -5.1962, -4.6659, -4.5122, -4.7796, -4.5185,\n",
      "         -4.7283, -4.7799, -4.7262, -4.6948, -4.5911, -4.4699, -4.8084, -4.8378,\n",
      "         -4.8082, -4.6810, -4.3885, -4.4935, -4.8137, -4.5495, -4.5371, -4.4357,\n",
      "         -4.4007, -4.1664, -4.2770, -4.3851, -4.7972, -4.4748, -4.4729, -3.9835,\n",
      "         -4.5327, -4.6380, -4.4242, -4.7169, -4.6249, -4.0324, -4.4317, -4.3516,\n",
      "         -5.0708, -4.8322, -4.9951, -4.9878, -4.3155, -4.3702, -4.1667, -4.8898,\n",
      "         -4.6133, -4.6368, -5.0140, -4.6592, -4.8204, -4.5609, -4.6642, -4.7185,\n",
      "         -4.8084, -4.4224, -4.5565, -4.7267, -4.8346, -4.1518, -4.7336, -4.6900,\n",
      "         -4.3313]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : weed\n",
      "target index is: [29] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5968, -4.7540, -4.5365, -4.6570, -4.1507, -4.7680, -4.4765, -4.3187,\n",
      "         -4.6894, -4.8039, -4.6622, -4.6442, -4.7045, -4.8166, -5.0355, -4.8114,\n",
      "         -4.4307, -4.4081, -4.4359, -4.6030, -4.5530, -4.6573, -4.6457, -4.4712,\n",
      "         -4.1714, -4.8276, -4.5495, -4.7140, -4.5828, -4.4500, -4.3227, -4.5946,\n",
      "         -4.5398, -4.7811, -4.6347, -4.7256, -4.3988, -4.5946, -4.3789, -4.6006,\n",
      "         -4.6305, -4.7129, -4.8321, -4.6394, -4.4998, -4.3022, -4.2216, -4.5199,\n",
      "         -4.6464, -4.4935, -4.7410, -4.3252, -4.8586, -4.4023, -4.4422, -4.5498,\n",
      "         -4.4589, -4.1978, -4.3397, -4.6582, -5.0310, -4.5428, -4.5275, -4.2396,\n",
      "         -4.8460, -4.6947, -4.6467, -4.6265, -4.4627, -4.5033, -4.5674, -4.6932,\n",
      "         -4.8394, -4.9255, -4.8191, -4.7734, -4.5938, -4.2510, -4.6193, -4.8861,\n",
      "         -4.6698, -4.5599, -4.6612, -4.5820, -4.7231, -4.5275, -4.4549, -4.7922,\n",
      "         -4.9746, -4.1629, -4.6811, -4.5250, -4.6381, -4.5085, -4.5557, -4.7984,\n",
      "         -4.6383]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : of\n",
      "target index is: [57] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5117, -4.3951, -4.3829, -4.6382, -3.8953, -4.7266, -4.9548, -4.5130,\n",
      "         -4.7185, -4.5996, -4.6317, -4.2535, -4.8531, -4.7414, -4.6292, -4.5918,\n",
      "         -4.5727, -4.9513, -4.4929, -4.7756, -4.4529, -4.2057, -4.5272, -4.4665,\n",
      "         -4.3920, -4.7372, -4.4130, -4.6808, -4.4167, -4.6206, -4.4534, -5.2738,\n",
      "         -4.7163, -4.3475, -4.6634, -5.0257, -4.5892, -4.9246, -4.4777, -4.8566,\n",
      "         -4.7136, -4.8409, -4.7674, -4.6596, -4.4414, -4.4156, -4.4352, -4.9702,\n",
      "         -4.8479, -4.4595, -4.6416, -4.4493, -4.7688, -4.3198, -4.9901, -4.5265,\n",
      "         -4.6864, -4.3674, -4.4902, -4.4665, -4.7629, -4.7556, -4.7200, -3.8571,\n",
      "         -4.8101, -4.6671, -5.0544, -4.6735, -4.6413, -4.7582, -4.3218, -4.5898,\n",
      "         -4.9649, -4.6624, -4.6707, -4.7689, -4.6758, -4.4627, -4.5135, -4.8746,\n",
      "         -4.5609, -4.0935, -4.8108, -4.7703, -4.4369, -4.5718, -4.3859, -4.5889,\n",
      "         -4.9022, -4.1542, -4.5920, -4.7662, -4.5301, -4.4936, -4.1043, -4.8196,\n",
      "         -4.4706]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : small\n",
      "target index is: [38] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3569, -4.2939, -4.6148, -4.8766, -4.3463, -4.7584, -4.5058, -4.5394,\n",
      "         -4.7144, -4.9440, -4.8451, -4.5672, -4.7678, -4.4894, -4.2859, -4.7823,\n",
      "         -4.8446, -5.0389, -4.6142, -4.2360, -4.8134, -4.5590, -4.5546, -4.4094,\n",
      "         -4.7375, -5.1032, -4.7523, -4.4518, -4.0837, -4.6424, -4.4647, -5.0025,\n",
      "         -4.7717, -4.7067, -4.4770, -4.8753, -4.7470, -4.8340, -4.9139, -4.4537,\n",
      "         -4.6545, -4.6039, -4.8467, -4.1416, -4.8184, -4.1709, -5.0310, -4.4203,\n",
      "         -4.4369, -4.8662, -4.9119, -4.7147, -4.7370, -4.4991, -4.6501, -4.6602,\n",
      "         -4.3040, -4.1713, -4.6608, -4.6728, -4.6246, -4.7067, -4.8747, -4.2904,\n",
      "         -5.0040, -4.4863, -5.1327, -4.2596, -4.6839, -4.7798, -4.2307, -4.7198,\n",
      "         -4.7652, -4.6440, -4.8574, -4.7386, -4.9925, -4.2785, -4.4035, -4.2230,\n",
      "         -4.6820, -4.3939, -4.7481, -4.8008, -4.6610, -4.0546, -4.3369, -4.4285,\n",
      "         -5.0323, -4.2512, -4.4897, -4.2556, -4.6468, -4.6087, -4.2380, -4.4230,\n",
      "         -4.3638]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : worth\n",
      "target index is: [83] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6670, -4.6167, -4.7982, -5.0806, -4.2721, -4.8438, -4.3416, -4.5635,\n",
      "         -4.7095, -4.7590, -5.0301, -4.8570, -4.8910, -4.7374, -4.4371, -4.5475,\n",
      "         -4.5526, -4.8780, -4.6514, -4.1309, -4.7669, -4.0123, -4.9606, -4.7207,\n",
      "         -4.1641, -5.1358, -4.2351, -4.0986, -4.5558, -4.6099, -5.0062, -4.9155,\n",
      "         -5.0336, -4.9852, -4.5743, -4.2891, -4.7987, -4.9086, -5.1924, -4.7143,\n",
      "         -5.0088, -5.1873, -4.7215, -4.6095, -4.6761, -4.5295, -4.8178, -5.0027,\n",
      "         -4.3268, -4.8669, -3.9582, -4.8069, -4.1859, -3.9384, -4.9730, -4.0279,\n",
      "         -4.8977, -4.4394, -4.4914, -4.6017, -4.7635, -4.6630, -4.6296, -4.2048,\n",
      "         -4.8566, -4.1593, -5.0828, -4.6123, -4.9051, -4.5609, -4.2634, -4.8214,\n",
      "         -4.8822, -4.1477, -4.5446, -5.0322, -4.3909, -4.4799, -4.6688, -4.7264,\n",
      "         -4.1856, -4.3851, -4.7480, -4.4602, -4.2758, -4.1718, -5.0437, -5.2841,\n",
      "         -4.5359, -4.2875, -4.4499, -4.6809, -4.5529, -4.3736, -4.4727, -4.7907,\n",
      "         -4.2858]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : held:\n",
      "target index is: [19] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3284, -4.3990, -5.0610, -5.0648, -4.0706, -4.8997, -4.3325, -4.5816,\n",
      "         -4.6762, -4.1901, -5.0579, -4.6413, -4.8835, -4.7132, -4.4228, -4.6380,\n",
      "         -4.6254, -4.6778, -5.0214, -4.4358, -4.3609, -4.3962, -4.7741, -4.7492,\n",
      "         -4.8026, -5.2166, -4.4605, -4.4923, -4.6026, -4.6576, -4.7524, -4.6486,\n",
      "         -4.6927, -5.2462, -4.5927, -4.5726, -4.4829, -4.5805, -5.0005, -4.2672,\n",
      "         -4.6053, -4.5729, -4.4893, -4.2546, -4.2457, -4.6168, -4.6994, -4.5376,\n",
      "         -4.2518, -5.3196, -4.3756, -5.0292, -4.6977, -4.4026, -4.7603, -4.5583,\n",
      "         -4.6271, -4.5746, -4.4833, -4.5968, -4.6290, -4.3264, -4.4396, -4.4844,\n",
      "         -4.4517, -4.5560, -4.6652, -4.3301, -4.5900, -4.3559, -4.6359, -5.0201,\n",
      "         -4.8661, -4.5120, -4.8886, -5.2945, -4.1659, -4.8099, -4.5132, -4.7812,\n",
      "         -4.6302, -4.2563, -4.8238, -4.5453, -5.2943, -3.8843, -5.1273, -4.5873,\n",
      "         -4.7230, -4.0679, -4.5415, -4.8355, -4.8346, -4.1637, -4.6363, -4.2742,\n",
      "         -4.2672]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Then\n",
      "target index is: [65] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3762, -4.5278, -4.9073, -4.7393, -3.9597, -4.8503, -4.5799, -4.7651,\n",
      "         -4.8345, -4.6503, -4.7275, -4.6216, -4.8132, -4.6945, -4.7379, -4.5395,\n",
      "         -4.5545, -4.6738, -5.1233, -4.7000, -4.6042, -4.2059, -4.7973, -4.3514,\n",
      "         -4.4090, -4.7482, -4.7849, -4.3083, -4.3407, -4.4192, -4.7060, -4.5585,\n",
      "         -4.7103, -4.9285, -4.5422, -4.2256, -4.6537, -4.9973, -4.9907, -4.4544,\n",
      "         -4.8861, -4.3833, -4.5369, -4.3512, -4.2359, -4.3579, -4.5005, -4.6965,\n",
      "         -4.3389, -4.9734, -4.6793, -4.5546, -4.9358, -4.0517, -4.5709, -4.4235,\n",
      "         -4.3271, -4.3979, -4.7019, -4.3747, -4.7571, -4.6209, -4.5377, -4.3972,\n",
      "         -4.6807, -4.5458, -4.7694, -4.2810, -4.6315, -4.4791, -4.4553, -4.7713,\n",
      "         -4.8294, -4.7727, -4.9290, -4.9472, -4.4156, -4.5331, -4.8642, -4.9970,\n",
      "         -4.4801, -4.2371, -4.4454, -4.5116, -4.8305, -4.0288, -4.8041, -5.0352,\n",
      "         -4.8720, -4.1356, -4.6864, -4.9284, -4.5263, -4.4214, -4.5301, -4.8661,\n",
      "         -4.6911]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : being\n",
      "target index is: [32] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3324, -4.2749, -4.6304, -5.0503, -4.1794, -4.3630, -4.5058, -4.1506,\n",
      "         -4.9661, -4.4645, -4.8458, -4.3407, -4.6647, -4.3725, -5.0173, -4.4331,\n",
      "         -4.4454, -4.4915, -4.7269, -4.0583, -4.8228, -4.7910, -4.4269, -4.4676,\n",
      "         -4.8753, -4.5738, -4.6571, -4.5373, -4.4282, -4.8025, -4.2356, -4.8256,\n",
      "         -4.9125, -4.6178, -4.5220, -4.8097, -4.4795, -4.9804, -4.9208, -4.8242,\n",
      "         -4.7089, -4.7252, -4.4871, -4.2024, -4.4428, -4.1407, -4.7445, -4.7498,\n",
      "         -4.7725, -4.7071, -4.7228, -4.4010, -4.5146, -4.5492, -5.0148, -4.7074,\n",
      "         -4.5643, -4.5763, -4.5511, -4.5689, -4.9153, -4.8292, -4.7856, -4.2587,\n",
      "         -4.6137, -4.5395, -4.9335, -4.5335, -4.6499, -4.8996, -4.5429, -4.7107,\n",
      "         -4.6593, -5.0513, -4.3997, -4.5551, -4.5642, -4.4282, -4.3584, -4.7012,\n",
      "         -4.6048, -4.4032, -4.4159, -4.8701, -4.8166, -4.4624, -4.3693, -4.2199,\n",
      "         -5.0656, -4.4140, -4.6356, -4.4187, -4.9932, -4.5300, -4.4039, -4.4104,\n",
      "         -4.7093]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : asked,\n",
      "target index is: [23] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1933, -4.5973, -4.4968, -4.6556, -4.0884, -4.8354, -4.6445, -4.3758,\n",
      "         -4.6856, -4.5951, -4.6304, -4.2909, -4.6219, -4.6672, -4.7069, -4.8130,\n",
      "         -4.7452, -5.0968, -4.4414, -4.8255, -4.5476, -4.5054, -4.6843, -4.6085,\n",
      "         -4.4118, -4.8631, -4.5242, -4.4910, -4.3514, -4.5468, -4.5808, -4.8150,\n",
      "         -4.6758, -4.6156, -4.7360, -5.0621, -4.5900, -4.4689, -4.4750, -4.6373,\n",
      "         -4.7701, -4.4369, -4.6454, -4.5159, -4.3884, -4.1966, -4.6563, -4.8794,\n",
      "         -4.7749, -4.5112, -4.6133, -4.3142, -4.8875, -4.4825, -4.8229, -4.3908,\n",
      "         -4.5920, -4.2264, -4.3769, -4.6105, -4.7113, -4.5095, -4.6141, -3.9948,\n",
      "         -4.7943, -4.6383, -4.9531, -4.6977, -4.8697, -4.6373, -4.5465, -4.6443,\n",
      "         -4.9212, -4.5113, -4.6613, -4.9692, -4.7419, -4.2509, -4.3909, -4.9206,\n",
      "         -4.5213, -4.2006, -4.9092, -4.6227, -4.4168, -4.5212, -4.6436, -4.5517,\n",
      "         -5.0382, -4.4272, -4.5095, -4.5276, -4.5973, -4.6564, -4.2997, -4.7250,\n",
      "         -4.4744]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : where\n",
      "target index is: [51] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3517, -4.3049, -4.6673, -4.9610, -4.2939, -4.9486, -4.7194, -4.6819,\n",
      "         -4.8825, -4.6557, -4.9540, -4.6206, -4.8349, -4.5858, -4.6532, -4.9709,\n",
      "         -4.7021, -4.5888, -4.9397, -4.5119, -4.6617, -4.5784, -4.7833, -4.5289,\n",
      "         -4.5795, -4.7514, -4.3919, -4.3936, -4.2695, -4.6536, -4.3135, -4.9451,\n",
      "         -4.7390, -4.6978, -4.5165, -4.9960, -4.4789, -4.6530, -4.7753, -4.5733,\n",
      "         -4.6144, -4.7098, -4.6109, -4.5941, -4.5091, -4.1632, -4.8044, -4.5938,\n",
      "         -4.7692, -4.7892, -4.2445, -4.9134, -4.6196, -4.5102, -4.5175, -4.6864,\n",
      "         -4.5533, -4.3402, -4.5600, -4.5265, -4.5515, -4.4141, -4.5300, -4.4201,\n",
      "         -4.4902, -4.8016, -5.0088, -4.3123, -4.3965, -4.3307, -4.6633, -4.5294,\n",
      "         -5.0879, -4.9228, -4.8680, -4.9448, -4.5541, -4.2496, -4.2599, -4.5030,\n",
      "         -4.3786, -4.3919, -4.7281, -4.8789, -4.8370, -4.2274, -4.3253, -4.4985,\n",
      "         -4.7612, -4.4404, -4.1922, -4.7265, -4.6999, -4.3677, -4.2706, -4.5699,\n",
      "         -4.2135]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : all\n",
      "target index is: [52] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4719, -4.2801, -4.6605, -4.7963, -4.4574, -4.8216, -4.4238, -4.4590,\n",
      "         -4.5508, -4.8912, -4.9873, -4.6892, -4.4996, -4.6184, -4.5850, -4.6565,\n",
      "         -4.6450, -4.7353, -4.5890, -4.2085, -4.7796, -4.7624, -4.6556, -4.4831,\n",
      "         -4.3739, -4.8714, -4.5154, -4.4984, -4.2059, -4.8527, -4.4687, -4.7797,\n",
      "         -4.8708, -4.8650, -4.4940, -4.5591, -4.6298, -4.4820, -4.6725, -4.6210,\n",
      "         -4.7469, -4.6210, -4.7445, -4.5077, -4.7490, -4.2330, -4.8514, -4.6430,\n",
      "         -4.5671, -4.8341, -4.4575, -4.4712, -4.5899, -4.3371, -4.7267, -4.5386,\n",
      "         -4.3899, -4.3468, -4.6178, -4.7395, -4.7781, -4.7387, -4.5944, -4.5888,\n",
      "         -4.8050, -4.5346, -5.0718, -4.3692, -4.6399, -4.6376, -4.4535, -4.5313,\n",
      "         -4.5590, -4.8775, -4.6424, -4.6723, -4.5319, -4.2158, -4.2651, -4.6608,\n",
      "         -4.4659, -4.5707, -4.5985, -4.7933, -4.6532, -4.2922, -4.4566, -4.5670,\n",
      "         -4.7124, -4.3464, -4.5866, -4.6519, -4.6602, -4.5490, -4.3540, -4.4842,\n",
      "         -4.2461]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3193, -4.3676, -4.9418, -4.7744, -4.2799, -4.7727, -4.8444, -4.3963,\n",
      "         -5.0862, -4.2684, -5.0108, -4.4071, -4.5158, -4.5908, -4.6716, -4.8401,\n",
      "         -4.5599, -4.4270, -4.4965, -4.5022, -4.6545, -4.4044, -4.4916, -4.8011,\n",
      "         -4.4004, -5.0716, -4.3788, -4.5409, -4.5020, -4.4821, -4.6535, -4.6649,\n",
      "         -4.8521, -4.6987, -4.8987, -5.1058, -4.7143, -4.6365, -4.8728, -4.5926,\n",
      "         -4.6608, -4.7832, -4.6706, -4.6278, -4.5271, -4.1258, -4.8234, -4.7286,\n",
      "         -4.9110, -4.6397, -4.7523, -4.7671, -4.5416, -4.3031, -4.4764, -4.7842,\n",
      "         -4.3031, -4.3624, -4.4589, -4.5192, -4.7026, -4.5073, -4.2602, -4.3471,\n",
      "         -4.2449, -4.7537, -4.7088, -4.2543, -4.5842, -4.3787, -4.4626, -4.6384,\n",
      "         -4.8155, -4.5758, -4.7964, -4.7183, -4.2426, -4.4958, -4.1807, -4.7099,\n",
      "         -4.2924, -4.5769, -4.8095, -5.0686, -4.8536, -4.4402, -4.7390, -4.6492,\n",
      "         -4.8899, -4.4736, -4.5072, -4.8061, -4.8314, -4.3580, -4.0674, -4.8465,\n",
      "         -4.4056]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty\n",
      "target index is: [0] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3316, -4.7072, -4.7280, -4.9182, -4.2206, -4.6955, -4.3485, -4.1984,\n",
      "         -5.1258, -4.4895, -4.7819, -4.4133, -4.2562, -4.5839, -4.8692, -5.1137,\n",
      "         -4.7231, -4.5578, -4.6691, -4.5531, -4.7675, -4.7344, -4.8165, -4.6561,\n",
      "         -4.4280, -5.2015, -4.3998, -4.4587, -4.2188, -4.6678, -4.4791, -4.3593,\n",
      "         -4.7461, -4.9616, -4.6892, -5.1731, -4.3537, -4.5120, -4.4000, -4.3659,\n",
      "         -4.5611, -4.3928, -4.6577, -4.3714, -4.5385, -4.1181, -4.9348, -4.6062,\n",
      "         -4.8346, -4.7732, -4.5286, -4.6626, -4.8204, -4.5782, -4.6029, -4.5920,\n",
      "         -4.4317, -4.3118, -4.5318, -4.3473, -4.7279, -4.4411, -4.3642, -4.4737,\n",
      "         -4.3046, -5.0202, -4.7407, -4.4411, -4.7467, -4.0250, -4.5917, -4.5273,\n",
      "         -5.1282, -4.9156, -4.7599, -4.7403, -4.5855, -3.9186, -4.1089, -4.7577,\n",
      "         -4.5522, -4.7936, -4.8593, -4.9371, -5.1319, -4.2968, -4.5886, -4.4137,\n",
      "         -5.3433, -4.8650, -4.7498, -4.6127, -4.8696, -4.3767, -4.5407, -4.8042,\n",
      "         -4.2972]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : lies,\n",
      "target index is: [59] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3069, -4.6812, -4.6449, -4.6779, -4.2102, -4.9037, -4.3585, -4.2129,\n",
      "         -4.6848, -5.1466, -4.7522, -4.3698, -4.5356, -4.8260, -4.7490, -4.6511,\n",
      "         -4.4814, -4.9515, -4.7577, -4.9138, -4.4346, -4.4731, -4.6413, -4.5334,\n",
      "         -4.1459, -4.8849, -4.5095, -4.3676, -4.3866, -4.5935, -4.6327, -4.7118,\n",
      "         -4.5175, -5.1494, -4.5204, -4.6578, -4.9162, -4.3159, -4.6913, -4.3972,\n",
      "         -5.0551, -4.2633, -4.7758, -4.4339, -4.4486, -4.1935, -4.4786, -4.5794,\n",
      "         -4.5239, -4.5444, -4.5998, -4.1711, -5.0205, -4.4112, -4.6834, -4.3344,\n",
      "         -4.5848, -4.4313, -4.7734, -4.7681, -4.6604, -4.3258, -4.5479, -4.3810,\n",
      "         -4.6536, -4.6836, -4.7165, -4.3552, -4.6620, -4.4308, -4.4515, -4.7053,\n",
      "         -4.4789, -4.9678, -4.8432, -4.9274, -4.6212, -4.1219, -4.5715, -5.0330,\n",
      "         -4.3885, -4.7448, -4.6995, -4.7794, -4.4361, -4.4161, -4.4703, -5.0370,\n",
      "         -5.0122, -4.5316, -4.6679, -4.6889, -4.4290, -4.6506, -4.7428, -4.5838,\n",
      "         -4.4494]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Where\n",
      "target index is: [18] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5388, -4.4356, -4.3890, -4.5959, -4.2488, -4.9786, -4.7449, -4.5341,\n",
      "         -4.6614, -4.7760, -4.7096, -4.5105, -4.7151, -4.7435, -4.5476, -4.5552,\n",
      "         -4.8485, -4.5902, -4.5750, -4.6098, -4.3981, -4.3325, -4.7246, -4.6521,\n",
      "         -4.3678, -4.7631, -4.6476, -4.4781, -4.3502, -4.5713, -4.7205, -4.6635,\n",
      "         -4.8296, -4.6104, -4.6399, -4.9032, -4.5764, -4.9089, -4.4827, -4.5250,\n",
      "         -4.6545, -4.6711, -4.8298, -4.5178, -4.6087, -4.4203, -4.5480, -4.6806,\n",
      "         -4.5083, -4.8347, -4.4817, -4.8418, -4.4813, -4.5979, -4.7216, -4.7610,\n",
      "         -4.3044, -4.4202, -4.3720, -4.5204, -4.8121, -4.7591, -4.5222, -4.2342,\n",
      "         -4.9023, -4.4430, -4.9245, -4.3683, -4.5752, -4.7282, -4.3103, -4.4987,\n",
      "         -4.8650, -4.9011, -4.8335, -4.7647, -4.2462, -4.3373, -4.6305, -4.5563,\n",
      "         -4.4501, -4.2967, -4.6218, -4.7500, -4.6448, -4.4483, -4.3766, -4.7240,\n",
      "         -4.7725, -4.2543, -4.5239, -4.7322, -4.5431, -4.4350, -4.2565, -4.4959,\n",
      "         -4.5588]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : all\n",
      "target index is: [52] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2773, -4.2295, -4.6080, -4.9580, -4.3558, -4.6168, -4.5486, -4.4924,\n",
      "         -4.7991, -4.9815, -4.8314, -4.4759, -4.7139, -4.6338, -4.5060, -4.7840,\n",
      "         -4.7604, -5.0677, -4.4266, -4.1514, -4.7677, -4.4309, -4.6522, -4.4638,\n",
      "         -4.6085, -4.7552, -4.4106, -4.4743, -4.1771, -5.0113, -4.4321, -4.9434,\n",
      "         -4.8751, -4.7036, -4.3244, -4.7364, -4.5717, -4.7896, -4.7924, -4.7423,\n",
      "         -4.6971, -4.6626, -4.7946, -4.5862, -4.8509, -4.2806, -5.0422, -4.6425,\n",
      "         -4.6323, -4.8763, -4.4344, -4.6556, -4.3772, -4.5349, -5.0281, -4.6036,\n",
      "         -4.6502, -4.4263, -4.6236, -4.7899, -4.5783, -4.5831, -4.7313, -4.4404,\n",
      "         -5.0049, -4.4742, -5.1067, -4.6349, -4.7718, -4.6719, -4.3175, -4.5911,\n",
      "         -4.5754, -4.7660, -4.4268, -4.6371, -4.5796, -4.1735, -4.2434, -4.4144,\n",
      "         -4.4470, -4.4199, -4.7258, -4.8273, -4.4422, -4.3848, -4.3465, -4.5524,\n",
      "         -4.7315, -4.2955, -4.4160, -4.4304, -4.7380, -4.5536, -4.1585, -4.4354,\n",
      "         -4.3753]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : the\n",
      "target index is: [82] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1439, -4.4092, -4.5747, -4.8750, -4.1869, -4.6909, -4.6582, -4.3298,\n",
      "         -4.6372, -4.7244, -4.8754, -4.7136, -4.6267, -4.7979, -4.6955, -4.6653,\n",
      "         -4.4307, -4.5060, -4.4588, -4.6309, -4.8793, -4.5333, -4.7855, -4.6027,\n",
      "         -4.1914, -4.5019, -4.5436, -4.5049, -4.4682, -4.5052, -4.5579, -4.6516,\n",
      "         -4.5540, -4.6929, -4.8948, -4.7731, -4.8502, -4.5465, -4.8654, -4.8209,\n",
      "         -4.7232, -4.5550, -4.7668, -4.3639, -4.6017, -4.1742, -4.6381, -4.5201,\n",
      "         -4.5586, -4.4563, -4.5066, -4.5965, -4.9591, -4.4521, -4.5104, -4.6806,\n",
      "         -4.4501, -4.5136, -4.4279, -4.5828, -5.1483, -4.6635, -4.4191, -4.0421,\n",
      "         -4.8473, -4.7423, -4.7400, -4.5193, -4.6463, -4.7352, -4.7345, -4.6566,\n",
      "         -4.4815, -4.5164, -4.5408, -4.5298, -4.3823, -4.4626, -4.4915, -4.8110,\n",
      "         -4.2061, -4.3347, -4.8756, -4.7692, -4.5838, -4.5569, -4.7729, -4.8191,\n",
      "         -4.9138, -4.3609, -4.5959, -4.5120, -4.6305, -4.5397, -4.3382, -4.6184,\n",
      "         -4.6333]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : treasure\n",
      "target index is: [31] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3590, -4.3704, -4.7166, -4.9705, -4.1182, -4.7676, -4.6439, -4.6068,\n",
      "         -4.7595, -4.5766, -4.6173, -4.2833, -4.7828, -4.7637, -4.8416, -4.8341,\n",
      "         -4.4893, -4.7539, -4.7040, -4.5605, -4.5273, -4.4850, -4.8284, -4.6083,\n",
      "         -4.7093, -4.9856, -4.2943, -4.4491, -4.2775, -4.8980, -4.2503, -5.0360,\n",
      "         -4.6790, -4.6152, -4.4997, -5.0416, -4.3671, -4.6871, -4.7085, -4.7832,\n",
      "         -4.5762, -4.7709, -4.4978, -4.3871, -4.5260, -4.2993, -4.6563, -4.7222,\n",
      "         -4.7646, -4.9188, -4.3192, -4.7625, -4.7137, -4.8449, -4.7195, -4.3866,\n",
      "         -4.5709, -4.1438, -4.4973, -4.6050, -4.5144, -4.3235, -4.7785, -4.2616,\n",
      "         -4.4953, -4.6301, -5.0259, -4.7182, -4.2660, -4.3157, -4.7230, -4.7534,\n",
      "         -4.8523, -4.8122, -4.7620, -5.0161, -4.6314, -4.2962, -4.4698, -4.5518,\n",
      "         -4.6214, -4.1965, -4.8007, -4.9708, -4.6445, -4.4459, -4.3448, -4.2919,\n",
      "         -4.7283, -4.5436, -4.3009, -4.4925, -4.8530, -4.4888, -4.5242, -4.4531,\n",
      "         -4.2993]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : of\n",
      "target index is: [57] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4772, -4.1768, -4.3152, -4.5624, -4.1715, -4.8557, -4.8713, -4.4318,\n",
      "         -4.8243, -4.7661, -5.0715, -4.5473, -4.6078, -4.5531, -4.7797, -4.7803,\n",
      "         -4.6695, -4.5551, -4.5650, -4.5473, -4.6058, -4.3848, -4.6710, -4.4004,\n",
      "         -4.0632, -4.6820, -4.5029, -4.5365, -4.3129, -4.4955, -4.6516, -5.0469,\n",
      "         -5.0239, -4.6030, -4.8646, -4.9211, -4.8329, -4.7658, -4.5104, -4.6977,\n",
      "         -4.8401, -4.5242, -4.6550, -4.5001, -4.5113, -4.3228, -4.7476, -4.9435,\n",
      "         -4.6218, -4.5246, -4.4244, -4.4134, -4.8327, -4.2415, -4.6507, -4.6536,\n",
      "         -4.4557, -4.3871, -4.4717, -4.7027, -4.9044, -4.7173, -4.3911, -4.1838,\n",
      "         -4.7046, -4.7324, -5.0235, -4.5062, -4.7704, -4.6968, -4.5806, -4.4894,\n",
      "         -4.7151, -4.8600, -4.6800, -4.7857, -4.5883, -4.1678, -4.3931, -4.9053,\n",
      "         -4.1624, -4.3551, -4.7505, -4.8251, -4.6183, -4.4635, -4.5392, -4.6956,\n",
      "         -4.7704, -4.2057, -4.6329, -4.8232, -4.5870, -4.4053, -4.3213, -4.6683,\n",
      "         -4.3386]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.0975, -4.2773, -4.8806, -5.0469, -4.2262, -4.7451, -4.7331, -4.2605,\n",
      "         -5.2637, -4.3851, -5.1271, -4.1578, -4.5610, -4.2543, -4.7328, -5.0080,\n",
      "         -4.5665, -4.5961, -4.7845, -4.1947, -4.7930, -4.8141, -4.4337, -4.4582,\n",
      "         -4.7292, -4.8554, -4.4171, -4.3598, -4.4092, -4.7000, -4.5558, -4.7687,\n",
      "         -5.0360, -4.8429, -4.8174, -5.2624, -4.6129, -4.5590, -4.9250, -4.4347,\n",
      "         -4.9091, -4.6593, -4.4731, -4.4183, -4.6504, -4.0115, -4.8879, -4.7338,\n",
      "         -4.8646, -4.7130, -4.6232, -4.7445, -4.4126, -4.3642, -4.8415, -4.8158,\n",
      "         -4.4488, -4.4606, -4.6870, -4.6345, -4.6262, -4.6023, -4.3112, -4.5579,\n",
      "         -4.3697, -4.7880, -5.1095, -4.3456, -4.5767, -4.6097, -4.2856, -4.7333,\n",
      "         -4.7001, -5.0153, -4.5734, -4.7108, -4.2862, -4.2254, -4.0924, -4.6174,\n",
      "         -4.3505, -4.5466, -4.6357, -4.9993, -5.1520, -4.2256, -4.6145, -4.3275,\n",
      "         -5.0843, -4.5698, -4.3899, -4.7945, -4.8824, -4.5228, -4.1866, -4.4814,\n",
      "         -4.3790]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : lusty\n",
      "target index is: [30] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2172, -4.6412, -4.3766, -4.9692, -4.2235, -4.7222, -4.4846, -4.1585,\n",
      "         -4.7004, -4.9725, -4.8755, -4.4407, -4.3724, -4.6648, -4.9121, -4.8511,\n",
      "         -4.4548, -4.7454, -4.3914, -4.8380, -4.7034, -5.0505, -4.6852, -4.6799,\n",
      "         -4.3750, -4.7203, -4.5477, -4.4816, -4.2180, -4.5131, -4.2116, -4.6944,\n",
      "         -4.6028, -4.9223, -4.7793, -4.9020, -4.4039, -4.4543, -4.4956, -4.5438,\n",
      "         -4.8251, -4.2882, -4.8199, -4.3495, -4.6512, -4.1821, -4.5430, -4.5874,\n",
      "         -4.6348, -4.5478, -4.6245, -4.3000, -5.0714, -4.5617, -4.8656, -4.7525,\n",
      "         -4.3535, -4.2893, -4.5521, -4.6133, -4.8695, -4.3929, -4.6251, -4.2197,\n",
      "         -4.6826, -4.8193, -4.7992, -4.8342, -4.7610, -4.4297, -4.6460, -4.4705,\n",
      "         -5.0362, -4.9653, -4.6864, -4.7006, -4.8959, -3.7840, -4.2691, -4.9923,\n",
      "         -4.4742, -4.5686, -4.6672, -4.8899, -4.8549, -4.4650, -4.4283, -4.4418,\n",
      "         -5.2642, -4.4024, -4.7816, -4.5082, -4.5035, -4.5973, -4.4171, -4.7724,\n",
      "         -4.4376]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : days;\n",
      "target index is: [48] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5399, -4.7278, -4.4261, -4.4833, -3.7241, -4.7704, -4.5431, -4.4544,\n",
      "         -4.5017, -4.9628, -4.4780, -4.5991, -5.0619, -4.9193, -4.6444, -4.6068,\n",
      "         -4.9302, -5.0995, -4.6278, -4.7247, -4.6344, -4.0649, -4.6973, -4.5358,\n",
      "         -4.4151, -4.8252, -4.4145, -4.5209, -4.5927, -4.5593, -4.6048, -4.6611,\n",
      "         -4.6908, -4.7890, -4.3989, -4.9579, -4.7172, -4.8924, -4.5240, -4.5830,\n",
      "         -4.8408, -4.6640, -4.9985, -4.4236, -4.8352, -4.7188, -4.3640, -4.4321,\n",
      "         -4.3166, -4.3497, -4.4556, -4.6597, -4.7332, -4.5050, -4.7049, -3.9131,\n",
      "         -4.6466, -4.1114, -4.4560, -4.6133, -4.6339, -4.7413, -5.0174, -3.9980,\n",
      "         -5.0580, -4.3903, -4.9453, -4.5683, -4.7470, -5.0697, -4.2462, -4.5828,\n",
      "         -4.8181, -4.9303, -4.4963, -5.0030, -4.6564, -4.5945, -4.4757, -4.6480,\n",
      "         -4.7521, -4.0641, -5.0152, -4.6446, -4.4731, -4.6457, -4.5726, -5.0301,\n",
      "         -4.8433, -4.2551, -4.6472, -4.4251, -4.4430, -4.5654, -4.4097, -4.4653,\n",
      "         -4.6227]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : To\n",
      "target index is: [26] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2504, -4.6698, -5.0322, -4.9620, -4.1035, -4.7776, -4.4555, -4.7331,\n",
      "         -4.5764, -4.6336, -4.9418, -4.5000, -4.8495, -4.4788, -4.8488, -4.6406,\n",
      "         -4.2368, -4.7062, -4.8813, -4.6035, -4.3537, -4.2006, -4.8323, -4.7176,\n",
      "         -4.5021, -4.8724, -4.4102, -4.4113, -4.3721, -4.8445, -4.6404, -4.9399,\n",
      "         -4.9123, -5.0161, -4.5757, -4.5501, -4.5721, -4.5183, -5.1371, -4.7041,\n",
      "         -4.7046, -4.6919, -4.3385, -4.7230, -4.1041, -4.4305, -4.5544, -4.8330,\n",
      "         -4.4548, -4.9854, -4.2561, -4.6152, -4.5905, -4.2621, -4.8016, -4.7347,\n",
      "         -4.6813, -4.5438, -4.5030, -4.6061, -4.6198, -4.3645, -4.5922, -4.3260,\n",
      "         -4.3518, -4.8131, -4.9571, -4.5236, -4.6213, -4.2840, -4.4063, -4.5773,\n",
      "         -4.9113, -4.4689, -4.8782, -4.9682, -4.5231, -4.3980, -4.7233, -4.6599,\n",
      "         -4.1429, -4.3681, -4.5661, -4.7188, -4.4300, -4.3278, -4.6512, -4.7417,\n",
      "         -4.8752, -4.6073, -4.4468, -4.9668, -4.5394, -4.2246, -4.4326, -4.6993,\n",
      "         -4.2781]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : say,\n",
      "target index is: [96] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.7515, -4.3185, -4.6568, -4.9178, -3.9650, -4.7139, -4.6001, -4.2941,\n",
      "         -4.7439, -4.5145, -4.7813, -4.6436, -4.6827, -4.7330, -4.6020, -4.8542,\n",
      "         -4.8136, -4.3562, -4.7689, -4.2386, -4.6672, -4.6004, -4.6531, -4.7176,\n",
      "         -4.4499, -4.8046, -4.4063, -4.5519, -4.2882, -4.5227, -4.6130, -4.6437,\n",
      "         -4.8480, -4.8085, -4.4319, -4.8573, -4.4931, -4.8326, -4.5415, -4.4596,\n",
      "         -4.5862, -4.6608, -4.6740, -4.4430, -4.6586, -4.5194, -4.4236, -4.5208,\n",
      "         -4.5613, -4.7040, -4.3599, -4.8417, -4.6113, -4.5696, -4.7721, -4.3785,\n",
      "         -4.6828, -4.3633, -4.4774, -4.6807, -4.6757, -4.6207, -4.5633, -4.2539,\n",
      "         -4.5882, -4.4458, -4.4920, -4.6323, -4.5492, -4.8547, -4.6788, -4.5278,\n",
      "         -4.8111, -5.1324, -4.6820, -4.7340, -4.3476, -4.5648, -4.3539, -4.8714,\n",
      "         -4.7468, -4.4120, -4.7069, -4.6873, -4.9676, -4.2243, -4.4146, -4.7364,\n",
      "         -4.6034, -4.1738, -4.7072, -4.6066, -4.6320, -4.3169, -4.6908, -4.4008,\n",
      "         -4.5238]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : within\n",
      "target index is: [34] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1790, -4.3437, -4.7131, -4.8814, -4.5252, -4.8509, -4.4564, -4.0738,\n",
      "         -5.1600, -4.5756, -4.9985, -4.3924, -4.2788, -4.6212, -5.1881, -5.0782,\n",
      "         -4.5802, -4.5658, -4.7241, -4.6149, -4.5310, -4.7593, -4.7188, -4.9199,\n",
      "         -4.4536, -4.9377, -4.2562, -4.3591, -4.1337, -4.5144, -4.5114, -4.6698,\n",
      "         -4.9742, -4.8897, -4.8448, -5.0220, -4.7938, -4.3696, -4.5734, -4.5229,\n",
      "         -4.6904, -4.6703, -4.4307, -4.3796, -4.3320, -4.0111, -4.7070, -4.7816,\n",
      "         -4.6152, -4.7573, -4.6654, -4.1928, -4.6770, -4.6457, -4.5417, -4.6701,\n",
      "         -4.5368, -4.1626, -4.4517, -4.9224, -4.8400, -4.5979, -4.5061, -4.4578,\n",
      "         -4.3574, -4.9667, -4.9343, -4.5431, -4.4779, -4.1775, -4.4548, -4.6335,\n",
      "         -4.7735, -4.7721, -4.6797, -4.8882, -4.5431, -4.0403, -4.2417, -5.0513,\n",
      "         -4.2336, -4.7525, -4.6272, -4.9431, -4.9017, -4.6427, -4.6942, -4.3829,\n",
      "         -5.1357, -4.6268, -4.4911, -4.4455, -4.8223, -4.5719, -4.4274, -4.5620,\n",
      "         -4.4138]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thine\n",
      "target index is: [56] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1463, -4.9398, -4.1271, -4.6035, -4.0640, -4.7275, -4.8280, -4.3291,\n",
      "         -4.7158, -4.8744, -4.7458, -4.7718, -4.6800, -4.6939, -4.7869, -4.6896,\n",
      "         -4.6077, -4.7625, -4.5045, -5.0063, -4.8380, -4.6121, -4.7964, -4.4578,\n",
      "         -4.2824, -4.7584, -4.6437, -4.5281, -4.3285, -4.3883, -4.3622, -4.5401,\n",
      "         -4.6280, -4.5736, -4.6934, -4.8906, -4.3845, -4.8678, -4.6403, -4.7168,\n",
      "         -5.0222, -4.3136, -4.9562, -4.2624, -4.8387, -4.3096, -4.6215, -4.4798,\n",
      "         -4.7579, -4.3161, -4.5505, -4.6858, -5.1464, -4.5891, -4.9156, -4.6208,\n",
      "         -4.2091, -4.2809, -4.4149, -4.2959, -4.7385, -4.5683, -4.6281, -4.0788,\n",
      "         -4.7773, -4.5005, -5.0699, -4.7815, -4.9088, -5.0250, -4.4945, -4.4988,\n",
      "         -5.2615, -5.0101, -4.6025, -4.8098, -4.6134, -4.0807, -4.3234, -4.8372,\n",
      "         -4.4685, -4.0591, -4.6845, -4.8126, -4.7066, -4.6276, -4.4224, -4.5810,\n",
      "         -5.2820, -4.2983, -4.3966, -4.3998, -4.3872, -4.8071, -4.2351, -4.7190,\n",
      "         -4.5137]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : own\n",
      "target index is: [92] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4017, -4.4283, -4.4793, -4.9646, -3.7357, -4.4370, -4.7005, -4.6483,\n",
      "         -4.9243, -5.0549, -4.8423, -4.6161, -5.0682, -4.7700, -4.7963, -4.7396,\n",
      "         -4.6110, -5.1791, -4.5277, -4.3237, -4.4922, -4.0518, -4.6992, -4.5671,\n",
      "         -4.7591, -4.7783, -4.4824, -4.5876, -4.5581, -5.0828, -4.2046, -4.8351,\n",
      "         -4.6533, -4.4622, -4.2160, -4.8898, -4.5796, -5.1413, -4.8101, -4.8646,\n",
      "         -4.5155, -4.7802, -4.9939, -4.2613, -4.8877, -4.4131, -4.6175, -4.5181,\n",
      "         -4.7766, -4.7294, -4.6143, -4.7962, -4.6026, -4.6242, -4.9673, -4.2333,\n",
      "         -4.8795, -4.3376, -4.4903, -4.6114, -4.4893, -4.6598, -5.1019, -3.8555,\n",
      "         -4.8122, -4.5155, -5.1287, -4.6323, -4.6376, -4.9872, -4.4577, -4.5633,\n",
      "         -4.5419, -5.0405, -4.4332, -4.6237, -4.6807, -4.6072, -4.4401, -4.4387,\n",
      "         -4.7170, -4.1953, -4.8683, -4.8276, -4.2371, -4.5009, -4.1615, -4.6085,\n",
      "         -4.8291, -4.4113, -4.3463, -4.3694, -4.7161, -4.6626, -3.9386, -4.6755,\n",
      "         -4.3381]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : deep\n",
      "target index is: [76] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3181, -4.6683, -4.6829, -4.8180, -4.2862, -4.5429, -4.3670, -4.2485,\n",
      "         -4.6996, -4.9185, -5.0173, -4.3571, -4.4960, -4.4743, -4.6467, -4.4407,\n",
      "         -4.1004, -4.7509, -4.6409, -4.5918, -4.5823, -4.6222, -4.5828, -4.6366,\n",
      "         -4.4690, -4.6392, -4.5925, -4.5033, -4.4887, -4.6228, -4.6358, -4.8633,\n",
      "         -4.8867, -4.9225, -4.7413, -4.8202, -4.7896, -4.4451, -5.1294, -4.7609,\n",
      "         -4.7375, -4.5094, -4.8735, -4.3977, -4.5195, -4.3424, -4.6376, -4.7926,\n",
      "         -4.5155, -4.4382, -4.5843, -4.3268, -4.7864, -4.3632, -4.8901, -4.6705,\n",
      "         -4.4324, -4.6393, -4.7538, -4.6351, -4.8103, -4.6098, -4.4811, -3.9859,\n",
      "         -4.6020, -4.4818, -4.9174, -4.4587, -4.5856, -4.6414, -4.4435, -4.6843,\n",
      "         -4.5266, -4.3955, -4.4897, -4.6156, -4.6702, -4.5696, -4.5195, -4.7231,\n",
      "         -4.0350, -4.5241, -4.6754, -4.7169, -4.4763, -4.3857, -4.7923, -4.7459,\n",
      "         -5.0143, -4.4794, -4.5077, -4.7676, -4.6663, -4.6778, -4.2422, -4.5838,\n",
      "         -4.6056]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : sunken\n",
      "target index is: [91] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3964, -4.5273, -4.7232, -4.8711, -4.2247, -4.8908, -4.5859, -4.7916,\n",
      "         -4.7295, -4.4492, -4.9457, -4.5037, -4.7968, -4.5918, -4.6827, -4.8444,\n",
      "         -4.9004, -4.8005, -4.7707, -4.2917, -4.4931, -4.2462, -4.8569, -4.5633,\n",
      "         -4.5683, -4.8871, -4.3552, -4.6889, -4.3211, -4.6452, -4.8783, -4.6607,\n",
      "         -4.6424, -4.8401, -4.7353, -5.0144, -4.7245, -4.6758, -4.7723, -4.2502,\n",
      "         -4.8222, -4.7484, -4.8163, -4.3631, -4.4931, -4.6056, -4.7044, -4.5723,\n",
      "         -4.3708, -4.8959, -3.9132, -5.2494, -4.3203, -4.4823, -4.7706, -4.2331,\n",
      "         -4.8396, -4.4528, -4.3678, -4.5196, -4.5122, -4.3312, -4.6703, -4.0314,\n",
      "         -4.5190, -4.5997, -4.9780, -4.5968, -4.6555, -4.5479, -4.4718, -4.6780,\n",
      "         -4.8552, -4.7331, -4.5935, -5.0088, -4.1734, -4.6175, -4.4303, -4.5589,\n",
      "         -4.6066, -4.2017, -4.9258, -4.5949, -4.7928, -4.2556, -4.7896, -4.8788,\n",
      "         -4.7812, -4.3126, -4.3817, -4.7204, -4.5227, -4.3810, -4.5244, -4.2508,\n",
      "         -4.3791]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : eyes,\n",
      "target index is: [58] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2453, -4.5244, -5.0630, -5.3312, -3.9100, -4.6414, -4.3319, -4.5067,\n",
      "         -4.7230, -4.6259, -5.1081, -4.6542, -4.7759, -4.5859, -4.6330, -4.6597,\n",
      "         -4.6076, -4.6969, -5.0139, -4.5257, -4.7170, -4.3146, -4.9195, -4.6478,\n",
      "         -4.5014, -4.8644, -4.4670, -4.3990, -4.3184, -4.7129, -4.7626, -4.5626,\n",
      "         -4.6381, -5.1218, -4.6025, -4.7029, -4.5023, -4.4430, -5.1284, -4.3294,\n",
      "         -4.5852, -4.3481, -4.7923, -4.4514, -4.5757, -4.3629, -4.8877, -4.4590,\n",
      "         -4.4934, -5.0294, -4.3270, -5.0032, -4.4958, -4.3024, -4.5045, -4.6669,\n",
      "         -4.5881, -4.7140, -4.6327, -4.3914, -4.5911, -4.2738, -4.1316, -4.4976,\n",
      "         -4.2430, -4.6476, -4.6534, -4.5784, -4.6302, -4.2471, -4.5293, -4.6605,\n",
      "         -4.9019, -4.7491, -4.7803, -4.7697, -4.3855, -4.5219, -4.4984, -4.7285,\n",
      "         -4.3953, -4.5161, -4.9399, -4.9038, -4.9015, -4.0080, -4.6666, -4.6780,\n",
      "         -4.7015, -4.4906, -4.7710, -4.6686, -4.8611, -4.1976, -4.7131, -4.5873,\n",
      "         -4.2469]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Were\n",
      "target index is: [37] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2521, -4.5373, -4.6851, -4.6387, -4.2388, -4.6936, -4.3674, -4.2622,\n",
      "         -4.7952, -4.9070, -4.5996, -4.4378, -4.5258, -4.8557, -4.9913, -4.6700,\n",
      "         -4.7418, -4.5291, -4.6369, -4.7276, -4.3212, -4.4364, -4.8369, -5.0404,\n",
      "         -4.2567, -4.9242, -4.5901, -4.4043, -4.2313, -4.3989, -4.6356, -4.6651,\n",
      "         -4.5680, -4.9105, -4.3647, -4.8289, -4.8484, -4.3754, -4.7684, -4.3808,\n",
      "         -4.6991, -4.5397, -4.7092, -4.6967, -4.5599, -4.2354, -4.2385, -4.7916,\n",
      "         -4.4652, -4.8875, -4.7281, -4.3380, -4.8046, -4.5265, -4.4650, -4.4800,\n",
      "         -4.3819, -4.3087, -4.4800, -4.8758, -4.6284, -4.1596, -4.5543, -4.3662,\n",
      "         -4.4830, -4.6927, -4.5888, -4.3692, -4.6630, -4.1762, -4.5408, -4.6180,\n",
      "         -4.6713, -5.1246, -4.8941, -4.9195, -4.6289, -4.2724, -4.5614, -4.8836,\n",
      "         -4.5540, -4.7380, -4.7790, -4.8017, -4.6147, -4.3496, -4.4717, -4.8141,\n",
      "         -4.8869, -4.4209, -4.7941, -4.5059, -4.6377, -4.5603, -4.8653, -4.7008,\n",
      "         -4.6235]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : an\n",
      "target index is: [74] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4852, -4.6976, -4.6900, -4.4943, -4.1036, -4.9793, -4.6213, -4.5549,\n",
      "         -4.7377, -4.5115, -4.9886, -4.7266, -4.8440, -4.8870, -4.7904, -4.8586,\n",
      "         -4.8308, -4.5783, -4.6649, -4.6880, -4.3841, -4.0897, -4.7513, -4.9008,\n",
      "         -4.3882, -5.2044, -4.3467, -4.2135, -4.6483, -4.3766, -4.8403, -4.5629,\n",
      "         -4.8476, -4.9734, -4.3944, -4.7126, -4.7577, -4.6005, -4.7805, -4.4837,\n",
      "         -4.9161, -4.7387, -4.5769, -4.5332, -4.4045, -4.4387, -4.5363, -4.5717,\n",
      "         -4.3779, -5.0006, -4.4280, -4.4739, -4.6134, -4.4248, -4.4375, -4.3260,\n",
      "         -4.4661, -4.2869, -4.2016, -4.8363, -4.5119, -4.5279, -4.6054, -4.3788,\n",
      "         -4.5914, -4.3578, -4.8406, -4.2996, -4.6972, -4.5662, -4.4327, -4.7012,\n",
      "         -4.8533, -4.8088, -5.0261, -5.1012, -4.3191, -4.2734, -4.3622, -4.8859,\n",
      "         -4.3282, -4.6245, -4.4747, -4.8127, -4.5342, -4.2427, -4.6659, -5.0556,\n",
      "         -4.8164, -4.6081, -4.3400, -4.4627, -4.5591, -4.5835, -4.6274, -4.4802,\n",
      "         -4.3645]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : all-eating\n",
      "target index is: [60] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4663, -4.5768, -4.8536, -4.7430, -3.9400, -4.7043, -4.7071, -4.4292,\n",
      "         -4.8362, -4.4599, -5.0132, -4.6883, -4.8965, -4.5999, -4.7259, -4.6750,\n",
      "         -4.4766, -4.4350, -4.8502, -4.4845, -4.7300, -4.5796, -4.7829, -4.8915,\n",
      "         -4.6601, -4.9182, -4.6980, -4.2923, -4.2624, -4.4329, -4.5373, -4.5488,\n",
      "         -4.8149, -4.9691, -4.3513, -4.7196, -4.2814, -4.9104, -4.8460, -4.6394,\n",
      "         -4.7520, -4.4270, -4.4792, -4.5647, -4.3359, -4.4639, -4.5614, -4.6555,\n",
      "         -4.6731, -4.8533, -4.5232, -4.8510, -4.8221, -4.2682, -4.6826, -4.7696,\n",
      "         -4.3408, -4.3782, -4.6491, -4.4855, -4.6511, -4.6012, -4.4899, -4.4805,\n",
      "         -4.4441, -4.3765, -4.5556, -4.3084, -4.7378, -4.5946, -4.4352, -4.3141,\n",
      "         -5.0662, -4.8714, -4.7677, -4.8180, -4.3138, -4.3744, -4.3664, -5.0378,\n",
      "         -4.4073, -4.3418, -4.3235, -4.9167, -5.0180, -4.0267, -4.7490, -4.5751,\n",
      "         -4.8615, -4.2715, -4.5066, -4.6797, -4.7344, -4.4826, -4.6089, -4.5450,\n",
      "         -4.5627]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : shame,\n",
      "target index is: [41] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6967, -4.7353, -4.8830, -4.5354, -4.1373, -4.5950, -4.6159, -4.4815,\n",
      "         -4.5982, -4.6416, -4.5568, -4.5117, -4.8739, -4.7289, -4.7789, -4.4784,\n",
      "         -4.4707, -4.9161, -4.5763, -4.4742, -4.5832, -4.2136, -4.6612, -4.6057,\n",
      "         -4.5139, -4.9788, -4.3581, -4.4946, -4.5033, -4.6200, -4.4450, -5.0346,\n",
      "         -5.0761, -4.8340, -4.5574, -4.6987, -4.4804, -5.0522, -4.7984, -4.7410,\n",
      "         -4.8000, -4.3790, -4.4794, -4.5673, -4.4251, -4.4935, -4.6113, -4.6508,\n",
      "         -4.4289, -4.6386, -4.8730, -4.2403, -4.8020, -4.3380, -4.8810, -4.1842,\n",
      "         -4.5017, -4.2546, -4.4426, -4.5184, -4.6437, -5.0202, -4.7292, -4.2312,\n",
      "         -4.8052, -4.2602, -5.0341, -4.5334, -4.6601, -4.6803, -4.0081, -4.4970,\n",
      "         -4.7474, -4.5875, -4.6298, -4.8724, -4.8113, -4.3490, -4.7759, -4.8246,\n",
      "         -4.6542, -4.4820, -4.4396, -4.5678, -4.3511, -4.4777, -4.3791, -4.7550,\n",
      "         -4.7758, -4.2071, -4.6606, -4.4214, -4.7287, -4.6562, -4.5303, -4.7265,\n",
      "         -4.4511]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : and\n",
      "target index is: [44] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6782, -4.4758, -4.5804, -4.6502, -4.2101, -4.7448, -4.5045, -4.4333,\n",
      "         -4.7135, -4.8084, -4.4702, -4.4784, -4.8470, -4.8137, -4.4648, -4.5262,\n",
      "         -4.6187, -4.9193, -4.6515, -4.5112, -4.3665, -4.3321, -4.4236, -4.4666,\n",
      "         -4.5519, -4.7046, -4.3431, -4.4465, -4.6320, -4.5812, -4.6461, -4.8438,\n",
      "         -4.7929, -4.7883, -4.4009, -4.5015, -4.7757, -4.9267, -4.5927, -4.5512,\n",
      "         -4.8036, -4.6856, -4.7726, -4.5105, -4.5322, -4.6163, -4.3765, -4.5746,\n",
      "         -4.3001, -4.5340, -4.5951, -4.5941, -4.5719, -4.3976, -4.8974, -4.4903,\n",
      "         -4.7844, -4.6505, -4.6116, -4.7120, -4.8110, -4.7086, -4.8350, -4.2145,\n",
      "         -4.9363, -4.4354, -4.8797, -4.4057, -4.6684, -4.8536, -4.3273, -4.8452,\n",
      "         -4.6092, -4.6063, -4.4163, -4.7388, -4.5484, -4.4889, -4.6521, -4.4243,\n",
      "         -4.4439, -4.3638, -4.6480, -4.6407, -4.6190, -4.3149, -4.6011, -4.8245,\n",
      "         -4.8677, -4.1585, -4.7693, -4.7551, -4.3212, -4.3805, -4.4476, -4.4040,\n",
      "         -4.5728]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thriftless\n",
      "target index is: [43] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3495, -4.4306, -4.5497, -4.7373, -4.1274, -4.5544, -4.6572, -4.4958,\n",
      "         -4.7467, -4.5376, -4.9714, -4.3713, -4.7483, -4.5820, -4.6410, -4.9321,\n",
      "         -4.8736, -4.5565, -4.9090, -4.2090, -4.7016, -4.8300, -4.5996, -4.5758,\n",
      "         -4.8364, -4.7525, -4.5448, -4.5115, -4.1677, -4.7657, -4.6404, -4.5059,\n",
      "         -4.7383, -4.6109, -4.6329, -5.0502, -4.6313, -4.9044, -4.5391, -4.4907,\n",
      "         -4.5636, -4.5786, -4.6935, -4.2023, -4.4870, -4.2869, -4.5094, -4.1552,\n",
      "         -4.5565, -4.7130, -4.8425, -4.9531, -4.5941, -4.6746, -4.9503, -4.7752,\n",
      "         -4.4082, -4.4156, -4.5257, -4.6932, -4.5622, -4.6602, -4.6017, -4.4203,\n",
      "         -4.6877, -4.8236, -4.8557, -4.4286, -4.4406, -4.7578, -4.2278, -4.7201,\n",
      "         -4.7760, -5.0478, -4.5914, -4.5763, -4.4175, -4.4820, -4.3691, -4.3981,\n",
      "         -4.6903, -4.2912, -4.5152, -4.7552, -5.0671, -4.3004, -4.5100, -4.5475,\n",
      "         -5.2558, -4.4760, -4.7149, -4.4712, -4.4876, -4.5425, -4.1052, -4.2883,\n",
      "         -4.6310]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : praise.\n",
      "target index is: [94] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-3.9293, -5.0606, -4.6982, -5.1552, -3.7557, -4.7144, -4.8370, -4.4104,\n",
      "         -4.6678, -5.0163, -4.6277, -4.2574, -4.3606, -4.5245, -4.8543, -4.5910,\n",
      "         -4.9123, -5.0883, -4.7102, -4.5383, -4.7735, -4.0977, -5.1673, -4.9805,\n",
      "         -4.3308, -4.8775, -4.4881, -4.1406, -3.9270, -4.8778, -4.5719, -4.8142,\n",
      "         -4.9052, -4.8480, -4.4670, -5.2954, -4.6615, -4.6262, -4.9860, -4.9598,\n",
      "         -4.6784, -4.3647, -4.8847, -4.6181, -4.7174, -4.4464, -4.9034, -4.6731,\n",
      "         -4.7124, -4.8519, -4.3242, -4.7899, -4.4525, -4.6700, -4.9053, -4.5246,\n",
      "         -3.9556, -4.3394, -4.5227, -4.6697, -4.4168, -4.3545, -4.3396, -4.3869,\n",
      "         -4.5695, -4.6837, -4.9992, -5.0301, -4.8736, -4.8020, -4.2065, -4.3417,\n",
      "         -4.8340, -5.0493, -4.5752, -4.5368, -4.6749, -4.0245, -4.3063, -4.4255,\n",
      "         -4.5089, -4.2007, -5.1885, -5.0360, -4.1154, -4.6365, -4.3215, -4.7972,\n",
      "         -5.2246, -4.9312, -4.9995, -4.2834, -4.7032, -4.3749, -4.5527, -4.4462,\n",
      "         -4.4998]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : How\n",
      "target index is: [12] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.1552, -4.7313, -4.4652, -5.0206, -4.0446, -5.0110, -4.5932, -4.3493,\n",
      "         -5.1492, -4.9782, -5.0476, -5.0762, -4.7315, -4.5213, -5.3487, -5.1242,\n",
      "         -4.8561, -4.3981, -4.7776, -4.7564, -4.6266, -4.8802, -4.7650, -5.0143,\n",
      "         -4.3509, -5.0795, -4.5912, -4.1991, -4.2953, -4.5839, -4.3040, -3.9700,\n",
      "         -4.6707, -4.7757, -4.4532, -5.2062, -4.5806, -4.5073, -4.5448, -4.5419,\n",
      "         -4.3507, -4.8551, -4.8329, -4.2354, -4.6193, -4.0264, -4.5084, -4.1802,\n",
      "         -5.0063, -4.5505, -4.3607, -4.7908, -4.6505, -4.7933, -4.5430, -4.8235,\n",
      "         -4.4028, -4.3536, -4.3046, -4.6499, -4.6508, -4.2671, -4.2786, -4.2483,\n",
      "         -4.5233, -4.9300, -4.6060, -4.3811, -4.1915, -4.4806, -4.5647, -4.3900,\n",
      "         -5.3004, -5.2662, -4.9228, -4.7867, -4.5255, -4.1069, -4.1757, -4.5951,\n",
      "         -4.5448, -4.9881, -4.7098, -5.1424, -5.0071, -4.1343, -4.2073, -4.8384,\n",
      "         -5.5313, -4.4852, -4.4658, -4.1746, -4.8034, -4.8762, -4.3804, -4.8007,\n",
      "         -4.5987]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : much\n",
      "target index is: [68] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4203, -4.9920, -4.6204, -4.4650, -3.3538, -4.4700, -4.7135, -4.2754,\n",
      "         -5.0021, -4.5668, -4.4577, -4.4744, -4.7973, -4.7104, -5.0249, -4.8063,\n",
      "         -4.8297, -4.9117, -4.1387, -4.8423, -4.7602, -4.1127, -4.9567, -4.8207,\n",
      "         -4.4510, -5.1361, -4.4732, -4.3949, -4.6129, -4.6031, -4.2362, -4.9853,\n",
      "         -4.6920, -4.5901, -4.4470, -5.3184, -4.4319, -5.0984, -4.6419, -4.9660,\n",
      "         -4.8668, -4.5758, -4.9189, -4.6597, -4.8172, -4.4229, -4.6942, -5.1524,\n",
      "         -4.9823, -4.5953, -4.9517, -4.3911, -5.0373, -4.1898, -4.6352, -4.0288,\n",
      "         -4.2811, -3.9065, -4.2673, -4.1616, -4.5356, -4.7777, -4.5572, -3.9094,\n",
      "         -4.6825, -4.4240, -4.6539, -4.5799, -5.1128, -4.7353, -4.4897, -4.3808,\n",
      "         -5.4710, -5.0164, -4.6149, -5.0747, -4.8507, -4.1800, -4.2198, -5.1257,\n",
      "         -4.7783, -4.1718, -4.9725, -4.8871, -4.3831, -4.5623, -4.6090, -4.8805,\n",
      "         -5.3096, -4.5001, -4.8801, -4.1773, -4.6326, -4.6513, -4.3647, -5.1672,\n",
      "         -4.4407]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : more\n",
      "target index is: [4] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3014, -4.8039, -4.7211, -4.4139, -4.1500, -4.5980, -4.8291, -4.4414,\n",
      "         -4.8971, -4.4806, -4.8607, -4.2937, -4.7081, -4.3558, -4.8364, -4.8106,\n",
      "         -4.6107, -4.7941, -4.7075, -4.6433, -4.4795, -4.4934, -4.6336, -4.6316,\n",
      "         -4.5550, -4.8203, -4.5804, -4.4587, -4.4189, -4.5743, -4.7477, -4.6850,\n",
      "         -4.8690, -4.6092, -4.9433, -5.0169, -4.8979, -4.7041, -4.7318, -4.6427,\n",
      "         -4.6139, -4.5558, -4.5681, -4.5142, -4.0655, -4.2615, -4.5300, -4.7255,\n",
      "         -4.7076, -4.5150, -4.9076, -4.3017, -4.7566, -4.3970, -4.8031, -4.4431,\n",
      "         -4.4770, -4.1811, -4.4799, -4.6885, -4.6055, -4.5723, -4.6153, -3.9100,\n",
      "         -4.5199, -4.6410, -4.8598, -4.6244, -4.6439, -4.6306, -4.0667, -4.6190,\n",
      "         -4.6914, -4.4597, -4.5111, -4.8373, -4.6632, -4.4818, -4.5190, -4.8092,\n",
      "         -4.4171, -4.2625, -4.6765, -4.7683, -4.5554, -4.5530, -4.7658, -4.7503,\n",
      "         -5.2366, -4.4847, -4.7083, -4.6741, -4.6259, -4.5674, -4.0964, -4.9560,\n",
      "         -4.5251]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : praise\n",
      "target index is: [45] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3738, -4.5264, -4.6812, -5.1959, -4.0391, -4.6036, -4.4624, -4.2934,\n",
      "         -5.2167, -4.6324, -4.8307, -4.3312, -4.7230, -4.5068, -5.1309, -4.8339,\n",
      "         -4.6935, -4.5061, -4.8016, -4.2415, -4.6825, -4.7123, -4.8429, -4.7136,\n",
      "         -4.8460, -4.9159, -4.5438, -4.2808, -4.2715, -4.6327, -4.2726, -4.4581,\n",
      "         -4.8882, -4.9103, -4.4691, -5.1811, -4.3158, -4.9949, -4.5442, -4.6200,\n",
      "         -4.4861, -4.5851, -4.7031, -4.2299, -4.6244, -4.1785, -4.7883, -4.4279,\n",
      "         -4.8014, -5.1312, -4.2544, -5.1051, -4.4076, -4.7967, -4.6311, -4.6457,\n",
      "         -4.3691, -4.3749, -4.4594, -4.4771, -4.5411, -4.2823, -4.6104, -4.4631,\n",
      "         -4.3380, -4.6189, -5.0258, -4.6194, -4.5184, -4.3296, -4.6974, -4.7033,\n",
      "         -5.2124, -5.1959, -4.6877, -4.9122, -4.4653, -4.1165, -4.1304, -4.4574,\n",
      "         -4.8116, -4.6499, -4.7194, -4.9957, -4.9892, -4.2419, -4.2565, -4.3169,\n",
      "         -5.1043, -4.7403, -4.5390, -4.0851, -5.0360, -4.5262, -4.6511, -4.3654,\n",
      "         -4.4159]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : deserv'd\n",
      "target index is: [66] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4210, -4.7328, -4.5115, -4.3378, -4.0299, -4.7408, -4.5435, -4.3458,\n",
      "         -4.8698, -4.8420, -4.4368, -4.7190, -4.7784, -4.7458, -4.9057, -4.8370,\n",
      "         -4.8650, -4.8469, -4.4773, -4.9506, -4.4284, -4.4588, -4.7248, -4.6615,\n",
      "         -4.2147, -5.1051, -4.6956, -4.4996, -4.3483, -4.6417, -4.2367, -4.7220,\n",
      "         -4.8116, -4.8056, -4.5646, -5.2426, -4.5079, -4.6907, -4.5351, -4.6123,\n",
      "         -4.7957, -4.6314, -4.8661, -4.5814, -4.7679, -4.3088, -4.7404, -4.5805,\n",
      "         -4.7658, -4.4861, -4.8574, -4.3013, -5.1111, -4.4702, -4.5862, -4.4997,\n",
      "         -4.0782, -4.0382, -4.2999, -4.4005, -4.6423, -4.5049, -4.5905, -4.2649,\n",
      "         -4.6457, -4.4699, -4.6194, -4.3023, -4.5115, -4.3429, -4.5527, -4.5301,\n",
      "         -5.2694, -4.9236, -4.8599, -4.9749, -4.9262, -3.9890, -4.4330, -4.8623,\n",
      "         -4.5532, -4.5171, -4.8854, -4.8521, -4.6710, -4.2962, -4.2068, -4.6459,\n",
      "         -5.1949, -4.3280, -4.4352, -4.5443, -4.7297, -4.7364, -4.2934, -4.8596,\n",
      "         -4.4456]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2428, -4.2455, -4.9374, -4.6783, -4.2289, -4.7407, -4.8531, -4.2151,\n",
      "         -5.0439, -4.7916, -5.3160, -4.5442, -4.4069, -4.6142, -4.6099, -4.8128,\n",
      "         -4.5064, -4.5382, -4.4182, -4.4231, -4.6458, -4.3041, -4.6792, -4.7201,\n",
      "         -4.3114, -5.0234, -4.3454, -4.4675, -4.5853, -4.6521, -4.7049, -4.7930,\n",
      "         -5.2546, -4.7604, -4.6385, -5.1014, -4.7460, -4.8025, -5.0118, -4.8081,\n",
      "         -4.8976, -4.7315, -4.8002, -4.6193, -4.7508, -4.0275, -4.8679, -4.9395,\n",
      "         -4.8794, -4.4902, -4.8506, -4.3391, -4.5125, -4.2389, -4.4863, -4.7791,\n",
      "         -4.3076, -4.1829, -4.6039, -4.5741, -4.7531, -4.6540, -4.1216, -4.4659,\n",
      "         -4.4776, -4.7488, -4.8925, -4.2494, -4.8161, -4.7726, -4.3558, -4.5670,\n",
      "         -4.7993, -4.8109, -4.7441, -4.6370, -4.3300, -4.3583, -4.1121, -4.7350,\n",
      "         -3.8575, -4.6737, -4.7623, -5.1097, -4.6426, -4.3853, -4.6974, -4.9104,\n",
      "         -4.7714, -4.4280, -4.5597, -4.7665, -4.9721, -4.3471, -3.8672, -4.9675,\n",
      "         -4.1961]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty's\n",
      "target index is: [80] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2957, -4.4851, -4.6973, -4.5536, -4.2295, -4.9478, -4.4773, -4.2912,\n",
      "         -4.4378, -5.1622, -4.9670, -4.0535, -4.6053, -4.7513, -4.6186, -4.7568,\n",
      "         -4.9160, -5.1812, -4.5186, -4.4283, -4.9510, -4.7645, -4.5388, -4.5083,\n",
      "         -4.2179, -4.6636, -4.6699, -4.4767, -3.8693, -4.5977, -4.8117, -4.5830,\n",
      "         -4.7165, -4.6381, -4.6870, -5.1528, -4.8628, -4.6255, -4.6677, -4.5474,\n",
      "         -4.7033, -4.2719, -4.9915, -4.0849, -4.4986, -4.1085, -4.4880, -4.4816,\n",
      "         -4.4933, -4.8989, -4.7696, -4.4509, -4.7538, -4.4142, -4.6333, -4.4230,\n",
      "         -4.3337, -4.2353, -4.7499, -5.0320, -4.8517, -4.1994, -4.5167, -4.1398,\n",
      "         -5.0451, -4.8237, -5.0667, -4.6949, -4.8071, -4.6103, -4.3415, -4.8049,\n",
      "         -4.5023, -4.8604, -4.7985, -4.9283, -5.1249, -4.0458, -4.2710, -4.4614,\n",
      "         -4.7483, -4.3205, -5.1982, -4.7144, -4.8845, -4.1010, -4.6200, -5.0107,\n",
      "         -5.0675, -4.5975, -5.1684, -4.4883, -4.5526, -4.5290, -4.2766, -4.3710,\n",
      "         -4.5943]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : use,\n",
      "target index is: [11] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.0981, -4.6016, -5.0480, -5.3087, -3.7789, -5.0985, -4.7069, -4.7010,\n",
      "         -4.6857, -4.6330, -4.9401, -4.8099, -5.2133, -4.6935, -4.6974, -4.8798,\n",
      "         -5.0295, -4.4940, -4.8111, -4.2747, -4.8482, -4.2256, -5.1119, -4.6909,\n",
      "         -4.2885, -4.8829, -4.2153, -4.2641, -4.0612, -5.0503, -4.7079, -4.5637,\n",
      "         -4.8169, -4.7447, -4.9786, -5.1992, -5.0755, -4.7350, -5.0919, -4.7608,\n",
      "         -4.7086, -5.3509, -4.8281, -4.6321, -4.7080, -4.4611, -4.8367, -4.3626,\n",
      "         -4.4963, -4.8286, -3.9425, -5.5265, -4.2301, -4.5410, -4.8988, -4.3308,\n",
      "         -4.5643, -4.3639, -4.2946, -4.2645, -4.6519, -4.1721, -4.4007, -3.7256,\n",
      "         -4.5743, -4.8396, -4.8930, -4.9716, -4.3620, -4.4946, -4.2650, -4.6988,\n",
      "         -5.0847, -4.4280, -4.7548, -4.8077, -4.0104, -4.6926, -4.4849, -4.5199,\n",
      "         -4.5028, -4.0463, -5.4891, -5.1015, -4.5899, -4.5816, -4.6752, -5.0515,\n",
      "         -4.7740, -4.3749, -4.2598, -4.4494, -4.6274, -4.0642, -4.2825, -4.6025,\n",
      "         -4.6206]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : If\n",
      "target index is: [61] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6992, -4.3261, -4.8669, -4.9900, -4.5014, -4.7971, -4.6970, -4.3088,\n",
      "         -4.6240, -4.7917, -4.7947, -4.1676, -4.7408, -4.4657, -4.8602, -4.8463,\n",
      "         -4.4205, -4.6293, -4.9170, -4.4706, -4.5197, -4.9331, -4.6627, -4.6004,\n",
      "         -4.5394, -4.8026, -4.5503, -4.2891, -4.3255, -4.4506, -4.4122, -4.7987,\n",
      "         -5.1941, -4.7498, -4.9531, -5.3636, -4.4174, -4.9190, -4.4669, -4.4925,\n",
      "         -4.2445, -4.8485, -4.2838, -4.4912, -4.1422, -4.3853, -4.5268, -4.8105,\n",
      "         -4.5576, -4.7751, -4.2782, -4.3961, -4.5737, -4.3913, -4.5475, -4.5263,\n",
      "         -4.6076, -4.3123, -4.8520, -4.6091, -4.6325, -4.2922, -4.4757, -3.7759,\n",
      "         -4.4300, -4.4105, -4.7152, -4.6715, -4.3005, -4.0073, -4.5103, -4.5983,\n",
      "         -4.8935, -4.8177, -5.0832, -5.0282, -4.8050, -4.0665, -4.5657, -4.7740,\n",
      "         -4.9841, -4.5875, -4.9238, -5.1329, -5.0018, -4.3174, -4.4303, -4.5770,\n",
      "         -5.0502, -4.1970, -4.6783, -4.8753, -4.9619, -4.2913, -4.6823, -4.7943,\n",
      "         -4.6404]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thou\n",
      "target index is: [22] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5271, -4.4340, -4.9576, -4.6321, -4.4301, -4.8942, -4.4052, -4.3926,\n",
      "         -4.4505, -4.7343, -4.6091, -4.4305, -4.7441, -4.9009, -4.5629, -4.5578,\n",
      "         -4.7606, -5.0787, -4.5209, -4.3817, -4.5723, -4.4499, -4.7927, -4.3654,\n",
      "         -4.2466, -4.6032, -4.4714, -4.6872, -4.5170, -4.7332, -4.9047, -4.9381,\n",
      "         -4.6721, -4.7880, -4.3790, -4.4984, -4.5456, -4.6609, -4.7225, -4.5327,\n",
      "         -5.0757, -4.1955, -4.8123, -4.7372, -4.4435, -4.4139, -4.3672, -4.4867,\n",
      "         -4.1507, -5.1247, -4.8715, -4.2926, -4.7236, -4.3993, -4.6900, -4.4622,\n",
      "         -4.5757, -4.4294, -4.5037, -4.7132, -4.7521, -4.4582, -4.3266, -4.4588,\n",
      "         -4.9210, -4.6332, -4.5579, -4.4815, -4.6222, -4.4355, -4.2151, -4.9830,\n",
      "         -4.5322, -4.7080, -4.6783, -4.8636, -4.4795, -4.3754, -4.5568, -4.4030,\n",
      "         -4.6071, -4.5879, -4.8473, -4.4523, -4.5461, -4.5493, -4.7220, -4.7340,\n",
      "         -4.8058, -4.3185, -4.9352, -4.4271, -4.5559, -4.5311, -4.6687, -4.5151,\n",
      "         -4.5004]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : couldst\n",
      "target index is: [47] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4704, -4.3685, -4.5124, -4.7896, -4.2377, -4.8002, -4.7747, -4.4185,\n",
      "         -4.5857, -4.7760, -4.6311, -4.5322, -4.6075, -4.8426, -4.6890, -4.3092,\n",
      "         -4.5651, -4.5174, -4.4692, -4.5744, -4.5234, -4.3406, -4.6787, -4.7796,\n",
      "         -4.2159, -4.5686, -4.4462, -4.6163, -4.3173, -4.6822, -4.5696, -4.8179,\n",
      "         -4.8169, -4.5369, -4.6366, -4.8355, -4.5868, -4.8029, -4.7382, -4.8504,\n",
      "         -4.5899, -4.7549, -4.7597, -4.6910, -4.5751, -4.5985, -4.6373, -4.7877,\n",
      "         -4.6090, -4.6177, -4.4976, -4.6602, -4.5550, -4.4871, -4.7427, -4.6591,\n",
      "         -4.4718, -4.4608, -4.4325, -4.5079, -4.8018, -4.5669, -4.4338, -4.1990,\n",
      "         -4.7481, -4.4880, -4.7952, -4.7325, -4.5074, -4.6053, -4.3730, -4.4492,\n",
      "         -4.7493, -4.7751, -4.7279, -4.6926, -4.3114, -4.4223, -4.6156, -4.6469,\n",
      "         -4.4487, -4.4186, -4.7860, -4.8288, -4.4980, -4.6213, -4.3778, -4.6850,\n",
      "         -4.5989, -4.3259, -4.5165, -4.7747, -4.6410, -4.2757, -4.4507, -4.5924,\n",
      "         -4.5932]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : answer\n",
      "target index is: [53] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3703, -4.7653, -4.7398, -4.7954, -4.2339, -4.5582, -4.6501, -4.2999,\n",
      "         -4.7849, -4.7430, -4.7216, -4.4441, -4.5174, -4.6816, -4.8159, -4.7069,\n",
      "         -4.2692, -4.6230, -4.3704, -4.7130, -4.5816, -4.3970, -4.5814, -4.5340,\n",
      "         -4.2560, -5.0287, -4.3393, -4.7721, -4.5932, -4.4966, -4.5443, -4.7571,\n",
      "         -4.8125, -4.7755, -4.4047, -4.9128, -4.5858, -4.3518, -4.7753, -4.7599,\n",
      "         -4.8070, -4.6669, -4.8021, -4.6732, -4.3774, -4.3385, -4.5261, -4.7211,\n",
      "         -4.7530, -4.3399, -4.7733, -4.4549, -4.7915, -4.3908, -4.5820, -4.5662,\n",
      "         -4.6197, -4.3795, -4.4292, -4.4335, -4.6245, -4.5731, -4.4463, -4.0421,\n",
      "         -4.5586, -4.6340, -4.8090, -4.6338, -4.6378, -4.5922, -4.4146, -4.6445,\n",
      "         -4.8017, -4.6574, -4.8278, -4.7467, -4.3718, -4.3408, -4.3965, -4.9061,\n",
      "         -4.2955, -4.6270, -4.7004, -4.8535, -4.6457, -4.6972, -4.5092, -4.5857,\n",
      "         -5.0897, -4.3169, -4.4188, -4.6939, -4.7459, -4.5389, -4.5207, -4.8165,\n",
      "         -4.3421]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : 'This\n",
      "target index is: [9] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4192, -4.7280, -4.8170, -4.7038, -3.6972, -4.6342, -4.3110, -4.3186,\n",
      "         -4.9321, -4.8391, -4.8921, -4.5862, -4.8854, -4.7718, -4.7547, -4.8039,\n",
      "         -4.4863, -4.8710, -4.6823, -4.5534, -4.4760, -4.2907, -4.7385, -4.4091,\n",
      "         -4.5447, -4.9997, -4.4461, -4.4488, -4.5510, -4.7905, -4.5541, -4.7009,\n",
      "         -4.5599, -4.9827, -4.3133, -4.6418, -4.5362, -4.7401, -4.8559, -4.3893,\n",
      "         -4.8302, -4.2114, -4.7427, -4.4106, -4.6726, -4.2052, -4.5319, -4.5433,\n",
      "         -4.5917, -4.8507, -4.9452, -4.5193, -4.9671, -4.0650, -4.4413, -4.2893,\n",
      "         -4.6503, -4.2641, -4.6818, -4.5637, -4.5103, -4.4795, -4.6887, -4.4857,\n",
      "         -4.4876, -4.6729, -4.4344, -4.2385, -4.6800, -4.7758, -4.4072, -4.6416,\n",
      "         -4.7796, -5.0663, -4.8739, -5.0224, -4.6461, -4.4163, -4.4713, -4.7821,\n",
      "         -4.7383, -4.5025, -4.7022, -4.7736, -4.6661, -4.1796, -4.4224, -4.8431,\n",
      "         -4.9424, -4.4341, -4.6640, -4.5077, -4.5991, -4.7005, -4.5495, -4.7049,\n",
      "         -4.3414]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : fair\n",
      "target index is: [21] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3576, -4.4579, -4.8983, -4.5804, -4.0859, -4.5459, -4.8231, -4.3022,\n",
      "         -4.6729, -4.4199, -4.8363, -4.5010, -4.5945, -4.6459, -4.7661, -4.5879,\n",
      "         -4.6496, -4.4675, -4.6342, -4.3588, -4.5677, -4.2780, -4.8507, -4.8900,\n",
      "         -4.3929, -4.7851, -4.4687, -4.4108, -4.3361, -4.6391, -4.6101, -4.7062,\n",
      "         -4.9701, -4.8384, -4.4866, -4.6576, -4.7681, -4.7920, -5.1368, -4.8243,\n",
      "         -4.7636, -4.5460, -4.4541, -4.7133, -4.4145, -4.2587, -4.6024, -4.8319,\n",
      "         -4.5778, -4.8757, -4.7417, -4.3214, -4.6988, -4.4080, -4.7143, -4.7063,\n",
      "         -4.2778, -4.3351, -4.5340, -4.5916, -4.6629, -4.5237, -4.5755, -4.5016,\n",
      "         -4.4690, -4.7162, -4.6758, -4.5700, -4.8158, -4.6352, -4.3800, -4.6539,\n",
      "         -4.5792, -4.8649, -4.5907, -4.6280, -4.4758, -4.5370, -4.4970, -4.7460,\n",
      "         -4.2852, -4.3522, -4.5338, -4.7272, -4.5779, -4.2602, -4.7649, -4.7600,\n",
      "         -4.7186, -4.3883, -4.8391, -4.8164, -4.7746, -4.2198, -4.3853, -4.6779,\n",
      "         -4.4148]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : child\n",
      "target index is: [5] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3757, -4.4597, -4.9499, -4.6434, -4.1273, -4.7638, -4.5379, -4.6844,\n",
      "         -4.7289, -4.4945, -4.9718, -4.5524, -4.8776, -4.7616, -4.7905, -4.8724,\n",
      "         -4.6074, -4.6683, -4.7924, -4.4975, -4.5533, -4.3520, -4.8174, -4.6398,\n",
      "         -4.6938, -5.2478, -4.5840, -4.4928, -4.1596, -4.7193, -4.4951, -4.8077,\n",
      "         -4.6876, -4.7390, -4.5662, -4.8062, -4.4507, -4.6472, -4.7151, -4.5335,\n",
      "         -4.6523, -4.4633, -4.5198, -4.4347, -4.5296, -4.2751, -4.7273, -4.5946,\n",
      "         -4.6025, -4.9077, -4.7816, -4.6158, -5.0126, -4.3958, -4.4286, -4.2463,\n",
      "         -4.3530, -4.0929, -4.5976, -4.7274, -4.5228, -4.4202, -4.7780, -4.4557,\n",
      "         -4.4424, -4.5632, -4.7403, -4.3257, -4.4459, -4.4010, -4.4316, -4.5856,\n",
      "         -4.8053, -4.9736, -4.9945, -5.2183, -4.7696, -4.2696, -4.4582, -4.7784,\n",
      "         -4.5982, -4.3906, -4.6634, -4.9681, -4.7244, -4.1493, -4.4077, -4.3042,\n",
      "         -4.8737, -4.4606, -4.4187, -4.4057, -4.6396, -4.5392, -4.6372, -4.5886,\n",
      "         -4.1886]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : of\n",
      "target index is: [57] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5976, -4.0811, -4.5817, -4.7143, -4.1191, -4.8011, -4.7909, -4.5538,\n",
      "         -4.7545, -4.8683, -5.1038, -4.5045, -4.5859, -4.5291, -4.6511, -4.5877,\n",
      "         -4.7708, -4.5516, -4.6865, -4.3803, -4.5159, -4.2237, -4.7548, -4.4437,\n",
      "         -4.2420, -4.6090, -4.4964, -4.4564, -4.2566, -4.7696, -4.7074, -4.9773,\n",
      "         -5.0530, -4.5985, -4.7078, -4.7270, -4.8724, -4.8856, -4.8141, -4.7472,\n",
      "         -4.7010, -4.4473, -4.5928, -4.5756, -4.4833, -4.2938, -4.8418, -4.9363,\n",
      "         -4.5364, -4.7608, -4.4968, -4.4873, -4.5509, -4.3135, -4.7775, -4.7310,\n",
      "         -4.4209, -4.4424, -4.4996, -4.5837, -4.8615, -4.8068, -4.4328, -4.3132,\n",
      "         -4.6313, -4.7479, -5.0603, -4.4483, -4.7941, -4.7030, -4.5390, -4.5726,\n",
      "         -4.6373, -4.9224, -4.6253, -4.7115, -4.5027, -4.4030, -4.4786, -4.7900,\n",
      "         -4.0725, -4.3778, -4.6027, -4.6587, -4.4686, -4.3221, -4.5307, -4.8337,\n",
      "         -4.5083, -4.2843, -4.8172, -4.8508, -4.6303, -4.2397, -4.2016, -4.7917,\n",
      "         -4.3417]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : mine\n",
      "target index is: [86] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.0955, -4.3489, -4.6067, -5.0337, -4.1619, -4.6413, -4.7899, -4.5113,\n",
      "         -4.6950, -4.7808, -5.0058, -4.2902, -4.8894, -4.5174, -4.5962, -4.8119,\n",
      "         -4.6681, -4.8685, -4.5854, -4.1914, -4.9364, -4.7391, -4.5557, -4.1148,\n",
      "         -4.5065, -4.4968, -4.6871, -4.4853, -4.2018, -4.6525, -4.5605, -4.9929,\n",
      "         -4.7775, -4.5495, -4.6607, -4.7106, -4.6503, -4.7351, -4.8092, -4.7501,\n",
      "         -4.9210, -4.4935, -4.7631, -4.5519, -4.7696, -4.1783, -4.8958, -4.6230,\n",
      "         -4.5583, -4.6012, -4.6552, -4.8782, -4.5958, -4.3716, -4.8278, -4.6763,\n",
      "         -4.3501, -4.3976, -4.6845, -4.5621, -4.6180, -4.5762, -4.4573, -4.3864,\n",
      "         -4.7727, -4.6432, -5.1581, -4.8235, -4.6455, -4.7878, -4.2829, -4.6030,\n",
      "         -4.5874, -4.8793, -4.6305, -4.6106, -4.5252, -4.2180, -4.4286, -4.4965,\n",
      "         -4.6007, -4.2494, -4.6890, -4.7687, -4.6878, -4.4462, -4.4138, -4.4280,\n",
      "         -4.9047, -4.2597, -4.4684, -4.6175, -4.4928, -4.5185, -4.3121, -4.6129,\n",
      "         -4.4099]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Shall\n",
      "target index is: [81] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2371, -4.4050, -4.5718, -5.0864, -4.0681, -4.7264, -4.6621, -4.5689,\n",
      "         -4.7055, -4.9434, -4.7636, -4.3069, -4.6438, -4.7563, -4.7141, -4.6297,\n",
      "         -4.3472, -4.7118, -4.5105, -4.6392, -4.5953, -4.5278, -4.6620, -4.4040,\n",
      "         -4.3745, -4.5360, -4.3859, -4.4487, -4.4076, -4.8562, -4.1567, -5.0105,\n",
      "         -4.5772, -4.6691, -4.5773, -5.0008, -4.4523, -4.6352, -4.8481, -4.9694,\n",
      "         -4.6496, -4.7901, -4.7515, -4.6367, -4.6037, -4.2162, -4.5184, -4.7149,\n",
      "         -4.7563, -4.6604, -4.5583, -4.6177, -4.6343, -4.4401, -4.5867, -5.0050,\n",
      "         -4.6109, -4.5889, -4.5484, -4.4937, -4.7137, -4.5266, -4.6456, -4.1856,\n",
      "         -4.7947, -4.7689, -4.7892, -4.5777, -4.5114, -4.3808, -4.7066, -4.6659,\n",
      "         -4.8183, -4.7889, -4.7252, -4.5295, -4.5709, -4.1953, -4.3884, -4.5055,\n",
      "         -4.4735, -4.3665, -4.7564, -5.0664, -4.5289, -4.5555, -4.1854, -4.5923,\n",
      "         -4.9032, -4.4025, -4.5185, -4.7836, -4.7835, -4.3888, -4.1551, -4.6824,\n",
      "         -4.4685]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : sum\n",
      "target index is: [70] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3037, -4.3908, -4.6955, -4.8333, -4.2049, -4.8801, -4.4971, -4.3700,\n",
      "         -4.6645, -4.7664, -4.7128, -4.3093, -4.5698, -4.9725, -4.7897, -4.6984,\n",
      "         -4.5304, -5.1704, -4.6935, -4.6336, -4.5970, -4.3131, -4.6880, -4.5909,\n",
      "         -4.3091, -4.9795, -4.3103, -4.4423, -4.4831, -4.6456, -4.5756, -4.8985,\n",
      "         -4.8702, -4.9649, -4.3331, -4.4877, -4.7328, -4.4741, -4.6866, -4.5974,\n",
      "         -5.0749, -4.4255, -4.5889, -4.5242, -4.3943, -4.2430, -4.3930, -4.6134,\n",
      "         -4.3317, -4.8053, -4.6144, -4.1281, -4.9441, -4.4611, -4.6832, -4.5572,\n",
      "         -4.6209, -4.4161, -4.6072, -4.9442, -4.8000, -4.6019, -4.6991, -4.3524,\n",
      "         -4.9268, -4.6137, -4.8528, -4.3902, -4.5802, -4.6098, -4.3487, -4.8349,\n",
      "         -4.5549, -4.8327, -4.6586, -4.7956, -4.5435, -4.1702, -4.4851, -4.8123,\n",
      "         -4.3006, -4.6753, -4.5404, -4.6447, -4.2647, -4.5632, -4.4906, -4.6836,\n",
      "         -5.0310, -4.4527, -4.5941, -4.5579, -4.5570, -4.7237, -4.5024, -4.4250,\n",
      "         -4.4218]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : my\n",
      "target index is: [90] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3865, -4.3831, -4.6065, -5.1607, -4.2542, -5.1531, -4.4815, -4.5010,\n",
      "         -4.7324, -4.6485, -5.1204, -4.5852, -4.7211, -4.7462, -4.3964, -4.6328,\n",
      "         -4.6331, -4.6834, -4.9622, -4.3081, -4.7808, -4.3278, -4.7030, -4.6189,\n",
      "         -4.3778, -4.9967, -4.2397, -4.4904, -4.1476, -4.6043, -4.6661, -4.8844,\n",
      "         -4.7950, -4.9411, -4.7357, -4.5700, -4.6873, -4.4015, -4.8817, -4.5377,\n",
      "         -4.9556, -4.7904, -4.8642, -4.4078, -4.8266, -4.3762, -4.8196, -4.6681,\n",
      "         -4.5610, -5.1822, -4.1371, -5.1022, -4.4219, -4.5696, -4.7379, -4.3961,\n",
      "         -4.5536, -4.4092, -4.3056, -5.0255, -4.5909, -4.3386, -4.4948, -4.3182,\n",
      "         -4.5937, -4.3515, -5.0483, -4.6119, -4.4126, -4.5141, -4.6248, -4.6426,\n",
      "         -4.7449, -4.6940, -4.7512, -5.0128, -4.3575, -4.3477, -4.2591, -4.6537,\n",
      "         -4.4030, -4.5158, -4.8200, -4.4435, -4.6319, -4.1612, -4.5236, -4.8635,\n",
      "         -4.4877, -4.6262, -4.3366, -4.5747, -4.7228, -4.3647, -4.6626, -4.3092,\n",
      "         -4.1855]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : count,\n",
      "target index is: [55] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5798, -4.2704, -4.7109, -4.9633, -4.5266, -4.9624, -4.5946, -4.4745,\n",
      "         -4.6238, -4.8890, -4.9565, -4.6675, -4.7019, -4.7622, -4.7330, -4.6510,\n",
      "         -4.5942, -4.5782, -4.8617, -4.6341, -4.6071, -4.6831, -4.8095, -4.4171,\n",
      "         -4.3771, -4.7035, -4.5456, -4.2226, -4.2933, -4.6153, -4.2328, -4.8889,\n",
      "         -5.0011, -4.8158, -4.8554, -4.6452, -4.5835, -4.8027, -4.7337, -4.5292,\n",
      "         -4.6145, -4.6623, -4.3990, -4.5962, -4.4040, -4.2616, -4.9880, -4.6725,\n",
      "         -4.6520, -4.9311, -4.2783, -4.6801, -4.7362, -4.3314, -4.6296, -4.4414,\n",
      "         -4.2331, -4.2042, -4.6552, -4.4558, -4.6109, -4.5273, -4.3361, -4.1785,\n",
      "         -4.5817, -4.4952, -4.9515, -4.4157, -4.2225, -4.1680, -4.4796, -4.5754,\n",
      "         -4.8278, -4.7674, -5.0177, -5.1175, -4.3236, -4.2513, -4.5606, -4.9041,\n",
      "         -4.6750, -4.7357, -4.8498, -4.8453, -4.7598, -4.2782, -4.1978, -4.5638,\n",
      "         -4.7785, -4.3607, -4.3015, -4.9436, -4.7949, -4.3035, -4.5906, -4.7292,\n",
      "         -4.4041]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : and\n",
      "target index is: [44] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6510, -4.4767, -4.7197, -4.6817, -4.2238, -4.9044, -4.3899, -4.2714,\n",
      "         -4.7488, -4.9916, -4.6553, -4.4960, -4.6648, -4.8912, -4.6464, -4.4096,\n",
      "         -4.3167, -4.8174, -4.5464, -4.6514, -4.4926, -4.2958, -4.3847, -4.5491,\n",
      "         -4.2073, -4.8345, -4.4586, -4.5039, -4.7814, -4.4682, -4.6258, -4.8401,\n",
      "         -4.7930, -4.8785, -4.3683, -4.2772, -4.9340, -4.8014, -4.8228, -4.6704,\n",
      "         -4.9903, -4.6377, -4.8505, -4.5378, -4.4295, -4.5486, -4.3068, -4.7740,\n",
      "         -4.2562, -4.5700, -4.6422, -4.3532, -4.7857, -4.2115, -4.5391, -4.6116,\n",
      "         -4.5624, -4.6072, -4.6935, -4.8181, -4.9773, -4.6952, -4.4176, -4.1627,\n",
      "         -4.9447, -4.4637, -4.7315, -4.1395, -4.6847, -4.8434, -4.5668, -4.9138,\n",
      "         -4.3676, -4.6427, -4.7782, -4.8328, -4.2905, -4.4802, -4.5966, -4.4682,\n",
      "         -4.2954, -4.5458, -4.7710, -4.7914, -4.6436, -4.4774, -4.6893, -4.8053,\n",
      "         -4.9667, -4.1509, -4.8368, -4.9286, -4.3502, -4.4600, -4.5020, -4.4549,\n",
      "         -4.5678]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : make\n",
      "target index is: [14] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4345, -4.2550, -4.7402, -5.1550, -4.3695, -4.6470, -4.5752, -4.4490,\n",
      "         -4.6753, -4.7045, -4.7647, -4.5680, -4.8175, -4.6324, -4.4289, -4.5931,\n",
      "         -4.6202, -4.7464, -4.7725, -4.1391, -4.8497, -4.6984, -4.8227, -4.4132,\n",
      "         -4.6805, -4.7003, -4.4342, -4.3813, -4.2721, -4.6848, -4.5700, -4.7981,\n",
      "         -4.8832, -4.8065, -4.4466, -4.4336, -4.5181, -4.9495, -4.8109, -4.6467,\n",
      "         -4.7250, -4.6539, -4.6101, -4.4691, -4.7041, -4.3823, -5.0919, -4.5204,\n",
      "         -4.4285, -4.9672, -4.2408, -4.8981, -4.2265, -4.5766, -5.0073, -4.2576,\n",
      "         -4.5455, -4.3390, -4.8193, -4.4789, -4.5953, -4.5668, -4.4183, -4.4672,\n",
      "         -4.6363, -4.4386, -5.1987, -4.9100, -4.4642, -4.5418, -4.2425, -4.7194,\n",
      "         -4.5826, -4.7723, -4.5362, -4.7822, -4.4101, -4.2938, -4.6037, -4.7251,\n",
      "         -4.6505, -4.6031, -4.6694, -4.7462, -4.6067, -4.4151, -4.4757, -4.5691,\n",
      "         -4.5146, -4.1992, -4.4743, -4.4185, -4.7877, -4.4330, -4.6433, -4.5193,\n",
      "         -4.3831]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : my\n",
      "target index is: [90] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3090, -4.2480, -4.8815, -5.0298, -4.2314, -4.9973, -4.3298, -4.4217,\n",
      "         -4.8116, -4.6810, -4.6825, -4.4068, -4.6144, -4.9755, -4.7710, -4.4893,\n",
      "         -4.4071, -4.8020, -4.7798, -4.6076, -4.7873, -4.1750, -4.6694, -4.9269,\n",
      "         -4.2383, -5.0265, -4.1967, -4.5413, -4.1810, -4.6867, -4.3685, -4.9003,\n",
      "         -4.6062, -4.7500, -4.7512, -4.6661, -4.8532, -4.3446, -5.0101, -4.8271,\n",
      "         -4.7189, -4.9364, -4.6324, -4.5896, -4.5278, -4.3315, -4.5642, -4.8875,\n",
      "         -4.6574, -4.7962, -4.5522, -4.6090, -4.6685, -4.6389, -4.5198, -4.7075,\n",
      "         -4.7600, -4.4681, -4.5136, -4.8720, -4.8184, -4.1404, -4.5022, -4.0626,\n",
      "         -4.7117, -4.8563, -4.8142, -4.5558, -4.4929, -4.0343, -4.7061, -4.7755,\n",
      "         -4.5864, -4.5495, -4.7763, -4.9025, -4.4386, -4.4874, -4.2549, -4.5530,\n",
      "         -4.4191, -4.5096, -4.9919, -4.7511, -4.5661, -4.6255, -4.6580, -4.5826,\n",
      "         -4.6081, -4.2737, -4.4833, -4.7679, -4.8345, -4.2639, -4.3748, -4.4668,\n",
      "         -4.3199]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : old\n",
      "target index is: [84] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.0868, -4.3713, -4.4148, -5.0264, -4.3069, -5.2517, -4.3772, -4.4170,\n",
      "         -4.5105, -4.9295, -4.9679, -4.8008, -4.2459, -4.8220, -4.9311, -4.4198,\n",
      "         -4.5313, -4.5546, -4.8587, -4.7450, -4.6995, -4.2846, -5.0429, -4.7697,\n",
      "         -3.9898, -4.8624, -4.3598, -4.5153, -3.9752, -4.7150, -4.6138, -4.6818,\n",
      "         -4.6431, -5.0090, -4.8841, -4.6006, -4.8029, -4.3153, -4.7442, -4.5728,\n",
      "         -4.8572, -4.5128, -4.7976, -4.3053, -4.5062, -4.4390, -4.8243, -4.5603,\n",
      "         -4.6139, -4.9152, -4.0846, -4.7399, -4.9022, -4.6810, -4.7101, -4.5593,\n",
      "         -4.2585, -4.5151, -4.4130, -4.8223, -4.9505, -4.3444, -4.3992, -4.3158,\n",
      "         -4.6521, -4.7419, -4.8793, -4.5812, -4.4772, -4.3741, -4.5973, -4.4605,\n",
      "         -4.7720, -4.8645, -4.7347, -4.9432, -4.3136, -4.3618, -4.5461, -4.8724,\n",
      "         -4.1107, -4.5793, -4.8413, -4.7589, -4.4948, -4.4936, -4.6184, -4.7864,\n",
      "         -4.8717, -4.5548, -4.5195, -4.6218, -4.6063, -4.4412, -4.8548, -4.3776,\n",
      "         -4.4307]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : excuse,'\n",
      "target index is: [64] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4726, -4.4320, -4.5224, -4.7966, -4.1921, -4.9254, -4.6048, -4.3594,\n",
      "         -4.7468, -4.8181, -4.7391, -4.6534, -4.4966, -4.4888, -4.8279, -4.6389,\n",
      "         -4.7155, -4.2801, -4.6507, -4.6113, -4.4014, -4.7153, -4.4267, -4.7716,\n",
      "         -4.2561, -4.7009, -4.5843, -4.5695, -4.3971, -4.2345, -4.6472, -4.6898,\n",
      "         -4.8940, -4.7793, -4.6501, -5.2396, -4.8290, -4.6789, -4.6020, -4.5269,\n",
      "         -4.3606, -4.7988, -4.8141, -4.6456, -4.5614, -4.6205, -4.5457, -4.4840,\n",
      "         -4.5061, -4.4606, -4.2833, -4.5198, -4.4639, -4.4970, -4.5704, -4.4246,\n",
      "         -4.6300, -4.4322, -4.3777, -4.6251, -4.9381, -4.5121, -4.5458, -3.7786,\n",
      "         -4.6881, -4.4286, -4.6710, -4.3710, -4.4789, -4.6607, -4.6235, -4.6266,\n",
      "         -4.9430, -4.8393, -4.8457, -4.6499, -4.6328, -4.5130, -4.3184, -4.5848,\n",
      "         -4.7157, -4.7222, -4.9545, -4.9324, -4.6779, -4.2340, -4.4346, -4.9653,\n",
      "         -4.8731, -4.1741, -4.4973, -4.7131, -4.5900, -4.5331, -4.6805, -4.5608,\n",
      "         -4.8910]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : Proving\n",
      "target index is: [25] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4294, -4.6003, -4.9559, -4.7567, -4.4842, -4.7007, -4.5972, -4.4875,\n",
      "         -4.6103, -4.5713, -4.9297, -4.4152, -4.4442, -4.4855, -4.5460, -4.8685,\n",
      "         -4.6049, -4.8709, -4.4030, -4.5612, -4.5227, -4.4991, -4.6512, -4.5310,\n",
      "         -4.4122, -4.7208, -4.2403, -4.6080, -4.4418, -4.4542, -5.0631, -4.8181,\n",
      "         -4.8137, -4.8552, -5.0005, -5.0148, -4.4826, -4.7132, -4.6235, -4.3695,\n",
      "         -4.7792, -4.5905, -4.6228, -4.6915, -4.3083, -4.3810, -4.7620, -4.8115,\n",
      "         -4.4516, -4.8704, -4.2722, -4.5428, -4.5182, -4.1702, -4.5482, -4.2815,\n",
      "         -4.7129, -4.3721, -4.5349, -4.3636, -4.4971, -4.3125, -4.3975, -4.0561,\n",
      "         -4.4436, -4.5849, -4.7148, -4.7290, -4.9667, -4.1963, -4.0777, -4.6052,\n",
      "         -5.1195, -4.3095, -4.8365, -4.9715, -4.3664, -4.4669, -4.3723, -4.6035,\n",
      "         -4.6335, -4.6271, -4.9344, -4.8949, -4.8995, -4.5198, -5.1262, -5.0251,\n",
      "         -4.8577, -4.4213, -4.6055, -4.6873, -4.7282, -4.2203, -4.6463, -4.8279,\n",
      "         -4.3635]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : his\n",
      "target index is: [49] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6066, -4.3218, -4.9128, -5.0933, -4.2758, -4.6021, -4.2075, -4.3974,\n",
      "         -4.9928, -4.4731, -4.7399, -4.3132, -4.7381, -4.6715, -4.8997, -4.5294,\n",
      "         -4.5189, -4.4834, -4.7152, -4.3267, -4.4600, -4.3950, -4.4195, -4.6341,\n",
      "         -4.6287, -4.7854, -4.4310, -4.5846, -4.7208, -4.5538, -4.7124, -4.5895,\n",
      "         -4.7533, -4.8092, -4.5078, -4.6649, -4.4875, -4.8052, -4.7494, -4.3478,\n",
      "         -4.4184, -4.5066, -4.4750, -4.3211, -4.4714, -4.7144, -4.4796, -4.3754,\n",
      "         -4.3650, -5.1747, -4.4611, -4.7926, -4.3755, -4.3852, -4.6326, -4.5547,\n",
      "         -4.9191, -4.6822, -4.2589, -4.7025, -4.9197, -4.4797, -4.5255, -4.3860,\n",
      "         -4.4774, -4.6351, -4.5012, -4.4083, -4.6745, -4.3087, -4.7760, -4.9260,\n",
      "         -4.7444, -4.7634, -4.6964, -4.9112, -4.3705, -4.5349, -4.2931, -4.5011,\n",
      "         -4.7937, -4.6951, -4.8448, -4.5768, -4.9885, -4.3283, -4.7495, -4.6149,\n",
      "         -4.8330, -4.3176, -4.6032, -4.3202, -4.9404, -4.5591, -4.7077, -4.5704,\n",
      "         -4.5409]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : beauty\n",
      "target index is: [0] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5354, -4.4942, -4.8427, -4.6754, -4.3897, -4.7140, -4.7050, -4.0945,\n",
      "         -4.7691, -4.4593, -4.6170, -4.3562, -4.3920, -4.7235, -4.7896, -4.7247,\n",
      "         -4.7140, -4.4772, -4.3392, -4.4927, -4.5851, -4.4789, -4.6953, -4.9348,\n",
      "         -4.2104, -5.2823, -4.3224, -4.7677, -4.0584, -4.4151, -4.6219, -4.6375,\n",
      "         -5.0042, -4.7232, -4.5276, -5.0371, -4.4694, -4.6031, -4.6421, -4.7665,\n",
      "         -4.7313, -4.6609, -4.7420, -4.7625, -4.6058, -4.4696, -4.7705, -5.0302,\n",
      "         -4.8670, -4.8033, -4.6917, -4.4513, -4.8305, -4.5971, -4.6720, -4.5801,\n",
      "         -4.2507, -4.0637, -4.4391, -4.3460, -4.6731, -4.5459, -4.4339, -4.4338,\n",
      "         -4.4313, -4.6927, -4.5934, -4.7453, -4.6604, -4.3417, -4.4911, -4.5210,\n",
      "         -5.1534, -4.6137, -4.9156, -4.8844, -4.4338, -4.2694, -4.1906, -4.8854,\n",
      "         -4.3614, -4.4548, -4.7059, -4.8379, -4.7756, -4.5142, -4.7136, -4.2993,\n",
      "         -4.7527, -4.5520, -4.6096, -4.6004, -4.8514, -4.3217, -4.6488, -4.6221,\n",
      "         -4.2535]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : by\n",
      "target index is: [62] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.0193, -4.6907, -4.6549, -4.6777, -3.8780, -4.7108, -4.3967, -4.0617,\n",
      "         -4.9103, -4.9279, -4.6950, -4.4577, -4.3999, -4.6984, -4.7644, -4.8081,\n",
      "         -4.4260, -4.6794, -4.5342, -4.8218, -4.7281, -4.4011, -4.8477, -4.7462,\n",
      "         -4.1324, -4.7897, -4.4977, -4.3985, -4.5502, -4.7231, -4.5466, -4.4511,\n",
      "         -4.5554, -4.9936, -4.5905, -5.1468, -4.8191, -4.2364, -4.7295, -4.3726,\n",
      "         -4.7067, -4.4608, -4.8658, -4.3685, -4.5305, -3.9293, -4.5345, -4.7634,\n",
      "         -4.8721, -4.5185, -4.7526, -4.3705, -4.8984, -4.3299, -4.4015, -4.4875,\n",
      "         -4.3215, -4.3475, -4.7033, -4.7645, -4.8457, -4.2520, -4.3648, -4.3869,\n",
      "         -4.5461, -4.8385, -4.5766, -4.2112, -4.9553, -4.6529, -4.7458, -4.8009,\n",
      "         -4.4948, -5.0401, -4.7182, -4.8120, -4.6509, -4.2919, -4.3863, -5.0186,\n",
      "         -4.2872, -4.5198, -5.0359, -5.0108, -4.6883, -4.3013, -4.7704, -5.1144,\n",
      "         -5.1619, -4.6093, -4.8840, -4.7203, -4.5085, -4.5411, -4.6320, -4.8326,\n",
      "         -4.5521]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : succession\n",
      "target index is: [7] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6277, -4.4164, -4.6495, -4.6821, -4.1916, -4.6707, -4.6720, -4.4448,\n",
      "         -4.7054, -4.5842, -4.7173, -4.2470, -4.7651, -4.5011, -4.9751, -4.6642,\n",
      "         -4.6551, -4.4982, -4.8568, -4.5137, -4.3579, -4.5944, -4.7439, -4.8804,\n",
      "         -4.4964, -4.6910, -4.5059, -4.2772, -4.1991, -4.4412, -4.4859, -4.7784,\n",
      "         -4.9312, -4.5720, -4.8808, -5.1952, -4.5408, -4.9379, -4.5251, -4.5251,\n",
      "         -4.2569, -4.6761, -4.4455, -4.7390, -4.2582, -4.5417, -4.3297, -4.8362,\n",
      "         -4.4084, -4.8446, -4.5135, -4.5390, -4.5285, -4.4119, -4.6829, -4.5404,\n",
      "         -4.5817, -4.3142, -4.6097, -4.7170, -4.5056, -4.4023, -4.4200, -3.9332,\n",
      "         -4.4004, -4.5439, -4.5761, -4.5572, -4.3954, -4.1205, -4.3876, -4.4601,\n",
      "         -4.9868, -4.7900, -4.7972, -4.9153, -4.7601, -4.3420, -4.4914, -4.8632,\n",
      "         -4.9537, -4.5550, -4.7225, -4.8917, -4.7444, -4.4194, -4.4609, -4.6062,\n",
      "         -4.9825, -4.4939, -4.7617, -4.6709, -4.8030, -4.7003, -4.5961, -4.9842,\n",
      "         -4.7077]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thine!\n",
      "target index is: [40] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5984, -4.2823, -4.6880, -4.4924, -4.2100, -4.7549, -4.5817, -4.2969,\n",
      "         -4.7215, -4.6634, -4.6329, -4.3869, -4.6924, -4.6843, -4.4866, -4.8521,\n",
      "         -4.8882, -5.0711, -4.6530, -4.5498, -4.5511, -4.5982, -4.5897, -4.5345,\n",
      "         -4.5372, -4.5992, -4.1816, -4.4197, -4.3975, -4.6821, -4.8467, -4.8578,\n",
      "         -4.9285, -4.5965, -4.5139, -4.8902, -4.7776, -4.7773, -4.5621, -4.4394,\n",
      "         -4.7416, -4.6323, -4.5806, -4.5693, -4.6108, -4.4788, -4.6009, -4.5502,\n",
      "         -4.3437, -4.7091, -4.3900, -4.4471, -4.4984, -4.5512, -4.9926, -4.1555,\n",
      "         -4.7852, -4.2912, -4.6885, -4.7701, -4.5136, -4.4502, -4.6403, -4.2165,\n",
      "         -4.8937, -4.5345, -4.7249, -4.6474, -4.7985, -4.6451, -4.2179, -4.8351,\n",
      "         -4.7877, -4.5046, -4.3583, -4.9416, -4.6713, -4.4219, -4.3578, -4.4397,\n",
      "         -4.6452, -4.3634, -4.9164, -4.8187, -4.7436, -4.4104, -4.8893, -4.8130,\n",
      "         -4.7179, -4.4007, -4.7385, -4.3575, -4.5730, -4.3129, -4.5455, -4.2764,\n",
      "         -4.6981]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : This\n",
      "target index is: [1] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4597, -4.3606, -4.7535, -4.7899, -4.2110, -4.5652, -4.7443, -4.4931,\n",
      "         -4.5398, -4.5694, -4.7796, -4.7028, -4.8103, -4.6783, -4.4576, -4.7169,\n",
      "         -4.6248, -4.6050, -4.8490, -4.3932, -4.6952, -4.6301, -5.0238, -4.5169,\n",
      "         -4.4953, -4.6897, -4.5247, -4.4413, -4.2601, -4.7362, -4.5780, -4.7594,\n",
      "         -4.7625, -4.7304, -4.6328, -4.8551, -4.4385, -4.8404, -4.6955, -4.6750,\n",
      "         -4.6127, -4.4109, -4.6356, -4.6588, -4.5477, -4.2544, -4.7699, -4.5642,\n",
      "         -4.3154, -4.7263, -4.4729, -4.7377, -4.6304, -4.5567, -4.8060, -4.4655,\n",
      "         -4.3249, -4.1714, -4.7246, -4.3125, -4.6188, -4.6471, -4.3865, -4.3124,\n",
      "         -4.5605, -4.7578, -4.8917, -4.7857, -4.4778, -4.3579, -4.1933, -4.3784,\n",
      "         -4.9581, -4.8260, -4.6693, -4.7977, -4.3805, -4.3820, -4.6041, -4.6684,\n",
      "         -4.5375, -4.4208, -4.6050, -4.8148, -4.7740, -4.5348, -4.5654, -4.5150,\n",
      "         -4.7512, -4.3042, -4.5345, -4.5777, -4.8727, -4.3756, -4.4893, -4.7548,\n",
      "         -4.5047]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : were\n",
      "target index is: [93] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2610, -4.4732, -4.7771, -4.8997, -3.8279, -4.5310, -4.4091, -4.2795,\n",
      "         -4.6327, -4.8807, -4.6145, -4.4473, -4.5940, -4.9252, -4.7596, -4.5443,\n",
      "         -4.5064, -4.9886, -4.5969, -4.4252, -4.8529, -4.1641, -4.7025, -4.9392,\n",
      "         -4.3337, -4.6836, -4.3921, -4.3560, -4.2986, -4.8726, -4.4002, -4.9224,\n",
      "         -4.6668, -4.6492, -4.3114, -4.8355, -4.8868, -4.5595, -5.1062, -4.7921,\n",
      "         -4.6909, -4.7001, -4.7448, -4.5995, -4.7997, -4.2626, -4.2593, -4.7301,\n",
      "         -4.4794, -4.7798, -4.8531, -4.3450, -4.7774, -4.6363, -4.6196, -4.4537,\n",
      "         -4.4093, -4.3527, -4.4555, -4.7745, -4.6414, -4.4588, -4.8551, -4.0865,\n",
      "         -4.7534, -4.7053, -4.7306, -4.6220, -4.7821, -4.5083, -4.5888, -4.6557,\n",
      "         -4.2659, -4.7903, -4.6520, -4.5177, -4.6799, -4.7018, -4.4982, -4.4385,\n",
      "         -4.6657, -4.5340, -5.0318, -4.7671, -4.2162, -4.6246, -4.4625, -4.7623,\n",
      "         -4.7288, -4.4368, -4.7570, -4.5609, -4.8082, -4.4884, -4.5164, -4.5291,\n",
      "         -4.5528]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : to\n",
      "target index is: [72] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5445, -4.5851, -4.7149, -4.4751, -4.4895, -4.7615, -4.9670, -4.2683,\n",
      "         -4.7026, -4.7058, -4.6189, -4.6595, -4.5147, -4.7192, -4.8255, -4.5692,\n",
      "         -4.7929, -4.1951, -4.6286, -4.6196, -4.3784, -4.5227, -5.0382, -4.8607,\n",
      "         -4.2456, -4.9917, -4.5587, -4.3118, -4.2067, -4.7100, -4.6449, -4.2730,\n",
      "         -5.1096, -4.8162, -4.5735, -5.1784, -4.5326, -4.7124, -4.6267, -4.7437,\n",
      "         -4.4776, -4.5441, -4.6087, -4.6263, -4.4886, -4.3396, -4.7188, -4.7577,\n",
      "         -4.7654, -4.6658, -4.3709, -4.5920, -4.6433, -4.7943, -4.8459, -4.6905,\n",
      "         -3.9774, -4.0681, -4.5123, -4.3090, -4.5488, -4.4227, -4.2728, -4.1961,\n",
      "         -4.4473, -4.5502, -4.8385, -4.9633, -4.4445, -4.4361, -4.1874, -4.2265,\n",
      "         -5.2085, -4.9706, -4.8888, -4.8989, -4.2662, -4.2886, -4.4831, -4.6805,\n",
      "         -4.4198, -4.5790, -4.5920, -5.0013, -4.7916, -4.5876, -4.5528, -4.5458,\n",
      "         -5.0461, -4.5025, -4.6395, -4.6949, -5.0856, -4.2455, -4.5345, -4.8881,\n",
      "         -4.6286]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : be\n",
      "target index is: [24] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.2009, -4.8608, -4.8250, -5.0787, -4.0460, -4.8210, -4.5562, -4.2426,\n",
      "         -4.8947, -5.0722, -4.9393, -4.3285, -4.6791, -4.9129, -4.9699, -4.5856,\n",
      "         -3.9922, -5.0296, -4.5610, -5.0247, -4.3739, -4.2091, -4.6007, -4.4807,\n",
      "         -4.2648, -5.0168, -4.0675, -4.5784, -4.6026, -4.7264, -4.2084, -5.3593,\n",
      "         -4.8519, -5.1401, -4.3513, -4.7314, -4.8408, -4.4735, -5.0274, -4.9718,\n",
      "         -5.0780, -4.4521, -4.6638, -4.4958, -4.1981, -4.1165, -4.4276, -4.6926,\n",
      "         -4.5772, -4.4822, -4.4741, -4.1113, -5.2078, -4.3894, -4.6920, -4.7064,\n",
      "         -4.8199, -4.4126, -4.5805, -4.9058, -4.9637, -4.5959, -4.7155, -3.9736,\n",
      "         -4.6350, -4.7791, -4.9905, -4.4579, -4.3987, -4.5263, -4.3293, -4.7897,\n",
      "         -4.6893, -4.8273, -4.6874, -4.8589, -4.7196, -4.0853, -4.4698, -4.9837,\n",
      "         -4.0878, -4.8436, -4.6951, -4.6728, -4.3248, -4.7967, -4.3055, -4.9168,\n",
      "         -5.0002, -4.4659, -4.2913, -4.6760, -4.7738, -4.6280, -4.3683, -4.6356,\n",
      "         -4.3044]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : new\n",
      "target index is: [27] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5413, -4.4761, -4.3665, -4.7295, -4.1854, -4.7301, -4.6485, -4.3894,\n",
      "         -4.6043, -4.6494, -4.8495, -4.5207, -4.6256, -4.7155, -4.5800, -4.6518,\n",
      "         -4.4959, -4.5661, -4.4869, -4.6061, -4.7607, -4.6388, -4.5134, -4.4792,\n",
      "         -4.3974, -4.6296, -4.4553, -4.6554, -4.4902, -4.4262, -4.5004, -4.6481,\n",
      "         -4.8434, -4.7450, -4.5474, -4.7206, -4.6648, -4.6880, -4.5648, -4.7055,\n",
      "         -4.6692, -4.5500, -4.9703, -4.6344, -4.7074, -4.6206, -4.6637, -4.5664,\n",
      "         -4.5442, -4.3721, -4.3120, -4.5415, -4.6408, -4.3405, -4.7272, -4.4784,\n",
      "         -4.5533, -4.6013, -4.5185, -4.6710, -4.7290, -4.5892, -4.5742, -4.1140,\n",
      "         -4.9846, -4.4650, -4.8788, -4.4411, -4.6960, -5.0102, -4.5969, -4.6371,\n",
      "         -4.7203, -4.7415, -4.6672, -4.6972, -4.4665, -4.4471, -4.3118, -4.8323,\n",
      "         -4.4154, -4.3462, -4.6015, -4.7773, -4.7048, -4.3236, -4.5723, -4.7822,\n",
      "         -4.7753, -4.1811, -4.5805, -4.8286, -4.3702, -4.5753, -4.3791, -4.4140,\n",
      "         -4.7215]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : made\n",
      "target index is: [16] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3340, -4.6382, -4.7472, -4.8599, -4.2522, -4.6905, -4.3932, -4.5323,\n",
      "         -4.6912, -4.3957, -4.8758, -4.4751, -4.6662, -4.5312, -4.6968, -4.8240,\n",
      "         -4.4724, -4.7112, -4.5955, -4.5990, -4.3506, -4.3782, -4.6560, -4.5712,\n",
      "         -4.6481, -5.1526, -4.1557, -4.6851, -4.6029, -4.7367, -4.5266, -4.8980,\n",
      "         -4.5627, -4.9553, -4.5252, -4.9753, -4.5336, -4.3521, -4.6435, -4.4085,\n",
      "         -4.6528, -4.5368, -4.5344, -4.4255, -4.4639, -4.4760, -4.7040, -4.5332,\n",
      "         -4.5900, -4.8412, -4.3726, -4.8027, -4.8016, -4.5128, -4.6212, -4.4313,\n",
      "         -4.7858, -4.5150, -4.3973, -4.5806, -4.5574, -4.4997, -4.5873, -4.2662,\n",
      "         -4.3402, -4.8570, -4.7873, -4.3784, -4.6142, -4.4031, -4.5748, -4.6991,\n",
      "         -4.8287, -4.6861, -4.7681, -4.8709, -4.4821, -4.3952, -4.2542, -4.6058,\n",
      "         -4.4271, -4.5997, -4.7447, -4.7453, -4.7848, -4.3760, -4.7531, -4.5337,\n",
      "         -4.9580, -4.6687, -4.3329, -4.5986, -4.6629, -4.5472, -4.5372, -4.4522,\n",
      "         -4.3226]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : when\n",
      "target index is: [85] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4302, -4.5790, -4.8215, -4.7594, -4.2437, -4.6482, -4.2442, -4.3677,\n",
      "         -4.9006, -4.5590, -4.9041, -4.4799, -4.7411, -4.6025, -4.4800, -4.5189,\n",
      "         -4.2756, -4.6728, -4.7391, -4.4069, -4.4504, -4.3327, -4.5912, -4.7524,\n",
      "         -4.6230, -5.0918, -4.5397, -4.2817, -4.7635, -4.7812, -4.6958, -4.5990,\n",
      "         -4.6939, -5.0664, -4.4805, -4.7464, -4.3647, -4.5640, -4.8925, -4.3712,\n",
      "         -4.6121, -4.6702, -4.6830, -4.3844, -4.5640, -4.1969, -4.7682, -4.8950,\n",
      "         -4.7398, -4.9360, -4.6078, -4.6890, -4.5206, -3.8706, -4.4003, -4.5734,\n",
      "         -4.6146, -4.5256, -4.5861, -4.6148, -4.5823, -4.5133, -4.4402, -4.5813,\n",
      "         -4.4685, -4.3968, -4.8753, -4.1913, -4.7749, -4.5181, -4.6366, -4.9230,\n",
      "         -4.8541, -4.7714, -4.8921, -5.0024, -4.4495, -4.4431, -4.2915, -4.8805,\n",
      "         -4.4708, -4.4681, -4.6364, -4.7201, -4.9240, -4.0282, -4.9660, -4.9448,\n",
      "         -4.8312, -4.4335, -4.4106, -4.6596, -4.7500, -4.5245, -4.5101, -4.7095,\n",
      "         -4.2815]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thou\n",
      "target index is: [22] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6157, -4.6170, -4.9583, -4.6489, -4.1955, -4.7527, -4.4619, -4.7213,\n",
      "         -4.6531, -4.5570, -4.6910, -4.2344, -4.7935, -4.7049, -4.7232, -4.2127,\n",
      "         -4.7329, -4.6515, -4.8211, -4.4773, -4.7738, -4.1734, -4.7444, -4.6169,\n",
      "         -4.1856, -4.7228, -4.7727, -4.4000, -4.3143, -4.3542, -4.7406, -4.5743,\n",
      "         -4.7005, -4.8591, -4.6051, -4.4395, -4.5842, -4.8069, -4.9668, -4.3618,\n",
      "         -4.8892, -4.1788, -4.6587, -4.5540, -4.3613, -4.5162, -4.5754, -4.7959,\n",
      "         -4.3789, -5.1423, -4.7387, -4.7061, -4.6368, -4.2581, -4.6188, -4.4355,\n",
      "         -4.2845, -4.4649, -4.6350, -4.4267, -4.6666, -4.5392, -4.3533, -4.5781,\n",
      "         -4.7296, -4.4427, -4.5750, -4.4523, -4.7984, -4.2476, -4.3267, -4.6727,\n",
      "         -4.8923, -4.8830, -4.7951, -4.9088, -4.4839, -4.6097, -4.6210, -4.6557,\n",
      "         -4.6367, -4.4252, -4.5624, -4.3889, -4.7174, -4.1594, -4.7394, -4.8899,\n",
      "         -4.8422, -4.4497, -4.7778, -4.6686, -4.5779, -4.5975, -4.6495, -4.6135,\n",
      "         -4.6905]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : art\n",
      "target index is: [15] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.3475, -4.4833, -4.7798, -4.9341, -4.2680, -4.7738, -4.5878, -4.4057,\n",
      "         -4.6043, -4.8039, -4.6659, -4.4707, -4.4098, -4.7478, -4.7553, -4.2590,\n",
      "         -4.4987, -4.4729, -4.2904, -4.5521, -4.5866, -4.2770, -4.7854, -4.8910,\n",
      "         -4.1475, -4.7050, -4.4295, -4.5481, -4.2127, -4.5730, -4.5469, -4.8529,\n",
      "         -4.8846, -4.6455, -4.5785, -4.9378, -4.6218, -4.6042, -4.9299, -4.9337,\n",
      "         -4.8299, -4.8651, -4.7394, -4.8068, -4.5969, -4.5189, -4.6434, -4.9717,\n",
      "         -4.6125, -4.6623, -4.4495, -4.7941, -4.4789, -4.5088, -4.7593, -4.6678,\n",
      "         -4.3897, -4.4109, -4.4805, -4.4344, -4.7088, -4.3422, -4.3837, -4.1727,\n",
      "         -4.6236, -4.4661, -4.8220, -4.8548, -4.6375, -4.4476, -4.5149, -4.5655,\n",
      "         -4.8870, -4.6949, -4.6252, -4.7833, -4.3559, -4.4551, -4.5558, -4.6487,\n",
      "         -4.4092, -4.4685, -4.9455, -4.8758, -4.4399, -4.6723, -4.5670, -4.6696,\n",
      "         -4.5135, -4.3565, -4.5140, -4.7180, -4.5980, -4.1811, -4.7140, -4.5189,\n",
      "         -4.4845]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : old,\n",
      "target index is: [8] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4148, -4.5677, -4.9759, -4.6850, -4.3451, -4.7164, -4.4786, -4.3370,\n",
      "         -4.7242, -4.5802, -4.8039, -4.3957, -4.5877, -4.9592, -5.0359, -4.9624,\n",
      "         -4.7182, -4.7267, -4.5614, -4.6832, -4.3414, -4.2949, -4.7244, -4.6258,\n",
      "         -4.3506, -5.1347, -4.3092, -4.6939, -4.6527, -4.5786, -4.6982, -4.7970,\n",
      "         -4.6803, -4.9067, -4.4895, -4.8691, -4.7553, -4.3881, -4.5935, -4.3253,\n",
      "         -4.6435, -4.6075, -4.6515, -4.5878, -4.2519, -4.3247, -4.4379, -4.3730,\n",
      "         -4.4862, -4.9128, -4.7724, -4.2718, -4.8645, -4.3981, -4.3296, -4.4170,\n",
      "         -4.5774, -4.1626, -4.2817, -4.7282, -4.7536, -4.4067, -4.4538, -4.2433,\n",
      "         -4.5074, -4.7443, -4.6803, -4.4039, -4.3671, -4.1756, -4.4075, -4.7683,\n",
      "         -4.6591, -4.8714, -4.9153, -4.9179, -4.4474, -4.3645, -4.5302, -4.8020,\n",
      "         -4.5575, -4.7813, -4.8820, -4.7448, -4.5855, -4.5577, -4.6058, -4.8573,\n",
      "         -5.0276, -4.3447, -4.7316, -4.7231, -4.6991, -4.3090, -4.6827, -4.7029,\n",
      "         -4.2944]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : And\n",
      "target index is: [6] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4883, -4.3710, -4.4980, -4.5576, -4.3752, -5.0141, -4.4875, -4.4482,\n",
      "         -4.6541, -4.8040, -4.8447, -4.3607, -4.5605, -4.6350, -4.6295, -4.7091,\n",
      "         -4.6677, -4.6228, -4.9392, -4.5672, -4.4880, -4.5131, -4.5669, -4.6019,\n",
      "         -4.2089, -4.7032, -4.6278, -4.4238, -4.3132, -4.5446, -4.7175, -4.7890,\n",
      "         -4.6429, -4.7456, -4.6205, -4.5436, -4.7947, -4.5922, -4.5531, -4.4124,\n",
      "         -4.8601, -4.3913, -4.7188, -4.4305, -4.4786, -4.3929, -4.4408, -4.6144,\n",
      "         -4.5278, -4.7903, -4.5332, -4.4639, -4.8832, -4.3489, -4.5864, -4.5350,\n",
      "         -4.4423, -4.5502, -4.5694, -4.8064, -4.6799, -4.5052, -4.5390, -4.4267,\n",
      "         -4.7019, -4.6659, -4.7589, -4.2364, -4.7046, -4.6198, -4.6179, -4.7096,\n",
      "         -4.5462, -4.9740, -4.7815, -4.7915, -4.5695, -4.2918, -4.5373, -4.7638,\n",
      "         -4.2668, -4.4626, -4.5954, -4.7128, -4.5562, -4.3047, -4.5950, -4.7689,\n",
      "         -4.8768, -4.5135, -4.7703, -4.7746, -4.2854, -4.5651, -4.5429, -4.5476,\n",
      "         -4.5243]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : see\n",
      "target index is: [67] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4175, -4.5674, -4.7721, -5.0041, -4.4566, -4.7373, -4.5421, -4.4680,\n",
      "         -4.7917, -4.6302, -5.0252, -4.8945, -4.6644, -4.7156, -4.6972, -4.7411,\n",
      "         -4.5466, -4.5430, -4.7277, -4.3636, -4.7479, -4.7326, -4.8909, -4.7258,\n",
      "         -4.6001, -4.9311, -4.5924, -4.3269, -4.3530, -4.7803, -4.5087, -4.7233,\n",
      "         -5.0403, -4.9495, -4.2880, -4.5965, -4.2513, -4.5455, -4.7543, -4.7762,\n",
      "         -4.7815, -4.6084, -4.5724, -4.6350, -4.4557, -4.1332, -4.8150, -4.7252,\n",
      "         -4.7976, -4.8497, -4.2689, -4.6130, -4.5735, -4.3816, -4.7424, -4.7606,\n",
      "         -4.4213, -4.2897, -4.6534, -4.4383, -4.7523, -4.5679, -4.4617, -4.6337,\n",
      "         -4.5615, -4.4613, -5.0663, -4.4583, -4.5250, -4.6828, -4.2674, -4.1861,\n",
      "         -5.0531, -4.8964, -4.8065, -4.8887, -4.2997, -4.1385, -4.2540, -4.7548,\n",
      "         -4.2481, -4.7122, -4.3373, -4.9382, -4.7716, -4.2981, -4.4852, -4.5278,\n",
      "         -4.7243, -4.3504, -4.2100, -4.5516, -4.9424, -4.3846, -4.4531, -4.5506,\n",
      "         -4.1588]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thy\n",
      "target index is: [78] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5631, -4.4089, -4.9602, -4.5614, -4.1677, -4.6451, -4.6178, -4.2171,\n",
      "         -5.1291, -4.3745, -4.7442, -4.2140, -4.3243, -4.5693, -4.7782, -4.8671,\n",
      "         -4.3748, -4.5312, -4.3931, -4.5858, -4.6460, -4.4096, -4.3149, -4.7407,\n",
      "         -4.3603, -5.1559, -4.2847, -4.9269, -4.5952, -4.4582, -4.6298, -4.5920,\n",
      "         -4.8411, -4.6658, -4.5935, -5.1197, -4.6103, -4.5424, -4.5957, -4.6630,\n",
      "         -4.4668, -4.8085, -4.8714, -4.6500, -4.4143, -4.1643, -4.5857, -5.0589,\n",
      "         -5.0379, -4.4622, -4.8402, -4.4098, -4.4151, -4.3375, -4.4374, -4.5139,\n",
      "         -4.6416, -4.2331, -4.3240, -4.5164, -4.7399, -4.7328, -4.4150, -4.0575,\n",
      "         -4.4662, -4.6976, -4.7022, -4.4311, -4.8193, -4.5245, -4.6808, -4.7023,\n",
      "         -4.8769, -4.5614, -4.8450, -4.8449, -4.3657, -4.5471, -4.2368, -4.9063,\n",
      "         -4.4334, -4.4901, -4.7757, -4.8451, -4.8272, -4.5763, -4.7749, -4.7440,\n",
      "         -4.9780, -4.4554, -4.6428, -4.8041, -4.8830, -4.3648, -4.2886, -4.9162,\n",
      "         -4.4744]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : blood\n",
      "target index is: [39] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5464, -4.4994, -4.7461, -4.5150, -4.3804, -4.7816, -4.2979, -4.3544,\n",
      "         -4.8604, -4.7742, -4.9479, -4.3452, -4.6744, -4.4667, -4.5326, -4.8866,\n",
      "         -4.6829, -4.8115, -4.3435, -4.4357, -4.7921, -4.8155, -4.5527, -4.4613,\n",
      "         -4.6323, -5.1463, -4.8153, -4.5306, -4.1469, -4.7229, -4.4695, -4.5559,\n",
      "         -4.7303, -4.7262, -4.7152, -5.3188, -4.3807, -4.6987, -4.4667, -4.2840,\n",
      "         -4.4854, -4.4396, -4.7118, -4.2059, -4.7681, -4.1843, -5.0577, -4.6636,\n",
      "         -4.6551, -4.8571, -4.7911, -4.7484, -4.7026, -4.3249, -4.4176, -4.5222,\n",
      "         -4.2798, -4.0342, -4.7400, -4.6230, -4.6568, -4.2487, -4.5955, -4.3822,\n",
      "         -4.5754, -4.5992, -4.6640, -4.2524, -4.6709, -4.1211, -4.5102, -4.6538,\n",
      "         -5.0447, -5.0345, -4.8843, -5.3088, -5.0359, -3.9399, -4.1366, -4.5618,\n",
      "         -5.0162, -4.6239, -5.0008, -5.0262, -5.2755, -4.0404, -4.4660, -4.5026,\n",
      "         -5.2406, -4.3962, -4.8150, -4.6098, -4.7627, -4.5287, -4.4379, -4.5435,\n",
      "         -4.3616]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : warm\n",
      "target index is: [2] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5350, -4.3906, -4.6789, -4.8348, -4.6018, -4.6482, -4.3930, -4.4911,\n",
      "         -4.7851, -5.0769, -4.9441, -4.7843, -4.7260, -4.7991, -4.6028, -4.5067,\n",
      "         -4.7200, -4.9840, -4.5482, -4.1585, -4.8491, -4.2955, -5.0461, -4.4919,\n",
      "         -4.1237, -4.7391, -4.4077, -4.2838, -4.3492, -4.7338, -4.7387, -4.7692,\n",
      "         -4.9265, -4.8833, -4.6094, -4.4202, -4.8145, -4.9481, -4.8924, -4.7447,\n",
      "         -4.8505, -4.5908, -4.6677, -4.5538, -4.6516, -4.3323, -4.8647, -4.8175,\n",
      "         -4.2543, -4.8572, -4.4732, -4.4131, -4.4053, -4.1800, -4.6931, -4.1965,\n",
      "         -4.5004, -4.1289, -4.6958, -4.6985, -4.7811, -4.7276, -4.3964, -4.4219,\n",
      "         -4.8045, -4.4609, -5.1454, -4.5590, -4.7004, -4.3180, -4.1365, -4.7337,\n",
      "         -4.3926, -4.4795, -4.5905, -4.7939, -4.3980, -4.3272, -4.4787, -4.8042,\n",
      "         -4.4127, -4.8436, -4.7272, -4.5547, -4.3550, -4.5029, -4.7736, -5.0749,\n",
      "         -4.5739, -4.1381, -4.5796, -4.5548, -4.7402, -4.7707, -4.3707, -4.7044,\n",
      "         -4.2619]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : when\n",
      "target index is: [85] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4499, -4.3403, -4.7592, -4.9786, -4.2720, -4.7551, -4.3294, -4.4305,\n",
      "         -4.7237, -4.3798, -4.6464, -4.6909, -4.8470, -4.6090, -4.4394, -4.5014,\n",
      "         -4.3108, -4.6409, -4.8244, -4.5438, -4.4731, -4.4552, -4.5314, -4.6859,\n",
      "         -4.5298, -5.0619, -4.4256, -4.3867, -4.8390, -4.6209, -4.6624, -4.5761,\n",
      "         -4.7260, -4.9756, -4.6004, -4.6927, -4.5212, -4.3899, -4.9213, -4.5408,\n",
      "         -4.5736, -4.9206, -4.6583, -4.3610, -4.3850, -4.4015, -4.6897, -4.7970,\n",
      "         -4.5717, -4.6861, -4.4545, -4.8573, -4.6793, -4.2883, -4.6388, -4.6291,\n",
      "         -4.6624, -4.7172, -4.5141, -4.5118, -4.8067, -4.4199, -4.5443, -4.1214,\n",
      "         -4.5266, -4.3998, -4.7354, -4.3396, -4.5806, -4.6443, -4.7880, -5.1075,\n",
      "         -4.9913, -4.1950, -4.7321, -4.9502, -4.4736, -4.7520, -4.5130, -4.6992,\n",
      "         -4.3061, -4.3510, -4.8838, -4.5642, -4.9060, -4.1730, -5.1101, -4.5826,\n",
      "         -4.6147, -4.2358, -4.2976, -4.7195, -4.7820, -4.2426, -4.5330, -4.5689,\n",
      "         -4.6818]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : thou\n",
      "target index is: [22] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.6166, -4.6186, -4.9526, -4.6495, -4.1966, -4.7530, -4.4569, -4.7218,\n",
      "         -4.6479, -4.5577, -4.6909, -4.2349, -4.7945, -4.7051, -4.7237, -4.1948,\n",
      "         -4.7332, -4.6522, -4.8220, -4.4788, -4.7746, -4.1738, -4.7371, -4.6176,\n",
      "         -4.1865, -4.7233, -4.7742, -4.4011, -4.3154, -4.3548, -4.7415, -4.5753,\n",
      "         -4.7013, -4.8597, -4.6062, -4.4399, -4.5849, -4.8078, -4.9682, -4.3579,\n",
      "         -4.8902, -4.1786, -4.6594, -4.5546, -4.3625, -4.5174, -4.5766, -4.7967,\n",
      "         -4.3797, -5.1431, -4.7398, -4.7072, -4.6380, -4.2593, -4.6203, -4.4368,\n",
      "         -4.2848, -4.4665, -4.6360, -4.4276, -4.6678, -4.5401, -4.3540, -4.5790,\n",
      "         -4.7299, -4.4427, -4.5754, -4.4475, -4.7997, -4.2486, -4.3276, -4.6736,\n",
      "         -4.8931, -4.8844, -4.7958, -4.9100, -4.4847, -4.6108, -4.6174, -4.6561,\n",
      "         -4.6374, -4.4261, -4.5635, -4.3899, -4.7183, -4.1496, -4.7403, -4.8909,\n",
      "         -4.8440, -4.4506, -4.7794, -4.6692, -4.5788, -4.5989, -4.6506, -4.6139,\n",
      "         -4.6919]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : feel'st\n",
      "target index is: [35] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.4585, -4.2263, -4.7360, -4.8571, -4.1406, -4.7314, -4.7170, -4.2120,\n",
      "         -4.7724, -4.4916, -4.7209, -4.6526, -4.7706, -4.8200, -4.6881, -4.5680,\n",
      "         -4.6227, -4.3285, -4.6269, -4.4929, -4.5750, -4.5175, -4.4662, -4.8715,\n",
      "         -4.5290, -4.7884, -4.4317, -4.5351, -4.5677, -4.5164, -4.4865, -4.6591,\n",
      "         -4.8669, -4.6668, -4.3002, -4.9282, -4.5163, -4.8165, -4.7570, -4.7753,\n",
      "         -4.5894, -4.8622, -4.5735, -4.6886, -4.4136, -4.4248, -4.4758, -4.6301,\n",
      "         -4.7236, -4.5683, -4.5932, -4.7096, -4.5885, -4.6236, -4.6872, -4.6266,\n",
      "         -4.5823, -4.3348, -4.4051, -4.5241, -4.9250, -4.5825, -4.5313, -4.2112,\n",
      "         -4.5539, -4.5037, -4.5150, -4.5947, -4.5017, -4.6802, -4.6755, -4.5837,\n",
      "         -4.8551, -4.8984, -4.7408, -4.7213, -4.3136, -4.5145, -4.3582, -4.7500,\n",
      "         -4.4540, -4.5157, -4.7228, -4.9076, -4.7568, -4.4189, -4.3949, -4.5658,\n",
      "         -4.5637, -4.1339, -4.4119, -4.5738, -4.8845, -4.4057, -4.5612, -4.6474,\n",
      "         -4.5278]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : it\n",
      "target index is: [88] \n",
      "context ids shape: torch.Size([2]) \n",
      "embeds shape before reshaping: torch.Size([2, 10])\n",
      "embeds shape after view function : torch.Size([1, 20])\n",
      "log probs shape after forward pass: torch.Size([1, 97])\n",
      "log_probs: tensor([[-4.5411, -4.4023, -4.7803, -4.7221, -4.1225, -4.8794, -4.5469, -4.2334,\n",
      "         -4.6348, -4.6331, -4.6585, -4.3407, -4.4523, -4.8249, -4.6914, -4.6269,\n",
      "         -4.5535, -5.0269, -4.5430, -4.6493, -4.6871, -4.3878, -4.9601, -4.6480,\n",
      "         -4.1346, -4.8399, -4.1559, -4.6105, -4.1217, -4.6864, -4.6477, -5.2976,\n",
      "         -5.0706, -4.7793, -4.9149, -5.1165, -4.5125, -4.7140, -4.7201, -4.7389,\n",
      "         -4.9459, -4.4515, -4.6274, -4.6389, -4.4600, -4.3233, -4.6788, -4.8549,\n",
      "         -4.4602, -4.7545, -4.7228, -4.1067, -4.8831, -4.3680, -4.8206, -4.4502,\n",
      "         -4.5387, -4.0953, -4.6921, -4.6669, -4.6582, -4.5863, -4.3082, -4.1977,\n",
      "         -4.7325, -4.8620, -4.7545, -4.6777, -4.5458, -4.2219, -4.1683, -4.3776,\n",
      "         -4.8730, -4.7419, -4.7179, -4.7167, -4.7735, -3.9770, -4.4704, -4.7314,\n",
      "         -4.4914, -4.5828, -4.8672, -4.8224, -4.5070, -4.6995, -4.3767, -4.6232,\n",
      "         -4.7974, -4.6298, -4.8420, -4.7760, -4.7479, -4.3080, -4.5918, -4.6519,\n",
      "         -4.2270]], grad_fn=<LogSoftmaxBackward>)\n",
      "target word is : cold.\n",
      "target index is: [79] \n",
      "[522.8830213546753, 520.6461908817291, 518.4240899085999, 516.2150418758392, 514.0177614688873, 511.8321022987366, 509.65753865242004, 507.49306631088257, 505.33823013305664, 503.192666053772]\n",
      "tensor([ 1.4059,  0.7362, -1.1389, -0.8769,  0.2561,  0.8967,  0.2462,  1.5630,\n",
      "        -0.8113,  0.6800], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class NGramLanguageModeler(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        print(f\"embeds shape before reshaping: {self.embeddings(inputs).shape}\")\n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "        print(f\"embeds shape after view function : {embeds.shape}\")\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs\n",
    "\n",
    "\n",
    "losses = []\n",
    "loss_function = nn.NLLLoss()\n",
    "model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    for context, target in ngrams:\n",
    "\n",
    "        # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\n",
    "        # into integer indices and wrap them in tensors)\n",
    "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "\n",
    "        print(f\"context ids shape: {context_idxs.shape} \")\n",
    "\n",
    "        # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n",
    "        # new instance, you need to zero out the gradients from the old\n",
    "        # instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 3. Run the forward pass, getting log probabilities over next\n",
    "        # words\n",
    "        log_probs = model(context_idxs)\n",
    "        print(f\"log probs shape after forward pass: {log_probs.shape}\")\n",
    "        print(f\"log_probs: {log_probs}\")\n",
    "        print(f\"target word is : {target}\")\n",
    "        print(f\"target index is: {[word_to_ix[target]]} \")\n",
    "\n",
    "        # Step 4. Compute your loss function. (Again, Torch wants the target\n",
    "        # word wrapped in a tensor)\n",
    "        loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
    "\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
    "        total_loss += loss.item()\n",
    "    losses.append(total_loss)\n",
    "print(losses)  # The loss decreased every iteration over the training data!\n",
    "\n",
    "# To get the embedding of a particular word, e.g. \"beauty\"\n",
    "print(model.embeddings.weight[word_to_ix[\"beauty\"]])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d1924dc1dd04b7e09b7d5eb58cba0f493e2fde5c6da36fb26502589a8e5856a6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('nlp': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
