{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source: https://docs.seldon.io/projects/alibi/en/latest/examples/anchor_text_movie.html\n",
    "import os\n",
    "import spacy\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from alibi.explainers import AnchorText\n",
    "from alibi.datasets import fetch_movie_sentiment\n",
    "from alibi.utils.download import spacy_model\n",
    "from alibi.utils.lang_model import DistilbertBaseUncased, BertBaseUncased, RobertaBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = fetch_movie_sentiment()\n",
    "movies.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = movies.data\n",
    "labels = movies.target\n",
    "target_names = movies.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, train_labels, test_labels = train_test_split(data, labels, test_size=.2, random_state=42)\n",
    "train, val, train_labels, val_labels = train_test_split(train, train_labels, test_size=.1, random_state=42)\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)\n",
    "val_labels = np.array(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=1)\n",
    "vectorizer.fit(train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "clf = LogisticRegression(solver='liblinear')\n",
    "clf.fit(vectorizer.transform(train), train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_fn = lambda x: clf.predict(vectorizer.transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.980\n",
      "Validation accuracy: 0.754\n",
      "Test accuracy: 0.759\n"
     ]
    }
   ],
   "source": [
    "preds_train = predict_fn(train)\n",
    "preds_val = predict_fn(val)\n",
    "preds_test = predict_fn(test)\n",
    "print('Train accuracy: %.3f' % accuracy_score(train_labels, preds_train))\n",
    "print('Validation accuracy: %.3f' % accuracy_score(val_labels, preds_val))\n",
    "print('Test accuracy: %.3f' % accuracy_score(test_labels, preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'en_core_web_sm'\n",
    "spacy_model(model=model)\n",
    "nlp = spacy.load(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Text: a visually flashy but narratively opaque and emotionally vapid exercise in style and mystification .\n",
      "* Prediction: negative\n"
     ]
    }
   ],
   "source": [
    "class_names = movies.target_names\n",
    "\n",
    "# select instance to be explained\n",
    "text = data[4]\n",
    "print(\"* Text: %s\" % text)\n",
    "\n",
    "# compute class prediction\n",
    "pred = class_names[predict_fn([text])[0]]\n",
    "alternative =  class_names[1 - predict_fn([text])[0]]\n",
    "print(\"* Prediction: %s\" % pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_fn([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a visually flashy but narratively opaque and emotionally vapid exercise in style and mystification .'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use unknown sampling strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = AnchorText(\n",
    "    predictor=predict_fn,\n",
    "    sampling_strategy='unknown',\n",
    "    nlp=nlp,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-b67246277949>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlookups\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "nlp.vocab.lookups.tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell if issues with lexeme_prob lookup table\n",
    "# import spacy\n",
    "# from alibi.utils.download import spacy_model\n",
    "# from alibi.explainers import AnchorText\n",
    "\n",
    "\n",
    "# from spacy.lookups import load_lookups\n",
    "\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# lookups = load_lookups(\"en\", [\"lexeme_prob\"])\n",
    "\n",
    "# # nlp.vocab.lookups.add_table(\"lexeme_prob\", lookups.get_table(\"lexeme_prob\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = explainer.explain(text, threshold=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['flashy']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanation.anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature': [2],\n",
       " 'mean': [0.99375],\n",
       " 'precision': [0.99375],\n",
       " 'coverage': [0.4993],\n",
       " 'examples': [{'covered_true': array(['a UNK flashy UNK UNK opaque and emotionally vapid exercise in style UNK mystification .',\n",
       "          'a UNK flashy UNK UNK UNK and emotionally UNK exercise UNK UNK and UNK UNK',\n",
       "          'a UNK flashy UNK narratively opaque UNK UNK UNK exercise in style and UNK UNK',\n",
       "          'UNK visually flashy UNK narratively UNK and emotionally UNK UNK UNK UNK UNK mystification .',\n",
       "          'UNK UNK flashy UNK UNK opaque and emotionally UNK UNK in UNK and UNK .',\n",
       "          'a visually flashy but UNK UNK and UNK UNK UNK in style UNK mystification .',\n",
       "          'a visually flashy but UNK opaque UNK emotionally vapid UNK in UNK and mystification .',\n",
       "          'a UNK flashy but narratively UNK UNK emotionally vapid exercise in style UNK mystification UNK',\n",
       "          'a UNK flashy but narratively opaque UNK emotionally vapid exercise in style and mystification .',\n",
       "          'a visually flashy UNK UNK opaque UNK UNK UNK exercise in UNK UNK UNK .'],\n",
       "         dtype='<U199'),\n",
       "   'covered_false': array(['UNK UNK flashy but narratively UNK and UNK UNK UNK in style and UNK UNK'],\n",
       "         dtype='<U199'),\n",
       "   'uncovered_true': array([], dtype=float64),\n",
       "   'uncovered_false': array([], dtype=float64)}],\n",
       " 'all_precision': 0,\n",
       " 'num_preds': 1000000,\n",
       " 'success': True,\n",
       " 'names': ['flashy'],\n",
       " 'positions': [11],\n",
       " 'instance': 'a visually flashy but narratively opaque and emotionally vapid exercise in style and mystification .',\n",
       " 'instances': ['a visually flashy but narratively opaque and emotionally vapid exercise in style and mystification .'],\n",
       " 'prediction': array([0])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanation.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: flashy\n",
      "Precision: 0.99\n",
      "\n",
      "Examples where anchor applies and model predicts negative:\n",
      "a UNK flashy UNK UNK opaque and emotionally vapid exercise in style UNK mystification .\n",
      "a UNK flashy UNK UNK UNK and emotionally UNK exercise UNK UNK and UNK UNK\n",
      "a UNK flashy UNK narratively opaque UNK UNK UNK exercise in style and UNK UNK\n",
      "UNK visually flashy UNK narratively UNK and emotionally UNK UNK UNK UNK UNK mystification .\n",
      "UNK UNK flashy UNK UNK opaque and emotionally UNK UNK in UNK and UNK .\n",
      "a visually flashy but UNK UNK and UNK UNK UNK in style UNK mystification .\n",
      "a visually flashy but UNK opaque UNK emotionally vapid UNK in UNK and mystification .\n",
      "a UNK flashy but narratively UNK UNK emotionally vapid exercise in style UNK mystification UNK\n",
      "a UNK flashy but narratively opaque UNK emotionally vapid exercise in style and mystification .\n",
      "a visually flashy UNK UNK opaque UNK UNK UNK exercise in UNK UNK UNK .\n",
      "\n",
      "Examples where anchor applies and model predicts positive:\n",
      "UNK UNK flashy but narratively UNK and UNK UNK UNK in style and UNK UNK\n"
     ]
    }
   ],
   "source": [
    "print('Anchor: %s' % (' AND '.join(explanation.anchor)))\n",
    "print('Precision: %.2f' % explanation.precision)\n",
    "print('\\nExamples where anchor applies and model predicts %s:' % pred)\n",
    "print('\\n'.join([x for x in explanation.raw['examples'][-1]['covered_true']]))\n",
    "print('\\nExamples where anchor applies and model predicts %s:' % alternative)\n",
    "print('\\n'.join([x for x in explanation.raw['examples'][-1]['covered_false']]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use similarity sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = AnchorText(\n",
    "    predictor=predict_fn,\n",
    "    sampling_strategy='similarity',   # replace masked words by simialar words\n",
    "    nlp=nlp,                          # spacy object\n",
    "    sample_proba=0.5,                 # probability of a word to be masked and replace by as similar word\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = explainer.explain(text, threshold=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: exercise AND emotionally\n",
      "Precision: 0.96\n",
      "\n",
      "Examples where anchor applies and model predicts negative:\n",
      "that visually flashy but narratively bright and emotionally snobby exercise in style and deceit .\n",
      "some technically flashy but eerily opaque and emotionally vapid exercise in improvisation and mystification .\n",
      "a visually flashy but electrically sensitive and emotionally pushy exercise in style and mystification .\n",
      "some incredibly ingenious but narratively coherent and emotionally contrived exercise on style and dogma .\n",
      "an extremely unwieldy but narratively translucent and emotionally vapid exercise in faux and mystification .\n",
      "a somewhat graceful but artistically transparent and emotionally vapid exercise across suit and mystification .\n",
      "this visually trendy but narratively opaque and emotionally vapid exercise without era and mystification .\n",
      "any masterfully bright but intellectually opaque and emotionally meaningless exercise in style and helplessness .\n",
      "both visually overbearing but narratively opaque and emotionally snobbish exercise before bubblegum and insanity .\n",
      "some visually chock but delightfully purple and emotionally vapid exercise in variety and mystification .\n",
      "\n",
      "Examples where anchor applies and model predicts positive:\n",
      "a visually ingenious but deliciously opaque and emotionally vapid exercise in style and sloth .\n",
      "an visually reductive but brilliantly undetectable and emotionally vapid exercise with style and disinterest .\n",
      "a mechanically unwieldy but deliciously colorful and emotionally vapid exercise against sass and mystification .\n",
      "both objectively outlandish but narratively opaque and emotionally fruitless exercise arround style and helplessness .\n",
      "a easily palatable but oddly opaque and emotionally inoffensive exercise above style and badness .\n",
      "both somewhat goof but narratively legible and emotionally vapid exercise above subgenre and trickery .\n"
     ]
    }
   ],
   "source": [
    "print('Anchor: %s' % (' AND '.join(explanation.anchor)))\n",
    "print('Precision: %.2f' % explanation.precision)\n",
    "print('\\nExamples where anchor applies and model predicts %s:' % pred)\n",
    "print('\\n'.join([x for x in explanation.raw['examples'][-1]['covered_true']]))\n",
    "print('\\nExamples where anchor applies and model predicts %s:' % alternative)\n",
    "print('\\n'.join([x for x in explanation.raw['examples'][-1]['covered_false']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "clf_name = XGBClassifier()\n",
    "\n",
    "print(str(clf_name).split(\"(\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [2 3 4 5 6 7] TEST: [0 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import pandas as pd\n",
    "X = np.ones(shape=(8, 2))\n",
    "y = np.ones(shape=(8, 1))\n",
    "groups = np.array([1, 1, 2, 2, 2, 3, 3, 3])\n",
    "\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=.7, random_state=42)\n",
    "gss.get_n_splits()\n",
    "\n",
    "for train_idx, test_idx in gss.split(X, y, groups):\n",
    "    print(\"TRAIN:\", train_idx, \"TEST:\", test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]]),\n",
       " array([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[train_idx]\n",
    "X_train, y[train_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 1.],\n",
       "        [1., 1.]]),\n",
       " array([[1.],\n",
       "        [1.]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X[test_idx]\n",
    "X_test, y[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original df:\n",
      "         X  y  groups\n",
      "7  pickle  3       2\n",
      "1  Rabble  1       0\n",
      "5  cheese  2       1\n",
      "0  Rabble  1       0\n",
      "8  pickle  3       2\n",
      "2  Rabble  1       0\n",
      "4  cheese  2       1\n",
      "3  Rabble  1       0\n",
      "6  cheese  2       1\n",
      "TRAIN: [0 2 4 6 8] TEST: [1 3 5 7]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame({\"X\":[\"Rabble\",\"Rabble\",\"Rabble\",\"Rabble\",\n",
    "                        \"cheese\",\"cheese\",\"cheese\",\n",
    "                        \"pickle\",\"pickle\"], \n",
    "                    \"y\":[1,1,1,1,2,2,2,3,3],\n",
    "                     \"groups\": [0,0,0,0,1,1,1,2,2]})\n",
    "\n",
    "df = shuffle(df, random_state = 42)\n",
    "\n",
    "print(f\"Original df:\\n {df}\")\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=.7, random_state=1234)\n",
    "# gss.get_n_splits()\n",
    "\n",
    "for train_idx, test_idx in gss.split(df, groups = df.groups):\n",
    "    print(\"TRAIN:\", train_idx, \"TEST:\", test_idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new train df:\n",
      "         X  y  groups\n",
      "7  pickle  3       2\n",
      "5  cheese  2       1\n",
      "8  pickle  3       2\n",
      "4  cheese  2       1\n",
      "6  cheese  2       1\n",
      "\n",
      " new test df:\n",
      "         X  y  groups\n",
      "1  Rabble  1       0\n",
      "0  Rabble  1       0\n",
      "2  Rabble  1       0\n",
      "3  Rabble  1       0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_df = df.iloc[train_idx]\n",
    "test_df = df.iloc[test_idx]\n",
    "\n",
    "print(f\"new train df:\\n {train_df}\")\n",
    "\n",
    "print(f\"\\n new test df:\\n {test_df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [0 1 4 5 6 7 8] TEST: [2 3]\n"
     ]
    }
   ],
   "source": [
    "df2= pd.DataFrame({\"X\":[\"splooge\",\"splooge\",\"splooge\",\"splooge\",\n",
    "                        \"dank\",\"dank\",\"dank\",\n",
    "                        \"ribblar\",\"ribblar\"], \n",
    "                    \"y\":[1,1,1,1,2,2,2,3,3],\n",
    "                     \"groups\": [1,1,0,0,1,1,1,2,2]})\n",
    "\n",
    "for train_idx_2, test_idx_2 in gss.split(df2, groups = df2.groups):\n",
    "    print(\"TRAIN:\", train_idx_2, \"TEST:\", test_idx_2)     \n",
    "\n",
    "\n",
    "train_2 = df2.iloc[train_idx_2]\n",
    "test_2 = df2.iloc[test_idx_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new train df:          X  y  groups\n",
      "0  splooge  1       1\n",
      "1  splooge  1       1\n",
      "4     dank  2       1\n",
      "5     dank  2       1\n",
      "6     dank  2       1\n",
      "7  ribblar  3       2\n",
      "8  ribblar  3       2\n",
      "\n",
      " new test df:          X  y  groups\n",
      "2  splooge  1       0\n",
      "3  splooge  1       0\n"
     ]
    }
   ],
   "source": [
    "print(f\"new train df: {train_2}\")\n",
    "\n",
    "print(f\"\\n new test df: {test_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(         X  y  groups\n",
       " 0  splooge  1       1\n",
       " 1  splooge  1       1\n",
       " 4     dank  2       1\n",
       " 5     dank  2       1\n",
       " 6     dank  2       1\n",
       " 7  ribblar  3       2\n",
       " 8  ribblar  3       2,\n",
       "          X  y  groups\n",
       " 0  splooge  1       1\n",
       " 1  splooge  1       1\n",
       " 7  ribblar  3       2\n",
       " 4     dank  2       1\n",
       " 6     dank  2       1\n",
       " 5     dank  2       1\n",
       " 8  ribblar  3       2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "train_2,shuffle(train_2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import shap\n",
    "X,y = shap.datasets.boston()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "0       15.3  396.90   4.98  \n",
       "1       17.8  396.90   9.14  \n",
       "2       17.8  392.83   4.03  \n",
       "3       18.7  394.63   2.94  \n",
       "4       18.7  396.90   5.33  \n",
       "..       ...     ...    ...  \n",
       "501     21.0  391.99   9.67  \n",
       "502     21.0  396.90   9.08  \n",
       "503     21.0  396.90   5.64  \n",
       "504     21.0  393.45   6.48  \n",
       "505     21.0  396.90   7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d1924dc1dd04b7e09b7d5eb58cba0f493e2fde5c6da36fb26502589a8e5856a6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('nlp': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
