{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be8ad4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textdataBeer import TextDataBeer\n",
    "import time, sys\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import time, datetime\n",
    "import math, random\n",
    "import nltk\n",
    "import pickle\n",
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "from LanguageModel_beer import LanguageModel\n",
    "\n",
    "import LSTM_IB_GAN_beer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02cdacec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import nltk  # For tokenize\n",
    "from tqdm import tqdm  # Progress bar\n",
    "import pickle  # Saving the data\n",
    "import math  # For float comparison\n",
    "import os  # Checking file existance\n",
    "import random, gzip\n",
    "import string, copy\n",
    "from nltk.tokenize import word_tokenize\n",
    "import jieba\n",
    "import json\n",
    "from Hyperparameters import args\n",
    "\n",
    "class Batch:\n",
    "    \"\"\"Struct containing batches info\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.encoderSeqs = []\n",
    "        self.encoder_lens = []\n",
    "        self.label = []\n",
    "        self.decoderSeqs = []\n",
    "        self.targetSeqs = []\n",
    "        self.decoder_lens = []\n",
    "        self.rationals = []\n",
    "        self.raw = []\n",
    "\n",
    "\n",
    "class TextDataBeer:\n",
    "    \"\"\"Dataset class\n",
    "    Warning: No vocabulary limit\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, corpusname, trainLM =False):\n",
    "\n",
    "        \"\"\"Load all conversations\n",
    "        Args:\n",
    "            args: parameters of the model\n",
    "        \"\"\"\n",
    "\n",
    "        # Path variables\n",
    "        if corpusname == 'cail':\n",
    "            self.tokenizer = lambda x: list(jieba.cut(x))\n",
    "        elif corpusname == 'beer':\n",
    "            self.tokenizer = word_tokenize\n",
    "\n",
    "        self.trainingSamples = []  # 2d array containing each question and his answer [[input,target]]\n",
    "        if not trainLM:\n",
    "            self.datasets= self.loadCorpus_Beer()\n",
    "        else:\n",
    "            self.datasets = self.load3aspects()\n",
    "\n",
    "\n",
    "        print('set')\n",
    "        # Plot some stats:\n",
    "        self._printStats(corpusname)\n",
    "\n",
    "        if args['playDataset']:\n",
    "            self.playDataset()\n",
    "\n",
    "        self.batches = {}\n",
    "\n",
    "    def _printStats(self, corpusname):\n",
    "        print('Loaded {}: {} words, {} QA'.format(corpusname, len(self.word2index), len(self.trainingSamples)))\n",
    "\n",
    "\n",
    "    def shuffle(self):\n",
    "        \"\"\"Shuffle the training samples\n",
    "        \"\"\"\n",
    "        print('Shuffling the dataset...')\n",
    "        random.shuffle(self.datasets['train'])\n",
    "\n",
    "    def _createBatch(self, samples):\n",
    "        \"\"\"Create a single batch from the list of sample. The batch size is automatically defined by the number of\n",
    "        samples given.\n",
    "        The inputs should already be inverted. The target should already have <go> and <eos>\n",
    "        Warning: This function should not make direct calls to args['batchSize'] !!!\n",
    "        Args:\n",
    "            samples (list<Obj>): a list of samples, each sample being on the form [input, target]\n",
    "        Return:\n",
    "            Batch: a batch object en\n",
    "        \"\"\"\n",
    "\n",
    "        batch = Batch()\n",
    "        batchSize = len(samples)\n",
    "\n",
    "        # Create the batch tensor\n",
    "        for i in range(batchSize):\n",
    "            # Unpack the sample\n",
    "            sen_ids, y, raw_sen, rational = samples[i]\n",
    "\n",
    "            if len(sen_ids) > args['maxLengthEnco']:\n",
    "                sen_ids = sen_ids[:args['maxLengthEnco']]\n",
    "\n",
    "            batch.encoderSeqs.append(sen_ids)\n",
    "            batch.encoder_lens.append(len(batch.encoderSeqs[i]))\n",
    "            batch.label.append(y)\n",
    "            batch.rationals.append(rational)\n",
    "            batch.raw.append(raw_sen)\n",
    "            # print(y)\n",
    "\n",
    "        maxlen_enc = max(batch.encoder_lens)\n",
    "\n",
    "\n",
    "        for i in range(batchSize):\n",
    "            batch.encoderSeqs[i] = batch.encoderSeqs[i] + [self.word2index['PAD']] * (maxlen_enc - len(batch.encoderSeqs[i]))\n",
    "\n",
    "\n",
    "        return batch\n",
    "\n",
    "    def getBatches(self, setname = 'train'):\n",
    "        \"\"\"Prepare the batches for the current epoch\n",
    "        Return:\n",
    "            list<Batch>: Get a list of the batches for the next epoch\n",
    "        \"\"\"\n",
    "        if setname not in self.batches:\n",
    "            # self.shuffle()\n",
    "\n",
    "            batches = []\n",
    "            print(setname, 'size:', len(self.datasets[setname]))\n",
    "            def genNextSamples():\n",
    "                \"\"\" Generator over the mini-batch training samples\n",
    "                \"\"\"\n",
    "                for i in range(0, self.getSampleSize(setname), args['batchSize']):\n",
    "                    yield self.datasets[setname][i:min(i + args['batchSize'], self.getSampleSize(setname))]\n",
    "\n",
    "            # TODO: Should replace that by generator (better: by tf.queue)\n",
    "\n",
    "            for index, samples in enumerate(genNextSamples()):\n",
    "                # print([self.index2word[id] for id in samples[5][0]], samples[5][2])\n",
    "                batch = self._createBatch(samples)\n",
    "                batches.append(batch)\n",
    "\n",
    "            self.batches[setname] = batches\n",
    "\n",
    "        # print([self.index2word[id] for id in batches[2].encoderSeqs[5]], batches[2].raws[5])\n",
    "        return self.batches[setname]\n",
    "\n",
    "    def _createBatch_forLM(self, samples):\n",
    "        \"\"\"Create a single batch from the list of sample. The batch size is automatically defined by the number of\n",
    "        samples given.\n",
    "        The inputs should already be inverted. The target should already have <go> and <eos>\n",
    "        Warning: This function should not make direct calls to args['batchSize'] !!!\n",
    "        Args:\n",
    "            samples (list<Obj>): a list of samples, each sample being on the form [input, target]\n",
    "        Return:\n",
    "            Batch: a batch object en\n",
    "        \"\"\"\n",
    "\n",
    "        batch = Batch()\n",
    "        batchSize = len(samples)\n",
    "\n",
    "        # Create the batch tensor\n",
    "        for i in range(batchSize):\n",
    "            # Unpack the sample\n",
    "            sen_ids = samples[i]\n",
    "            if len(sen_ids) > args['maxLengthEnco']:\n",
    "                sen_ids = sen_ids[:args['maxLengthEnco']]\n",
    "            batch.decoderSeqs.append([self.word2index['START_TOKEN']] + sen_ids)\n",
    "            batch.decoder_lens.append(len(batch.decoderSeqs[i]))\n",
    "            batch.targetSeqs.append(sen_ids + [self.word2index['END_TOKEN']])\n",
    "\n",
    "        # print(batch.decoderSeqs)\n",
    "        # print(batch.decoder_lens)\n",
    "        maxlen_dec = max(batch.decoder_lens)\n",
    "        maxlen_dec = min(maxlen_dec, args['maxLengthEnco'])\n",
    "\n",
    "        for i in range(batchSize):\n",
    "            batch.decoderSeqs[i] = batch.decoderSeqs[i] + [self.word2index['PAD']] * (maxlen_dec - len(batch.decoderSeqs[i]))\n",
    "            batch.targetSeqs[i] = batch.targetSeqs[i] + [self.word2index['PAD']] * (maxlen_dec - len(batch.targetSeqs[i]))\n",
    "\n",
    "        return batch\n",
    "\n",
    "    def paragraph2sentence(self, doclist):\n",
    "        split_tokens = [self.word2index['.']]\n",
    "        sen_list = []\n",
    "        for sen_ids, y, raw_sen, rational in doclist:\n",
    "            start = 0\n",
    "            for ind, w in enumerate(sen_ids):\n",
    "                if w in split_tokens:\n",
    "                    sen_list.append(sen_ids[start:ind + 1])\n",
    "                    start = ind + 1\n",
    "\n",
    "            if start < len(sen_ids) - 1:\n",
    "                sen_list.append(sen_ids[start:])\n",
    "\n",
    "        return sen_list\n",
    "\n",
    "    def getBatches_forLM(self, setname = 'train'):\n",
    "        \"\"\"Prepare the batches for the current epoch\n",
    "        Return:\n",
    "            list<Batch>: Get a list of the batches for the next epoch\n",
    "        \"\"\"\n",
    "        if setname not in self.batches:\n",
    "            self.shuffle()\n",
    "\n",
    "            dataset_sen = self.paragraph2sentence(self.datasets[setname])\n",
    "            sennum = len(dataset_sen)\n",
    "            print(sennum)\n",
    "\n",
    "            batches = []\n",
    "            print(len(self.datasets[setname]))\n",
    "            def genNextSamples():\n",
    "                \"\"\" Generator over the mini-batch training samples\n",
    "                \"\"\"\n",
    "                for i in range(0, sennum, args['batchSize']):\n",
    "                    yield dataset_sen[i:min(i + args['batchSize'], sennum)]\n",
    "\n",
    "            # TODO: Should replace that by generator (better: by tf.queue)\n",
    "\n",
    "            for index, samples in enumerate(genNextSamples()):\n",
    "                # print([self.index2word[id] for id in samples[5][0]], samples[5][2])\n",
    "                batch = self._createBatch_forLM(samples)\n",
    "                batches.append(batch)\n",
    "\n",
    "            self.batches[setname] = batches\n",
    "\n",
    "        # print([self.index2word[id] for id in batches[2].encoderSeqs[5]], batches[2].raws[5])\n",
    "        return self.batches[setname]\n",
    "\n",
    "    def getSampleSize(self, setname = 'train'):\n",
    "        \"\"\"Return the size of the dataset\n",
    "        Return:\n",
    "            int: Number of training samples\n",
    "        \"\"\"\n",
    "        return len(self.datasets[setname])\n",
    "\n",
    "    def getVocabularySize(self):\n",
    "        \"\"\"Return the number of words present in the dataset\n",
    "        Return:\n",
    "            int: Number of word on the loader corpus\n",
    "        \"\"\"\n",
    "        return len(self.word2index)\n",
    "\n",
    "\n",
    "    def loadCorpus_Beer(self):\n",
    "        \"\"\"Load/create the conversations data\n",
    "        \"\"\"\n",
    "        self.basedir = './data/beer/'\n",
    "        self.corpus_file_train = self.basedir + 'reviews.aspect'+str(args['aspect'])+'.train.txt'\n",
    "        self.corpus_file_dev =  self.basedir + 'reviews.aspect'+str(args['aspect'])+'.heldout.txt'\n",
    "        self.corpus_file_test =  self.basedir + 'annotations.json'\n",
    "        self.embfile = self.basedir + 'review+wiki.filtered.200.txt.gz'\n",
    "        self.data_dump_path = args['rootDir'] + '/Beerdata'+str(args['aspect'])+'.pkl'\n",
    "\n",
    "        print(self.data_dump_path)\n",
    "        datasetExist = os.path.isfile(self.data_dump_path)\n",
    "\n",
    "        if not datasetExist:  # First time we load the database: creating all files\n",
    "            print('Training data not found. Creating dataset...')\n",
    "\n",
    "            total_words = []\n",
    "            dataset = {'train': [], 'dev':[], 'test':[]}\n",
    "\n",
    "            self.word2index, self.index2word, self.index2vector = self.read_word2vec_from_pretrained(self.embfile,\n",
    "                                                                                                     topk_word_num=-1)\n",
    "            self.index2word_set = set(self.index2word)\n",
    "\n",
    "            with open(self.corpus_file_train, 'r',encoding=\"utf-8\") as rhandle:\n",
    "                lines = rhandle.readlines()\n",
    "\n",
    "                for line in tqdm(lines):\n",
    "                    y, sep, x = line.partition(\"\\t\")\n",
    "                    x, y = x.split(), y.split()\n",
    "                    if len(x) == 0: continue\n",
    "                    y = np.asarray([float(v) for v in y])\n",
    "\n",
    "                    dataset['train'].append((x, y, -1))\n",
    "\n",
    "            with open(self.corpus_file_dev, 'r') as rhandle:\n",
    "                lines = rhandle.readlines()\n",
    "\n",
    "                for line in tqdm(lines):\n",
    "                    y, sep, x = line.partition(\"\\t\")\n",
    "                    x, y = x.split(), y.split()\n",
    "                    if len(x) == 0: continue\n",
    "                    y = np.asarray([float(v) for v in y])\n",
    "\n",
    "                    dataset['dev'].append((x, y, -1))\n",
    "\n",
    "            with open(self.corpus_file_test, 'r') as rhandle:\n",
    "                for line in tqdm(rhandle.readlines()):\n",
    "                    review = json.loads(line)\n",
    "                    word_seq = review['x']\n",
    "                    y = np.asarray(review['y'])\n",
    "                    # raw_x = eval(review['raw'])['review/text']\n",
    "                    # words = self.tokenizer(raw_x.lower())\n",
    "                    rational={}\n",
    "                    for i in range(5):\n",
    "                        intervals = review[str(i)]\n",
    "                        all_rw_in_rational = []\n",
    "                        for start,end in intervals:\n",
    "                            rw = word_seq[start:end]\n",
    "                            all_rw_in_rational.extend(rw)\n",
    "                        rational[i]=set([self.word2index[w] for w in set(all_rw_in_rational) if w in self.word2index])\n",
    "\n",
    "\n",
    "                    dataset['test'].append((word_seq, y, rational))\n",
    "\n",
    "            print(len(dataset['train']), len(dataset['dev']), len(dataset['test']))\n",
    "\n",
    "\n",
    "            # self.raw_sentences = copy.deepcopy(dataset)\n",
    "            for setname in ['train', 'dev', 'test']:\n",
    "                dataset[setname] = [(self.TurnWordID(sen), y, sen, rational) for sen, y, rational in tqdm(dataset[setname])]\n",
    "\n",
    "            # Saving\n",
    "            print('Saving dataset...')\n",
    "            self.saveDataset(self.data_dump_path, dataset)  # Saving tf samples\n",
    "        else:\n",
    "            dataset = self.loadDataset(self.data_dump_path)\n",
    "            print('loaded')\n",
    "\n",
    "        return  dataset\n",
    "\n",
    "    def saveDataset(self, filename, datasets):\n",
    "        \"\"\"Save samples to file\n",
    "        Args:\n",
    "            filename (str): pickle filename\n",
    "        \"\"\"\n",
    "        with open(os.path.join(filename), 'wb') as handle:\n",
    "            data = {  # Warning: If adding something here, also modifying loadDataset\n",
    "                'word2index': self.word2index,\n",
    "                'index2word': self.index2word,\n",
    "                'index2vector': self.index2vector,\n",
    "                'datasets': datasets\n",
    "            }\n",
    "            pickle.dump(data, handle, -1)  # Using the highest protocol available\n",
    "\n",
    "\n",
    "    def loadDataset(self, filename):\n",
    "        \"\"\"Load samples from file\n",
    "        Args:\n",
    "            filename (str): pickle filename\n",
    "        \"\"\"\n",
    "        dataset_path = os.path.join(filename)\n",
    "        print('Loading dataset from {}'.format(dataset_path))\n",
    "        with open(dataset_path, 'rb') as handle:\n",
    "            data = pickle.load(handle)  # Warning: If adding something here, also modifying saveDataset\n",
    "            self.word2index = data['word2index']\n",
    "            self.index2word = data['index2word']\n",
    "            self.index2vector = data['index2vector']\n",
    "            datasets = data['datasets']\n",
    "            dataset_all = data\n",
    "        print('training: \\t', len(datasets['train']))\n",
    "        print('dev: \\t', len(datasets['dev']))\n",
    "        print('testing: \\t', len(datasets['test']))\n",
    "        self.index2word_set = set(self.index2word)\n",
    "        print('w2i shape: ', len(self.word2index))\n",
    "        print('i2w shape: ', len(self.index2word))\n",
    "        print('embeding shape: ', self.index2vector.shape)\n",
    "        return  datasets, data\n",
    "\n",
    "    def load3aspects(self):\n",
    "        self.data_dump_path1 = args['rootDir'] + '/Beerdata0.pkl'\n",
    "        self.data_dump_path2 = args['rootDir'] + '/Beerdata1.pkl'\n",
    "        self.data_dump_path3 = args['rootDir'] + '/Beerdata2.pkl'\n",
    "        d1 = self.loadDataset(self.data_dump_path1)\n",
    "        d2 = self.loadDataset(self.data_dump_path2)\n",
    "        d3 = self.loadDataset(self.data_dump_path3)\n",
    "        data={'train':[], 'dev':[], 'test':[]}\n",
    "        data['train']=d1['train']+d2['train']+d3['train']\n",
    "        data['dev']=d1['dev']+d2['dev']+d3['dev']\n",
    "        data['test']=d1['test']\n",
    "        return data\n",
    "\n",
    "    def read_word2vec(self, vocfile ):\n",
    "        word2index = dict()\n",
    "        word2index['PAD'] = 0\n",
    "        word2index['START_TOKEN'] = 1\n",
    "        word2index['END_TOKEN'] = 2\n",
    "        word2index['UNK'] = 3\n",
    "        cnt = 4\n",
    "        with open(vocfile, \"r\") as v:\n",
    "\n",
    "            for line in v:\n",
    "                word = line.strip().split()[0]\n",
    "                word2index[word] = cnt\n",
    "                print(word,cnt)\n",
    "                cnt += 1\n",
    "\n",
    "        print(len(word2index),cnt)\n",
    "        # dic = {w:numpy.random.normal(size=[int(sys.argv[1])]).astype('float32') for w in word2index}\n",
    "        print ('Dictionary Got!')\n",
    "        return word2index\n",
    "\n",
    "    def read_word2vec_from_pretrained(self, embfile, topk_word_num=-1):\n",
    "        fopen = gzip.open if embfile.endswith(\".gz\") else open\n",
    "        word2index = dict()\n",
    "        word2index['PAD'] = 0\n",
    "        word2index['START_TOKEN'] = 1\n",
    "        word2index['END_TOKEN'] = 2\n",
    "        word2index['UNK'] = 3\n",
    "        # word2index['PAD'] = 1\n",
    "        # word2index['UNK'] = 0\n",
    "\n",
    "        cnt = 4\n",
    "        vectordim = -1\n",
    "        index2vector = []\n",
    "        with fopen(embfile, \"r\") as v:\n",
    "            lines = v.readlines()\n",
    "            if topk_word_num > 0:\n",
    "                lines = lines[:topk_word_num]\n",
    "            for line in tqdm(lines):\n",
    "                word_vec = line.strip().split()\n",
    "                word = bytes.decode(word_vec[0])\n",
    "                vector = np.asarray([float(value) for value in word_vec[1:]])\n",
    "                if vectordim == -1:\n",
    "                    vectordim = len(vector)\n",
    "                index2vector.append(vector)\n",
    "                word2index[word] = cnt\n",
    "                print(word, cnt)\n",
    "                cnt += 1\n",
    "        print('before add special token:' , len(index2vector))\n",
    "        index2vector = [np.random.normal(size=[vectordim]).astype('float32') for _ in range(4)] + index2vector\n",
    "        print('after add special token:' ,len(index2vector))\n",
    "        index2vector = np.asarray(index2vector)\n",
    "        index2word = [w for w, n in word2index.items()]\n",
    "        print(len(word2index), cnt)\n",
    "        print('Dictionary Got!')\n",
    "        return word2index, index2word, index2vector\n",
    "\n",
    "    def TurnWordID(self, words):\n",
    "        res = []\n",
    "        for w in words:\n",
    "            w = w.lower()\n",
    "            if w in self.index2word_set:\n",
    "                id = self.word2index[w]\n",
    "                res.append(id)\n",
    "            else:\n",
    "                res.append(self.word2index['UNK'])\n",
    "        return res\n",
    "\n",
    "\n",
    "    def printBatch(self, batch):\n",
    "        \"\"\"Print a complete batch, useful for debugging\n",
    "        Args:\n",
    "            batch (Batch): a batch object\n",
    "        \"\"\"\n",
    "        print('----- Print batch -----')\n",
    "        for i in range(len(batch.encoderSeqs[0])):  # Batch size\n",
    "            print('Encoder: {}'.format(self.batchSeq2str(batch.encoderSeqs, seqId=i)))\n",
    "            print('Decoder: {}'.format(self.batchSeq2str(batch.decoderSeqs, seqId=i)))\n",
    "            print('Targets: {}'.format(self.batchSeq2str(batch.targetSeqs, seqId=i)))\n",
    "            print('Weights: {}'.format(' '.join([str(weight) for weight in [batchWeight[i] for batchWeight in batch.weights]])))\n",
    "\n",
    "    def sequence2str(self, sequence, clean=False, reverse=False):\n",
    "        \"\"\"Convert a list of integer into a human readable string\n",
    "        Args:\n",
    "            sequence (list<int>): the sentence to print\n",
    "            clean (Bool): if set, remove the <go>, <pad> and <eos> tokens\n",
    "            reverse (Bool): for the input, option to restore the standard order\n",
    "        Return:\n",
    "            str: the sentence\n",
    "        \"\"\"\n",
    "\n",
    "        if not sequence:\n",
    "            return ''\n",
    "\n",
    "        if not clean:\n",
    "            return ' '.join([self.index2word[idx] for idx in sequence])\n",
    "\n",
    "        sentence = []\n",
    "        for wordId in sequence:\n",
    "            if wordId == self.word2index['END_TOKEN']:  # End of generated sentence\n",
    "                break\n",
    "            elif wordId != self.word2index['PAD'] and wordId != self.word2index['START_TOKEN']:\n",
    "                sentence.append(self.index2word[wordId])\n",
    "\n",
    "        if reverse:  # Reverse means input so no <eos> (otherwise pb with previous early stop)\n",
    "            sentence.reverse()\n",
    "\n",
    "        return self.detokenize(sentence)\n",
    "\n",
    "    def detokenize(self, tokens):\n",
    "        \"\"\"Slightly cleaner version of joining with spaces.\n",
    "        Args:\n",
    "            tokens (list<string>): the sentence to print\n",
    "        Return:\n",
    "            str: the sentence\n",
    "        \"\"\"\n",
    "        return ''.join([\n",
    "            ' ' + t if not t.startswith('\\'') and\n",
    "                       t not in string.punctuation\n",
    "                    else t\n",
    "            for t in tokens]).strip().capitalize()\n",
    "\n",
    "    def batchSeq2str(self, batchSeq, seqId=0, **kwargs):\n",
    "        \"\"\"Convert a list of integer into a human readable string.\n",
    "        The difference between the previous function is that on a batch object, the values have been reorganized as\n",
    "        batch instead of sentence.\n",
    "        Args:\n",
    "            batchSeq (list<list<int>>): the sentence(s) to print\n",
    "            seqId (int): the position of the sequence inside the batch\n",
    "            kwargs: the formatting options( See sequence2str() )\n",
    "        Return:\n",
    "            str: the sentence\n",
    "        \"\"\"\n",
    "        sequence = []\n",
    "        for i in range(len(batchSeq)):  # Sequence length\n",
    "            sequence.append(batchSeq[i][seqId])\n",
    "        return self.sequence2str(sequence, **kwargs)\n",
    "\n",
    "    def sentence2enco(self, sentence):\n",
    "        \"\"\"Encode a sequence and return a batch as an input for the model\n",
    "        Return:\n",
    "            Batch: a batch object containing the sentence, or none if something went wrong\n",
    "        \"\"\"\n",
    "\n",
    "        if sentence == '':\n",
    "            return None\n",
    "\n",
    "        # First step: Divide the sentence in token\n",
    "        tokens = nltk.word_tokenize(sentence)\n",
    "        if len(tokens) > args['maxLength']:\n",
    "            return None\n",
    "\n",
    "        # Second step: Convert the token in word ids\n",
    "        wordIds = []\n",
    "        for token in tokens:\n",
    "            wordIds.append(self.getWordId(token, create=False))  # Create the vocabulary and the training sentences\n",
    "\n",
    "        # Third step: creating the batch (add padding, reverse)\n",
    "        batch = self._createBatch([[wordIds, []]])  # Mono batch, no target output\n",
    "\n",
    "        return batch\n",
    "\n",
    "    def deco2sentence(self, decoderOutputs):\n",
    "        \"\"\"Decode the output of the decoder and return a human friendly sentence\n",
    "        decoderOutputs (list<np.array>):\n",
    "        \"\"\"\n",
    "        sequence = []\n",
    "\n",
    "        # Choose the words with the highest prediction score\n",
    "        for out in decoderOutputs:\n",
    "            sequence.append(np.argmax(out))  # Adding each predicted word ids\n",
    "\n",
    "        return sequence  # We return the raw sentence. Let the caller do some cleaning eventually\n",
    "\n",
    "    def playDataset(self):\n",
    "        \"\"\"Print a random dialogue from the dataset\n",
    "        \"\"\"\n",
    "        print('Randomly play samples:')\n",
    "        print(len(self.datasets['train']))\n",
    "        for i in range(args['playDataset']):\n",
    "            idSample = random.randint(0, len(self.datasets['train']) - 1)\n",
    "            print('sen: {} {}'.format(self.sequence2str(self.datasets['train'][idSample][0], clean=True), self.datasets['train'][idSample][1]))\n",
    "            print()\n",
    "        pass\n",
    "\n",
    "\n",
    "def tqdm_wrap(iterable, *args, **kwargs):\n",
    "    \"\"\"Forward an iterable eventually wrapped around a tqdm decorator\n",
    "    The iterable is only wrapped if the iterable contains enough elements\n",
    "    Args:\n",
    "        iterable (list): An iterable object which define the __len__ method\n",
    "        *args, **kwargs: the tqdm parameters\n",
    "    Return:\n",
    "        iter: The iterable eventually decorated\n",
    "    \"\"\"\n",
    "    if len(iterable) > 100:\n",
    "        return tqdm(iterable, *args, **kwargs)\n",
    "    return iterable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862c83ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'aspect':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9d119e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from textdataBeer import TextDataBeer\n",
    "\n",
    "class test_beer_data:\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        print(\"in init\")\n",
    "        print(self.filename)\n",
    "        \n",
    "        \n",
    "    def return_dataset(self):\n",
    "        self.dataset = TextDataBeer.loadDataset(self, self.filename)\n",
    "        return self.dataset\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "359f73c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in init\n",
      "./artifacts/Beerdata0.pkl\n"
     ]
    }
   ],
   "source": [
    "test_beer = test_beer_data(\"./artifacts/Beerdata0.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd32156a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from ./artifacts/Beerdata0.pkl\n",
      "training: \t 80000\n",
      "dev: \t 10000\n",
      "testing: \t 994\n",
      "w2i shape:  147763\n",
      "i2w shape:  147763\n",
      "embeding shape:  (147763, 200)\n"
     ]
    }
   ],
   "source": [
    "datasets, data_all = test_beer.return_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a75e5b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'dev', 'test'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2ea60984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['word2index', 'index2word', 'index2vector', 'datasets'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc18eb43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PAD': 0,\n",
       " 'START_TOKEN': 1,\n",
       " 'END_TOKEN': 2,\n",
       " 'UNK': 3,\n",
       " 'the': 4,\n",
       " '.': 5,\n",
       " 'a': 6,\n",
       " ',': 7,\n",
       " 'of': 8,\n",
       " 'and': 9,\n",
       " 'is': 10,\n",
       " 'to': 11,\n",
       " 'in': 12,\n",
       " 'one': 13,\n",
       " 'with': 14,\n",
       " 'it': 15,\n",
       " 'i': 16,\n",
       " 'zero': 17,\n",
       " 'this': 18,\n",
       " 'two': 19,\n",
       " 'that': 20,\n",
       " 'but': 21,\n",
       " 'for': 22,\n",
       " 'as': 23,\n",
       " 'nine': 24,\n",
       " 'was': 25,\n",
       " 'beer': 26,\n",
       " 'on': 27,\n",
       " 'not': 28,\n",
       " 'very': 29,\n",
       " ':': 30,\n",
       " 'head': 31,\n",
       " 'three': 32,\n",
       " 'eight': 33,\n",
       " 'four': 34,\n",
       " 'five': 35,\n",
       " 'from': 36,\n",
       " 'some': 37,\n",
       " 'are': 38,\n",
       " 'six': 39,\n",
       " 'at': 40,\n",
       " 'seven': 41,\n",
       " 'an': 42,\n",
       " 'taste': 43,\n",
       " 'by': 44,\n",
       " 's': 45,\n",
       " 'nice': 46,\n",
       " 'good': 47,\n",
       " \"'s\": 48,\n",
       " 'there': 49,\n",
       " 'light': 50,\n",
       " 'like': 51,\n",
       " 'be': 52,\n",
       " 'malt': 53,\n",
       " 'more': 54,\n",
       " 'hops': 55,\n",
       " 'or': 56,\n",
       " '-': 57,\n",
       " 'sweet': 58,\n",
       " 'have': 59,\n",
       " 'bit': 60,\n",
       " 'has': 61,\n",
       " 'carbonation': 62,\n",
       " 'flavor': 63,\n",
       " 'dark': 64,\n",
       " 'well': 65,\n",
       " \"n't\": 66,\n",
       " 'aroma': 67,\n",
       " 'my': 68,\n",
       " 'little': 69,\n",
       " 'had': 70,\n",
       " 'all': 71,\n",
       " 'out': 72,\n",
       " 'up': 73,\n",
       " 'which': 74,\n",
       " 'into': 75,\n",
       " 'color': 76,\n",
       " 'glass': 77,\n",
       " 'smell': 78,\n",
       " 'finish': 79,\n",
       " 'bottle': 80,\n",
       " 'just': 81,\n",
       " 'you': 82,\n",
       " 'mouthfeel': 83,\n",
       " 'would': 84,\n",
       " 'pours': 85,\n",
       " 'hop': 86,\n",
       " 'than': 87,\n",
       " 'no': 88,\n",
       " 'lacing': 89,\n",
       " 'body': 90,\n",
       " 'white': 91,\n",
       " 'also': 92,\n",
       " '...': 93,\n",
       " 'much': 94,\n",
       " 'brown': 95,\n",
       " 'really': 96,\n",
       " 'alcohol': 97,\n",
       " ')': 98,\n",
       " 'medium': 99,\n",
       " 'caramel': 100,\n",
       " 'great': 101,\n",
       " '!': 102,\n",
       " 'its': 103,\n",
       " 'chocolate': 104,\n",
       " 'me': 105,\n",
       " 'poured': 106,\n",
       " '(': 107,\n",
       " 'first': 108,\n",
       " 'too': 109,\n",
       " 'so': 110,\n",
       " 'his': 111,\n",
       " 'other': 112,\n",
       " 'notes': 113,\n",
       " 'he': 114,\n",
       " 'nose': 115,\n",
       " 'can': 116,\n",
       " 'malts': 117,\n",
       " 'smooth': 118,\n",
       " 'bitterness': 119,\n",
       " 'if': 120,\n",
       " 'bitter': 121,\n",
       " 'citrus': 122,\n",
       " 'flavors': 123,\n",
       " 't': 124,\n",
       " 'quite': 125,\n",
       " 'pretty': 126,\n",
       " 'sweetness': 127,\n",
       " 'after': 128,\n",
       " 'm': 129,\n",
       " 'were': 130,\n",
       " 'slightly': 131,\n",
       " 'they': 132,\n",
       " 'coffee': 133,\n",
       " 'about': 134,\n",
       " 'style': 135,\n",
       " 'brew': 136,\n",
       " 'dry': 137,\n",
       " 'overall': 138,\n",
       " 'when': 139,\n",
       " 'age': 140,\n",
       " 'could': 141,\n",
       " 'thin': 142,\n",
       " 'what': 143,\n",
       " 'down': 144,\n",
       " 'drink': 145,\n",
       " 'almost': 146,\n",
       " 'creamy': 147,\n",
       " 'black': 148,\n",
       " 'd': 149,\n",
       " 'over': 150,\n",
       " 'time': 151,\n",
       " 'only': 152,\n",
       " 'ale': 153,\n",
       " 'slight': 154,\n",
       " 'roasted': 155,\n",
       " 'most': 156,\n",
       " 'thick': 157,\n",
       " 'strong': 158,\n",
       " 'through': 159,\n",
       " 'orange': 160,\n",
       " 'do': 161,\n",
       " 'their': 162,\n",
       " 'big': 163,\n",
       " 'fruit': 164,\n",
       " 'who': 165,\n",
       " 'amber': 166,\n",
       " 'clear': 167,\n",
       " 'still': 168,\n",
       " 'off': 169,\n",
       " 'malty': 170,\n",
       " 'american': 171,\n",
       " 'any': 172,\n",
       " 'does': 173,\n",
       " 'population': 174,\n",
       " 'again': 175,\n",
       " 'get': 176,\n",
       " 'then': 177,\n",
       " 'drinkable': 178,\n",
       " 'way': 179,\n",
       " 'new': 180,\n",
       " 'though': 181,\n",
       " 'been': 182,\n",
       " 'drinkability': 183,\n",
       " 'years': 184,\n",
       " ';': 185,\n",
       " 'even': 186,\n",
       " 'here': 187,\n",
       " 'smells': 188,\n",
       " 'see': 189,\n",
       " 'full': 190,\n",
       " 'average': 191,\n",
       " 'hint': 192,\n",
       " 'yeast': 193,\n",
       " 'decent': 194,\n",
       " 'bodied': 195,\n",
       " 'around': 196,\n",
       " 'while': 197,\n",
       " 'many': 198,\n",
       " 'golden': 199,\n",
       " \"''\": 200,\n",
       " 'ipa': 201,\n",
       " 'appearance': 202,\n",
       " 'will': 203,\n",
       " 'quickly': 204,\n",
       " 'these': 205,\n",
       " \"'m\": 206,\n",
       " 'under': 207,\n",
       " 'back': 208,\n",
       " 'mild': 209,\n",
       " 'small': 210,\n",
       " 'pale': 211,\n",
       " 'fruity': 212,\n",
       " 'better': 213,\n",
       " 'feel': 214,\n",
       " 'best': 215,\n",
       " 'high': 216,\n",
       " 'tan': 217,\n",
       " 'deep': 218,\n",
       " 'character': 219,\n",
       " 'touch': 220,\n",
       " 'finger': 221,\n",
       " 'balanced': 222,\n",
       " 'city': 223,\n",
       " 'lace': 224,\n",
       " 'end': 225,\n",
       " 'km': 226,\n",
       " '?': 227,\n",
       " 'beers': 228,\n",
       " '``': 229,\n",
       " 'did': 230,\n",
       " 'aftertaste': 231,\n",
       " 'pint': 232,\n",
       " 'leaves': 233,\n",
       " \"'ve\": 234,\n",
       " 'crisp': 235,\n",
       " 'may': 236,\n",
       " 'rich': 237,\n",
       " 'easy': 238,\n",
       " 'being': 239,\n",
       " 'lots': 240,\n",
       " 'think': 241,\n",
       " 'bad': 242,\n",
       " 'hoppy': 243,\n",
       " 'mouth': 244,\n",
       " 'county': 245,\n",
       " 'retention': 246,\n",
       " 'floral': 247,\n",
       " 'definitely': 248,\n",
       " 'another': 249,\n",
       " 'present': 250,\n",
       " 'such': 251,\n",
       " 'living': 252,\n",
       " 'made': 253,\n",
       " 'stout': 254,\n",
       " 'balance': 255,\n",
       " 'hints': 256,\n",
       " 'mi': 257,\n",
       " 'tastes': 258,\n",
       " 'long': 259,\n",
       " 'lot': 260,\n",
       " 'red': 261,\n",
       " 'used': 262,\n",
       " 'few': 263,\n",
       " 'spicy': 264,\n",
       " 'before': 265,\n",
       " 'abv': 266,\n",
       " 'those': 267,\n",
       " 'enough': 268,\n",
       " 'nothing': 269,\n",
       " 'palate': 270,\n",
       " 'try': 271,\n",
       " 'them': 272,\n",
       " 'clean': 273,\n",
       " 'hazy': 274,\n",
       " 'however': 275,\n",
       " 'pine': 276,\n",
       " 'right': 277,\n",
       " 'sour': 278,\n",
       " 'amount': 279,\n",
       " 'left': 280,\n",
       " 'people': 281,\n",
       " 'front': 282,\n",
       " 'top': 283,\n",
       " 'income': 284,\n",
       " 'wheat': 285,\n",
       " '%': 286,\n",
       " 'fairly': 287,\n",
       " 'total': 288,\n",
       " 'median': 289,\n",
       " 'complex': 290,\n",
       " 'make': 291,\n",
       " 'because': 292,\n",
       " 'maybe': 293,\n",
       " 'pour': 294,\n",
       " 'spice': 295,\n",
       " 'solid': 296,\n",
       " 'vanilla': 297,\n",
       " 'something': 298,\n",
       " 'same': 299,\n",
       " 'every': 300,\n",
       " 'fresh': 301,\n",
       " 'grapefruit': 302,\n",
       " 'your': 303,\n",
       " 'sugar': 304,\n",
       " 'between': 305,\n",
       " 'earthy': 306,\n",
       " 'heavy': 307,\n",
       " 'side': 308,\n",
       " 'rather': 309,\n",
       " 'states': 310,\n",
       " 'yellow': 311,\n",
       " 'along': 312,\n",
       " 'united': 313,\n",
       " 'drinking': 314,\n",
       " 'where': 315,\n",
       " 'line': 316,\n",
       " 'belgian': 317,\n",
       " 'world': 318,\n",
       " 'tongue': 319,\n",
       " 'comes': 320,\n",
       " 'moderate': 321,\n",
       " 'now': 322,\n",
       " 'area': 323,\n",
       " 'fruits': 324,\n",
       " 'low': 325,\n",
       " \"'d\": 326,\n",
       " 'come': 327,\n",
       " 'aromas': 328,\n",
       " 'water': 329,\n",
       " 'town': 330,\n",
       " 'seems': 331,\n",
       " 'census': 332,\n",
       " 'lemon': 333,\n",
       " 'day': 334,\n",
       " 'going': 335,\n",
       " 'refreshing': 336,\n",
       " 'older': 337,\n",
       " 'say': 338,\n",
       " 'interesting': 339,\n",
       " 'foam': 340,\n",
       " 'makes': 341,\n",
       " 'bubbles': 342,\n",
       " 'both': 343,\n",
       " 'got': 344,\n",
       " 'year': 345,\n",
       " 'somewhat': 346,\n",
       " 'honey': 347,\n",
       " 'thanks': 348,\n",
       " 'part': 349,\n",
       " 'during': 350,\n",
       " 'family': 351,\n",
       " 'sure': 352,\n",
       " 'families': 353,\n",
       " '&': 354,\n",
       " 'nicely': 355,\n",
       " 'although': 356,\n",
       " 'go': 357,\n",
       " 'tap': 358,\n",
       " 'how': 359,\n",
       " 'males': 360,\n",
       " 'females': 361,\n",
       " 'oz': 362,\n",
       " 'should': 363,\n",
       " 'cloudy': 364,\n",
       " 'presence': 365,\n",
       " 'households': 366,\n",
       " 'love': 367,\n",
       " 'served': 368,\n",
       " 'copper': 369,\n",
       " 'finishes': 370,\n",
       " 'large': 371,\n",
       " 'expected': 372,\n",
       " 'without': 373,\n",
       " 'bready': 374,\n",
       " 'yet': 375,\n",
       " 'different': 376,\n",
       " 'sticky': 377,\n",
       " 'name': 378,\n",
       " 'am': 379,\n",
       " 'her': 380,\n",
       " 'pleasant': 381,\n",
       " 'tart': 382,\n",
       " 'tasty': 383,\n",
       " 'last': 384,\n",
       " 'less': 385,\n",
       " 'goes': 386,\n",
       " 'looking': 387,\n",
       " 'use': 388,\n",
       " 'since': 389,\n",
       " 'probably': 390,\n",
       " 'known': 391,\n",
       " 'faint': 392,\n",
       " 'huge': 393,\n",
       " 'found': 394,\n",
       " 'below': 395,\n",
       " 'english': 396,\n",
       " 'toffee': 397,\n",
       " 'carbonated': 398,\n",
       " 'old': 399,\n",
       " 'size': 400,\n",
       " 'oak': 401,\n",
       " 'note': 402,\n",
       " 'actually': 403,\n",
       " 'sip': 404,\n",
       " 'never': 405,\n",
       " 'kind': 406,\n",
       " 'bread': 407,\n",
       " 'excellent': 408,\n",
       " 'lager': 409,\n",
       " 'worth': 410,\n",
       " 'subtle': 411,\n",
       " 'toasted': 412,\n",
       " 'north': 413,\n",
       " 'spices': 414,\n",
       " 'find': 415,\n",
       " 'leaving': 416,\n",
       " 'gold': 417,\n",
       " 'together': 418,\n",
       " 'o': 419,\n",
       " 'each': 420,\n",
       " 'ever': 421,\n",
       " '--': 422,\n",
       " 'fine': 423,\n",
       " 'looks': 424,\n",
       " '12': 425,\n",
       " 'war': 426,\n",
       " 'mostly': 427,\n",
       " 'banana': 428,\n",
       " 'external': 429,\n",
       " 'off-white': 430,\n",
       " 'state': 431,\n",
       " 'know': 432,\n",
       " 'ca': 433,\n",
       " 'links': 434,\n",
       " 'west': 435,\n",
       " 'similar': 436,\n",
       " 'perfect': 437,\n",
       " 'take': 438,\n",
       " 'middle': 439,\n",
       " 'later': 440,\n",
       " 'real': 441,\n",
       " 'away': 442,\n",
       " 'grain': 443,\n",
       " 'she': 444,\n",
       " 'far': 445,\n",
       " 'often': 446,\n",
       " 'second': 447,\n",
       " 'grassy': 448,\n",
       " 'followed': 449,\n",
       " 'called': 450,\n",
       " 'located': 451,\n",
       " 'enjoyable': 452,\n",
       " 'thing': 453,\n",
       " 'apple': 454,\n",
       " 'th': 455,\n",
       " 'bourbon': 456,\n",
       " 'colored': 457,\n",
       " 'half': 458,\n",
       " 'work': 459,\n",
       " 'porter': 460,\n",
       " 'throughout': 461,\n",
       " 'might': 462,\n",
       " 'bite': 463,\n",
       " 'burnt': 464,\n",
       " 'profile': 465,\n",
       " 'we': 466,\n",
       " 'give': 467,\n",
       " 'several': 468,\n",
       " 'cherry': 469,\n",
       " 'lightly': 470,\n",
       " 'soft': 471,\n",
       " 'level': 472,\n",
       " 'lingering': 473,\n",
       " 'film': 474,\n",
       " 'warms': 475,\n",
       " 'history': 476,\n",
       " 'watery': 477,\n",
       " 'example': 478,\n",
       " 'density': 479,\n",
       " 'hard': 480,\n",
       " 'him': 481,\n",
       " 'perhaps': 482,\n",
       " 'tasting': 483,\n",
       " 'want': 484,\n",
       " 'background': 485,\n",
       " 'night': 486,\n",
       " 'until': 487,\n",
       " 'de': 488,\n",
       " 'quality': 489,\n",
       " 'foamy': 490,\n",
       " 'session': 491,\n",
       " 'behind': 492,\n",
       " 'races': 493,\n",
       " 'inch': 494,\n",
       " 'household': 495,\n",
       " 'certainly': 496,\n",
       " 'thought': 497,\n",
       " 'favorite': 498,\n",
       " 'version': 499,\n",
       " 'poverty': 500,\n",
       " 'herbal': 501,\n",
       " 'brewery': 502,\n",
       " 'either': 503,\n",
       " 'especially': 504,\n",
       " 'became': 505,\n",
       " 'tulip': 506,\n",
       " 'due': 507,\n",
       " 'bright': 508,\n",
       " 'b': 509,\n",
       " 'number': 510,\n",
       " 'summer': 511,\n",
       " 'non': 512,\n",
       " 'fades': 513,\n",
       " 'once': 514,\n",
       " 'enjoy': 515,\n",
       " 'starts': 516,\n",
       " 'slowly': 517,\n",
       " 'piney': 518,\n",
       " 'imperial': 519,\n",
       " 'label': 520,\n",
       " 'look': 521,\n",
       " 'point': 522,\n",
       " 'ring': 523,\n",
       " 'u': 524,\n",
       " 'date': 525,\n",
       " 'green': 526,\n",
       " 'early': 527,\n",
       " 'grainy': 528,\n",
       " 'place': 529,\n",
       " 'short': 530,\n",
       " 'life': 531,\n",
       " 'south': 532,\n",
       " \"'ll\": 533,\n",
       " 'molasses': 534,\n",
       " 'enjoyed': 535,\n",
       " 'general': 536,\n",
       " 'university': 537,\n",
       " 'german': 538,\n",
       " 'citrusy': 539,\n",
       " 'said': 540,\n",
       " 'times': 541,\n",
       " 'c': 542,\n",
       " 'series': 543,\n",
       " 'system': 544,\n",
       " 'least': 545,\n",
       " 'land': 546,\n",
       " 'according': 547,\n",
       " 'highly': 548,\n",
       " 'wine': 549,\n",
       " 'tried': 550,\n",
       " 'review': 551,\n",
       " 'extremely': 552,\n",
       " 'frothy': 553,\n",
       " 'clove': 554,\n",
       " 'standard': 555,\n",
       " 'having': 556,\n",
       " 'john': 557,\n",
       " 'easily': 558,\n",
       " 'near': 559,\n",
       " 'british': 560,\n",
       " 'e': 561,\n",
       " 'scent': 562,\n",
       " 'yeasty': 563,\n",
       " 'per': 564,\n",
       " 'form': 565,\n",
       " 'expect': 566,\n",
       " 'coming': 567,\n",
       " 'government': 568,\n",
       " 'own': 569,\n",
       " 'including': 570,\n",
       " 'beautiful': 571,\n",
       " 'start': 572,\n",
       " 'children': 573,\n",
       " 'against': 574,\n",
       " 'held': 575,\n",
       " 'must': 576,\n",
       " 'cap': 577,\n",
       " 'hot': 578,\n",
       " 'given': 579,\n",
       " 'delicious': 580,\n",
       " 'plenty': 581,\n",
       " 'things': 582,\n",
       " 'fluffy': 583,\n",
       " 'above': 584,\n",
       " '12oz': 585,\n",
       " 'township': 586,\n",
       " 'next': 587,\n",
       " 'national': 588,\n",
       " 'pumpkin': 589,\n",
       " 'a-': 590,\n",
       " 'warming': 591,\n",
       " 'mix': 592,\n",
       " 'came': 593,\n",
       " 'special': 594,\n",
       " 'whole': 595,\n",
       " 'home': 596,\n",
       " 'roasty': 597,\n",
       " 'maltiness': 598,\n",
       " 'typical': 599,\n",
       " 'lighter': 600,\n",
       " 'itself': 601,\n",
       " 'done': 602,\n",
       " 'n': 603,\n",
       " 'minimal': 604,\n",
       " 'king': 605,\n",
       " 'school': 606,\n",
       " 'noticeable': 607,\n",
       " 'usually': 608,\n",
       " 'others': 609,\n",
       " 'based': 610,\n",
       " 'else': 611,\n",
       " 's-': 612,\n",
       " 'put': 613,\n",
       " 'cocoa': 614,\n",
       " 't-': 615,\n",
       " 'anything': 616,\n",
       " \"'\": 617,\n",
       " 'cherries': 618,\n",
       " 'century': 619,\n",
       " 'someone': 620,\n",
       " 'list': 621,\n",
       " '2': 622,\n",
       " 'us': 623,\n",
       " 'show': 624,\n",
       " 'ruby': 625,\n",
       " 'local': 626,\n",
       " 'tasted': 627,\n",
       " 'music': 628,\n",
       " 'straw': 629,\n",
       " '$': 630,\n",
       " 'party': 631,\n",
       " 'stuff': 632,\n",
       " 'wonderful': 633,\n",
       " 'unique': 634,\n",
       " 'nutty': 635,\n",
       " 'warm': 636,\n",
       " 'smoke': 637,\n",
       " 'nearly': 638,\n",
       " 'power': 639,\n",
       " 'man': 640,\n",
       " 'let': 641,\n",
       " 'snifter': 642,\n",
       " 'x': 643,\n",
       " 'm-': 644,\n",
       " 'fingers': 645,\n",
       " 'lingers': 646,\n",
       " 'always': 647,\n",
       " 'getting': 648,\n",
       " 'fact': 649,\n",
       " 'complexity': 650,\n",
       " 'bomber': 651,\n",
       " 'sharp': 652,\n",
       " 'french': 653,\n",
       " 'hit': 654,\n",
       " 'making': 655,\n",
       " 'winter': 656,\n",
       " 'gives': 657,\n",
       " 'mixed': 658,\n",
       " 'pepper': 659,\n",
       " 'overly': 660,\n",
       " 'keep': 661,\n",
       " 'opaque': 662,\n",
       " 'within': 663,\n",
       " 'hue': 664,\n",
       " 'base': 665,\n",
       " 'house': 666,\n",
       " 'cream': 667,\n",
       " 'married': 668,\n",
       " 'flavour': 669,\n",
       " 'roast': 670,\n",
       " 'case': 671,\n",
       " 'major': 672,\n",
       " 'fruitiness': 673,\n",
       " 'type': 674,\n",
       " 'super': 675,\n",
       " 'alone': 676,\n",
       " 'born': 677,\n",
       " 'order': 678,\n",
       " 'works': 679,\n",
       " 'trying': 680,\n",
       " 'wood': 681,\n",
       " 'syrupy': 682,\n",
       " 'colour': 683,\n",
       " 'reminds': 684,\n",
       " 'raisins': 685,\n",
       " 'took': 686,\n",
       " 'buy': 687,\n",
       " 'single': 688,\n",
       " 'main': 689,\n",
       " 'set': 690,\n",
       " 'towards': 691,\n",
       " 'game': 692,\n",
       " 'river': 693,\n",
       " 'seen': 694,\n",
       " 'reddish': 695,\n",
       " 'village': 696,\n",
       " 'york': 697,\n",
       " 'went': 698,\n",
       " 'female': 699,\n",
       " 'pick': 700,\n",
       " 'cold': 701,\n",
       " 'texture': 702,\n",
       " 'across': 703,\n",
       " 'african': 704,\n",
       " 'group': 705,\n",
       " 'available': 706,\n",
       " 'backbone': 707,\n",
       " 'native': 708,\n",
       " '1': 709,\n",
       " 'grains': 710,\n",
       " 'race': 711,\n",
       " 'f': 712,\n",
       " 'public': 713,\n",
       " 'ok': 714,\n",
       " 'cinnamon': 715,\n",
       " 'surprisingly': 716,\n",
       " 'become': 717,\n",
       " 'east': 718,\n",
       " 'st': 719,\n",
       " 'dissipates': 720,\n",
       " 'seem': 721,\n",
       " 'despite': 722,\n",
       " 'experience': 723,\n",
       " 'sort': 724,\n",
       " 'bubbly': 725,\n",
       " 'pacific': 726,\n",
       " 'following': 727,\n",
       " 'units': 728,\n",
       " 'layer': 729,\n",
       " 'fizzy': 730,\n",
       " 'book': 731,\n",
       " 'original': 732,\n",
       " 'initial': 733,\n",
       " 'upon': 734,\n",
       " 'hidden': 735,\n",
       " 'fan': 736,\n",
       " 'rye': 737,\n",
       " 'expecting': 738,\n",
       " 'milk': 739,\n",
       " 'gets': 740,\n",
       " 'funk': 741,\n",
       " 'g': 742,\n",
       " 'price': 743,\n",
       " 'amazing': 744,\n",
       " 'weak': 745,\n",
       " 'couple': 746,\n",
       " 'wow': 747,\n",
       " 'spread': 748,\n",
       " 'd-': 749,\n",
       " 'forward': 750,\n",
       " 'mind': 751,\n",
       " 'common': 752,\n",
       " 'picked': 753,\n",
       " 'individuals': 754,\n",
       " 'close': 755,\n",
       " 'oily': 756,\n",
       " 'offering': 757,\n",
       " 'soon': 758,\n",
       " 'ii': 759,\n",
       " 'simple': 760,\n",
       " 'shows': 761,\n",
       " 'feels': 762,\n",
       " 'tartness': 763,\n",
       " 'bottom': 764,\n",
       " 'r': 765,\n",
       " 'edges': 766,\n",
       " 'highlights': 767,\n",
       " 'late': 768,\n",
       " 'asian': 769,\n",
       " 'husband': 770,\n",
       " 'geography': 771,\n",
       " 'law': 772,\n",
       " 'company': 773,\n",
       " 'sourness': 774,\n",
       " 'why': 775,\n",
       " 'metallic': 776,\n",
       " 'barley': 777,\n",
       " 'blend': 778,\n",
       " 'pack': 779,\n",
       " 'among': 780,\n",
       " 'hoppiness': 781,\n",
       " 'pilsner': 782,\n",
       " 'wish': 783,\n",
       " 'overpowering': 784,\n",
       " 'everything': 785,\n",
       " 'completely': 786,\n",
       " 'center': 787,\n",
       " 'toasty': 788,\n",
       " 'spiciness': 789,\n",
       " 'means': 790,\n",
       " 'candy': 791,\n",
       " 'country': 792,\n",
       " 'include': 793,\n",
       " 'true': 794,\n",
       " 'death': 795,\n",
       " 'chewy': 796,\n",
       " 'corn': 797,\n",
       " 'grass': 798,\n",
       " 'island': 799,\n",
       " 'housing': 800,\n",
       " 'term': 801,\n",
       " 'named': 802,\n",
       " 'air': 803,\n",
       " 'glad': 804,\n",
       " 'international': 805,\n",
       " 'bureau': 806,\n",
       " 'open': 807,\n",
       " 'takes': 808,\n",
       " 'higher': 809,\n",
       " 'president': 810,\n",
       " 'ales': 811,\n",
       " 'earth': 812,\n",
       " 'language': 813,\n",
       " 'p': 814,\n",
       " 'l': 815,\n",
       " 'kick': 816,\n",
       " 'sometimes': 817,\n",
       " 'tiny': 818,\n",
       " 'versus': 819,\n",
       " 'popular': 820,\n",
       " 'need': 821,\n",
       " 'settles': 822,\n",
       " 'racial': 823,\n",
       " 'mellow': 824,\n",
       " 'trade': 825,\n",
       " 'intense': 826,\n",
       " 'becomes': 827,\n",
       " \"'re\": 828,\n",
       " 'sides': 829,\n",
       " 'demographics': 830,\n",
       " 'appears': 831,\n",
       " 'peel': 832,\n",
       " 'fantastic': 833,\n",
       " 'fair': 834,\n",
       " 'apples': 835,\n",
       " 'barrel': 836,\n",
       " 'march': 837,\n",
       " 'play': 838,\n",
       " 'image': 839,\n",
       " 'believe': 840,\n",
       " 'hits': 841,\n",
       " 'dense': 842,\n",
       " 'regular': 843,\n",
       " 'booze': 844,\n",
       " 'double': 845,\n",
       " 'couples': 846,\n",
       " 'impressive': 847,\n",
       " 'using': 848,\n",
       " 'none': 849,\n",
       " 'instead': 850,\n",
       " 'capita': 851,\n",
       " 'modern': 852,\n",
       " 'days': 853,\n",
       " 'forms': 854,\n",
       " 'makeup': 855,\n",
       " 'esters': 856,\n",
       " 'tropical': 857,\n",
       " 'considered': 858,\n",
       " 'follows': 859,\n",
       " 'hispanic': 860,\n",
       " 'aged': 861,\n",
       " 'drank': 862,\n",
       " 'liquid': 863,\n",
       " 'coriander': 864,\n",
       " 'bottles': 865,\n",
       " 'residing': 866,\n",
       " 'leave': 867,\n",
       " 'january': 868,\n",
       " 'dipa': 869,\n",
       " 'political': 870,\n",
       " 'awesome': 871,\n",
       " 'latino': 872,\n",
       " 'today': 873,\n",
       " 'church': 874,\n",
       " 'word': 875,\n",
       " 'relatively': 876,\n",
       " 'bottled': 877,\n",
       " 'initially': 878,\n",
       " 'mildly': 879,\n",
       " 'coast': 880,\n",
       " 'surface': 881,\n",
       " 'guess': 882,\n",
       " 'liked': 883,\n",
       " 'able': 884,\n",
       " 'islander': 885,\n",
       " 'began': 886,\n",
       " 'tones': 887,\n",
       " 'stone': 888,\n",
       " 'heat': 889,\n",
       " 'crystal': 890,\n",
       " 'produced': 891,\n",
       " 'months': 892,\n",
       " 'edge': 893,\n",
       " 'released': 894,\n",
       " 'upfront': 895,\n",
       " 'particularly': 896,\n",
       " 'finally': 897,\n",
       " 'peppery': 898,\n",
       " 'members': 899,\n",
       " 'classic': 900,\n",
       " 'generally': 901,\n",
       " 'biscuit': 902,\n",
       " 'minutes': 903,\n",
       " 'july': 904,\n",
       " 'round': 905,\n",
       " 'site': 906,\n",
       " 'official': 907,\n",
       " 'college': 908,\n",
       " 'hand': 909,\n",
       " 'bought': 910,\n",
       " 'damn': 911,\n",
       " 'dominate': 912,\n",
       " 'course': 913,\n",
       " 'pineapple': 914,\n",
       " 'beige': 915,\n",
       " 'flat': 916,\n",
       " 'london': 917,\n",
       " 'past': 918,\n",
       " 'june': 919,\n",
       " 'free': 920,\n",
       " 'boozy': 921,\n",
       " 'sense': 922,\n",
       " 'location': 923,\n",
       " 'syrup': 924,\n",
       " 'brewed': 925,\n",
       " 'tons': 926,\n",
       " 'england': 927,\n",
       " 'food': 928,\n",
       " 'october': 929,\n",
       " 'stouts': 930,\n",
       " 'traditional': 931,\n",
       " 'lasting': 932,\n",
       " 'battle': 933,\n",
       " 'god': 934,\n",
       " 'various': 935,\n",
       " 'brews': 936,\n",
       " 'live': 937,\n",
       " 'covered': 938,\n",
       " 'change': 939,\n",
       " 'darker': 940,\n",
       " 'band': 941,\n",
       " 'sugary': 942,\n",
       " 'immediately': 943,\n",
       " 'simply': 944,\n",
       " 'december': 945,\n",
       " 'call': 946,\n",
       " 'military': 947,\n",
       " 'september': 948,\n",
       " 'lower': 949,\n",
       " 'sticks': 950,\n",
       " 'information': 951,\n",
       " 'recommend': 952,\n",
       " '3': 953,\n",
       " 'cities': 954,\n",
       " 'april': 955,\n",
       " 'la': 956,\n",
       " 'started': 957,\n",
       " 'murky': 958,\n",
       " 'release': 959,\n",
       " 'died': 960,\n",
       " 'feeling': 961,\n",
       " 'funky': 962,\n",
       " 'important': 963,\n",
       " 'added': 964,\n",
       " 'lack': 965,\n",
       " 'otherwise': 966,\n",
       " 'v': 967,\n",
       " 'help': 968,\n",
       " 'lost': 969,\n",
       " 'add': 970,\n",
       " 'slick': 971,\n",
       " 'class': 972,\n",
       " 'august': 973,\n",
       " 'impressed': 974,\n",
       " 'bc': 975,\n",
       " 'further': 976,\n",
       " 'support': 977,\n",
       " 'thus': 978,\n",
       " 'juice': 979,\n",
       " 'control': 980,\n",
       " 'smelled': 981,\n",
       " 'led': 982,\n",
       " 'flavorful': 983,\n",
       " 'apricot': 984,\n",
       " 'dried': 985,\n",
       " 'remains': 986,\n",
       " 'third': 987,\n",
       " 'article': 988,\n",
       " 'combination': 989,\n",
       " 'licorice': 990,\n",
       " 'j': 991,\n",
       " 'addition': 992,\n",
       " 'characteristics': 993,\n",
       " 'rock': 994,\n",
       " 'seemed': 995,\n",
       " 'opinion': 996,\n",
       " 'giving': 997,\n",
       " 'dryness': 998,\n",
       " 'album': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all['word2index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2795fd25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAD',\n",
       " 'START_TOKEN',\n",
       " 'END_TOKEN',\n",
       " 'UNK',\n",
       " 'the',\n",
       " '.',\n",
       " 'a',\n",
       " ',',\n",
       " 'of',\n",
       " 'and',\n",
       " 'is',\n",
       " 'to',\n",
       " 'in',\n",
       " 'one',\n",
       " 'with',\n",
       " 'it',\n",
       " 'i',\n",
       " 'zero',\n",
       " 'this',\n",
       " 'two',\n",
       " 'that',\n",
       " 'but',\n",
       " 'for',\n",
       " 'as',\n",
       " 'nine',\n",
       " 'was',\n",
       " 'beer',\n",
       " 'on',\n",
       " 'not',\n",
       " 'very',\n",
       " ':',\n",
       " 'head',\n",
       " 'three',\n",
       " 'eight',\n",
       " 'four',\n",
       " 'five',\n",
       " 'from',\n",
       " 'some',\n",
       " 'are',\n",
       " 'six',\n",
       " 'at',\n",
       " 'seven',\n",
       " 'an',\n",
       " 'taste',\n",
       " 'by',\n",
       " 's',\n",
       " 'nice',\n",
       " 'good',\n",
       " \"'s\",\n",
       " 'there',\n",
       " 'light',\n",
       " 'like',\n",
       " 'be',\n",
       " 'malt',\n",
       " 'more',\n",
       " 'hops',\n",
       " 'or',\n",
       " '-',\n",
       " 'sweet',\n",
       " 'have',\n",
       " 'bit',\n",
       " 'has',\n",
       " 'carbonation',\n",
       " 'flavor',\n",
       " 'dark',\n",
       " 'well',\n",
       " \"n't\",\n",
       " 'aroma',\n",
       " 'my',\n",
       " 'little',\n",
       " 'had',\n",
       " 'all',\n",
       " 'out',\n",
       " 'up',\n",
       " 'which',\n",
       " 'into',\n",
       " 'color',\n",
       " 'glass',\n",
       " 'smell',\n",
       " 'finish',\n",
       " 'bottle',\n",
       " 'just',\n",
       " 'you',\n",
       " 'mouthfeel',\n",
       " 'would',\n",
       " 'pours',\n",
       " 'hop',\n",
       " 'than',\n",
       " 'no',\n",
       " 'lacing',\n",
       " 'body',\n",
       " 'white',\n",
       " 'also',\n",
       " '...',\n",
       " 'much',\n",
       " 'brown',\n",
       " 'really',\n",
       " 'alcohol',\n",
       " ')',\n",
       " 'medium',\n",
       " 'caramel',\n",
       " 'great',\n",
       " '!',\n",
       " 'its',\n",
       " 'chocolate',\n",
       " 'me',\n",
       " 'poured',\n",
       " '(',\n",
       " 'first',\n",
       " 'too',\n",
       " 'so',\n",
       " 'his',\n",
       " 'other',\n",
       " 'notes',\n",
       " 'he',\n",
       " 'nose',\n",
       " 'can',\n",
       " 'malts',\n",
       " 'smooth',\n",
       " 'bitterness',\n",
       " 'if',\n",
       " 'bitter',\n",
       " 'citrus',\n",
       " 'flavors',\n",
       " 't',\n",
       " 'quite',\n",
       " 'pretty',\n",
       " 'sweetness',\n",
       " 'after',\n",
       " 'm',\n",
       " 'were',\n",
       " 'slightly',\n",
       " 'they',\n",
       " 'coffee',\n",
       " 'about',\n",
       " 'style',\n",
       " 'brew',\n",
       " 'dry',\n",
       " 'overall',\n",
       " 'when',\n",
       " 'age',\n",
       " 'could',\n",
       " 'thin',\n",
       " 'what',\n",
       " 'down',\n",
       " 'drink',\n",
       " 'almost',\n",
       " 'creamy',\n",
       " 'black',\n",
       " 'd',\n",
       " 'over',\n",
       " 'time',\n",
       " 'only',\n",
       " 'ale',\n",
       " 'slight',\n",
       " 'roasted',\n",
       " 'most',\n",
       " 'thick',\n",
       " 'strong',\n",
       " 'through',\n",
       " 'orange',\n",
       " 'do',\n",
       " 'their',\n",
       " 'big',\n",
       " 'fruit',\n",
       " 'who',\n",
       " 'amber',\n",
       " 'clear',\n",
       " 'still',\n",
       " 'off',\n",
       " 'malty',\n",
       " 'american',\n",
       " 'any',\n",
       " 'does',\n",
       " 'population',\n",
       " 'again',\n",
       " 'get',\n",
       " 'then',\n",
       " 'drinkable',\n",
       " 'way',\n",
       " 'new',\n",
       " 'though',\n",
       " 'been',\n",
       " 'drinkability',\n",
       " 'years',\n",
       " ';',\n",
       " 'even',\n",
       " 'here',\n",
       " 'smells',\n",
       " 'see',\n",
       " 'full',\n",
       " 'average',\n",
       " 'hint',\n",
       " 'yeast',\n",
       " 'decent',\n",
       " 'bodied',\n",
       " 'around',\n",
       " 'while',\n",
       " 'many',\n",
       " 'golden',\n",
       " \"''\",\n",
       " 'ipa',\n",
       " 'appearance',\n",
       " 'will',\n",
       " 'quickly',\n",
       " 'these',\n",
       " \"'m\",\n",
       " 'under',\n",
       " 'back',\n",
       " 'mild',\n",
       " 'small',\n",
       " 'pale',\n",
       " 'fruity',\n",
       " 'better',\n",
       " 'feel',\n",
       " 'best',\n",
       " 'high',\n",
       " 'tan',\n",
       " 'deep',\n",
       " 'character',\n",
       " 'touch',\n",
       " 'finger',\n",
       " 'balanced',\n",
       " 'city',\n",
       " 'lace',\n",
       " 'end',\n",
       " 'km',\n",
       " '?',\n",
       " 'beers',\n",
       " '``',\n",
       " 'did',\n",
       " 'aftertaste',\n",
       " 'pint',\n",
       " 'leaves',\n",
       " \"'ve\",\n",
       " 'crisp',\n",
       " 'may',\n",
       " 'rich',\n",
       " 'easy',\n",
       " 'being',\n",
       " 'lots',\n",
       " 'think',\n",
       " 'bad',\n",
       " 'hoppy',\n",
       " 'mouth',\n",
       " 'county',\n",
       " 'retention',\n",
       " 'floral',\n",
       " 'definitely',\n",
       " 'another',\n",
       " 'present',\n",
       " 'such',\n",
       " 'living',\n",
       " 'made',\n",
       " 'stout',\n",
       " 'balance',\n",
       " 'hints',\n",
       " 'mi',\n",
       " 'tastes',\n",
       " 'long',\n",
       " 'lot',\n",
       " 'red',\n",
       " 'used',\n",
       " 'few',\n",
       " 'spicy',\n",
       " 'before',\n",
       " 'abv',\n",
       " 'those',\n",
       " 'enough',\n",
       " 'nothing',\n",
       " 'palate',\n",
       " 'try',\n",
       " 'them',\n",
       " 'clean',\n",
       " 'hazy',\n",
       " 'however',\n",
       " 'pine',\n",
       " 'right',\n",
       " 'sour',\n",
       " 'amount',\n",
       " 'left',\n",
       " 'people',\n",
       " 'front',\n",
       " 'top',\n",
       " 'income',\n",
       " 'wheat',\n",
       " '%',\n",
       " 'fairly',\n",
       " 'total',\n",
       " 'median',\n",
       " 'complex',\n",
       " 'make',\n",
       " 'because',\n",
       " 'maybe',\n",
       " 'pour',\n",
       " 'spice',\n",
       " 'solid',\n",
       " 'vanilla',\n",
       " 'something',\n",
       " 'same',\n",
       " 'every',\n",
       " 'fresh',\n",
       " 'grapefruit',\n",
       " 'your',\n",
       " 'sugar',\n",
       " 'between',\n",
       " 'earthy',\n",
       " 'heavy',\n",
       " 'side',\n",
       " 'rather',\n",
       " 'states',\n",
       " 'yellow',\n",
       " 'along',\n",
       " 'united',\n",
       " 'drinking',\n",
       " 'where',\n",
       " 'line',\n",
       " 'belgian',\n",
       " 'world',\n",
       " 'tongue',\n",
       " 'comes',\n",
       " 'moderate',\n",
       " 'now',\n",
       " 'area',\n",
       " 'fruits',\n",
       " 'low',\n",
       " \"'d\",\n",
       " 'come',\n",
       " 'aromas',\n",
       " 'water',\n",
       " 'town',\n",
       " 'seems',\n",
       " 'census',\n",
       " 'lemon',\n",
       " 'day',\n",
       " 'going',\n",
       " 'refreshing',\n",
       " 'older',\n",
       " 'say',\n",
       " 'interesting',\n",
       " 'foam',\n",
       " 'makes',\n",
       " 'bubbles',\n",
       " 'both',\n",
       " 'got',\n",
       " 'year',\n",
       " 'somewhat',\n",
       " 'honey',\n",
       " 'thanks',\n",
       " 'part',\n",
       " 'during',\n",
       " 'family',\n",
       " 'sure',\n",
       " 'families',\n",
       " '&',\n",
       " 'nicely',\n",
       " 'although',\n",
       " 'go',\n",
       " 'tap',\n",
       " 'how',\n",
       " 'males',\n",
       " 'females',\n",
       " 'oz',\n",
       " 'should',\n",
       " 'cloudy',\n",
       " 'presence',\n",
       " 'households',\n",
       " 'love',\n",
       " 'served',\n",
       " 'copper',\n",
       " 'finishes',\n",
       " 'large',\n",
       " 'expected',\n",
       " 'without',\n",
       " 'bready',\n",
       " 'yet',\n",
       " 'different',\n",
       " 'sticky',\n",
       " 'name',\n",
       " 'am',\n",
       " 'her',\n",
       " 'pleasant',\n",
       " 'tart',\n",
       " 'tasty',\n",
       " 'last',\n",
       " 'less',\n",
       " 'goes',\n",
       " 'looking',\n",
       " 'use',\n",
       " 'since',\n",
       " 'probably',\n",
       " 'known',\n",
       " 'faint',\n",
       " 'huge',\n",
       " 'found',\n",
       " 'below',\n",
       " 'english',\n",
       " 'toffee',\n",
       " 'carbonated',\n",
       " 'old',\n",
       " 'size',\n",
       " 'oak',\n",
       " 'note',\n",
       " 'actually',\n",
       " 'sip',\n",
       " 'never',\n",
       " 'kind',\n",
       " 'bread',\n",
       " 'excellent',\n",
       " 'lager',\n",
       " 'worth',\n",
       " 'subtle',\n",
       " 'toasted',\n",
       " 'north',\n",
       " 'spices',\n",
       " 'find',\n",
       " 'leaving',\n",
       " 'gold',\n",
       " 'together',\n",
       " 'o',\n",
       " 'each',\n",
       " 'ever',\n",
       " '--',\n",
       " 'fine',\n",
       " 'looks',\n",
       " '12',\n",
       " 'war',\n",
       " 'mostly',\n",
       " 'banana',\n",
       " 'external',\n",
       " 'off-white',\n",
       " 'state',\n",
       " 'know',\n",
       " 'ca',\n",
       " 'links',\n",
       " 'west',\n",
       " 'similar',\n",
       " 'perfect',\n",
       " 'take',\n",
       " 'middle',\n",
       " 'later',\n",
       " 'real',\n",
       " 'away',\n",
       " 'grain',\n",
       " 'she',\n",
       " 'far',\n",
       " 'often',\n",
       " 'second',\n",
       " 'grassy',\n",
       " 'followed',\n",
       " 'called',\n",
       " 'located',\n",
       " 'enjoyable',\n",
       " 'thing',\n",
       " 'apple',\n",
       " 'th',\n",
       " 'bourbon',\n",
       " 'colored',\n",
       " 'half',\n",
       " 'work',\n",
       " 'porter',\n",
       " 'throughout',\n",
       " 'might',\n",
       " 'bite',\n",
       " 'burnt',\n",
       " 'profile',\n",
       " 'we',\n",
       " 'give',\n",
       " 'several',\n",
       " 'cherry',\n",
       " 'lightly',\n",
       " 'soft',\n",
       " 'level',\n",
       " 'lingering',\n",
       " 'film',\n",
       " 'warms',\n",
       " 'history',\n",
       " 'watery',\n",
       " 'example',\n",
       " 'density',\n",
       " 'hard',\n",
       " 'him',\n",
       " 'perhaps',\n",
       " 'tasting',\n",
       " 'want',\n",
       " 'background',\n",
       " 'night',\n",
       " 'until',\n",
       " 'de',\n",
       " 'quality',\n",
       " 'foamy',\n",
       " 'session',\n",
       " 'behind',\n",
       " 'races',\n",
       " 'inch',\n",
       " 'household',\n",
       " 'certainly',\n",
       " 'thought',\n",
       " 'favorite',\n",
       " 'version',\n",
       " 'poverty',\n",
       " 'herbal',\n",
       " 'brewery',\n",
       " 'either',\n",
       " 'especially',\n",
       " 'became',\n",
       " 'tulip',\n",
       " 'due',\n",
       " 'bright',\n",
       " 'b',\n",
       " 'number',\n",
       " 'summer',\n",
       " 'non',\n",
       " 'fades',\n",
       " 'once',\n",
       " 'enjoy',\n",
       " 'starts',\n",
       " 'slowly',\n",
       " 'piney',\n",
       " 'imperial',\n",
       " 'label',\n",
       " 'look',\n",
       " 'point',\n",
       " 'ring',\n",
       " 'u',\n",
       " 'date',\n",
       " 'green',\n",
       " 'early',\n",
       " 'grainy',\n",
       " 'place',\n",
       " 'short',\n",
       " 'life',\n",
       " 'south',\n",
       " \"'ll\",\n",
       " 'molasses',\n",
       " 'enjoyed',\n",
       " 'general',\n",
       " 'university',\n",
       " 'german',\n",
       " 'citrusy',\n",
       " 'said',\n",
       " 'times',\n",
       " 'c',\n",
       " 'series',\n",
       " 'system',\n",
       " 'least',\n",
       " 'land',\n",
       " 'according',\n",
       " 'highly',\n",
       " 'wine',\n",
       " 'tried',\n",
       " 'review',\n",
       " 'extremely',\n",
       " 'frothy',\n",
       " 'clove',\n",
       " 'standard',\n",
       " 'having',\n",
       " 'john',\n",
       " 'easily',\n",
       " 'near',\n",
       " 'british',\n",
       " 'e',\n",
       " 'scent',\n",
       " 'yeasty',\n",
       " 'per',\n",
       " 'form',\n",
       " 'expect',\n",
       " 'coming',\n",
       " 'government',\n",
       " 'own',\n",
       " 'including',\n",
       " 'beautiful',\n",
       " 'start',\n",
       " 'children',\n",
       " 'against',\n",
       " 'held',\n",
       " 'must',\n",
       " 'cap',\n",
       " 'hot',\n",
       " 'given',\n",
       " 'delicious',\n",
       " 'plenty',\n",
       " 'things',\n",
       " 'fluffy',\n",
       " 'above',\n",
       " '12oz',\n",
       " 'township',\n",
       " 'next',\n",
       " 'national',\n",
       " 'pumpkin',\n",
       " 'a-',\n",
       " 'warming',\n",
       " 'mix',\n",
       " 'came',\n",
       " 'special',\n",
       " 'whole',\n",
       " 'home',\n",
       " 'roasty',\n",
       " 'maltiness',\n",
       " 'typical',\n",
       " 'lighter',\n",
       " 'itself',\n",
       " 'done',\n",
       " 'n',\n",
       " 'minimal',\n",
       " 'king',\n",
       " 'school',\n",
       " 'noticeable',\n",
       " 'usually',\n",
       " 'others',\n",
       " 'based',\n",
       " 'else',\n",
       " 's-',\n",
       " 'put',\n",
       " 'cocoa',\n",
       " 't-',\n",
       " 'anything',\n",
       " \"'\",\n",
       " 'cherries',\n",
       " 'century',\n",
       " 'someone',\n",
       " 'list',\n",
       " '2',\n",
       " 'us',\n",
       " 'show',\n",
       " 'ruby',\n",
       " 'local',\n",
       " 'tasted',\n",
       " 'music',\n",
       " 'straw',\n",
       " '$',\n",
       " 'party',\n",
       " 'stuff',\n",
       " 'wonderful',\n",
       " 'unique',\n",
       " 'nutty',\n",
       " 'warm',\n",
       " 'smoke',\n",
       " 'nearly',\n",
       " 'power',\n",
       " 'man',\n",
       " 'let',\n",
       " 'snifter',\n",
       " 'x',\n",
       " 'm-',\n",
       " 'fingers',\n",
       " 'lingers',\n",
       " 'always',\n",
       " 'getting',\n",
       " 'fact',\n",
       " 'complexity',\n",
       " 'bomber',\n",
       " 'sharp',\n",
       " 'french',\n",
       " 'hit',\n",
       " 'making',\n",
       " 'winter',\n",
       " 'gives',\n",
       " 'mixed',\n",
       " 'pepper',\n",
       " 'overly',\n",
       " 'keep',\n",
       " 'opaque',\n",
       " 'within',\n",
       " 'hue',\n",
       " 'base',\n",
       " 'house',\n",
       " 'cream',\n",
       " 'married',\n",
       " 'flavour',\n",
       " 'roast',\n",
       " 'case',\n",
       " 'major',\n",
       " 'fruitiness',\n",
       " 'type',\n",
       " 'super',\n",
       " 'alone',\n",
       " 'born',\n",
       " 'order',\n",
       " 'works',\n",
       " 'trying',\n",
       " 'wood',\n",
       " 'syrupy',\n",
       " 'colour',\n",
       " 'reminds',\n",
       " 'raisins',\n",
       " 'took',\n",
       " 'buy',\n",
       " 'single',\n",
       " 'main',\n",
       " 'set',\n",
       " 'towards',\n",
       " 'game',\n",
       " 'river',\n",
       " 'seen',\n",
       " 'reddish',\n",
       " 'village',\n",
       " 'york',\n",
       " 'went',\n",
       " 'female',\n",
       " 'pick',\n",
       " 'cold',\n",
       " 'texture',\n",
       " 'across',\n",
       " 'african',\n",
       " 'group',\n",
       " 'available',\n",
       " 'backbone',\n",
       " 'native',\n",
       " '1',\n",
       " 'grains',\n",
       " 'race',\n",
       " 'f',\n",
       " 'public',\n",
       " 'ok',\n",
       " 'cinnamon',\n",
       " 'surprisingly',\n",
       " 'become',\n",
       " 'east',\n",
       " 'st',\n",
       " 'dissipates',\n",
       " 'seem',\n",
       " 'despite',\n",
       " 'experience',\n",
       " 'sort',\n",
       " 'bubbly',\n",
       " 'pacific',\n",
       " 'following',\n",
       " 'units',\n",
       " 'layer',\n",
       " 'fizzy',\n",
       " 'book',\n",
       " 'original',\n",
       " 'initial',\n",
       " 'upon',\n",
       " 'hidden',\n",
       " 'fan',\n",
       " 'rye',\n",
       " 'expecting',\n",
       " 'milk',\n",
       " 'gets',\n",
       " 'funk',\n",
       " 'g',\n",
       " 'price',\n",
       " 'amazing',\n",
       " 'weak',\n",
       " 'couple',\n",
       " 'wow',\n",
       " 'spread',\n",
       " 'd-',\n",
       " 'forward',\n",
       " 'mind',\n",
       " 'common',\n",
       " 'picked',\n",
       " 'individuals',\n",
       " 'close',\n",
       " 'oily',\n",
       " 'offering',\n",
       " 'soon',\n",
       " 'ii',\n",
       " 'simple',\n",
       " 'shows',\n",
       " 'feels',\n",
       " 'tartness',\n",
       " 'bottom',\n",
       " 'r',\n",
       " 'edges',\n",
       " 'highlights',\n",
       " 'late',\n",
       " 'asian',\n",
       " 'husband',\n",
       " 'geography',\n",
       " 'law',\n",
       " 'company',\n",
       " 'sourness',\n",
       " 'why',\n",
       " 'metallic',\n",
       " 'barley',\n",
       " 'blend',\n",
       " 'pack',\n",
       " 'among',\n",
       " 'hoppiness',\n",
       " 'pilsner',\n",
       " 'wish',\n",
       " 'overpowering',\n",
       " 'everything',\n",
       " 'completely',\n",
       " 'center',\n",
       " 'toasty',\n",
       " 'spiciness',\n",
       " 'means',\n",
       " 'candy',\n",
       " 'country',\n",
       " 'include',\n",
       " 'true',\n",
       " 'death',\n",
       " 'chewy',\n",
       " 'corn',\n",
       " 'grass',\n",
       " 'island',\n",
       " 'housing',\n",
       " 'term',\n",
       " 'named',\n",
       " 'air',\n",
       " 'glad',\n",
       " 'international',\n",
       " 'bureau',\n",
       " 'open',\n",
       " 'takes',\n",
       " 'higher',\n",
       " 'president',\n",
       " 'ales',\n",
       " 'earth',\n",
       " 'language',\n",
       " 'p',\n",
       " 'l',\n",
       " 'kick',\n",
       " 'sometimes',\n",
       " 'tiny',\n",
       " 'versus',\n",
       " 'popular',\n",
       " 'need',\n",
       " 'settles',\n",
       " 'racial',\n",
       " 'mellow',\n",
       " 'trade',\n",
       " 'intense',\n",
       " 'becomes',\n",
       " \"'re\",\n",
       " 'sides',\n",
       " 'demographics',\n",
       " 'appears',\n",
       " 'peel',\n",
       " 'fantastic',\n",
       " 'fair',\n",
       " 'apples',\n",
       " 'barrel',\n",
       " 'march',\n",
       " 'play',\n",
       " 'image',\n",
       " 'believe',\n",
       " 'hits',\n",
       " 'dense',\n",
       " 'regular',\n",
       " 'booze',\n",
       " 'double',\n",
       " 'couples',\n",
       " 'impressive',\n",
       " 'using',\n",
       " 'none',\n",
       " 'instead',\n",
       " 'capita',\n",
       " 'modern',\n",
       " 'days',\n",
       " 'forms',\n",
       " 'makeup',\n",
       " 'esters',\n",
       " 'tropical',\n",
       " 'considered',\n",
       " 'follows',\n",
       " 'hispanic',\n",
       " 'aged',\n",
       " 'drank',\n",
       " 'liquid',\n",
       " 'coriander',\n",
       " 'bottles',\n",
       " 'residing',\n",
       " 'leave',\n",
       " 'january',\n",
       " 'dipa',\n",
       " 'political',\n",
       " 'awesome',\n",
       " 'latino',\n",
       " 'today',\n",
       " 'church',\n",
       " 'word',\n",
       " 'relatively',\n",
       " 'bottled',\n",
       " 'initially',\n",
       " 'mildly',\n",
       " 'coast',\n",
       " 'surface',\n",
       " 'guess',\n",
       " 'liked',\n",
       " 'able',\n",
       " 'islander',\n",
       " 'began',\n",
       " 'tones',\n",
       " 'stone',\n",
       " 'heat',\n",
       " 'crystal',\n",
       " 'produced',\n",
       " 'months',\n",
       " 'edge',\n",
       " 'released',\n",
       " 'upfront',\n",
       " 'particularly',\n",
       " 'finally',\n",
       " 'peppery',\n",
       " 'members',\n",
       " 'classic',\n",
       " 'generally',\n",
       " 'biscuit',\n",
       " 'minutes',\n",
       " 'july',\n",
       " 'round',\n",
       " 'site',\n",
       " 'official',\n",
       " 'college',\n",
       " 'hand',\n",
       " 'bought',\n",
       " 'damn',\n",
       " 'dominate',\n",
       " 'course',\n",
       " 'pineapple',\n",
       " 'beige',\n",
       " 'flat',\n",
       " 'london',\n",
       " 'past',\n",
       " 'june',\n",
       " 'free',\n",
       " 'boozy',\n",
       " 'sense',\n",
       " 'location',\n",
       " 'syrup',\n",
       " 'brewed',\n",
       " 'tons',\n",
       " 'england',\n",
       " 'food',\n",
       " 'october',\n",
       " 'stouts',\n",
       " 'traditional',\n",
       " 'lasting',\n",
       " 'battle',\n",
       " 'god',\n",
       " 'various',\n",
       " 'brews',\n",
       " 'live',\n",
       " 'covered',\n",
       " 'change',\n",
       " 'darker',\n",
       " 'band',\n",
       " 'sugary',\n",
       " 'immediately',\n",
       " 'simply',\n",
       " 'december',\n",
       " 'call',\n",
       " 'military',\n",
       " 'september',\n",
       " 'lower',\n",
       " 'sticks',\n",
       " 'information',\n",
       " 'recommend',\n",
       " '3',\n",
       " 'cities',\n",
       " 'april',\n",
       " 'la',\n",
       " 'started',\n",
       " 'murky',\n",
       " 'release',\n",
       " 'died',\n",
       " 'feeling',\n",
       " 'funky',\n",
       " 'important',\n",
       " 'added',\n",
       " 'lack',\n",
       " 'otherwise',\n",
       " 'v',\n",
       " 'help',\n",
       " 'lost',\n",
       " 'add',\n",
       " 'slick',\n",
       " 'class',\n",
       " 'august',\n",
       " 'impressed',\n",
       " 'bc',\n",
       " 'further',\n",
       " 'support',\n",
       " 'thus',\n",
       " 'juice',\n",
       " 'control',\n",
       " 'smelled',\n",
       " 'led',\n",
       " 'flavorful',\n",
       " 'apricot',\n",
       " 'dried',\n",
       " 'remains',\n",
       " 'third',\n",
       " 'article',\n",
       " 'combination',\n",
       " 'licorice',\n",
       " 'j',\n",
       " 'addition',\n",
       " 'characteristics',\n",
       " 'rock',\n",
       " 'seemed',\n",
       " 'opinion',\n",
       " 'giving',\n",
       " 'dryness',\n",
       " 'album',\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all['index2word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a9ce14d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all['word2index'][',']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20fa84a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.38027054e-01,  2.39060545e+00, -1.01396251e+00,  1.69249162e-01,\n",
       "        1.96114197e-01, -1.15109585e-01,  8.24877739e-01, -1.55759358e+00,\n",
       "       -2.29276195e-01, -9.80664860e-04,  4.45391178e-01,  5.16192794e-01,\n",
       "       -9.95504916e-01,  2.45408490e-01, -8.56612682e-01,  1.44205511e+00,\n",
       "       -1.22433051e-01, -2.16272026e-01, -2.04418764e-01,  4.06475335e-01,\n",
       "        2.81324887e+00, -9.10368919e-01, -4.36727554e-01,  3.83445323e-01,\n",
       "        7.90370628e-02, -5.34986377e-01,  9.95387256e-01,  1.85926068e+00,\n",
       "        6.98307276e-01,  9.07113433e-01,  1.51528716e+00,  8.76923621e-01,\n",
       "        1.13870457e-01, -8.01007986e-01,  9.25668359e-01,  3.51027548e-01,\n",
       "       -6.76974356e-01, -1.82705462e+00, -9.52161074e-01,  6.80048048e-01,\n",
       "       -5.65241992e-01,  1.15620680e-01,  6.47632629e-02,  1.42970896e+00,\n",
       "        1.26917517e+00, -2.49857068e+00,  2.81687140e-01,  1.51361096e+00,\n",
       "       -5.62527597e-01, -4.73937094e-01,  1.51258504e+00,  7.72027254e-01,\n",
       "        1.40174854e+00, -2.49143735e-01,  8.15885901e-01,  6.51858330e-01,\n",
       "        2.56292880e-01,  8.68666112e-01, -1.97533280e-01,  7.04093099e-01,\n",
       "        5.36014318e-01, -8.82870108e-02, -1.08244829e-02,  9.95587587e-01,\n",
       "       -5.38876414e-01, -7.79014051e-01,  1.14861381e+00,  6.81234181e-01,\n",
       "        1.88986242e-01,  8.15238118e-01, -1.13782835e+00, -1.28598738e+00,\n",
       "        3.96777511e-01,  3.00052953e+00, -7.10697711e-01, -1.23217046e+00,\n",
       "        5.26568770e-01, -1.24329753e-01,  2.30521873e-01, -3.91332239e-01,\n",
       "       -1.03889167e+00,  1.26670092e-01,  1.19109714e+00, -5.83612859e-01,\n",
       "       -3.46510082e-01,  4.67227668e-01,  1.58603227e+00, -1.99093804e-01,\n",
       "        1.36851037e+00, -1.54005989e-01,  2.09348232e-01,  9.56715345e-01,\n",
       "       -2.53131121e-01, -1.20187022e-01,  2.33277515e-01, -1.98168516e-01,\n",
       "        2.13137776e-01,  6.04585886e-01, -1.26855338e+00, -5.07588625e-01,\n",
       "        6.66773438e-01, -1.48330069e+00, -7.68756643e-02,  2.54938632e-01,\n",
       "       -1.62099019e-01, -4.23112869e-01,  1.33998513e-01,  7.87206829e-01,\n",
       "       -1.44481266e+00,  4.22260463e-01, -7.05512092e-02, -7.07300723e-01,\n",
       "        2.64729214e+00,  8.56464803e-01,  4.67127353e-01,  1.23163128e+00,\n",
       "       -6.84219182e-01,  6.11468673e-01, -1.45547032e-01, -1.03928280e+00,\n",
       "        2.71259844e-01, -9.60833907e-01,  6.41797066e-01, -1.73276448e+00,\n",
       "       -4.94975477e-01, -1.06249404e+00, -2.76516825e-01, -6.08884171e-02,\n",
       "       -7.34605968e-01, -1.10017002e-01, -1.63510358e+00, -6.50793910e-01,\n",
       "       -6.29022419e-01, -1.29844868e+00, -2.37402935e-02,  7.99686372e-01,\n",
       "       -1.09578416e-01, -2.59647042e-01,  9.58074778e-02, -4.05199140e-01,\n",
       "       -1.09575713e+00,  1.00315416e+00, -2.34891462e+00,  1.35063434e+00,\n",
       "        2.74725050e-01, -3.46424103e-01, -1.18265581e+00,  1.77796865e+00,\n",
       "       -1.44952461e-01,  5.47085524e-01, -8.53813291e-01, -1.05729008e+00,\n",
       "       -1.57470569e-01, -1.66659904e+00,  6.67930841e-01,  1.52857095e-01,\n",
       "       -5.05118787e-01,  4.82693225e-01, -6.62553728e-01,  1.46029449e+00,\n",
       "       -6.86824203e-01, -2.60939375e-02,  1.69716454e+00, -3.73201996e-01,\n",
       "        4.09608215e-01, -1.57441545e+00, -6.49407089e-01, -2.06445789e+00,\n",
       "        4.45783615e-01, -4.79903489e-01,  6.41254485e-01,  1.51593506e+00,\n",
       "       -2.33164573e+00, -1.25240481e+00,  1.97826073e-01, -1.06475651e+00,\n",
       "        1.92287639e-01,  4.03739393e-01, -7.16037899e-02,  9.11247581e-02,\n",
       "       -3.58602852e-02, -1.72175789e+00,  7.40357399e-01, -1.67360711e+00,\n",
       "        1.00986350e+00, -2.98900992e-01, -6.58375382e-01, -8.49668086e-01,\n",
       "       -5.38015842e-01,  1.02463877e+00,  1.15664959e+00,  5.57690382e-01,\n",
       "       -5.33333063e-01, -2.47079778e+00,  1.00530434e+00, -2.48674795e-01,\n",
       "        8.50136757e-01,  5.28507226e-04, -1.23361623e+00,  9.59082425e-01])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all[\"index2vector\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779b6bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e35be11",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'word2index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-064911fbb1a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword2index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'word2index'"
     ]
    }
   ],
   "source": [
    "class Runner:\n",
    "    def __init__(self):\n",
    "        self.model_path = args['rootDir'] + '/chargemodel_' + args['model_arch'] + '.mdl'\n",
    "\n",
    "    def main(self):\n",
    "\n",
    "        self.textData = TextDataBeer('beer')\n",
    "        # self.start_token = self.textData.word2index['START_TOKEN']\n",
    "        # self.end_token = self.textData.word2index['END_TOKEN']\n",
    "        args['vocabularySize'] = self.textData.getVocabularySize()\n",
    "        args['chargenum'] = 5\n",
    "        args['embeddingSize'] = self.textData.index2vector.shape[1]\n",
    "        print(self.textData.getVocabularySize())\n",
    "        args['model_arch'] = 'lstmibgan'\n",
    "        # args['aspect'] = 0\n",
    "        args['hiddenSize'] = 200\n",
    "\n",
    "        print(args)\n",
    "        if args['model_arch'] == 'lstmibgan':\n",
    "            print('Using LSTM information bottleneck GAN model for Beer.')\n",
    "            LM = torch.load(args['rootDir']+'/LMbeer3.pkl', map_location=args['device'])\n",
    "            for param in LM.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            ppl = self.CalPPL(LM)\n",
    "            print('PPL=',ppl)\n",
    "            # LM=0\n",
    "            LSTM_IB_GAN_beer.train(self.textData, LM, self.textData.index2vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a475658c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80000"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datasets['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d73c3130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[4, 689, 1009, 14, 18, 26, 10, 20, 15, 61, 88,...</td>\n",
       "      <td>[0.3, 0.3, 0.5, 0.3, 0.3]</td>\n",
       "      <td>[the, main, problem, with, this, beer, is, tha...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[15, 10, 29, 6747, 18, 2852, 466, 59, 187, 5, ...</td>\n",
       "      <td>[0.4, 0.4, 0.6, 0.4, 0.6]</td>\n",
       "      <td>[it, is, very, unfortunate, this, situation, w...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[202, 10, 6, 50, 199, 311, 14, 6, 157, 235, 31...</td>\n",
       "      <td>[0.8, 0.5, 0.6, 0.3, 0.4]</td>\n",
       "      <td>[appearance, is, a, light, golden, yellow, wit...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[15, 61, 6, 101, 76, 11, 4, 90, 5, 18, 26, 106...</td>\n",
       "      <td>[0.9, 0.7, 0.4, 0.7, 0.6]</td>\n",
       "      <td>[it, has, a, great, color, to, the, body, ., t...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[181, 18, 26, 10, 7, 56, 913, 7, 28, 398, 7, 1...</td>\n",
       "      <td>[0.8, 0.9, 0.2, 0.3, 0.2]</td>\n",
       "      <td>[though, this, beer, is, ,, or, course, ,, not...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  [4, 689, 1009, 14, 18, 26, 10, 20, 15, 61, 88,...   \n",
       "1  [15, 10, 29, 6747, 18, 2852, 466, 59, 187, 5, ...   \n",
       "2  [202, 10, 6, 50, 199, 311, 14, 6, 157, 235, 31...   \n",
       "3  [15, 61, 6, 101, 76, 11, 4, 90, 5, 18, 26, 106...   \n",
       "4  [181, 18, 26, 10, 7, 56, 913, 7, 28, 398, 7, 1...   \n",
       "\n",
       "                           1  \\\n",
       "0  [0.3, 0.3, 0.5, 0.3, 0.3]   \n",
       "1  [0.4, 0.4, 0.6, 0.4, 0.6]   \n",
       "2  [0.8, 0.5, 0.6, 0.3, 0.4]   \n",
       "3  [0.9, 0.7, 0.4, 0.7, 0.6]   \n",
       "4  [0.8, 0.9, 0.2, 0.3, 0.2]   \n",
       "\n",
       "                                                   2  3  \n",
       "0  [the, main, problem, with, this, beer, is, tha... -1  \n",
       "1  [it, is, very, unfortunate, this, situation, w... -1  \n",
       "2  [appearance, is, a, light, golden, yellow, wit... -1  \n",
       "3  [it, has, a, great, color, to, the, body, ., t... -1  \n",
       "4  [though, this, beer, is, ,, or, course, ,, not... -1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test_df = pd.DataFrame(datasets['train'][0:10])\n",
    "test_df.head()\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c6226d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [4, 689, 1009, 14, 18, 26, 10, 20, 15, 61, 88,...\n",
       "1    [15, 10, 29, 6747, 18, 2852, 466, 59, 187, 5, ...\n",
       "2    [202, 10, 6, 50, 199, 311, 14, 6, 157, 235, 31...\n",
       "3    [15, 61, 6, 101, 76, 11, 4, 90, 5, 18, 26, 106...\n",
       "4    [181, 18, 26, 10, 7, 56, 913, 7, 28, 398, 7, 1...\n",
       "5    [215, 44, 100766, 5, 585, 80, 93, 6, 30, 218, ...\n",
       "6    [1192, 7911, 1082, 953, 106, 75, 2622, 1569, 5...\n",
       "7    [67, 30, 46, 3700, 243, 67, 7, 14, 81, 6, 69, ...\n",
       "8    [106, 36, 8820, 40, 4949, 75, 3929, 387, 3526,...\n",
       "9    [344, 6, 425, 779, 8, 18, 22, 630, 15338, 18, ...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce0f2113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[4, 689, 1009, 14, 18, 26, 10, 20, 15, 61, 88,...</td>\n",
       "      <td>[0.3, 0.3, 0.5, 0.3, 0.3]</td>\n",
       "      <td>[the, main, problem, with, this, beer, is, tha...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[15, 10, 29, 6747, 18, 2852, 466, 59, 187, 5, ...</td>\n",
       "      <td>[0.4, 0.4, 0.6, 0.4, 0.6]</td>\n",
       "      <td>[it, is, very, unfortunate, this, situation, w...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[202, 10, 6, 50, 199, 311, 14, 6, 157, 235, 31...</td>\n",
       "      <td>[0.8, 0.5, 0.6, 0.3, 0.4]</td>\n",
       "      <td>[appearance, is, a, light, golden, yellow, wit...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[15, 61, 6, 101, 76, 11, 4, 90, 5, 18, 26, 106...</td>\n",
       "      <td>[0.9, 0.7, 0.4, 0.7, 0.6]</td>\n",
       "      <td>[it, has, a, great, color, to, the, body, ., t...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[181, 18, 26, 10, 7, 56, 913, 7, 28, 398, 7, 1...</td>\n",
       "      <td>[0.8, 0.9, 0.2, 0.3, 0.2]</td>\n",
       "      <td>[though, this, beer, is, ,, or, course, ,, not...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[215, 44, 100766, 5, 585, 80, 93, 6, 30, 218, ...</td>\n",
       "      <td>[0.8, 0.5, 0.5, 0.4, 0.8]</td>\n",
       "      <td>[best, by, 10/31/10, ., 12oz, bottle, ..., a, ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1192, 7911, 1082, 953, 106, 75, 2622, 1569, 5...</td>\n",
       "      <td>[0.6, 1.0, 0.7, 1.0, 0.8]</td>\n",
       "      <td>[vintage, 07, batch, 3, poured, into, chimay, ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[67, 30, 46, 3700, 243, 67, 7, 14, 81, 6, 69, ...</td>\n",
       "      <td>[1.0, 0.8, 0.6, 0.7, 0.7]</td>\n",
       "      <td>[aroma, :, nice, grapefruity, hoppy, aroma, ,,...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[106, 36, 8820, 40, 4949, 75, 3929, 387, 3526,...</td>\n",
       "      <td>[1.0, 0.6, 1.0, 0.8, 0.9]</td>\n",
       "      <td>[poured, from, taps, at, abc, into, authentic,...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[344, 6, 425, 779, 8, 18, 22, 630, 15338, 18, ...</td>\n",
       "      <td>[0.4, 0.6, 0.4, 0.8, 0.8]</td>\n",
       "      <td>[got, a, 12, pack, of, this, for, $, 10.99, th...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  [4, 689, 1009, 14, 18, 26, 10, 20, 15, 61, 88,...   \n",
       "1  [15, 10, 29, 6747, 18, 2852, 466, 59, 187, 5, ...   \n",
       "2  [202, 10, 6, 50, 199, 311, 14, 6, 157, 235, 31...   \n",
       "3  [15, 61, 6, 101, 76, 11, 4, 90, 5, 18, 26, 106...   \n",
       "4  [181, 18, 26, 10, 7, 56, 913, 7, 28, 398, 7, 1...   \n",
       "5  [215, 44, 100766, 5, 585, 80, 93, 6, 30, 218, ...   \n",
       "6  [1192, 7911, 1082, 953, 106, 75, 2622, 1569, 5...   \n",
       "7  [67, 30, 46, 3700, 243, 67, 7, 14, 81, 6, 69, ...   \n",
       "8  [106, 36, 8820, 40, 4949, 75, 3929, 387, 3526,...   \n",
       "9  [344, 6, 425, 779, 8, 18, 22, 630, 15338, 18, ...   \n",
       "\n",
       "                           1  \\\n",
       "0  [0.3, 0.3, 0.5, 0.3, 0.3]   \n",
       "1  [0.4, 0.4, 0.6, 0.4, 0.6]   \n",
       "2  [0.8, 0.5, 0.6, 0.3, 0.4]   \n",
       "3  [0.9, 0.7, 0.4, 0.7, 0.6]   \n",
       "4  [0.8, 0.9, 0.2, 0.3, 0.2]   \n",
       "5  [0.8, 0.5, 0.5, 0.4, 0.8]   \n",
       "6  [0.6, 1.0, 0.7, 1.0, 0.8]   \n",
       "7  [1.0, 0.8, 0.6, 0.7, 0.7]   \n",
       "8  [1.0, 0.6, 1.0, 0.8, 0.9]   \n",
       "9  [0.4, 0.6, 0.4, 0.8, 0.8]   \n",
       "\n",
       "                                                   2   3  \n",
       "0  [the, main, problem, with, this, beer, is, tha...  -1  \n",
       "1  [it, is, very, unfortunate, this, situation, w...  -1  \n",
       "2  [appearance, is, a, light, golden, yellow, wit...  -1  \n",
       "3  [it, has, a, great, color, to, the, body, ., t...  -1  \n",
       "4  [though, this, beer, is, ,, or, course, ,, not...  -1  \n",
       "5  [best, by, 10/31/10, ., 12oz, bottle, ..., a, ...  -1  \n",
       "6  [vintage, 07, batch, 3, poured, into, chimay, ...  -1  \n",
       "7  [aroma, :, nice, grapefruity, hoppy, aroma, ,,...  -1  \n",
       "8  [poured, from, taps, at, abc, into, authentic,...  -1  \n",
       "9  [got, a, 12, pack, of, this, for, $, 10.99, th...  -1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.asarray(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf93ffa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[202,\n",
       " 57,\n",
       " 296,\n",
       " 148,\n",
       " 27,\n",
       " 4,\n",
       " 294,\n",
       " 5,\n",
       " 6,\n",
       " 2143,\n",
       " 600,\n",
       " 1104,\n",
       " 31,\n",
       " 8,\n",
       " 32,\n",
       " 645,\n",
       " 158,\n",
       " 12,\n",
       " 6,\n",
       " 1449,\n",
       " 1455,\n",
       " 5,\n",
       " 47,\n",
       " 1164,\n",
       " 27,\n",
       " 4,\n",
       " 31,\n",
       " 7,\n",
       " 6,\n",
       " 510,\n",
       " 8,\n",
       " 224,\n",
       " 1523,\n",
       " 280,\n",
       " 492,\n",
       " 23,\n",
       " 466,\n",
       " 357,\n",
       " 5,\n",
       " 67,\n",
       " 57,\n",
       " 134,\n",
       " 4,\n",
       " 299,\n",
       " 381,\n",
       " 155,\n",
       " 443,\n",
       " 67,\n",
       " 23,\n",
       " 4,\n",
       " 1348,\n",
       " 1990,\n",
       " 7,\n",
       " 21,\n",
       " 14,\n",
       " 6,\n",
       " 50,\n",
       " 49629,\n",
       " 97,\n",
       " 893,\n",
       " 5,\n",
       " 43,\n",
       " 57,\n",
       " 47,\n",
       " 237,\n",
       " 597,\n",
       " 63,\n",
       " 7,\n",
       " 37,\n",
       " 47,\n",
       " 133,\n",
       " 123,\n",
       " 12,\n",
       " 977,\n",
       " 7,\n",
       " 343,\n",
       " 12811,\n",
       " 44,\n",
       " 37,\n",
       " 3,\n",
       " 266,\n",
       " 5,\n",
       " 113,\n",
       " 8,\n",
       " 990,\n",
       " 27,\n",
       " 4,\n",
       " 1304,\n",
       " 7,\n",
       " 9,\n",
       " 6,\n",
       " 79,\n",
       " 8,\n",
       " 218,\n",
       " 670,\n",
       " 5,\n",
       " 83,\n",
       " 57,\n",
       " 191,\n",
       " 1732,\n",
       " 7,\n",
       " 293,\n",
       " 6,\n",
       " 60,\n",
       " 54,\n",
       " 5,\n",
       " 325,\n",
       " 62,\n",
       " 7,\n",
       " 126,\n",
       " 118,\n",
       " 5,\n",
       " 183,\n",
       " 57,\n",
       " 4,\n",
       " 215,\n",
       " 1990,\n",
       " 1432,\n",
       " 44,\n",
       " 445,\n",
       " 2093,\n",
       " 5,\n",
       " 2462,\n",
       " 11,\n",
       " 4,\n",
       " 310,\n",
       " 5,\n",
       " 6,\n",
       " 46,\n",
       " 1065,\n",
       " 1230,\n",
       " 128,\n",
       " 5655,\n",
       " 468,\n",
       " 1962,\n",
       " 72,\n",
       " 12,\n",
       " 4,\n",
       " 1621,\n",
       " 3498,\n",
       " 2337,\n",
       " 5]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['dev'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18cc023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the train data seems to be in the form: \n",
    "\n",
    "# index2word, labels, word2index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
