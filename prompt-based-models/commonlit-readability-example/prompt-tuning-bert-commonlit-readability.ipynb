{"cells":[{"cell_type":"markdown","metadata":{},"source":[" <h1 style=\"font-family:verdana;\"> <center>CommonLit Readability:Prompt Tuning BERT</center> </h1>"]},{"cell_type":"markdown","metadata":{},"source":["üìåGPT-2 Fine Tuning:https://www.kaggle.com/shreyasajal/pytorch-openai-gpt2-commonlit-readability"]},{"cell_type":"markdown","metadata":{},"source":["<h4 style=\"font-family:verdana\">\n","    What is Prompt Tuning?<br><br>\n","Prompt-tuning is a simple yet effective mechanism for learning ‚Äúsoft prompts‚Äù to condition frozen language models to perform specific downstream tasks.Soft prompts are learned through backpropagation and can be tuned to incorporate\n","signal from any number of labeled examples. Finally, we show that conditioning,a frozen model with soft prompts confers benefits in robustness to domain transfer, as compared to full model tuning.<br>\n","Instead of modeling classification as the probability of an output class given some input, p(y|X),where X is a series of tokens and y is a single class label, we now model it as conditional generation,where Y is a sequence of tokens that represent a class label.<br>\n","Prompting is the approach of adding extra information for the model to condition on during its generation of Y . Normally, prompting is done by prepending a series of tokens, P, to the input X,such that the model maximizes the likelihood of the\n","correct Y , pŒ∏(Y |[P; X]), while keeping the model parameters, Œ∏, fixed.<br>\n","Given a series of n tokens, {x0, x1, . . . , xn}, the first thing is embedding the tokens, forming a matrix Xe ‚àà Rn√óe where e is the dimension ofthe embedding space. Our soft-prompts are represented as a parameter Pe ‚àà Rp√óe\n",", where p is the length of the prompt. Our prompt is then concatenated to the embedded input forming a single matrix [Pe; Xe] ‚àà R(p+n)√óe\n","    \n"]},{"cell_type":"markdown","metadata":{},"source":["üìå[The Paper:The Power of Scale for Parameter-Efficient Prompt Tuning](https://arxiv.org/pdf/2104.08691v1.pdf)"]},{"cell_type":"markdown","metadata":{},"source":["**NOTE:This notebook mainly illustrates the use of prompt embeddings in tuning your model.I didn't implement freezing because it wasn't giving good results in this case,just using the prompts embeddings worked good .Feel free to fork the notebook and experiment freezing or other things with it.**"]},{"cell_type":"markdown","metadata":{},"source":["# Let's start"]},{"cell_type":"markdown","metadata":{},"source":["\n","<p style=\"color:#159364; font-family:cursive;\">INSTALL THE TRANSFORMERS PACKAGE FROM THE HUGGING FACE LIBRARY</center></p>\n"]},{"cell_type":"code","execution_count":3,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2021-05-22T16:49:57.126565Z","iopub.status.busy":"2021-05-22T16:49:57.126257Z","iopub.status.idle":"2021-05-22T16:50:03.945327Z","shell.execute_reply":"2021-05-22T16:50:03.944387Z","shell.execute_reply.started":"2021-05-22T16:49:57.126537Z"},"trusted":true},"outputs":[],"source":["# !pip install transformers\n","# !pip install plotly"]},{"cell_type":"markdown","metadata":{},"source":["# <p style=\"color:#159364; font-family:cursive;\">IMPORT THE LIBRARIES</center></p>"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2021-05-22T16:50:03.947377Z","iopub.status.busy":"2021-05-22T16:50:03.947016Z","iopub.status.idle":"2021-05-22T16:50:10.809653Z","shell.execute_reply":"2021-05-22T16:50:10.808768Z","shell.execute_reply.started":"2021-05-22T16:50:03.947338Z"},"trusted":true},"outputs":[],"source":["import os\n","import gc\n","import copy\n","import datetime\n","import time\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch.utils.data import Dataset, DataLoader\n","from torch.cuda import amp\n","import transformers\n","from transformers import BertTokenizer,BertForSequenceClassification, BertModel, BertConfig\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from tqdm import tqdm\n","from collections import defaultdict\n","import plotly.graph_objects as go\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import StratifiedKFold, KFold\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n"]},{"cell_type":"markdown","metadata":{},"source":["# <p style=\"color:#159364; font-family:cursive;\">DEFINE PROMPT EMBEDDINGS CLASS</center></p>"]},{"cell_type":"markdown","metadata":{},"source":["Reference:https://github.com/kipgparker/"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2021-05-22T16:50:10.811688Z","iopub.status.busy":"2021-05-22T16:50:10.811378Z","iopub.status.idle":"2021-05-22T16:50:10.82073Z","shell.execute_reply":"2021-05-22T16:50:10.819875Z","shell.execute_reply.started":"2021-05-22T16:50:10.811662Z"},"trusted":true},"outputs":[],"source":["class PROMPTEmbedding(nn.Module):\n","    def __init__(self, \n","                wte: nn.Embedding,\n","                n_tokens: int = 10, \n","                random_range: float = 0.5,\n","                initialize_from_vocab: bool = True):\n","        super(PROMPTEmbedding, self).__init__()\n","        self.wte = wte\n","        self.n_tokens = n_tokens\n","        self.learned_embedding = nn.parameter.Parameter(self.initialize_embedding(wte,\n","                                                                               n_tokens, \n","                                                                               random_range, \n","                                                                               initialize_from_vocab))\n","            \n","    def initialize_embedding(self, \n","                             wte: nn.Embedding,\n","                             n_tokens: int = 10, \n","                             random_range: float = 0.5, \n","                             initialize_from_vocab: bool = True):\n","        if initialize_from_vocab:\n","            return self.wte.weight[:n_tokens].clone().detach()\n","        return torch.FloatTensor(wte.weight.size(1), n_tokens).uniform_(-random_range, random_range)\n","            \n","    def forward(self, tokens):\n","        print(f\"inside prompt embeddings class, original tokens: {tokens}\")\n","        input_embedding = self.wte(tokens[:, self.n_tokens:])\n","        print(f\"intput_embeddings shape: {input_embedding.shape}\")\n","        learned_embedding = self.learned_embedding.repeat(input_embedding.size(0), 1, 1)\n","        return torch.cat([learned_embedding, input_embedding], 1)"]},{"cell_type":"markdown","metadata":{},"source":["# <p style=\"color:#159364; font-family:cursive;\">LOOK AT THE DATA</center></p>"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2021-05-22T16:50:10.822854Z","iopub.status.busy":"2021-05-22T16:50:10.822316Z","iopub.status.idle":"2021-05-22T16:50:10.944014Z","shell.execute_reply":"2021-05-22T16:50:10.943074Z","shell.execute_reply.started":"2021-05-22T16:50:10.822818Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of training sentences: 2,834\n","\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>url_legal</th>\n","      <th>license</th>\n","      <th>excerpt</th>\n","      <th>target</th>\n","      <th>standard_error</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>485</th>\n","      <td>7bcdf0b70</td>\n","      <td>https://simple.wikipedia.org/wiki/Middle_Ages</td>\n","      <td>CC BY-SA 3.0 and GFDL</td>\n","      <td>The Middle Ages are a time period in European ...</td>\n","      <td>-0.929455</td>\n","      <td>0.464225</td>\n","    </tr>\n","    <tr>\n","      <th>2582</th>\n","      <td>097311017</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>After they had eaten all they wanted, they tho...</td>\n","      <td>-0.572768</td>\n","      <td>0.476274</td>\n","    </tr>\n","    <tr>\n","      <th>1807</th>\n","      <td>fb13e084e</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>It is now a well established fact that matter,...</td>\n","      <td>-2.115730</td>\n","      <td>0.509237</td>\n","    </tr>\n","    <tr>\n","      <th>392</th>\n","      <td>438d0393b</td>\n","      <td>https://simple.wikipedia.org/wiki/Glucose</td>\n","      <td>CC BY-SA 3.0 and GFDL</td>\n","      <td>Glucose is a simple carbohydrate, or sugar. It...</td>\n","      <td>0.104885</td>\n","      <td>0.490678</td>\n","    </tr>\n","    <tr>\n","      <th>2277</th>\n","      <td>eb57cde1c</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>History in its broadest aspect is a record of ...</td>\n","      <td>-2.186442</td>\n","      <td>0.535444</td>\n","    </tr>\n","    <tr>\n","      <th>2088</th>\n","      <td>7c053644e</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>In another moment down went Alice after it, ne...</td>\n","      <td>-0.274541</td>\n","      <td>0.460605</td>\n","    </tr>\n","    <tr>\n","      <th>239</th>\n","      <td>bf1f402ca</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>\"When you want a thing done well, do it yourse...</td>\n","      <td>-0.426813</td>\n","      <td>0.478220</td>\n","    </tr>\n","    <tr>\n","      <th>2551</th>\n","      <td>82486c2a2</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Ceasing his restless walk up and down the room...</td>\n","      <td>-0.158522</td>\n","      <td>0.495309</td>\n","    </tr>\n","    <tr>\n","      <th>1659</th>\n","      <td>3974b08a4</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>In compound lenses the matter is complicated b...</td>\n","      <td>-2.014504</td>\n","      <td>0.519803</td>\n","    </tr>\n","    <tr>\n","      <th>2054</th>\n","      <td>4625afea0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>I had finished eating my dinner, set my pail u...</td>\n","      <td>0.255064</td>\n","      <td>0.490130</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             id                                      url_legal  \\\n","485   7bcdf0b70  https://simple.wikipedia.org/wiki/Middle_Ages   \n","2582  097311017                                            NaN   \n","1807  fb13e084e                                            NaN   \n","392   438d0393b      https://simple.wikipedia.org/wiki/Glucose   \n","2277  eb57cde1c                                            NaN   \n","2088  7c053644e                                            NaN   \n","239   bf1f402ca                                            NaN   \n","2551  82486c2a2                                            NaN   \n","1659  3974b08a4                                            NaN   \n","2054  4625afea0                                            NaN   \n","\n","                    license  \\\n","485   CC BY-SA 3.0 and GFDL   \n","2582                    NaN   \n","1807                    NaN   \n","392   CC BY-SA 3.0 and GFDL   \n","2277                    NaN   \n","2088                    NaN   \n","239                     NaN   \n","2551                    NaN   \n","1659                    NaN   \n","2054                    NaN   \n","\n","                                                excerpt    target  \\\n","485   The Middle Ages are a time period in European ... -0.929455   \n","2582  After they had eaten all they wanted, they tho... -0.572768   \n","1807  It is now a well established fact that matter,... -2.115730   \n","392   Glucose is a simple carbohydrate, or sugar. It...  0.104885   \n","2277  History in its broadest aspect is a record of ... -2.186442   \n","2088  In another moment down went Alice after it, ne... -0.274541   \n","239   \"When you want a thing done well, do it yourse... -0.426813   \n","2551  Ceasing his restless walk up and down the room... -0.158522   \n","1659  In compound lenses the matter is complicated b... -2.014504   \n","2054  I had finished eating my dinner, set my pail u...  0.255064   \n","\n","      standard_error  \n","485         0.464225  \n","2582        0.476274  \n","1807        0.509237  \n","392         0.490678  \n","2277        0.535444  \n","2088        0.460605  \n","239         0.478220  \n","2551        0.495309  \n","1659        0.519803  \n","2054        0.490130  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["data_dir = \"../../data/commonlitreadabilityprize\"\n","df = pd.read_csv(f\"{data_dir}/train.csv\")\n","test_df = pd.read_csv(f\"{data_dir}/test.csv\",usecols=[\"id\",\"excerpt\"])\n","print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n","df.sample(10)"]},{"cell_type":"markdown","metadata":{},"source":["# <p style=\"color:#159364; font-family:cursive;\">A BIT OF PREPROCESSING</center></p>"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2021-05-22T16:50:10.945918Z","iopub.status.busy":"2021-05-22T16:50:10.945517Z","iopub.status.idle":"2021-05-22T16:50:10.967233Z","shell.execute_reply":"2021-05-22T16:50:10.966063Z","shell.execute_reply.started":"2021-05-22T16:50:10.945875Z"},"trusted":true},"outputs":[],"source":["def prep_text(text_df):\n","    text_df = text_df.str.replace(\"\\n\",\"\",regex=False) \n","    return text_df.str.replace(\"\\'s\",r\"s\",regex=True).values\n","df[\"excerpt\"] = prep_text(df[\"excerpt\"])\n","test_df[\"excerpt\"] = prep_text(test_df[\"excerpt\"])"]},{"cell_type":"markdown","metadata":{},"source":["# <p style=\"color:#159364; font-family:cursive;\">CREATE FOLDS</center></p>"]},{"cell_type":"markdown","metadata":{},"source":["Code taken from:https://www.kaggle.com/abhishek/step-1-create-folds"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2021-05-22T16:50:10.969447Z","iopub.status.busy":"2021-05-22T16:50:10.969015Z","iopub.status.idle":"2021-05-22T16:50:10.992465Z","shell.execute_reply":"2021-05-22T16:50:10.991575Z","shell.execute_reply.started":"2021-05-22T16:50:10.96939Z"},"trusted":true},"outputs":[],"source":["def create_folds(data, num_splits):\n","    # we create a new column called kfold and fill it with -1\n","    data[\"kfold\"] = -1\n","    \n","    # the next step is to randomize the rows of the data\n","    data = data.sample(frac=1).reset_index(drop=True)\n","\n","    # calculate number of bins by Sturge's rule\n","    # I take the floor of the value, you can also\n","    # just round it\n","    num_bins = int(np.floor(1 + np.log2(len(data))))\n","    \n","    # bin targets\n","    data.loc[:, \"bins\"] = pd.cut(\n","        data[\"target\"], bins=num_bins, labels=False\n","    )\n","    \n","    # initiate the kfold class from model_selection module\n","    kf = StratifiedKFold(n_splits=num_splits)\n","    \n","    # fill the new kfold column\n","    # note that, instead of targets, we use bins!\n","    for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)):\n","        data.loc[v_, 'kfold'] = f\n","    \n","    # drop the bins column\n","    data = data.drop(\"bins\", axis=1)\n","\n","    # return dataframe with folds\n","    return data\n","\n","\n","# create folds\n","df = create_folds(df, num_splits=5)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>url_legal</th>\n","      <th>license</th>\n","      <th>excerpt</th>\n","      <th>target</th>\n","      <th>standard_error</th>\n","      <th>kfold</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>55990b441</td>\n","      <td>https://kids.frontiersin.org/article/10.3389/f...</td>\n","      <td>CC BY 4.0</td>\n","      <td>The previous arthropods may seem pretty harmle...</td>\n","      <td>-1.179180</td>\n","      <td>0.464665</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3efb796e2</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>But at length, one night, as Hilarion heard th...</td>\n","      <td>-2.086623</td>\n","      <td>0.512389</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>b300ba844</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>In many industries there are operations that h...</td>\n","      <td>-1.933358</td>\n","      <td>0.488522</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>08aa1ae28</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>In another instant, however, the girls attenti...</td>\n","      <td>-0.506932</td>\n","      <td>0.480851</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>8be3592cf</td>\n","      <td>https://kids.frontiersin.org/article/10.3389/f...</td>\n","      <td>CC BY 4.0</td>\n","      <td>What actually happens when parts of the brain ...</td>\n","      <td>-0.556070</td>\n","      <td>0.525426</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5e854dab8</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>He was a very selfish Giant.The poor children ...</td>\n","      <td>-0.057944</td>\n","      <td>0.504743</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>2defec2e6</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>The two lads had come to a halt on the road ab...</td>\n","      <td>-1.075147</td>\n","      <td>0.475292</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7448774f1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Four days on the Platte, and yet no buffalo! L...</td>\n","      <td>-1.059063</td>\n","      <td>0.450921</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>3b1faa196</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>The first two weeks at Overton glided by with ...</td>\n","      <td>-1.717180</td>\n","      <td>0.516009</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>37567968b</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Our first domestic war loan of ¬£6,000 was made...</td>\n","      <td>-1.683823</td>\n","      <td>0.476443</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          id                                          url_legal    license  \\\n","0  55990b441  https://kids.frontiersin.org/article/10.3389/f...  CC BY 4.0   \n","1  3efb796e2                                                NaN        NaN   \n","2  b300ba844                                                NaN        NaN   \n","3  08aa1ae28                                                NaN        NaN   \n","4  8be3592cf  https://kids.frontiersin.org/article/10.3389/f...  CC BY 4.0   \n","5  5e854dab8                                                NaN        NaN   \n","6  2defec2e6                                                NaN        NaN   \n","7  7448774f1                                                NaN        NaN   \n","8  3b1faa196                                                NaN        NaN   \n","9  37567968b                                                NaN        NaN   \n","\n","                                             excerpt    target  \\\n","0  The previous arthropods may seem pretty harmle... -1.179180   \n","1  But at length, one night, as Hilarion heard th... -2.086623   \n","2  In many industries there are operations that h... -1.933358   \n","3  In another instant, however, the girls attenti... -0.506932   \n","4  What actually happens when parts of the brain ... -0.556070   \n","5  He was a very selfish Giant.The poor children ... -0.057944   \n","6  The two lads had come to a halt on the road ab... -1.075147   \n","7  Four days on the Platte, and yet no buffalo! L... -1.059063   \n","8  The first two weeks at Overton glided by with ... -1.717180   \n","9  Our first domestic war loan of ¬£6,000 was made... -1.683823   \n","\n","   standard_error  kfold  \n","0        0.464665      0  \n","1        0.512389      0  \n","2        0.488522      0  \n","3        0.480851      0  \n","4        0.525426      0  \n","5        0.504743      0  \n","6        0.475292      0  \n","7        0.450921      0  \n","8        0.516009      0  \n","9        0.476443      0  "]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df.head(10)"]},{"cell_type":"markdown","metadata":{},"source":["# <p style=\"color:#159364; font-family:cursive;\">TRAINING CONFIGURATION</center></p>"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2021-05-22T16:50:10.995423Z","iopub.status.busy":"2021-05-22T16:50:10.994851Z","iopub.status.idle":"2021-05-22T16:50:14.837561Z","shell.execute_reply":"2021-05-22T16:50:14.836709Z","shell.execute_reply.started":"2021-05-22T16:50:10.995382Z"},"trusted":true},"outputs":[],"source":["class CONFIG:\n","    gpu_num = 0\n","    seed = 42\n","    max_len = 331\n","    train_batch = 16\n","    valid_batch = 32\n","    epochs = 10\n","    n_tokens=20\n","    learning_rate = 2e-5\n","    splits = 5\n","    scaler = amp.GradScaler()\n","    model='bert-base-cased'\n","    tokenizer = BertTokenizer.from_pretrained(model, do_lower_case=True)\n","    tokenizer.save_pretrained('./tokenizer')\n","    device = torch.device(f'cuda:{gpu_num}' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["device(type='cuda', index=0)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["CONFIG.device"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["'NVIDIA GeForce GTX 1050 Ti with Max-Q Design'"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.get_device_name()"]},{"cell_type":"markdown","metadata":{},"source":["# <p style=\"color:#159364; font-family:cursive;\">REPRODUCIBILITY</center></p>"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2021-05-22T16:50:14.840845Z","iopub.status.busy":"2021-05-22T16:50:14.840478Z","iopub.status.idle":"2021-05-22T16:50:14.84852Z","shell.execute_reply":"2021-05-22T16:50:14.847706Z","shell.execute_reply.started":"2021-05-22T16:50:14.840806Z"},"trusted":true},"outputs":[],"source":["def set_seed(seed = CONFIG.seed):\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","set_seed(CONFIG.seed)"]},{"cell_type":"markdown","metadata":{},"source":["# <p style=\"color:#159364; font-family:cursive;\">DEFINE THE DATASET CLASS</center></p>"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2021-05-22T16:50:14.850557Z","iopub.status.busy":"2021-05-22T16:50:14.850199Z","iopub.status.idle":"2021-05-22T16:50:14.860018Z","shell.execute_reply":"2021-05-22T16:50:14.859017Z","shell.execute_reply.started":"2021-05-22T16:50:14.85052Z"},"trusted":true},"outputs":[],"source":["class BERTDataset(Dataset):\n","    def __init__(self,df):\n","        self.text = df['excerpt'].values\n","        self.target = df['target'].values\n","        self.max_len = CONFIG.max_len\n","        self.tokenizer = CONFIG.tokenizer\n","        self.n_tokens=CONFIG.n_tokens\n","        \n","    def __len__(self):\n","        return len(self.text)\n","    \n","    def __getitem__(self, index):\n","        text = self.text[index]\n","        text = ' '.join(text.split())\n","        inputs = self.tokenizer.encode_plus(\n","            text,\n","            None,\n","            truncation=True,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            padding='max_length',\n","            return_token_type_ids=True\n","        )\n","        org_input_ids = inputs['input_ids']\n","        inputs['input_ids']=torch.cat((torch.full((1,self.n_tokens), 500).resize(CONFIG.n_tokens),torch.tensor(inputs['input_ids'], dtype=torch.long)))\n","        inputs['attention_mask'] = torch.cat((torch.full((1,self.n_tokens), 1).resize(CONFIG.n_tokens), torch.tensor(inputs['attention_mask'], dtype=torch.long)))\n","\n","        return {\n","            'ids': inputs['input_ids'],\n","            'mask': inputs['attention_mask'],\n","    \n","            'target': torch.tensor(self.target[index], dtype=torch.float),\n","            'org_ids': org_input_ids\n","        }\n","    "]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"data":{"text/plain":["{'ids': tensor([  500,   500,   500,   500,   500,   500,   500,   500,   500,   500,\n","           500,   500,   500,   500,   500,   500,   500,   500,   500,   500,\n","           101,  1107,  1242,  7519,  1175,  1132,  2500,  1115,  1138,  1106,\n","          1129,  4892,  1120,  2366, 14662,   117,  1105,   117,  1111,  1142,\n","          2255,   117,  1103,  2058,  1104,  1126, 16486,  1111,  2368,   170,\n","          4344,   117,  1136,  1178,  1120,  1103,  2396,  4275,   117,  1133,\n","          1145,  1120,  4463, 14662,   117,  1110,   170,  2187,  1104,  2199,\n","           119,  1103,  2304,  1104,  1833,  1142,  1144,  1151, 13785,  1107,\n","           170,  1304, 12002,  1236,  1118,   182,  1197,   119, 27466,  7580,\n","          1107,  1103, 11918,  1104,  1103, 16486,   119,  1122,  2923,  1104,\n","           170,  4705,  2133, 17693,  1110,  2136,  1114,   170,  1326,  1104,\n","          1353, 18607,   119,  1103,  1493,  1132, 22233,  8360,  1121,  1103,\n","          1692,  1105, 10621,  1114,  1141,  1104,  1103, 16739,  1104,   170,\n","          8501,  4049,  1107,  1103,  2884,   119,  1103,  1692,  1110,  3387,\n","          1114,  1103,  1168,  7712,   119,   170,  1353,   191, 27885,  7315,\n","          1110,  9455, 13541,  1107,  1103,  6090,   119,  1191,  1122,  1129,\n","          8759,  1106,  6268,   170,  4344,  1120,   170,  2218,  2396,   117,\n","          1103,  7671, 10473,  1110, 13137,   117,  1105,  1103,  1289,  1852,\n","          6893,  1142, 15336,  1103,  6090,   117,  1105,  1103,  7315,  8374,\n","           119,  1103,  7315,  1110, 15869,  1107,  1665, 20316,  1181,  1439,\n","          1103,  2884,   119,  1175,  1132,  1160, 10389,  1104, 18607,   118,\n","           118,  1141,  1104,  1172,  1111,  2005,   117,  1105,  1103,  1168,\n","          1111,  1904,   119,  1152,  1132, 22445,  2452,  1106,  5420,   119,\n","           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0]),\n"," 'mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n"," 'target': tensor(-1.9334),\n"," 'org_ids': [101,\n","  1107,\n","  1242,\n","  7519,\n","  1175,\n","  1132,\n","  2500,\n","  1115,\n","  1138,\n","  1106,\n","  1129,\n","  4892,\n","  1120,\n","  2366,\n","  14662,\n","  117,\n","  1105,\n","  117,\n","  1111,\n","  1142,\n","  2255,\n","  117,\n","  1103,\n","  2058,\n","  1104,\n","  1126,\n","  16486,\n","  1111,\n","  2368,\n","  170,\n","  4344,\n","  117,\n","  1136,\n","  1178,\n","  1120,\n","  1103,\n","  2396,\n","  4275,\n","  117,\n","  1133,\n","  1145,\n","  1120,\n","  4463,\n","  14662,\n","  117,\n","  1110,\n","  170,\n","  2187,\n","  1104,\n","  2199,\n","  119,\n","  1103,\n","  2304,\n","  1104,\n","  1833,\n","  1142,\n","  1144,\n","  1151,\n","  13785,\n","  1107,\n","  170,\n","  1304,\n","  12002,\n","  1236,\n","  1118,\n","  182,\n","  1197,\n","  119,\n","  27466,\n","  7580,\n","  1107,\n","  1103,\n","  11918,\n","  1104,\n","  1103,\n","  16486,\n","  119,\n","  1122,\n","  2923,\n","  1104,\n","  170,\n","  4705,\n","  2133,\n","  17693,\n","  1110,\n","  2136,\n","  1114,\n","  170,\n","  1326,\n","  1104,\n","  1353,\n","  18607,\n","  119,\n","  1103,\n","  1493,\n","  1132,\n","  22233,\n","  8360,\n","  1121,\n","  1103,\n","  1692,\n","  1105,\n","  10621,\n","  1114,\n","  1141,\n","  1104,\n","  1103,\n","  16739,\n","  1104,\n","  170,\n","  8501,\n","  4049,\n","  1107,\n","  1103,\n","  2884,\n","  119,\n","  1103,\n","  1692,\n","  1110,\n","  3387,\n","  1114,\n","  1103,\n","  1168,\n","  7712,\n","  119,\n","  170,\n","  1353,\n","  191,\n","  27885,\n","  7315,\n","  1110,\n","  9455,\n","  13541,\n","  1107,\n","  1103,\n","  6090,\n","  119,\n","  1191,\n","  1122,\n","  1129,\n","  8759,\n","  1106,\n","  6268,\n","  170,\n","  4344,\n","  1120,\n","  170,\n","  2218,\n","  2396,\n","  117,\n","  1103,\n","  7671,\n","  10473,\n","  1110,\n","  13137,\n","  117,\n","  1105,\n","  1103,\n","  1289,\n","  1852,\n","  6893,\n","  1142,\n","  15336,\n","  1103,\n","  6090,\n","  117,\n","  1105,\n","  1103,\n","  7315,\n","  8374,\n","  119,\n","  1103,\n","  7315,\n","  1110,\n","  15869,\n","  1107,\n","  1665,\n","  20316,\n","  1181,\n","  1439,\n","  1103,\n","  2884,\n","  119,\n","  1175,\n","  1132,\n","  1160,\n","  10389,\n","  1104,\n","  18607,\n","  118,\n","  118,\n","  1141,\n","  1104,\n","  1172,\n","  1111,\n","  2005,\n","  117,\n","  1105,\n","  1103,\n","  1168,\n","  1111,\n","  1904,\n","  119,\n","  1152,\n","  1132,\n","  22445,\n","  2452,\n","  1106,\n","  5420,\n","  119,\n","  102,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0,\n","  0]}"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset = BERTDataset(df)\n","train_dataset.__getitem__(2)"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([20])"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["torch.cat((torch.full((1,20),500),"]},{"cell_type":"markdown","metadata":{},"source":["# <p style=\"color:#159364; font-family:cursive;\">MODEL:BERT FOR SEQUENCE CLASSIFICATION from ü§ó </center></p>"]},{"cell_type":"markdown","metadata":{},"source":["<p style=\"color:#159364; font-family:cursive;\">With prompt embeddings in the input,and all the layers have requires_grad True,you can try layer freezing as well\n","</center></p>\n"]},{"cell_type":"code","execution_count":10,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2021-05-22T16:50:14.862125Z","iopub.status.busy":"2021-05-22T16:50:14.861527Z","iopub.status.idle":"2021-05-22T16:50:36.577927Z","shell.execute_reply":"2021-05-22T16:50:36.577122Z","shell.execute_reply.started":"2021-05-22T16:50:14.862085Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): PROMPTEmbedding(\n","        (wte): Embedding(30522, 768, padding_idx=0)\n","      )\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",")"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["model = BertForSequenceClassification.from_pretrained(\n","    \"bert-base-uncased\",\n","    num_labels = 1,\n","    output_attentions = False,\n","    output_hidden_states = False, \n",")\n","\n","original_emb = model.get_input_embeddings()\n","prompt_emb = PROMPTEmbedding(model.get_input_embeddings(), \n","                      n_tokens=20, \n","                      initialize_from_vocab=True)\n","model.set_input_embeddings(prompt_emb)\n","model.cuda()"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["Embedding(30522, 768, padding_idx=0)"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["original_emb"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/plain":["Parameter containing:\n","tensor([[-0.0102, -0.0615, -0.0265,  ..., -0.0199, -0.0372, -0.0098],\n","        [-0.0117, -0.0600, -0.0323,  ..., -0.0168, -0.0401, -0.0107],\n","        [-0.0198, -0.0627, -0.0326,  ..., -0.0165, -0.0420, -0.0032],\n","        ...,\n","        [-0.0210, -0.0524, -0.0289,  ..., -0.0206, -0.0384, -0.0176],\n","        [-0.0098, -0.0563, -0.0322,  ..., -0.0215, -0.0314, -0.0087],\n","        [-0.0166, -0.0492, -0.0288,  ..., -0.0235, -0.0364, -0.0148]],\n","       device='cuda:0', requires_grad=True)"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["prompt_emb.learned_embedding"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([20, 768])"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["model.bert.embeddings.word_embeddings.learned_embedding.shape"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["PROMPTEmbedding(\n","  (wte): Embedding(30522, 768, padding_idx=0)\n",")"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["model.bert.embeddings.word_embeddings.learned_embedding.requires_grad"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["odict_keys(['bert.embeddings.position_ids', 'bert.embeddings.word_embeddings.learned_embedding', 'bert.embeddings.word_embeddings.wte.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.weight', 'classifier.bias'])"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["para_dict = model.state_dict()\n","# para_dict.keys()"]},{"cell_type":"markdown","metadata":{},"source":["# <p style=\"color:#159364; font-family:cursive;\">GET THE PREPARED DATA</center></p>"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2021-05-22T16:50:36.579451Z","iopub.status.busy":"2021-05-22T16:50:36.579129Z","iopub.status.idle":"2021-05-22T16:50:36.585436Z","shell.execute_reply":"2021-05-22T16:50:36.584658Z","shell.execute_reply.started":"2021-05-22T16:50:36.579421Z"},"trusted":true},"outputs":[],"source":["def get_data(fold):\n","    df_train = df[df.kfold != fold].reset_index(drop=True)\n","    df_valid = df[df.kfold == fold].reset_index(drop=True)\n","    \n","    train_dataset = BERTDataset(df_train)\n","    valid_dataset = BERTDataset(df_valid)\n","\n","    train_loader = DataLoader(train_dataset, batch_size=CONFIG.train_batch, \n","                              num_workers=0, shuffle=True, pin_memory=True)\n","    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG.valid_batch, \n","                              num_workers=0, shuffle=False, pin_memory=True)\n","    \n","    return train_loader, valid_loader"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["array(['One old woman especially loved the smells that drifted out of the bakery window every morning. This was Ma Shange who slept on a bench in the park every night. A few weeks before, a kind person had given her the money to buy herself a cinnamon bun. She had taken the bun back to the park and ate it very slowly, licking her lips and sharing the last crumbs with the birds. After that, although the old woman didn\\'t have enough money to buy breakfast, she longed for the delicious bun again. So, every morning she walked slowly past Mr Shabangus bakery, sniffing the air and smiling blissfully at the mouth-watering smell. Ma Shanges new habit made the baker very angry. As each day went by, he grew angrier and angrier with her. Finally, one winter morning when he was in an especially bad mood, he stormed out of his bakery and grabbed the old woman by the arm. \"How dare you steal my smells!\" he shouted. \"You\\'re nothing but a smell thief!\" He wiped his hands on an apron, then pulled it off and threw it back into the bakery.',\n","       \"Once upon a time, in Joburgs Orange Grove, a little girl called Phyllis was born into the world. Two people in love hugged their sweet little babe. No one knew, then, what a dancer they'd made. By the time she was four, she had learned very quick. She impressed all her teachers with her ducky feet flicks! Before school and after, she danced every day. Nothing pleased Phyllis more than ballet. When the world was ready for Phyllis at fifteen, she arrived in big, old London, ready to live her dream. She said goodbye to all her friends. She was ready to start fresh. Watch out, Royal Ballet School! Phyllis is here to impress. When Phyllis danced Swan Lake, it was fit to show the Queen! After years of pirouetting, she was ready to be seen. Dancing for the audience, she turned and twirled about. Look! Everyone is smiling! See how they clap and shout!\",\n","       'Abel had no driver for his new cart. He said to his sister Meri, \"I want a driver for my cart. Please give me your doll. She can sit in the cart.\" But Meri said, \"No, I want my doll.\" When Meri would not let him take the doll, Abel was very angry. He grabbed the doll and pulled her. Meri pulled the dolls other arm. Abel pulled and Meri pulled. The dolls arm came off! Meri cried and ran to her mother. \"Look Mother,\" she said, \"Abel pulled my dolls arm and it came off. He wanted my doll to sit in his new cart, but I wanted to play with her.\" Her mother said, \"Abel did not behave well.\" Mother thought about how to teach her son not to touch his sisters toys. She had an idea. She went to her friend who was a doctor and she asked, \"I want you to help me please.\" The doctor replied, \"How can I help, my friend?\" Mother answered, \"My son Abel is behaving badly these days. He pulled the arm off his sisters doll. He must not do that.',\n","       ...,\n","       'Now, it happened a long time ago, in the year ‚Äî‚Äî, but the exact year does not matter, because you will not find this story written in the history of any of the nations of the world. But in one of the countries of Europe bordering on the Mediterranean Sea was a lofty mountain, which, to the dwellers in the plains below, seemed to reach to the very sky. At times its summit was covered with clouds, so that it could not be seen; at other times it stood out fair and clear, as though silently asking the people to look up and not down. The lower slopes of the mountain were covered with olive trees, with groves of oranges and lemons, and with vineyards, and they were dotted here and there with the little white cottages of the peasants who made their living from these groves and vineyards, the fruit of which they sold in the city not far away.',\n","       'There are various types of mechanoreceptors (receptors concerned with touch). In the hairy skin, the hair follicle receptor is the main mechanoreceptor. In addition, the hairy skin contains fibers that respond well to slow stroking with a soft brush, and stimulation of these fibers results in an experience of pleasant touch. The non-hairy skin contains four main types of mechanoreceptors, which can be divided into two functional groups. The first group contains fast adapting mechanoreceptors, which respond only at onset, and frequently at the end, of a touch, but not in between. The second group consists of slowly adapting mechanoreceptors, which respond slowly to the onset of a touch, but continue to respond during the middle. The density of mechanoreceptors varies in different parts of the body. Within the hand, the highest density of receptors is found in the fingertips. The higher the density of mechanoreceptors, the smaller the distance between two touches that can be distinguished.',\n","       'Blondin, the celebrated tight-rope walker, has just died in London, at the age of seventy-three.The performance which made him famous was the crossing of Niagara Falls on the tight-rope.Blondin was a Frenchman, his father having been one of Napoleons soldiers.A story is told of him that when he was five years old he saw an acrobat performing on a tight-rope.He was so pleased with what he saw, that when he got home he stretched a rope between two posts, and, as soon as his mother was out of the way, took his fathers fishing-rod, and, using it as a balancing pole, made his first appearance as a tight-rope walker.He was trained for an acrobat and tight-rope walking, and came to this country with a troup of pantomimists.While here he visited Niagara Falls, and the idea at once struck him that, if he dared to cross those terrible waters on a rope, his fortune would be made. He made up his mind to try it, and stayed in the village of Niagara for weeks, until he had learned just how it would be possible for him to perform the feat.'],\n","      dtype=object)"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["train_testing = BERTDataset(df[df.kfold != 0].reset_index(drop=True))\n","train_testing.text"]},{"cell_type":"markdown","metadata":{},"source":["# <p style=\"color:#159364; font-family:cursive;\">FOLD:0</center></p>"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2021-05-22T16:50:36.587425Z","iopub.status.busy":"2021-05-22T16:50:36.586748Z","iopub.status.idle":"2021-05-22T16:50:36.61847Z","shell.execute_reply":"2021-05-22T16:50:36.617777Z","shell.execute_reply.started":"2021-05-22T16:50:36.587384Z"},"trusted":true},"outputs":[{"data":{"text/plain":["142"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["train_dataloader,validation_dataloader=get_data(0)\n","len(train_dataloader)"]},{"cell_type":"markdown","metadata":{},"source":["# <p style=\"color:#159364; font-family:cursive;\">OPTIMIZER</center></p>"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2021-05-22T16:50:36.620027Z","iopub.status.busy":"2021-05-22T16:50:36.619667Z","iopub.status.idle":"2021-05-22T16:50:36.631474Z","shell.execute_reply":"2021-05-22T16:50:36.630627Z","shell.execute_reply.started":"2021-05-22T16:50:36.619993Z"},"trusted":true},"outputs":[],"source":["param_optimizer = list(model.named_parameters())\n","no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","optimizer_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \n","     'weight_decay': 0.0001},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n","     'weight_decay': 0.0}\n","    ]  \n","\n","optimizer = AdamW(optimizer_parameters, lr=CONFIG.learning_rate)\n"]},{"cell_type":"markdown","metadata":{},"source":["# <p style=\"color:#159364; font-family:cursive;\">LEARNING RATE SCHEDULER</center></p>"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2021-05-22T16:50:36.633396Z","iopub.status.busy":"2021-05-22T16:50:36.632764Z","iopub.status.idle":"2021-05-22T16:50:37.39326Z","shell.execute_reply":"2021-05-22T16:50:37.392405Z","shell.execute_reply.started":"2021-05-22T16:50:36.633358Z"},"trusted":true},"outputs":[{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"mode":"lines+markers","name":"Learning_rate","type":"scatter","x":[0,1,2,3,4,5,6,7,8,9],"y":[0.000019985915492957748,0.000019971830985915494,0.00001995774647887324,0.000019943661971830987,0.000019929577464788734,0.00001991549295774648,0.000019901408450704226,0.000019887323943661973,0.00001987323943661972,0.000019859154929577465]}],"layout":{"template":{"data":{"bar":[{"error_x":{"color":"#f2f5fa"},"error_y":{"color":"#f2f5fa"},"marker":{"line":{"color":"rgb(17,17,17)","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"rgb(17,17,17)","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#A2B1C6","gridcolor":"#506784","linecolor":"#506784","minorgridcolor":"#506784","startlinecolor":"#A2B1C6"},"baxis":{"endlinecolor":"#A2B1C6","gridcolor":"#506784","linecolor":"#506784","minorgridcolor":"#506784","startlinecolor":"#A2B1C6"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"marker":{"line":{"color":"#283442"}},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"line":{"color":"#283442"}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#506784"},"line":{"color":"rgb(17,17,17)"}},"header":{"fill":{"color":"#2a3f5f"},"line":{"color":"rgb(17,17,17)"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#f2f5fa","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#f2f5fa"},"geo":{"bgcolor":"rgb(17,17,17)","lakecolor":"rgb(17,17,17)","landcolor":"rgb(17,17,17)","showlakes":true,"showland":true,"subunitcolor":"#506784"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"dark"},"paper_bgcolor":"rgb(17,17,17)","plot_bgcolor":"rgb(17,17,17)","polar":{"angularaxis":{"gridcolor":"#506784","linecolor":"#506784","ticks":""},"bgcolor":"rgb(17,17,17)","radialaxis":{"gridcolor":"#506784","linecolor":"#506784","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"rgb(17,17,17)","gridcolor":"#506784","gridwidth":2,"linecolor":"#506784","showbackground":true,"ticks":"","zerolinecolor":"#C8D4E3"},"yaxis":{"backgroundcolor":"rgb(17,17,17)","gridcolor":"#506784","gridwidth":2,"linecolor":"#506784","showbackground":true,"ticks":"","zerolinecolor":"#C8D4E3"},"zaxis":{"backgroundcolor":"rgb(17,17,17)","gridcolor":"#506784","gridwidth":2,"linecolor":"#506784","showbackground":true,"ticks":"","zerolinecolor":"#C8D4E3"}},"shapedefaults":{"line":{"color":"#f2f5fa"}},"sliderdefaults":{"bgcolor":"#C8D4E3","bordercolor":"rgb(17,17,17)","borderwidth":1,"tickwidth":0},"ternary":{"aaxis":{"gridcolor":"#506784","linecolor":"#506784","ticks":""},"baxis":{"gridcolor":"#506784","linecolor":"#506784","ticks":""},"bgcolor":"rgb(17,17,17)","caxis":{"gridcolor":"#506784","linecolor":"#506784","ticks":""}},"title":{"x":0.05},"updatemenudefaults":{"bgcolor":"#506784","borderwidth":0},"xaxis":{"automargin":true,"gridcolor":"#283442","linecolor":"#506784","ticks":"","title":{"standoff":15},"zerolinecolor":"#283442","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#283442","linecolor":"#506784","ticks":"","title":{"standoff":15},"zerolinecolor":"#283442","zerolinewidth":2}}},"title":{"text":"Learning_rate"}}}},"metadata":{},"output_type":"display_data"}],"source":["# Defining LR Scheduler\n","scheduler = get_linear_schedule_with_warmup(\n","    optimizer, \n","    num_warmup_steps=0, \n","    num_training_steps=len(train_dataloader)*CONFIG.epochs\n",")\n","\n","lrs = []\n","for epoch in range(1, CONFIG.epochs + 1):\n","    if scheduler is not None:\n","        scheduler.step()\n","    lrs.append(optimizer.param_groups[0][\"lr\"])\n","layout = go.Layout(template= \"plotly_dark\",title='Learning_rate')\n","fig = go.Figure(layout=layout)\n","\n","fig.add_trace(go.Scatter(x=list(range(CONFIG.epochs)), y=lrs,\n","                    mode='lines+markers',\n","                    name='Learning_rate'))\n","fig.show()"]},{"cell_type":"markdown","metadata":{},"source":["# <p style=\"color:#159364; font-family:cursive;\">DEFINE LOSS AND TIME FUNCTIONS</center></p>"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2021-05-22T16:50:37.394831Z","iopub.status.busy":"2021-05-22T16:50:37.394488Z","iopub.status.idle":"2021-05-22T16:50:37.399429Z","shell.execute_reply":"2021-05-22T16:50:37.398621Z","shell.execute_reply.started":"2021-05-22T16:50:37.394793Z"},"trusted":true},"outputs":[],"source":["def loss_fn(output,target):\n","     return torch.sqrt(nn.MSELoss()(output,target))\n","def format_time(elapsed):\n","    elapsed_rounded = int(round((elapsed)))\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"]},{"cell_type":"markdown","metadata":{},"source":["# <p style=\"color:#159364; font-family:cursive;\">DEFINE THE FUNCTION FOR TRAINING,VALIDATION AND RUNNING</center></p>"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2021-05-22T16:50:37.401321Z","iopub.status.busy":"2021-05-22T16:50:37.400712Z","iopub.status.idle":"2021-05-22T16:50:37.42087Z","shell.execute_reply":"2021-05-22T16:50:37.420177Z","shell.execute_reply.started":"2021-05-22T16:50:37.401278Z"},"trusted":true},"outputs":[],"source":["def run(model,optimizer,scheduler):\n","    set_seed(40)\n","    scaler=CONFIG.scaler\n","    training_stats = []\n","    total_t0 = time.time()\n","    best_rmse = np.inf\n","    epochs=CONFIG.epochs\n","    for epoch_i in range(0, epochs):\n","        print(\"\")\n","        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","        print('Training...')\n","        t0 = time.time()\n","        total_train_loss = 0\n","        data_size=0\n","        model.train()\n","        for step, batch in enumerate(train_dataloader):    \n","            tr_loss=[]\n","            b_input_ids = batch['ids'].to(CONFIG.device)\n","            b_input_mask = batch['mask'].to(CONFIG.device)\n","            b_labels = batch['target'].to(CONFIG.device)\n","            batch_size = b_input_ids.size(0)\n","            model.zero_grad() \n","            with amp.autocast(enabled=True):\n","                output= model(b_input_ids,attention_mask=b_input_mask)          \n","                output=output[\"logits\"].squeeze(-1)\n","                loss = loss_fn(output,b_labels)\n","                # print(\"\")\n","                # print(f\"batch loss is: {loss.item()}\")\n","                tr_loss.append(loss.item()/len(output))\n","            scheduler.step()\n","            scaler.scale(loss).backward()\n","            scaler.step(optimizer)\n","            scaler.update()\n","        avg_train_loss = np.mean(tr_loss)    \n","        training_time = format_time(time.time() - t0)\n","        gc.collect()\n","        print(\"\")\n","        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","        print(\"  Training epoch took: {:}\".format(training_time))\n","        print(\"\")\n","        print(\"Running Validation...\")\n","\n","        t0 = time.time()\n","        model.eval()\n","        val_loss = 0\n","        allpreds = []\n","        alltargets = []\n","        for batch in validation_dataloader:\n","            losses = []\n","            with torch.no_grad():\n","                device=CONFIG.device\n","                ids = batch[\"ids\"].to(device)\n","                mask = batch[\"mask\"].to(device)\n","                output = model(ids,mask)\n","                output = output[\"logits\"].squeeze(-1)\n","                target = batch[\"target\"].to(device)\n","                loss = loss_fn(output,target)\n","                losses.append(loss.item()/len(output))\n","                allpreds.append(output.detach().cpu().numpy())\n","                alltargets.append(target.detach().squeeze(-1).cpu().numpy())\n","                \n","        allpreds = np.concatenate(allpreds)\n","        alltargets = np.concatenate(alltargets)\n","        val_rmse=mean_squared_error(alltargets, allpreds, squared=False)\n","        losses = np.mean(losses)\n","        gc.collect() \n","        validation_time = format_time(time.time() - t0)\n","        print(\"  Validation Loss: {0:.2f}\".format(losses))\n","        print(\"  Validation took: {:}\".format(validation_time))\n","        \n","        if val_rmse <= best_rmse:\n","            print(f\"Validation RMSE Improved ({best_rmse} -> {val_rmse})\")\n","            best_rmse = val_rmse\n","            best_model_wts = copy.deepcopy(model.state_dict())\n","            PATH = \"rmse{:.4f}_epoch{:.0f}.bin\".format(best_rmse, epoch_i)\n","            torch.save(model.state_dict(), PATH)\n","            print(\"Model Saved\")\n","            \n","        training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': losses,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    ) \n","    print(\"\")\n","    print(\"Training complete!\")\n","    return training_stats  "]},{"cell_type":"markdown","metadata":{},"source":["# <p style=\"color:#159364; font-family:cursive;\">VISUALIZATION FUNCTION </center></p>"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2021-05-22T16:50:37.42232Z","iopub.status.busy":"2021-05-22T16:50:37.421868Z","iopub.status.idle":"2021-05-22T16:50:37.434498Z","shell.execute_reply":"2021-05-22T16:50:37.433763Z","shell.execute_reply.started":"2021-05-22T16:50:37.422283Z"},"trusted":true},"outputs":[],"source":["def Visualizations(training_stats):\n","    pd.set_option('precision', 2)\n","    df_stats = pd.DataFrame(data=training_stats)\n","    df_stats = df_stats.set_index('epoch')\n","    layout = go.Layout(template= \"plotly_dark\")\n","    fig = go.Figure(layout=layout)\n","    fig.add_trace(go.Scatter(x=df_stats.index, y=df_stats['Training Loss'],\n","                    mode='lines+markers',\n","                    name='Training Loss'))\n","    fig.add_trace(go.Scatter(x=df_stats.index, y=df_stats['Valid. Loss'],\n","                    mode='lines+markers',\n","                    name='Validation Loss'))\n","    fig.show()"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["original ids: tensor([1191, 1103, 6434, 1159, 5871, 1103, 1126, 1208,  170,  172, 1892, 1103,\n","        1141, 1103, 1103, 1126])\n","inside prompt embeddings class, original tokens: tensor([[500, 500, 500,  ...,   0,   0,   0],\n","        [500, 500, 500,  ...,   0,   0,   0],\n","        [500, 500, 500,  ...,   0,   0,   0],\n","        ...,\n","        [500, 500, 500,  ...,   0,   0,   0],\n","        [500, 500, 500,  ...,   0,   0,   0],\n","        [500, 500, 500,  ...,   0,   0,   0]], device='cuda:0')\n","intput_embeddings shape: torch.Size([16, 331, 768])\n"]},{"ename":"RuntimeError","evalue":"CUDA out of memory. Tried to allocate 92.00 MiB (GPU 0; 4.00 GiB total capacity; 2.91 GiB already allocated; 0 bytes free; 3.05 GiB reserved in total by PyTorch)","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12368/2379298748.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"original ids: {b_org_ids[1]}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_input_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb_input_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1522\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1524\u001b[1;33m         outputs = self.bert(\n\u001b[0m\u001b[0;32m   1525\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    988\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m         )\n\u001b[1;32m--> 990\u001b[1;33m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[0;32m    991\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    580\u001b[0m                 )\n\u001b[0;32m    581\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 582\u001b[1;33m                 layer_outputs = layer_module(\n\u001b[0m\u001b[0;32m    583\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    468\u001b[0m         \u001b[1;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 470\u001b[1;33m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[0;32m    471\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m     ):\n\u001b[1;32m--> 401\u001b[1;33m         self_outputs = self.self(\n\u001b[0m\u001b[0;32m    402\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# This is actually dropping out entire tokens to attend to, which might\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[1;31m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 333\u001b[1;33m         \u001b[0mattention_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_probs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[1;31m# Mask heads if we want to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\modules\\dropout.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\envs\\nlp\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m   1166\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1167\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dropout probability has to be between 0 and 1, \"\u001b[0m \u001b[1;34m\"but got {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1168\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 92.00 MiB (GPU 0; 4.00 GiB total capacity; 2.91 GiB already allocated; 0 bytes free; 3.05 GiB reserved in total by PyTorch)"]}],"source":["model.train()\n","for step, batch in enumerate(train_dataloader):    \n","    tr_loss=[]\n","    b_org_ids = batch['org_ids']\n","    b_input_ids = batch['ids'].to(CONFIG.device)\n","    b_input_mask = batch['mask'].to(CONFIG.device)\n","\n","    print(f\"original ids: {b_org_ids[1]}\")\n","    output = model(b_input_ids,b_input_mask)\n","\n","    \n","    break\n"]},{"cell_type":"markdown","metadata":{},"source":["\n"," <p style=\"color:#159364; font-family:cursive;\">RUN THE MODEL WITH PROMPT EMBEDDINGS ON FOLD 0 </center></p>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-05-22T16:50:37.438784Z","iopub.status.busy":"2021-05-22T16:50:37.435511Z","iopub.status.idle":"2021-05-22T17:06:55.074606Z","shell.execute_reply":"2021-05-22T17:06:55.07367Z","shell.execute_reply.started":"2021-05-22T16:50:37.438745Z"},"trusted":true},"outputs":[],"source":["# df=run(model,optimizer,scheduler)\n","# Visualizations(df)"]},{"cell_type":"markdown","metadata":{},"source":["\n","![Upvote!](https://img.shields.io/badge/Upvote-If%20you%20like%20my%20work-07b3c8?style=for-the-badge&logo=kaggle)\n"]}],"metadata":{"interpreter":{"hash":"d1924dc1dd04b7e09b7d5eb58cba0f493e2fde5c6da36fb26502589a8e5856a6"},"kernelspec":{"display_name":"Python 3.8.11 64-bit ('nlp': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.11"}},"nbformat":4,"nbformat_minor":4}
