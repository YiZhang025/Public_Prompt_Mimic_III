{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c5148f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tbparse import SummaryReader\n",
    "import torch\n",
    "# import required module\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f836b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"../prompt-based-models/logs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0072db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "          \n",
    " \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27043646",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TB_DataProcessor:\n",
    "    \n",
    "    '''\n",
    "    Class to handle the tensorboard events files produced by this repos experiments\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    def __init__(self,log_dir):\n",
    "        # set the log dir \n",
    "        self.log_dir = log_dir\n",
    "        \n",
    "        # concatenate all the log files in the directory \n",
    "        self.all_logs = self.concatenate_all_logs(self.log_dir)       \n",
    "            \n",
    "    \n",
    "    def concatenate_all_logs(self, log_dir):\n",
    "        \n",
    "        '''\n",
    "        Function to read in, organise and augment tensorboard events files by dynamically reading in and \n",
    "        adding variables best on filenames - as per the setup of the training\n",
    "        \n",
    "        \n",
    "        '''\n",
    "       \n",
    "        print(\"concatenating all log files!\")\n",
    "        # empy list to fill\n",
    "        dfs = []\n",
    "        # that directory\n",
    "        for root, dirs, files in tqdm(os.walk(log_dir), desc = \"Finding logs!\"):\n",
    "            for filename in files:                \n",
    "                full_path = os.path.join(root, filename) \n",
    "                # the file name for tensorboard logs is horrible so just regex for tfevents\n",
    "                if \"tfevents\" in full_path:    \n",
    "                                            \n",
    "                    # now parse the tensorboard summary data\n",
    "                    reader = SummaryReader(full_path)\n",
    "                    df = reader.scalars\n",
    "                \n",
    "                    # get the model paramters based on filename\n",
    "                    \n",
    "                    # now add the training type e.g. prompt learning or traditional                       \n",
    "                        \n",
    "                    # can also pull the dataset/task name from the filepath\n",
    "                    df[\"training_type\"] = full_path.split(\"/\")[1]\n",
    "                    df[\"task\"] = full_path.split(\"/\")[3]\n",
    "\n",
    "                    # Was plm frozen?\n",
    "                    if 'frozen_plm' in full_path:\n",
    "                        df[\"plm_frozen\"] = True\n",
    "                    else:\n",
    "                        df[\"plm_frozen\"] = True\n",
    "\n",
    "                    # which template type\n",
    "                    if 'tempmanual' in full_path:\n",
    "                        df[\"temp_type\"] = \"manual\"\n",
    "                    elif 'tempsoft' in full_path:\n",
    "                        df[\"temp_type\"] = \"soft\"\n",
    "                    \n",
    "                    elif 'tempmixed' in full_path:\n",
    "                        df[\"temp_type\"] = \"mixed\" \n",
    "                    # which verbalizer type \n",
    "                    if 'verbmanual' in full_path:\n",
    "                        df[\"verb_type\"] = \"manual\"\n",
    "                    elif 'verbsoft' in full_path:\n",
    "                        df[\"verb_type\"] = \"soft\"\n",
    "                    \n",
    "                    df.reset_index(inplace = True, drop=True)\n",
    "                    # append individual df to list\n",
    "                    dfs.append(df)    \n",
    "        \n",
    "        # concat all the dfs\n",
    "        all_logs = pd.concat(dfs)        \n",
    "            \n",
    "        return all_logs\n",
    "    \n",
    "    def extract_metric(self, mode = \"all\",metrics = \"all\"):\n",
    "        '''\n",
    "        Function to pull certain specified features from the full logs dataframes\n",
    "        \n",
    "        Args: \n",
    "            mode: The dataset you want metrics for e.g. train/valid/test\n",
    "            metrics: The metric you want to look at e.g. f1, precision etc.\n",
    "        '''\n",
    "        # get the logs to work with\n",
    "        all_logs = self.all_logs\n",
    "        if metrics == \"all\" and mode == \"all\":\n",
    "            return all_logs\n",
    "        \n",
    "        # now for cases where mode is specific        \n",
    "        elif metrics == \"all\" and mode != \"all\": \n",
    "            metrics_df = all_logs[all_logs[\"tag\"].str.contains(mode)]            \n",
    "        \n",
    "      \n",
    "        # cases where metric is specific but mode is all\n",
    "        elif metrics != \"all\" and mode == \"all\":\n",
    "            metrics_df =  all_logs[all_logs[\"tag\"].str.contains(metrics)]\n",
    "        \n",
    "        # now for cases where both metric and mode are specific\n",
    "        elif metrics != \"all\" and mode != \"all\":\n",
    "            metrics_df = all_logs[(all_logs[\"tag\"].str.contains(metrics)) & (all_logs[\"tag\"].str.contains(mode))]    \n",
    "            \n",
    "        \n",
    "        \n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "            \n",
    "        # reset index and return\n",
    "        metrics_df.reset_index(inplace=True, drop=True)\n",
    "        return metrics_df\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afca1cb",
   "metadata": {},
   "source": [
    "# load prompt logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dbb22fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concatenating all log files!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding logs!: 28it [00:02,  9.63it/s]\n"
     ]
    }
   ],
   "source": [
    "# instantiate the TB_DataProcessor and provide log dir for the prompt based models\n",
    "prompt_tb_data_processor = TB_DataProcessor(log_dir = \"../prompt-based-models/logs/icd9_triage/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "756bfd6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>tag</th>\n",
       "      <th>value</th>\n",
       "      <th>training_type</th>\n",
       "      <th>task</th>\n",
       "      <th>plm_frozen</th>\n",
       "      <th>temp_type</th>\n",
       "      <th>verb_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>train/batch_loss</td>\n",
       "      <td>2.553897</td>\n",
       "      <td>prompt-based-models</td>\n",
       "      <td>icd9_triage</td>\n",
       "      <td>True</td>\n",
       "      <td>manual</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>train/batch_loss</td>\n",
       "      <td>2.464560</td>\n",
       "      <td>prompt-based-models</td>\n",
       "      <td>icd9_triage</td>\n",
       "      <td>True</td>\n",
       "      <td>manual</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>train/batch_loss</td>\n",
       "      <td>2.555808</td>\n",
       "      <td>prompt-based-models</td>\n",
       "      <td>icd9_triage</td>\n",
       "      <td>True</td>\n",
       "      <td>manual</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>train/batch_loss</td>\n",
       "      <td>2.480603</td>\n",
       "      <td>prompt-based-models</td>\n",
       "      <td>icd9_triage</td>\n",
       "      <td>True</td>\n",
       "      <td>manual</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>train/batch_loss</td>\n",
       "      <td>2.439957</td>\n",
       "      <td>prompt-based-models</td>\n",
       "      <td>icd9_triage</td>\n",
       "      <td>True</td>\n",
       "      <td>manual</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>9</td>\n",
       "      <td>valid/recall</td>\n",
       "      <td>0.938343</td>\n",
       "      <td>prompt-based-models</td>\n",
       "      <td>icd9_triage</td>\n",
       "      <td>True</td>\n",
       "      <td>soft</td>\n",
       "      <td>manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12000</th>\n",
       "      <td>0</td>\n",
       "      <td>zero_shot/accuracy</td>\n",
       "      <td>0.132030</td>\n",
       "      <td>prompt-based-models</td>\n",
       "      <td>icd9_triage</td>\n",
       "      <td>True</td>\n",
       "      <td>soft</td>\n",
       "      <td>manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12001</th>\n",
       "      <td>0</td>\n",
       "      <td>zero_shot/f1</td>\n",
       "      <td>0.062982</td>\n",
       "      <td>prompt-based-models</td>\n",
       "      <td>icd9_triage</td>\n",
       "      <td>True</td>\n",
       "      <td>soft</td>\n",
       "      <td>manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12002</th>\n",
       "      <td>0</td>\n",
       "      <td>zero_shot/precision</td>\n",
       "      <td>0.444971</td>\n",
       "      <td>prompt-based-models</td>\n",
       "      <td>icd9_triage</td>\n",
       "      <td>True</td>\n",
       "      <td>soft</td>\n",
       "      <td>manual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12003</th>\n",
       "      <td>0</td>\n",
       "      <td>zero_shot/recall</td>\n",
       "      <td>0.081337</td>\n",
       "      <td>prompt-based-models</td>\n",
       "      <td>icd9_triage</td>\n",
       "      <td>True</td>\n",
       "      <td>soft</td>\n",
       "      <td>manual</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136912 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       step                  tag     value        training_type         task  \\\n",
       "0         0     train/batch_loss  2.553897  prompt-based-models  icd9_triage   \n",
       "1         1     train/batch_loss  2.464560  prompt-based-models  icd9_triage   \n",
       "2         2     train/batch_loss  2.555808  prompt-based-models  icd9_triage   \n",
       "3         3     train/batch_loss  2.480603  prompt-based-models  icd9_triage   \n",
       "4         4     train/batch_loss  2.439957  prompt-based-models  icd9_triage   \n",
       "...     ...                  ...       ...                  ...          ...   \n",
       "11999     9         valid/recall  0.938343  prompt-based-models  icd9_triage   \n",
       "12000     0   zero_shot/accuracy  0.132030  prompt-based-models  icd9_triage   \n",
       "12001     0         zero_shot/f1  0.062982  prompt-based-models  icd9_triage   \n",
       "12002     0  zero_shot/precision  0.444971  prompt-based-models  icd9_triage   \n",
       "12003     0     zero_shot/recall  0.081337  prompt-based-models  icd9_triage   \n",
       "\n",
       "       plm_frozen temp_type verb_type  \n",
       "0            True    manual      soft  \n",
       "1            True    manual      soft  \n",
       "2            True    manual      soft  \n",
       "3            True    manual      soft  \n",
       "4            True    manual      soft  \n",
       "...           ...       ...       ...  \n",
       "11999        True      soft    manual  \n",
       "12000        True      soft    manual  \n",
       "12001        True      soft    manual  \n",
       "12002        True      soft    manual  \n",
       "12003        True      soft    manual  \n",
       "\n",
       "[136912 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_tb_data_processor.all_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfb1764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just look at f1\n",
    "prompt_metrics = prompt_tb_data_processor.extract_metric(mode = \"valid\", metrics = \"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "072c605b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "verb_type  temp_type\n",
       "manual     manual       0.946914\n",
       "           mixed        0.948727\n",
       "           soft         0.949100\n",
       "soft       manual       0.949605\n",
       "           mixed        0.949256\n",
       "           soft         0.946888\n",
       "Name: value, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_metrics.groupby([\"verb_type\",\"temp_type\"])[\"value\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d36327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37cc3b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_metrics[(prompt_metrics[\"temp_type\"]==\"manual\") &(prompt_metrics[\"verb_type\"]==\"manual\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e044efe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_metrics[(prompt_metrics[\"temp_type\"]==\"soft\") &(prompt_metrics[\"verb_type\"]==\"soft\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb564a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b06f9328",
   "metadata": {},
   "source": [
    "# same for traditional learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664808d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the TB_DataProcessor and provide log dir for the prompt based models\n",
    "trad_tb_data_processor = TB_DataProcessor(log_dir = \"../clinical-longformer/logs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ee27a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3-7-NLP",
   "language": "python",
   "name": "3-7-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
